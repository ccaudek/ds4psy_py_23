<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Data Science per psicologi - 37&nbsp; Criterio di informazione e convalida incrociata</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./frequentist_inference.html" rel="next">
<link href="./091_kl.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Criterio di informazione e convalida incrociata</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/data_science/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Benvenuti</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">Prefazione</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./basics.html" class="sidebar-item-text sidebar-link">Parte 1: Nozioni di base</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_key_notions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Concetti chiave</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_measurement.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_freq_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_loc_scale.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_penguins.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Manipolazione e visualizzazione dei dati in <span class="math inline">\(\mathsf{R}\)</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./prob.html" class="sidebar-item-text sidebar-link">Parte 2: Il calcolo delle probabilità</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_prob_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">La logica dell’incerto</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_conditional_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Probabilità condizionata: significato, teoremi, eventi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_bayes_theorem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./018_expval_var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Indici di posizione, di varianza e di associazione di variabili casuali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./019_joint_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./020_density_func.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La densità di probabilità</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./distr.html" class="sidebar-item-text sidebar-link">Parte 3: Distribuzioni di v.c. discrete e continue</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./022_discr_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./023_cont_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./024_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">La funzione di verosimiglianza</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./bayes_inference.html" class="sidebar-item-text sidebar-link">Parte 4: Inferenza bayesiana</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./025_intro_bayes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Credibilità, modelli e parametri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./026_subj_prop.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./029_conjugate_families.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./030_balance_prior_post.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./036_posterior_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Approssimazione della distribuzione a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./040_beta_binomial_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Il modello beta-binomiale in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./041_mcmc_diagnostics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./045_summarize_posterior.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./046_bayesian_prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./050_normal_normal_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./regression.html" class="sidebar-item-text sidebar-link">Parte 5: Regressione lineare</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./051_reglin1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./052_reglin2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Regressione lineare bivariata</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./053_reglin3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Modello di regressione in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./054_reglin4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Inferenza sul modello lineare</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./055_reglin5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./056_pred_check.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Predictive checks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./060_anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Confronto tra le medie di tre o più gruppi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./070_mod_hier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modello gerarchico</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./071_mod_hier_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Modello gerarchico: simulazioni</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./entropy.html" class="sidebar-item-text sidebar-link">Parte 6: Entropia</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./090_entropy.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Entropia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./091_kl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./092_info_criterion.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Criterio di informazione e convalida incrociata</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./frequentist_inference.html" class="sidebar-item-text sidebar-link">Parte 7: Inferenza frequentista</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./220_intro_frequentist.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Legge dei grandi numeri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./221_conf_interv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Intervallo fiduciale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./225_distr_camp_mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Distribuzione campionaria</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./226_test_ipotesi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Significatività statistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./227_ttest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza sulle medie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./228_limiti_stat_frequentista.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./999_refs.html" class="sidebar-item-text sidebar-link">Riferimenti bibliografici</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">Appendici</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a01_math_symbols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a02_number_sets.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a03_set_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Insiemi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a04_summation_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Simbolo di somma (sommatorie)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a05_calculus_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a10_markov_chains.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Le catene di Markov</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a15_stan_lang.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Programmare in Stan</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul>
<li>
<a href="#aic-dic-e-waic" id="toc-aic-dic-e-waic" class="nav-link active" data-scroll-target="#aic-dic-e-waic"><span class="toc-section-number">37.1</span>  AIC, DIC e WAIC</a>
  <ul class="collapse">
<li><a href="#criterio-dinformazione-di-akaike" id="toc-criterio-dinformazione-di-akaike" class="nav-link" data-scroll-target="#criterio-dinformazione-di-akaike"><span class="toc-section-number">37.1.1</span>  Criterio d’informazione di Akaike</a></li>
  </ul>
</li>
  <li>
<a href="#convalida-incrociata-k-fold" id="toc-convalida-incrociata-k-fold" class="nav-link" data-scroll-target="#convalida-incrociata-k-fold"><span class="toc-section-number">37.2</span>  Convalida incrociata K-fold</a>
  <ul class="collapse">
<li><a href="#importance-sampling" id="toc-importance-sampling" class="nav-link" data-scroll-target="#importance-sampling"><span class="toc-section-number">37.2.1</span>  Importance sampling</a></li>
  </ul>
</li>
  <li><a href="#confronto-tra-aic-e-loo-cv" id="toc-confronto-tra-aic-e-loo-cv" class="nav-link" data-scroll-target="#confronto-tra-aic-e-loo-cv"><span class="toc-section-number">37.3</span>  Confronto tra AIC e LOO-CV</a></li>
  <li><a href="#confronto-tra-modelli-mediante-loo-cv" id="toc-confronto-tra-modelli-mediante-loo-cv" class="nav-link" data-scroll-target="#confronto-tra-modelli-mediante-loo-cv"><span class="toc-section-number">37.4</span>  Confronto tra modelli mediante LOO-CV</a></li>
  <li><a href="#outlier" id="toc-outlier" class="nav-link" data-scroll-target="#outlier"><span class="toc-section-number">37.5</span>  Outlier</a></li>
  <li><a href="#regolarizzazione" id="toc-regolarizzazione" class="nav-link" data-scroll-target="#regolarizzazione"><span class="toc-section-number">37.6</span>  Regolarizzazione</a></li>
  <li><a href="#commenti-e-considerazioni-finali" id="toc-commenti-e-considerazioni-finali" class="nav-link" data-scroll-target="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-info-crit" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Criterio di informazione e convalida incrociata</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Codice</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><div class="cell">

</div>
<p>Nel Capitolo precedente abbiamo visto che la @ref(eq:lppd) fornisce una sovrastima della <span class="math inline">\(\mbox{elpd}\)</span>. Il modo migliore per stimare <span class="math inline">\(\mbox{elpd}\)</span> è raccogliere un nuovo campione indipendente di dati, che si ritiene condivida lo stesso processo di generazione dei dati del campione corrente, e stimare <span class="math inline">\(\mbox{elpd}\)</span> sul nuovo campione. Questa procedura è chiamata <em>out-of-sample validation</em>. Il problema, però, è che solitamente non abbiamo le risorse per raccogliere un nuovo campione di osservazioni. Di conseguenza, gli statistici hanno messo a punto vari metodi per evitare la sovrastima della <span class="math inline">\(\mbox{elpd}\)</span> che deriva dal solo utizzo del campione corrente. Ci sono due approcci generali:</p>
<ul>
<li>l’introduzione di un fattore di correzione;</li>
<li>la convalida incrociata cosiddetta K-fold.</li>
</ul>
<p>Lo scopo del presente Capitolo è di fornire una breve introduzione ai criteri dell’informazione e alla procedura della convalida incrociata.</p>
<section id="aic-dic-e-waic" class="level2" data-number="37.1"><h2 data-number="37.1" class="anchored" data-anchor-id="aic-dic-e-waic">
<span class="header-section-number">37.1</span> AIC, DIC e WAIC</h2>
<p>Allo scopo di evitare la sovrastima della @ref(eq:lppd), le statistiche <em>Akaike Information Criterion</em> (AIC), <em>Deviance Information Criterion</em> (DIC) e <em>Widely Applicable Information Criterion</em> (WAIC) introducono un fattore di correzione. Le statistiche DIC e WAIC sono più complesse di AIC, ma producono un’approssimazione migliore. Tuttavia, i valori AIC, DIC e WAIC sono spesso molto simili tra loro. Per convenienza, dunque, qui ci accontenteremo di esaminare in dettaglio la statistica più semplice, ovvero AIC.</p>
<section id="criterio-dinformazione-di-akaike" class="level3" data-number="37.1.1"><h3 data-number="37.1.1" class="anchored" data-anchor-id="criterio-dinformazione-di-akaike">
<span class="header-section-number">37.1.1</span> Criterio d’informazione di Akaike</h3>
<p>Il criterio d’informazione di Akaike (in inglese <em>Akaike information criterion</em>, indicato come AIC) fornisce un metodo molto semplice per approssimare <span class="math inline">\(\mbox{elpd}\)</span>.</p>
<div class="definition">
<p>Il criterio d’informazione di Akaike è definito come</p>
<span class="math display">\[\begin{equation}
AIC = -2 \log p(y \mid \hat{\theta}_{MLE}) + 2k,
\end{equation}\]</span>
<p>dove <span class="math inline">\(k\)</span> è il numero di parametri stimati nel modello e <span class="math inline">\(p(y \mid \hat{\theta}_{MLE})\)</span> è il valore massimizzato della funzione di verosimiglianza del modello stimato.</p>
</div>
<p>Dividendo per -2, otteniamo <span class="math inline">\(\mbox{elpd}_{AIC}\)</span>:</p>
<span class="math display">\[\begin{equation}
\widehat{\mbox{elpd}}_{AIC} = \log p(y \mid \hat{\theta}_{MLE}) - k,
\end{equation}\]</span>
<p>dove <span class="math inline">\(k\)</span> è il fattore di correzione introdotto per evitare la sovrastima discussa in precedenza.</p>
<p>AIC è di interesse principalmente storico e produce una approssimazione attendibile di <span class="math inline">\(\mbox{elpd}\)</span> quando:</p>
<ol type="1">
<li>le distribuzioni a priori sono non informative;</li>
<li>la distribuzione a posteriori è approssimativamente gaussiana multivariata;</li>
<li>la dimensione <span class="math inline">\(n\)</span> del campione è molto maggiore del numero <span class="math inline">\(k\)</span> dei parametri.</li>
</ol>
<div class="example">
<p>Per meglio comprendere la statistica <span class="math inline">\(\widehat{\mbox{elpd}}_{AIC}\)</span>, esaminiamo un esempio discusso da <span class="citation" data-cites="gelman2014understanding">Gelman et al. (<a href="999_refs.html#ref-gelman2014understanding" role="doc-biblioref">2014</a>)</span>. Sia <span class="math inline">\(y_1, \dots, y_n \sim \mathcal{N}(\mu, 1)\)</span> un campione di osservazioni. Nel caso di una distribuzione a priori non-informativa <span class="math inline">\(p(\theta) \propto 1\)</span>, la stima di massima verosimiglianza è <span class="math inline">\(\bar{y}\)</span>. La verosimiglianza è</p>
<p><span class="math display">\[
f(Y \mid \mu, \sigma) = \prod_{i=1}^n f(y \mid \mu, \sigma)
\]</span></p>
<p>e la log-verosimiglianza diventa</p>
<p><span class="math display">\[
\ell(Y \mid \mu, \sigma) = \sum_{i=1}^n \log (f(y \mid \mu, \sigma)).
\]</span></p>
<p>Ovvero,</p>
<span class="math display">\[\begin{align}
\ell(Y \mid \mu, \sigma) &amp;= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi\sigma^2 }}}\exp \left(-{\frac {1}{2}}{\frac {(y_i-\mu )^{2}}{\sigma^{2}}}\right) \right)\notag\\
&amp;= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi \sigma^2}}} \right) - \sum_{i=1}^n{\frac {1}{2}}{\frac {(y_i-\mu )^{2}}{\sigma ^{2}}} \notag\\
&amp;= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi \sigma^2}}} \right) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag \\
&amp;= \sum_{i=1}^n \log (1) - \sum_{i=1}^n\log \sqrt{2\pi \sigma^2} - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag\\
&amp;= - \sum_{i=1}^n\frac{1}{2}  \log (2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag\\
&amp;= - \frac{n}{2}  \log (2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2}. \notag
\end{align}\]</span>
<p>Se <span class="math inline">\(y \sim \mathcal{N}(\mu, 1)\)</span>, usando lo stimatore di massima verosimiglianza per <span class="math inline">\(\mu\)</span>, la log-verosimiglianza diventa</p>
<span class="math display">\[\begin{align}
\log p(y \mid \hat{\theta}_{MLE}) &amp;= -\frac{n}{2} \log (2\pi) - \frac{1}{2}\sum_{i=1}^n (y_i - \bar{y})^2 \notag\\
&amp;= -\frac{n}{2} \log (2\pi) - \frac{1}{2} (n-1)s_y^2,
\end{align}\]</span>
<p>dove <span class="math inline">\(s_y^2\)</span> è la varianza campionaria.</p>
<p>Nel caso di un modello gaussiano con con varianza nota e una distribuzione a priori uniforme viene stimato un solo parametro, per cui</p>
<span class="math display">\[\begin{align}
\widehat{\mbox{elpd}}_{AIC} &amp;= \log p(y \mid \hat{\theta}_{MLE}) - k \notag \\
&amp;= -\frac{n}{2} \log (2\pi) - \frac{1}{2} (n-1)s_y^2 - 1.
\end{align}\]</span>
</div>
</section></section><section id="convalida-incrociata-k-fold" class="level2" data-number="37.2"><h2 data-number="37.2" class="anchored" data-anchor-id="convalida-incrociata-k-fold">
<span class="header-section-number">37.2</span> Convalida incrociata K-fold</h2>
<p>La sovrastima della @ref(eq:lppd) può anche essere evitata usando una tecnica chiamata <em>K-fold cross-validation</em>. Mediante questo metodo vengono stimati i parametri del modello tralasciando una porzione di osservazioni (chiamata <em>fold</em>) dal campione per poi valutare il modello sulle osservazioni che sono state escluse. Una stima complessiva dell’accuratezza si ottiene poi calcolando la media del punteggio di accuratezza ottenuto in ogni fold. Il numero minimo di fold è 2; all’altro estremo, è possibile impiegare una singola osservazione in ciascun fold e adattare il modello tante volte (<span class="math inline">\(n\)</span>) quante sono le singole osservazioni. Questa strategia è chiamata <em>leave-one-out cross-validation</em> (LOO-CV).</p>
<section id="importance-sampling" class="level3" data-number="37.2.1"><h3 data-number="37.2.1" class="anchored" data-anchor-id="importance-sampling">
<span class="header-section-number">37.2.1</span> Importance sampling</h3>
<p>La strategia LOO-CV è computazionalmente onerosa (ovvero, richiede un tempo di esecuzione molto lungo). È però possibile approssimare LOO-CV mediante un metodo chiamato <em>Pareto-smoothed importance sampling cross-validation</em> [PSIS; <span class="citation" data-cites="vehtari2017practical">Vehtari et al. (<a href="999_refs.html#ref-vehtari2017practical" role="doc-biblioref">2017</a>)</span>]. Tralasciando qui i dettagli matematici, l’intuizione di base è che PSIS fa leva sul punteggio di “importanza” posseduto da ciascuna osservazione all’interno della distribuzione a posteriori. Per “importanza” si intende il fatto che alcune osservazioni hanno un impatto maggiore sulle proprietà della distribuzione a posteriori di altre: se viene rimossa un’osservazione importante, le proprietà della distribuzione a posteriori cambiano molto; se viene rimossa un’osservazione poco importante, la distribuzione a posteriori cambia poco. L’“importanza” così intesa viene chiamata “peso” (<em>weight</em>) e tali pesi vengono utilizzati per stimare l’accuratezza <em>out-of-sample</em> del modello. PSIS-LOO-CV richiede che il modello venga adattato una volta soltanto ai dati e fornisce una stima della devianza <em>out-of-sample</em> che evita la sovrastima della @ref(eq:lppd). Inoltre, PSIS-LOO-CV fornisce un feedback sulla propria affidabilità identificando le osservazioni i cui pesi molto elevati potrebbero rendere imprecisa la predizione.</p>
<p>Valori <span class="math inline">\(\widehat{\mbox{elpd}}_{LOO}\)</span> più grandi indicano una maggiore accuratezza predittiva. In alternativa, anziché considerare <span class="math inline">\(\widehat{\mbox{elpd}}\)</span>, è possibile usare la quantità <span class="math inline">\(-2 \cdot \widehat{\mbox{elpd}}\)</span>, la quale è chiamata <em>LOO Information Criterion</em> (LOOIC). In questo secondo caso, valori LOOIC più piccoli sono da preferire.</p>
<p>La quantità <span class="math inline">\(\widehat{\mbox{elpd}}_{LOO}\)</span> viene calcolata dai pacchetti <code>loo</code> e <code>brms</code> ed è chiamata <code>elpd_loo</code> o <code>elpd_kfold</code>. È anche possibile calcolare la differenza della quantità <code>elpd_loo</code> per modelli alternativi, insieme alla deviazione standard della distribuzione campionaria di tale differenza.</p>
</section></section><section id="confronto-tra-aic-e-loo-cv" class="level2" data-number="37.3"><h2 data-number="37.3" class="anchored" data-anchor-id="confronto-tra-aic-e-loo-cv">
<span class="header-section-number">37.3</span> Confronto tra AIC e LOO-CV</h2>
<p>Per fare un esempio, faremo qui un confronto tra <span class="math inline">\(\widehat{\mbox{elpd}}_{AIC}\)</span> e <span class="math inline">\(\widehat{\mbox{elpd}}_{LOO-CV}\)</span>. Esaminiamo nuovamente l’associazione tra il QI dei figli e il QI delle madri nel campione di dati discusso da <span class="citation" data-cites="gelman2020regression">Gelman et al. (<a href="999_refs.html#ref-gelman2020regression" role="doc-biblioref">2020</a>)</span>. Una tale relazione può essere descritta da un modello di regressione nel quale la <span class="math inline">\(y\)</span> corrisponde al QI dei figli e la <span class="math inline">\(x\)</span> al QI delle madri.</p>
<p>Leggiamo i dati in :</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://svn.r-project.org/R-packages/trunk/foreign/">"foreign"</a></span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/foreign/man/read.dta.html">read.dta</a></span><span class="op">(</span><span class="fu">here</span><span class="op">(</span><span class="st">"data"</span>, <span class="st">"kidiq.dta"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">df</span><span class="op">$</span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">kid_score</span><span class="op">)</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">df</span><span class="op">$</span><span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">mom_iq</span><span class="op">)</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span>
<span><span class="co">#&gt;   kid_score mom_hs    mom_iq mom_work mom_age           y         x1</span></span>
<span><span class="co">#&gt; 1        65      1 121.11753        4      27 -1.06793237  1.4078352</span></span>
<span><span class="co">#&gt; 2        98      1  89.36188        4      25  0.54886757 -0.7092079</span></span>
<span><span class="co">#&gt; 3        85      1 115.44316        4      27 -0.08805362  1.0295443</span></span>
<span><span class="co">#&gt; 4        83      1  99.44964        3      25 -0.18604150 -0.0366907</span></span>
<span><span class="co">#&gt; 5       115      1  92.74571        4      27  1.38176451 -0.4836193</span></span>
<span><span class="co">#&gt; 6        98      0 107.90184        1      18  0.54886757  0.5267892</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Dato che AIC non è una statistica bayesiana, può essere calcolata mediante strumenti frequentisti:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">m1_freq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span>, data <span class="op">=</span> <span class="va">df</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">AIC</a></span><span class="op">(</span><span class="va">m1_freq</span><span class="op">)</span> <span class="op">/</span> <span class="op">-</span><span class="fl">2</span></span>
<span><span class="co">#&gt; [1] -569.6384</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per ottenere LOO-CV adattiamo ai dati un modello di regressione bayesiano:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">modelString</span> <span class="op">=</span> <span class="st">"</span></span>
<span><span class="st">data {</span></span>
<span><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span><span class="st">  vector[N] x1;</span></span>
<span><span class="st">  vector[N] y;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">parameters {</span></span>
<span><span class="st">  real alpha;</span></span>
<span><span class="st">  real beta1;</span></span>
<span><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">transformed parameters {</span></span>
<span><span class="st">  vector[N] mu;</span></span>
<span><span class="st">  for (n in 1 : N) {</span></span>
<span><span class="st">    mu[n] = alpha + beta1 * x1[n];</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">model {</span></span>
<span><span class="st">  alpha ~ normal(0, 1);</span></span>
<span><span class="st">  beta1 ~ normal(0, 1);</span></span>
<span><span class="st">  sigma ~ cauchy(0, 1);</span></span>
<span><span class="st">  y ~ normal(mu, sigma);</span></span>
<span><span class="st">}</span></span>
<span><span class="st">generated quantities {</span></span>
<span><span class="st">  vector[N] y_rep;</span></span>
<span><span class="st">  vector[N] log_lik;</span></span>
<span><span class="st">  for (n in 1 : N) {</span></span>
<span><span class="st">    y_rep[n] = normal_rng(mu[n], sigma);</span></span>
<span><span class="st">    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1, sigma);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">modelString</span>, con <span class="op">=</span> <span class="st">"code/simplereg.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">data1_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">kid_score</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">y</span>,</span>
<span>  x1 <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">x1</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">file1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"simplereg.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod1</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Eseguiamo il campionamento MCMC:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit1</span> <span class="op">&lt;-</span> <span class="va">mod1</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">data1_list</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">4000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">2000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="va">SEED</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  cores <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcoliamo infine la quantità <span class="math inline">\(\widehat{\mbox{elpd}}_{LOO-CV}\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">loo1_result</span> <span class="op">&lt;-</span> <span class="va">fit1</span><span class="op">$</span><span class="fu">loo</span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">loo1_result</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Computed from 16000 by 434 log-likelihood matrix</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          Estimate   SE</span></span>
<span><span class="co">#&gt; elpd_loo   -568.6 14.5</span></span>
<span><span class="co">#&gt; p_loo         1.9  0.2</span></span>
<span><span class="co">#&gt; looic      1137.2 28.9</span></span>
<span><span class="co">#&gt; ------</span></span>
<span><span class="co">#&gt; Monte Carlo SE of elpd_loo is 0.0.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; All Pareto k estimates are good (k &lt; 0.5).</span></span>
<span><span class="co">#&gt; See help('pareto-k-diagnostic') for details.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si noti la somiglianza tra <span class="math inline">\(\widehat{\mbox{elpd}}_{LOO-CV}\)</span> e <span class="math inline">\(\widehat{\mbox{elpd}}_{AIC}\)</span>. In conclusione, possiamo dunque dire che <span class="math inline">\(\widehat{\mbox{elpd}}_{LOO-CV}\)</span> è la risposta bayesiana allo stesso problema che trova una soluzione frequentista nella statistica <span class="math inline">\(\widehat{\mbox{elpd}}_{AIC}\)</span>.</p>
</section><section id="confronto-tra-modelli-mediante-loo-cv" class="level2" data-number="37.4"><h2 data-number="37.4" class="anchored" data-anchor-id="confronto-tra-modelli-mediante-loo-cv">
<span class="header-section-number">37.4</span> Confronto tra modelli mediante LOO-CV</h2>
<p>Come menzionato in precedenza, l’obiettivo centrale della misurazione dell’accuratezza predittiva è il confronto di modelli. Una volta capito come calcolare LOO-CV con un condice scritto in linguaggio Stan, svolgeremo ora un confronto di modelli.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>Considereremo qui un confronto di modelli di regressione. Il modello di regressione discusso nel Paragrafo precedente prevede il QI dei bambini dal QI delle madri. Aggiungiamo a tale modello un secondo predittore che corrisponde all’età della madre. L’aggiunta di tale predittore migliori l’accuratezza predittiva del modello?</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">modelString</span> <span class="op">=</span> <span class="st">"</span></span>
<span><span class="st">data {</span></span>
<span><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span><span class="st">  vector[N] x1;</span></span>
<span><span class="st">  vector[N] x2;</span></span>
<span><span class="st">  vector[N] y;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">parameters {</span></span>
<span><span class="st">  real alpha;</span></span>
<span><span class="st">  real beta1;</span></span>
<span><span class="st">  real beta2;</span></span>
<span><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">transformed parameters {</span></span>
<span><span class="st">  vector[N] mu;</span></span>
<span><span class="st">  for (n in 1 : N) {</span></span>
<span><span class="st">    mu[n] = alpha + beta1 * x1[n] + beta2 * x2[n];</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">model {</span></span>
<span><span class="st">  alpha ~ normal(0, 1);</span></span>
<span><span class="st">  beta1 ~ normal(0, 1);</span></span>
<span><span class="st">  beta2 ~ normal(0, 1);</span></span>
<span><span class="st">  sigma ~ cauchy(0, 1);</span></span>
<span><span class="st">  y ~ normal(mu, sigma);</span></span>
<span><span class="st">}</span></span>
<span><span class="st">generated quantities {</span></span>
<span><span class="st">  vector[N] y_rep;</span></span>
<span><span class="st">  vector[N] log_lik;</span></span>
<span><span class="st">  for (n in 1 : N) {</span></span>
<span><span class="st">    y_rep[n] = normal_rng(mu[n], sigma);</span></span>
<span><span class="st">    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x2[n] * beta2, sigma);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">modelString</span>, con <span class="op">=</span> <span class="st">"code/mreg2.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">df</span><span class="op">$</span><span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">mom_age</span><span class="op">)</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">data2_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">kid_score</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">y</span>,</span>
<span>  x1 <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">x1</span>,</span>
<span>  x2 <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">x2</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">file2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"mreg2.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compile model</span></span>
<span><span class="va">mod2</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Running MCMC</span></span>
<span><span class="va">fit2</span> <span class="op">&lt;-</span> <span class="va">mod2</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">data2_list</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">4000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">2000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="va">SEED</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  cores <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit2</span><span class="op">$</span><span class="fu">summary</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"alpha"</span>, <span class="st">"beta1"</span>, <span class="st">"beta2"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 4 × 10</span></span>
<span><span class="co">#&gt;   variable      mean   median     sd    mad      q5    q95  rhat ess_b…¹ ess_t…²</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 alpha    -0.000255 -1.62e-4 0.0431 0.0427 -0.0714 0.0705  1.00  19419.  12820.</span></span>
<span><span class="co">#&gt; 2 beta1     0.442     4.42e-1 0.0427 0.0427  0.372  0.512   1.00  17850.  12381.</span></span>
<span><span class="co">#&gt; 3 beta2     0.0515    5.14e-2 0.0427 0.0428 -0.0179 0.121   1.00  16802.  12540.</span></span>
<span><span class="co">#&gt; 4 sigma     0.896     8.95e-1 0.0305 0.0303  0.848  0.948   1.00  19032.  12320.</span></span>
<span><span class="co">#&gt; # … with abbreviated variable names ¹​ess_bulk, ²​ess_tail</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">loo2_result</span> <span class="op">&lt;-</span> <span class="va">fit2</span><span class="op">$</span><span class="fu">loo</span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">loo2_result</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Computed from 16000 by 434 log-likelihood matrix</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          Estimate   SE</span></span>
<span><span class="co">#&gt; elpd_loo   -568.9 14.5</span></span>
<span><span class="co">#&gt; p_loo         3.0  0.3</span></span>
<span><span class="co">#&gt; looic      1137.8 29.0</span></span>
<span><span class="co">#&gt; ------</span></span>
<span><span class="co">#&gt; Monte Carlo SE of elpd_loo is 0.0.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; All Pareto k estimates are good (k &lt; 0.5).</span></span>
<span><span class="co">#&gt; See help('pareto-k-diagnostic') for details.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Consideriamo infine un terzo modello che utilizza come predittori, oltre al QI della madre, una variabile dicotomica (codificata 0 o 1) che distingue madri che hanno completato le scuole superiori da quelle che non le hanno completate. Nuovamente, la domanda è se l’aggiunta di tale predittore migliori la capacità predittiva del modello.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">modelString</span> <span class="op">=</span> <span class="st">"</span></span>
<span><span class="st">data {</span></span>
<span><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span><span class="st">  vector[N] x1;</span></span>
<span><span class="st">  vector[N] x3;</span></span>
<span><span class="st">  vector[N] y;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">parameters {</span></span>
<span><span class="st">  real alpha;</span></span>
<span><span class="st">  real beta1;</span></span>
<span><span class="st">  real beta3;</span></span>
<span><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">transformed parameters {</span></span>
<span><span class="st">  vector[N] mu;</span></span>
<span><span class="st">  for (n in 1 : N) {</span></span>
<span><span class="st">    mu[n] = alpha + beta1 * x1[n] + beta3 * x3[n];</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">model {</span></span>
<span><span class="st">  alpha ~ normal(0, 1);</span></span>
<span><span class="st">  beta1 ~ normal(0, 1);</span></span>
<span><span class="st">  beta3 ~ normal(0, 1);</span></span>
<span><span class="st">  sigma ~ cauchy(0, 1);</span></span>
<span><span class="st">  y ~ normal(mu, sigma);</span></span>
<span><span class="st">}</span></span>
<span><span class="st">generated quantities {</span></span>
<span><span class="st">  vector[N] y_rep;</span></span>
<span><span class="st">  vector[N] log_lik;</span></span>
<span><span class="st">  for (n in 1 : N) {</span></span>
<span><span class="st">    y_rep[n] = normal_rng(mu[n], sigma);</span></span>
<span><span class="st">    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x3[n] * beta3, sigma);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">modelString</span>, con <span class="op">=</span> <span class="st">"code/mreg3.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">df</span><span class="op">$</span><span class="va">x3</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">$</span><span class="va">mom_hs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">data3_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">kid_score</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">y</span>,</span>
<span>  x1 <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">x1</span>,</span>
<span>  x3 <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">x3</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">file3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"mreg3.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod3</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit3</span> <span class="op">&lt;-</span> <span class="va">mod3</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">data3_list</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">4000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">2000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="va">SEED</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  cores <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit3</span><span class="op">$</span><span class="fu">summary</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"alpha"</span>, <span class="st">"beta1"</span>, <span class="st">"beta3"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 4 × 10</span></span>
<span><span class="co">#&gt;   variable   mean median     sd    mad     q5     q95  rhat ess_bulk ess_tail</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 alpha    -0.225 -0.224 0.0947 0.0945 -0.382 -0.0705  1.00    8433.    9191.</span></span>
<span><span class="co">#&gt; 2 beta1     0.415  0.414 0.0449 0.0450  0.341  0.488   1.00   10941.   10324.</span></span>
<span><span class="co">#&gt; 3 beta3     0.286  0.285 0.108  0.108   0.111  0.465   1.00    8452.    8606.</span></span>
<span><span class="co">#&gt; 4 sigma     0.890  0.889 0.0302 0.0302  0.842  0.941   1.00   10828.    9623.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">loo3_result</span> <span class="op">&lt;-</span> <span class="va">fit3</span><span class="op">$</span><span class="fu">loo</span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">loo3_result</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Computed from 16000 by 434 log-likelihood matrix</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          Estimate   SE</span></span>
<span><span class="co">#&gt; elpd_loo   -584.2 16.4</span></span>
<span><span class="co">#&gt; p_loo         7.5  0.6</span></span>
<span><span class="co">#&gt; looic      1168.3 32.8</span></span>
<span><span class="co">#&gt; ------</span></span>
<span><span class="co">#&gt; Monte Carlo SE of elpd_loo is 0.0.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; All Pareto k estimates are good (k &lt; 0.5).</span></span>
<span><span class="co">#&gt; See help('pareto-k-diagnostic') for details.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per eseguire un confronto tra modelli in termini della loro capacità predittiva esaminiamo la differenza di LOO-CV tra coppie di modelli. Le seguenti istruzioni <span class="math inline">\(\mathsf{R}\)</span> producono la quantità <code>elpd_diff</code>, ovvero la differenza tra stime della <span class="math inline">\(elpd\)</span> fornite da due modelli. Il primo argomento della funzione <code>loo_compare()</code> specifica il modello che viene usato come confronto. Nella prima riga dell’output, il valore <code>elpd_diff</code> è 0 (cioè, <span class="math inline">\(x − x = 0\)</span>). Nelle righe successive sono riportate le differenze rispetto al modello di confronto (in questo caso, il modello 1). La colonna <code>se_diff</code> riporta l’errore standard di tali differenze.</p>
<p>L’incertezza della stima dell’accuratezza <em>out-of-sample</em> si distribuisce in maniera approssimativamente normale con media uguale al valore riportato dal software e deviazione standard uguale a ciò che è indicato nell’output come errore standard. Quando il campione è piccolo, questa approssimazione produce una forte sottostima dell’incertezza, ma fornisce comunque una stima migliore di AIC, DIC e WAIC.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu">loo_compare</span><span class="op">(</span><span class="va">loo1_result</span>, <span class="va">loo2_result</span>, <span class="va">loo3_result</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">w</span><span class="op">)</span></span>
<span><span class="co">#&gt;        elpd_diff se_diff</span></span>
<span><span class="co">#&gt; model1   0.0       0.0  </span></span>
<span><span class="co">#&gt; model2  -0.3       1.3  </span></span>
<span><span class="co">#&gt; model3 -15.6       6.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per interpretare l’output, usiamo il criterio suggerito da <span class="citation" data-cites="gelman1995bayesian">Gelman et al. (<a href="999_refs.html#ref-gelman1995bayesian" role="doc-biblioref">1995</a>)</span>: consideriamo “credibile” una differenza se <code>elpd_diff</code> è almeno due volte maggiore di <code>se_diff</code>. Nel caso presente, dunque, il confronto tra il modello 2 e il modello 1 indica che la quantità <code>elpd_diff</code> è molto piccola rispetto al suo errore standard. Questo accade se un predittore è associato in modo trascurabile con la variabile dipendente. I dati presenti, dunque, non offrono alcuna evidenza che aggiungere dell’età della madre come predittore migliori la capacità predittiva del modello. Nel confronto tra modello 3 e modello 1, invece, la quantità <code>elpd_diff</code> è maggiore di due volte il valore dell’errore standard. Questo suggerisce un incremento della capacità predittiva del modello quiando il livello di istruzione della madre viene incluso tra i predittori.</p>
<p>È anche possibile calcolare l’intervallo di credibilità per <code>elpd_diff</code>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fl">15.5</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">.95</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="fl">6.0</span></span>
<span><span class="co">#&gt; [1]  5.630878 25.369122</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="outlier" class="level2" data-number="37.5"><h2 data-number="37.5" class="anchored" data-anchor-id="outlier">
<span class="header-section-number">37.5</span> Outlier</h2>
<p>Si è soliti pensare che la maggior parte delle osservazioni del campione sia prodotta da un unico meccanismo generatore dei dati, mentre le rimanenti osservazioni sono la realizzazione di un diverso processo stocastico. Le osservazioni che appartengono a questo secondo gruppo si chiamano <em>outlier</em>. È dunque necessario identificare gli outlier e limitare la loro influenza sull’inferenza.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Poniamoci ora il problema di identificare gli outlier con la tecnica PSIS-LOO-CV. Quando PSIS-LOO-CV viene calcolato con il pacchetto <code>loo</code>, l’output riporta il parametro di forma della distribuzione di Pareto (valore <code>k</code>). Tale valore può essere utilizzato per identificare gli outlier. Infatti, il valore <code>k</code> valuta, per ciascun punto del campione, l’approssimazione usata da PSIS-LOO-CV. Se <span class="math inline">\(k &lt; 0.5\)</span>, i pesi di importanza vengono stimati in modo accurato; se il valore <span class="math inline">\(k\)</span> di Pareto di un punto è <span class="math inline">\(&gt; 0.7\)</span>, i pesi di importanza possono essere inaccurati. Le osservazioni con <span class="math inline">\(k &gt; 0.7\)</span> sono dunque osservazioni outlier.</p>
<p>Per fare un esempio concreto, introduciamo nel campione dell’esempio precedente una singola osservazione outlier.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">df1</span> <span class="op">&lt;-</span> <span class="va">df</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">df1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 434   9</span></span>
<span><span class="va">df1</span><span class="op">$</span><span class="va">x1</span><span class="op">[</span><span class="fl">434</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">df1</span><span class="op">$</span><span class="va">y</span><span class="op">[</span><span class="fl">434</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sistemiamo i dati nel formato appropriato per Stan:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">data1a_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">df1</span><span class="op">$</span><span class="va">kid_score</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="va">df1</span><span class="op">$</span><span class="va">y</span>,</span>
<span>  x1 <span class="op">=</span> <span class="va">df1</span><span class="op">$</span><span class="va">x1</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Adattiamo nuovamente il modello 1 ad un campione di dati che contiene un outlier.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit1a</span> <span class="op">&lt;-</span> <span class="va">mod1</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">data1a_list</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">4000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">2000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="va">SEED</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">loo1a_result</span> <span class="op">&lt;-</span> <span class="va">fit1a</span><span class="op">$</span><span class="fu">loo</span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Una tabella diagnostica che riassume le stime dei parametri di forma della distribuzione di Pareto si ottiene nel modo seguente:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">loo1a_result</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Computed from 16000 by 434 log-likelihood matrix</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          Estimate   SE</span></span>
<span><span class="co">#&gt; elpd_loo   -586.2 19.9</span></span>
<span><span class="co">#&gt; p_loo         6.6  5.0</span></span>
<span><span class="co">#&gt; looic      1172.5 39.8</span></span>
<span><span class="co">#&gt; ------</span></span>
<span><span class="co">#&gt; Monte Carlo SE of elpd_loo is NA.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Pareto k diagnostic values:</span></span>
<span><span class="co">#&gt;                          Count Pct.    Min. n_eff</span></span>
<span><span class="co">#&gt; (-Inf, 0.5]   (good)     433   99.8%   10708     </span></span>
<span><span class="co">#&gt;  (0.5, 0.7]   (ok)         0    0.0%   &lt;NA&gt;      </span></span>
<span><span class="co">#&gt;    (0.7, 1]   (bad)        1    0.2%   75        </span></span>
<span><span class="co">#&gt;    (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      </span></span>
<span><span class="co">#&gt; See help('pareto-k-diagnostic') for details.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Un grafico che riporta le stime dei parametri di forma della distribuzione di Pareto per ciascuna osservazione è dato da:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">loo1a_result</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="092_info_criterion_files/figure-html/unnamed-chunk-33-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Il valore <code>k</code> stimato da PSIS-LOO-CV mette chiaramente in luce il fatto che il valore introdotto nel campione è un outlier. L’indice dell’osservazione outlier è identificato con:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">pareto_k_ids</span><span class="op">(</span><span class="va">loo1a_result</span>, threshold <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 434</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="regolarizzazione" class="level2" data-number="37.6"><h2 data-number="37.6" class="anchored" data-anchor-id="regolarizzazione">
<span class="header-section-number">37.6</span> Regolarizzazione</h2>
<p>Abbiamo motivato la presente discussione affermando che uno dei problemi più grandi che i ricercatori devono afforntare è quello della generalizzabilità dei loro risultati. <span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="999_refs.html#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span> fa notare che un modo per favorire la capacità del modello di generalizzarsi a nuovi campioni è quello di fare in modo che produca un adattamento <em>peggiore</em> ai dati del campione presente. Il problema del sovra-adattamento (e quindi di una bassa generalizzabilità) dipende dal fatto che tutte le regolarità presenti nei dati del campione (e dunque, anche quelle che costituiscono un aspetto idiosincratico del campione presente) “vengono egualmente prese sul serio” da un modello che utilizza prior uniformi per i parametri. In tali circostanze, <em>qualsiasi</em> valore dei parametri viene considerato plausibile. Un modo per evitare un tale modo di procedere, che sicuramente è inadeguato, è quello di utilizzare dei prior che <span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="999_refs.html#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span> chiama “scettici”. I priori “scettici” più comuni sono quelli che hanno una funzione di regolarizzazione. Tali prior, se calibrati correttamente, riducono il sovra-adattamento pur consentendo al modello di rappresentare le regolarità che emergono dai dati del campione. Se il prior è “troppo scettico”, tuttavia, le regolarità dei dati campionari non vengono rappresentate dal modello; di conseguenza, ciò produce un sotto-adattamento. Il problema è quello di trovare un equilibrio tra gli opposti pericoli del sovra-adattamento e del sotto-adattamento. La buona notizia è che anche un prior “moderatamente scettico” è in grado di fornire un grande aiuto al modello, e questo è tutto quello che possiamo sperare di ottenere dato che, in generale, non ci sono né modelli ottimali né distribuzioni a priori ottimali (ovvero, modelli e distribuzioni a priori che non possono essere migliorati).</p>
<p>Un esempio di una distribuzione a priori di regolarizzazione può essere fornito facendo riferimento al modello lineare, per esempio. Se standardizziamo i dati, un prior <span class="math inline">\(\beta \sim \mathcal{N}(0, 1)\)</span> per il parametro che codifica la pendenza della retta di regressione ci dice che, prima di osservare i dati, il modello “è molto scettico” rispetto ai valori possibili di <span class="math inline">\(\beta\)</span> esterni all’intervallo <span class="math inline">\([-2, 2]\)</span> deviazioni standard. In altri termini, ritiene che sia molto improbabile che un cambiamento di 1 deviazione standard nella <span class="math inline">\(x\)</span> sia associato ad un cambiamento medio superiore a 2 unità di deviazione standard nella <span class="math inline">\(y\)</span>.</p>
<p>Ma potremmo anche usare una distribuzione a priori gaussiana con parametro <span class="math inline">\(\sigma\)</span> uguale a 0.5 oppure a 0.2. Quale prior usare dipende dal modello e dai dati – non c’è una raccomandazione che risulta sempre valida. L’effetto maggiore dei prior “molto scettici” si manifesta nel caso di modelli complessi e nel caso di piccole numerosità campionarie – ovvero, proprio nei casi in cui il rischio del sovra-adattamento è più grande. Se invece il campione è sufficientemente grande e il modello non è eccessivamente complesso, i prior, quali essi siano, hanno invece un effetto trascurabile sulla stima della distribuzione a posteriori.</p>
</section><section id="commenti-e-considerazioni-finali" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="commenti-e-considerazioni-finali">Commenti e considerazioni finali</h2>
<p>In questo Capitolo, utilizzando Stan insieme al pacchetto <code>loo</code>, abbiamo imparato ad usare la convalida incrociata K-fold e la convalida incrociata leave-one-out. Abbiamo esaminato alcuni esempi nei quali la convalida incrociata ci consente di distinguere tra due modelli. In generale, la convalida incrociata si dimostra utile utile quando vengono confrontati modelli piuttosto diversi; quando i modelli sono molto simili, invece, risulta spesso difficile distinguerli con le tecniche qui discusse. In particolare, risulta spesso difficile ottenere risultati conclusivi dal confronto di modelli tramite la convalida incrociata se l’effetto è molto piccolo e/o se il campione di dati è piccolo. In questi casi, alcuni ricercatori ritengono che siano più adatti altri metodi di confronto dei modelli, come ad esempio i fattori di Bayes. L’uso dei fattori di Bayes, tuttavia, è controverso, dato che essi dipendono fortemente dalla scelta delle distribuzioni a priori. Se possibile è preferibile utilizzare le procedure descritte in questa parte della dispensa, con campioni di ampiezza adeguata.</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography" style="display: none">
<div id="ref-gelman1995bayesian" class="csl-entry" role="doc-biblioentry">
Gelman, A., Carlin, J. B., Stern, H. S., &amp; Rubin, D. B. (1995). <em>Bayesian data analysis</em>. Chapman; Hall/CRC.
</div>
<div id="ref-gelman2020regression" class="csl-entry" role="doc-biblioentry">
Gelman, A., Hill, J., &amp; Vehtari, A. (2020). <em>Regression and other stories</em>. Cambridge University Press.
</div>
<div id="ref-gelman2014understanding" class="csl-entry" role="doc-biblioentry">
Gelman, A., Hwang, J., &amp; Vehtari, A. (2014). Understanding predictive information criteria for bayesian models. <em>Statistics and Computing</em>, <em>24</em>(6), 997–1016.
</div>
<div id="ref-McElreath_rethinking" class="csl-entry" role="doc-biblioentry">
McElreath, R. (2020). <em>Statistical rethinking: <span>A</span> <span>Bayesian</span> course with examples in <span>R</span> and <span>Stan</span></em> (2nd Edition). CRC Press.
</div>
<div id="ref-navarro2019between" class="csl-entry" role="doc-biblioentry">
Navarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. <em>Computational Brain &amp; Behavior</em>, <em>2</em>(1), 28–34.
</div>
<div id="ref-vehtari2017practical" class="csl-entry" role="doc-biblioentry">
Vehtari, A., Gelman, A., &amp; Gabry, J. (2017). Practical bayesian model evaluation using leave-one-out cross-validation and WAIC. <em>Statistics and Computing</em>, <em>27</em>(5), 1413–1432.
</div>
</div>
</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>A questo proposito, è necessario aggiungere una nota di cautela. Come fa notare <span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="999_refs.html#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span>, fare previsioni e inferire i rapporti causali sono due cose molto diverse. Statistiche quali AIC, WAIC e LOO-CV consentono di individuare modelli con buone capacità predittive. Tali modelli, tuttavia, non riflettono necessariamente la struttura causale del fenomeno considerato: la selezione di modelli basata unicamente sull’accuratezza predittiva non garantisce che venga selezionato il modello che riflette la struttura causale del fenomeno <span class="citation" data-cites="navarro2019between">(si veda anche <a href="999_refs.html#ref-navarro2019between" role="doc-biblioref">Navarro, 2019</a>)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="999_refs.html#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span> nota che, spesso, i ricercatori eliminano i valori anomali prima di adattare un modello ai dati, basandosi solo sulla distanza dal valore medio della variabile dipendente misurata in termini di unità di deviazione standard. Secondo <span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="999_refs.html#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span> questo non dovrebbe mai essere fatto: un’osservazione può essere considerata come un valore anomalo o un valore influente solo alla luce delle predizioni di un modello (mai prima di avere adattato il modello ai dati). Se ci sono solo pochi valori anomali una strategia possibile è quella di riportare i risultati delle analisi statistiche svolte su tutto il campione dei dati oppure dopo avere eliminato le osservazioni anomale e influenti.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./091_kl.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./frequentist_inference.html" class="pagination-link">
        <span class="nav-page-text">Parte 7: Inferenza frequentista</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb34" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Criterio di informazione e convalida incrociata {#sec-info-crit}</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE}</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_stan_options.R"</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>Nel Capitolo precedente abbiamo visto che la \@ref(eq:lppd) fornisce una sovrastima della $\mbox{elpd}$. Il modo migliore per stimare $\mbox{elpd}$ è raccogliere un nuovo campione indipendente di dati, che si ritiene condivida lo stesso processo di generazione dei dati del campione corrente, e stimare $\mbox{elpd}$ sul nuovo campione. Questa procedura è chiamata *out-of-sample validation*. Il problema, però, è che solitamente non abbiamo le risorse per raccogliere un nuovo campione di osservazioni. Di conseguenza, gli statistici hanno messo a punto vari metodi per evitare la sovrastima della $\mbox{elpd}$ che deriva dal solo utizzo del campione corrente. Ci sono due approcci generali:</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>l'introduzione di un fattore di correzione;</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la convalida incrociata cosiddetta K-fold.</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>Lo scopo del presente Capitolo è di fornire una breve introduzione ai criteri dell'informazione e alla procedura della convalida incrociata.</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="fu">## AIC, DIC e WAIC</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>Allo scopo di evitare la sovrastima della \@ref(eq:lppd), le statistiche *Akaike Information Criterion* (AIC), *Deviance Information Criterion* (DIC) e *Widely Applicable Information Criterion* (WAIC) introducono un fattore di correzione. Le statistiche DIC e WAIC sono più complesse di AIC, ma producono un'approssimazione migliore. Tuttavia, i valori AIC, DIC e WAIC sono spesso molto simili tra loro. Per convenienza, dunque, qui ci accontenteremo di esaminare in dettaglio la statistica più semplice, ovvero AIC.</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="fu">### Criterio d'informazione di Akaike</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>Il criterio d'informazione di Akaike (in inglese *Akaike information criterion*, indicato come AIC) fornisce un metodo molto semplice per approssimare $\mbox{elpd}$.</span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>::: definition</span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>Il criterio d'informazione di Akaike è definito come</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a><span class="in">AIC = -2 \log p(y \mid \hat{\theta}_{MLE}) + 2k,</span></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a>dove $k$ è il numero di parametri stimati nel modello e $p(y \mid \hat{\theta}_{MLE})$ è il valore massimizzato della funzione di verosimiglianza del modello stimato.</span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a>Dividendo per -2, otteniamo $\mbox{elpd}_{AIC}$:</span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a><span class="in">\widehat{\mbox{elpd}}_{AIC} = \log p(y \mid \hat{\theta}_{MLE}) - k,</span></span>
<span id="cb34-39"><a href="#cb34-39" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb34-40"><a href="#cb34-40" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-41"><a href="#cb34-41" aria-hidden="true" tabindex="-1"></a>dove $k$ è il fattore di correzione introdotto per evitare la sovrastima discussa in precedenza.</span>
<span id="cb34-42"><a href="#cb34-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-43"><a href="#cb34-43" aria-hidden="true" tabindex="-1"></a>AIC è di interesse principalmente storico e produce una approssimazione attendibile di $\mbox{elpd}$ quando:</span>
<span id="cb34-44"><a href="#cb34-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-45"><a href="#cb34-45" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>le distribuzioni a priori sono non informative;</span>
<span id="cb34-46"><a href="#cb34-46" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>la distribuzione a posteriori è approssimativamente gaussiana multivariata;</span>
<span id="cb34-47"><a href="#cb34-47" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>la dimensione $n$ del campione è molto maggiore del numero $k$ dei parametri.</span>
<span id="cb34-48"><a href="#cb34-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-49"><a href="#cb34-49" aria-hidden="true" tabindex="-1"></a>::: example</span>
<span id="cb34-50"><a href="#cb34-50" aria-hidden="true" tabindex="-1"></a>Per meglio comprendere la statistica $\widehat{\mbox{elpd}}_{AIC}$, esaminiamo un esempio discusso da @gelman2014understanding. Sia $y_1, \dots, y_n \sim \mathcal{N}(\mu, 1)$ un campione di osservazioni. Nel caso di una distribuzione a priori non-informativa $p(\theta) \propto 1$, la stima di massima verosimiglianza è $\bar{y}$. La verosimiglianza è</span>
<span id="cb34-51"><a href="#cb34-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-52"><a href="#cb34-52" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb34-53"><a href="#cb34-53" aria-hidden="true" tabindex="-1"></a>f(Y \mid \mu, \sigma) = \prod_{i=1}^n f(y \mid \mu, \sigma)</span>
<span id="cb34-54"><a href="#cb34-54" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb34-55"><a href="#cb34-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-56"><a href="#cb34-56" aria-hidden="true" tabindex="-1"></a>e la log-verosimiglianza diventa</span>
<span id="cb34-57"><a href="#cb34-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-58"><a href="#cb34-58" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb34-59"><a href="#cb34-59" aria-hidden="true" tabindex="-1"></a>\ell(Y \mid \mu, \sigma) = \sum_{i=1}^n \log (f(y \mid \mu, \sigma)).</span>
<span id="cb34-60"><a href="#cb34-60" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb34-61"><a href="#cb34-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-62"><a href="#cb34-62" aria-hidden="true" tabindex="-1"></a>Ovvero,</span>
<span id="cb34-63"><a href="#cb34-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-64"><a href="#cb34-64" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb34-65"><a href="#cb34-65" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{align}</span></span>
<span id="cb34-66"><a href="#cb34-66" aria-hidden="true" tabindex="-1"></a><span class="in">\ell(Y \mid \mu, \sigma) &amp;= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi\sigma^2 }}}\exp \left(-{\frac {1}{2}}{\frac {(y_i-\mu )^{2}}{\sigma^{2}}}\right) \right)\notag\\</span></span>
<span id="cb34-67"><a href="#cb34-67" aria-hidden="true" tabindex="-1"></a><span class="in">&amp;= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi \sigma^2}}} \right) - \sum_{i=1}^n{\frac {1}{2}}{\frac {(y_i-\mu )^{2}}{\sigma ^{2}}} \notag\\</span></span>
<span id="cb34-68"><a href="#cb34-68" aria-hidden="true" tabindex="-1"></a><span class="in">&amp;= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi \sigma^2}}} \right) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag \\</span></span>
<span id="cb34-69"><a href="#cb34-69" aria-hidden="true" tabindex="-1"></a><span class="in">&amp;= \sum_{i=1}^n \log (1) - \sum_{i=1}^n\log \sqrt{2\pi \sigma^2} - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag\\</span></span>
<span id="cb34-70"><a href="#cb34-70" aria-hidden="true" tabindex="-1"></a><span class="in">&amp;= - \sum_{i=1}^n\frac{1}{2}  \log (2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag\\</span></span>
<span id="cb34-71"><a href="#cb34-71" aria-hidden="true" tabindex="-1"></a><span class="in">&amp;= - \frac{n}{2}  \log (2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2}. \notag</span></span>
<span id="cb34-72"><a href="#cb34-72" aria-hidden="true" tabindex="-1"></a><span class="in">\end{align}</span></span>
<span id="cb34-73"><a href="#cb34-73" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-74"><a href="#cb34-74" aria-hidden="true" tabindex="-1"></a>Se $y \sim \mathcal{N}(\mu, 1)$, usando lo stimatore di massima verosimiglianza per $\mu$, la log-verosimiglianza diventa</span>
<span id="cb34-75"><a href="#cb34-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-76"><a href="#cb34-76" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb34-77"><a href="#cb34-77" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{align}</span></span>
<span id="cb34-78"><a href="#cb34-78" aria-hidden="true" tabindex="-1"></a><span class="in">\log p(y \mid \hat{\theta}_{MLE}) &amp;= -\frac{n}{2} \log (2\pi) - \frac{1}{2}\sum_{i=1}^n (y_i - \bar{y})^2 \notag\\</span></span>
<span id="cb34-79"><a href="#cb34-79" aria-hidden="true" tabindex="-1"></a><span class="in">&amp;= -\frac{n}{2} \log (2\pi) - \frac{1}{2} (n-1)s_y^2,</span></span>
<span id="cb34-80"><a href="#cb34-80" aria-hidden="true" tabindex="-1"></a><span class="in">\end{align}</span></span>
<span id="cb34-81"><a href="#cb34-81" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-82"><a href="#cb34-82" aria-hidden="true" tabindex="-1"></a>dove $s_y^2$ è la varianza campionaria.</span>
<span id="cb34-83"><a href="#cb34-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-84"><a href="#cb34-84" aria-hidden="true" tabindex="-1"></a>Nel caso di un modello gaussiano con con varianza nota e una distribuzione a priori uniforme viene stimato un solo parametro, per cui</span>
<span id="cb34-85"><a href="#cb34-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-86"><a href="#cb34-86" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb34-87"><a href="#cb34-87" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{align}</span></span>
<span id="cb34-88"><a href="#cb34-88" aria-hidden="true" tabindex="-1"></a><span class="in">\widehat{\mbox{elpd}}_{AIC} &amp;= \log p(y \mid \hat{\theta}_{MLE}) - k \notag \\</span></span>
<span id="cb34-89"><a href="#cb34-89" aria-hidden="true" tabindex="-1"></a><span class="in">&amp;= -\frac{n}{2} \log (2\pi) - \frac{1}{2} (n-1)s_y^2 - 1.</span></span>
<span id="cb34-90"><a href="#cb34-90" aria-hidden="true" tabindex="-1"></a><span class="in">\end{align}</span></span>
<span id="cb34-91"><a href="#cb34-91" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-92"><a href="#cb34-92" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-93"><a href="#cb34-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-94"><a href="#cb34-94" aria-hidden="true" tabindex="-1"></a><span class="fu">## Convalida incrociata K-fold</span></span>
<span id="cb34-95"><a href="#cb34-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-96"><a href="#cb34-96" aria-hidden="true" tabindex="-1"></a>La sovrastima della \@ref(eq:lppd) può anche essere evitata usando una tecnica chiamata *K-fold cross-validation*. Mediante questo metodo vengono stimati i parametri del modello tralasciando una porzione di osservazioni (chiamata *fold*) dal campione per poi valutare il modello sulle osservazioni che sono state escluse. Una stima complessiva dell'accuratezza si ottiene poi calcolando la media del punteggio di accuratezza ottenuto in ogni fold. Il numero minimo di fold è 2; all'altro estremo, è possibile impiegare una singola osservazione in ciascun fold e adattare il modello tante volte ($n$) quante sono le singole osservazioni. Questa strategia è chiamata *leave-one-out cross-validation* (LOO-CV).</span>
<span id="cb34-97"><a href="#cb34-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-98"><a href="#cb34-98" aria-hidden="true" tabindex="-1"></a><span class="fu">### Importance sampling</span></span>
<span id="cb34-99"><a href="#cb34-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-100"><a href="#cb34-100" aria-hidden="true" tabindex="-1"></a>La strategia LOO-CV è computazionalmente onerosa (ovvero, richiede un tempo di esecuzione molto lungo). È però possibile approssimare LOO-CV mediante un metodo chiamato *Pareto-smoothed importance sampling cross-validation* [PSIS; @vehtari2017practical]. Tralasciando qui i dettagli matematici, l'intuizione di base è che PSIS fa leva sul punteggio di "importanza" posseduto da ciascuna osservazione all'interno della distribuzione a posteriori. Per "importanza" si intende il fatto che alcune osservazioni hanno un impatto maggiore sulle proprietà della distribuzione a posteriori di altre: se viene rimossa un'osservazione importante, le proprietà della distribuzione a posteriori cambiano molto; se viene rimossa un'osservazione poco importante, la distribuzione a posteriori cambia poco. L'"importanza" così intesa viene chiamata "peso" (*weight*) e tali pesi vengono utilizzati per stimare l'accuratezza *out-of-sample* del modello. PSIS-LOO-CV richiede che il modello venga adattato una volta soltanto ai dati e fornisce una stima della devianza *out-of-sample* che evita la sovrastima della \@ref(eq:lppd). Inoltre, PSIS-LOO-CV fornisce un feedback sulla propria affidabilità identificando le osservazioni i cui pesi molto elevati potrebbero rendere imprecisa la predizione.</span>
<span id="cb34-101"><a href="#cb34-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-102"><a href="#cb34-102" aria-hidden="true" tabindex="-1"></a>Valori $\widehat{\mbox{elpd}}_{LOO}$ più grandi indicano una maggiore accuratezza predittiva. In alternativa, anziché considerare $\widehat{\mbox{elpd}}$, è possibile usare la quantità $-2 \cdot \widehat{\mbox{elpd}}$, la quale è chiamata *LOO Information Criterion* (LOOIC). In questo secondo caso, valori LOOIC più piccoli sono da preferire.</span>
<span id="cb34-103"><a href="#cb34-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-104"><a href="#cb34-104" aria-hidden="true" tabindex="-1"></a>La quantità $\widehat{\mbox{elpd}}_{LOO}$ viene calcolata dai pacchetti <span class="in">`loo`</span> e <span class="in">`brms`</span> ed è chiamata <span class="in">`elpd_loo`</span> o <span class="in">`elpd_kfold`</span>. È anche possibile calcolare la differenza della quantità <span class="in">`elpd_loo`</span> per modelli alternativi, insieme alla deviazione standard della distribuzione campionaria di tale differenza.</span>
<span id="cb34-105"><a href="#cb34-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-106"><a href="#cb34-106" aria-hidden="true" tabindex="-1"></a><span class="fu">## Confronto tra AIC e LOO-CV</span></span>
<span id="cb34-107"><a href="#cb34-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-108"><a href="#cb34-108" aria-hidden="true" tabindex="-1"></a>Per fare un esempio, faremo qui un confronto tra $\widehat{\mbox{elpd}}_{AIC}$ e $\widehat{\mbox{elpd}}_{LOO-CV}$. Esaminiamo nuovamente l'associazione tra il QI dei figli e il QI delle madri nel campione di dati discusso da @gelman2020regression. Una tale relazione può essere descritta da un modello di regressione nel quale la $y$ corrisponde al QI dei figli e la $x$ al QI delle madri.</span>
<span id="cb34-109"><a href="#cb34-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-110"><a href="#cb34-110" aria-hidden="true" tabindex="-1"></a>Leggiamo i dati in \mathsf{R}:</span>
<span id="cb34-111"><a href="#cb34-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-114"><a href="#cb34-114" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-115"><a href="#cb34-115" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"foreign"</span>)</span>
<span id="cb34-116"><a href="#cb34-116" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="fu">here</span>(<span class="st">"data"</span>, <span class="st">"kidiq.dta"</span>))</span>
<span id="cb34-117"><a href="#cb34-117" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>y <span class="ot">&lt;-</span> <span class="fu">scale</span>(df<span class="sc">$</span>kid_score)[, <span class="dv">1</span>]</span>
<span id="cb34-118"><a href="#cb34-118" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>x1 <span class="ot">&lt;-</span> <span class="fu">scale</span>(df<span class="sc">$</span>mom_iq)[, <span class="dv">1</span>]</span>
<span id="cb34-119"><a href="#cb34-119" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df)</span>
<span id="cb34-120"><a href="#cb34-120" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-121"><a href="#cb34-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-122"><a href="#cb34-122" aria-hidden="true" tabindex="-1"></a>Dato che AIC non è una statistica bayesiana, può essere calcolata mediante strumenti frequentisti:</span>
<span id="cb34-123"><a href="#cb34-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-126"><a href="#cb34-126" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-127"><a href="#cb34-127" aria-hidden="true" tabindex="-1"></a>m1_freq <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> df)</span>
<span id="cb34-128"><a href="#cb34-128" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(m1_freq) <span class="sc">/</span> <span class="sc">-</span><span class="dv">2</span></span>
<span id="cb34-129"><a href="#cb34-129" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-130"><a href="#cb34-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-131"><a href="#cb34-131" aria-hidden="true" tabindex="-1"></a>Per ottenere LOO-CV adattiamo ai dati un modello di regressione bayesiano:</span>
<span id="cb34-132"><a href="#cb34-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-135"><a href="#cb34-135" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-136"><a href="#cb34-136" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">"</span></span>
<span id="cb34-137"><a href="#cb34-137" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb34-138"><a href="#cb34-138" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb34-139"><a href="#cb34-139" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x1;</span></span>
<span id="cb34-140"><a href="#cb34-140" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y;</span></span>
<span id="cb34-141"><a href="#cb34-141" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-142"><a href="#cb34-142" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb34-143"><a href="#cb34-143" aria-hidden="true" tabindex="-1"></a><span class="st">  real alpha;</span></span>
<span id="cb34-144"><a href="#cb34-144" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta1;</span></span>
<span id="cb34-145"><a href="#cb34-145" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span id="cb34-146"><a href="#cb34-146" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-147"><a href="#cb34-147" aria-hidden="true" tabindex="-1"></a><span class="st">transformed parameters {</span></span>
<span id="cb34-148"><a href="#cb34-148" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] mu;</span></span>
<span id="cb34-149"><a href="#cb34-149" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1 : N) {</span></span>
<span id="cb34-150"><a href="#cb34-150" aria-hidden="true" tabindex="-1"></a><span class="st">    mu[n] = alpha + beta1 * x1[n];</span></span>
<span id="cb34-151"><a href="#cb34-151" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb34-152"><a href="#cb34-152" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-153"><a href="#cb34-153" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb34-154"><a href="#cb34-154" aria-hidden="true" tabindex="-1"></a><span class="st">  alpha ~ normal(0, 1);</span></span>
<span id="cb34-155"><a href="#cb34-155" aria-hidden="true" tabindex="-1"></a><span class="st">  beta1 ~ normal(0, 1);</span></span>
<span id="cb34-156"><a href="#cb34-156" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma ~ cauchy(0, 1);</span></span>
<span id="cb34-157"><a href="#cb34-157" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ normal(mu, sigma);</span></span>
<span id="cb34-158"><a href="#cb34-158" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-159"><a href="#cb34-159" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb34-160"><a href="#cb34-160" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y_rep;</span></span>
<span id="cb34-161"><a href="#cb34-161" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] log_lik;</span></span>
<span id="cb34-162"><a href="#cb34-162" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1 : N) {</span></span>
<span id="cb34-163"><a href="#cb34-163" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = normal_rng(mu[n], sigma);</span></span>
<span id="cb34-164"><a href="#cb34-164" aria-hidden="true" tabindex="-1"></a><span class="st">    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1, sigma);</span></span>
<span id="cb34-165"><a href="#cb34-165" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb34-166"><a href="#cb34-166" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-167"><a href="#cb34-167" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb34-168"><a href="#cb34-168" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">"code/simplereg.stan"</span>)</span>
<span id="cb34-169"><a href="#cb34-169" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-170"><a href="#cb34-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-173"><a href="#cb34-173" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-174"><a href="#cb34-174" aria-hidden="true" tabindex="-1"></a>data1_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb34-175"><a href="#cb34-175" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(df<span class="sc">$</span>kid_score),</span>
<span id="cb34-176"><a href="#cb34-176" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> df<span class="sc">$</span>y,</span>
<span id="cb34-177"><a href="#cb34-177" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> df<span class="sc">$</span>x1</span>
<span id="cb34-178"><a href="#cb34-178" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-179"><a href="#cb34-179" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-180"><a href="#cb34-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-183"><a href="#cb34-183" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-184"><a href="#cb34-184" aria-hidden="true" tabindex="-1"></a>file1 <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"simplereg.stan"</span>)</span>
<span id="cb34-185"><a href="#cb34-185" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-186"><a href="#cb34-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-189"><a href="#cb34-189" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-190"><a href="#cb34-190" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file1)</span>
<span id="cb34-191"><a href="#cb34-191" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-192"><a href="#cb34-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-193"><a href="#cb34-193" aria-hidden="true" tabindex="-1"></a>Eseguiamo il campionamento MCMC:</span>
<span id="cb34-194"><a href="#cb34-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-195"><a href="#cb34-195" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message = FALSE, warning=FALSE, results='hide'}</span></span>
<span id="cb34-196"><a href="#cb34-196" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> mod1<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb34-197"><a href="#cb34-197" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data1_list,</span>
<span id="cb34-198"><a href="#cb34-198" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb34-199"><a href="#cb34-199" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb34-200"><a href="#cb34-200" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb34-201"><a href="#cb34-201" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb34-202"><a href="#cb34-202" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> 4L,</span>
<span id="cb34-203"><a href="#cb34-203" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb34-204"><a href="#cb34-204" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-205"><a href="#cb34-205" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-206"><a href="#cb34-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-207"><a href="#cb34-207" aria-hidden="true" tabindex="-1"></a>Calcoliamo infine la quantità $\widehat{\mbox{elpd}}_{LOO-CV}$:</span>
<span id="cb34-208"><a href="#cb34-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-211"><a href="#cb34-211" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-212"><a href="#cb34-212" aria-hidden="true" tabindex="-1"></a>loo1_result <span class="ot">&lt;-</span> fit1<span class="sc">$</span><span class="fu">loo</span>(<span class="at">cores =</span> <span class="dv">4</span>)</span>
<span id="cb34-213"><a href="#cb34-213" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(loo1_result)</span>
<span id="cb34-214"><a href="#cb34-214" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-215"><a href="#cb34-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-216"><a href="#cb34-216" aria-hidden="true" tabindex="-1"></a>Si noti la somiglianza tra $\widehat{\mbox{elpd}}_{LOO-CV}$ e $\widehat{\mbox{elpd}}_{AIC}$. In conclusione, possiamo dunque dire che $\widehat{\mbox{elpd}}_{LOO-CV}$ è la risposta bayesiana allo stesso problema che trova una soluzione frequentista nella statistica $\widehat{\mbox{elpd}}_{AIC}$.</span>
<span id="cb34-217"><a href="#cb34-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-218"><a href="#cb34-218" aria-hidden="true" tabindex="-1"></a><span class="fu">## Confronto tra modelli mediante LOO-CV</span></span>
<span id="cb34-219"><a href="#cb34-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-220"><a href="#cb34-220" aria-hidden="true" tabindex="-1"></a>Come menzionato in precedenza, l'obiettivo centrale della misurazione dell'accuratezza predittiva è il confronto di modelli. Una volta capito come calcolare LOO-CV con un condice scritto in linguaggio Stan, svolgeremo ora un confronto di modelli.<span class="ot">[^info_criterion-1]</span></span>
<span id="cb34-221"><a href="#cb34-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-222"><a href="#cb34-222" aria-hidden="true" tabindex="-1"></a><span class="ot">[^info_criterion-1]: </span>A questo proposito, è necessario aggiungere una nota di cautela. Come fa notare @McElreath_rethinking, fare previsioni e inferire i rapporti causali sono due cose molto diverse. Statistiche quali AIC, WAIC e LOO-CV consentono di individuare modelli con buone capacità predittive. Tali modelli, tuttavia, non riflettono necessariamente la struttura causale del fenomeno considerato: la selezione di modelli basata unicamente sull'accuratezza predittiva non garantisce che venga selezionato il modello che riflette la struttura causale del fenomeno <span class="co">[</span><span class="ot">si veda anche @navarro2019between</span><span class="co">]</span>.</span>
<span id="cb34-223"><a href="#cb34-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-224"><a href="#cb34-224" aria-hidden="true" tabindex="-1"></a>Considereremo qui un confronto di modelli di regressione. Il modello di regressione discusso nel Paragrafo precedente prevede il QI dei bambini dal QI delle madri. Aggiungiamo a tale modello un secondo predittore che corrisponde all'età della madre. L'aggiunta di tale predittore migliori l'accuratezza predittiva del modello?</span>
<span id="cb34-225"><a href="#cb34-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-228"><a href="#cb34-228" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-229"><a href="#cb34-229" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">"</span></span>
<span id="cb34-230"><a href="#cb34-230" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb34-231"><a href="#cb34-231" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb34-232"><a href="#cb34-232" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x1;</span></span>
<span id="cb34-233"><a href="#cb34-233" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x2;</span></span>
<span id="cb34-234"><a href="#cb34-234" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y;</span></span>
<span id="cb34-235"><a href="#cb34-235" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-236"><a href="#cb34-236" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb34-237"><a href="#cb34-237" aria-hidden="true" tabindex="-1"></a><span class="st">  real alpha;</span></span>
<span id="cb34-238"><a href="#cb34-238" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta1;</span></span>
<span id="cb34-239"><a href="#cb34-239" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta2;</span></span>
<span id="cb34-240"><a href="#cb34-240" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span id="cb34-241"><a href="#cb34-241" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-242"><a href="#cb34-242" aria-hidden="true" tabindex="-1"></a><span class="st">transformed parameters {</span></span>
<span id="cb34-243"><a href="#cb34-243" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] mu;</span></span>
<span id="cb34-244"><a href="#cb34-244" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1 : N) {</span></span>
<span id="cb34-245"><a href="#cb34-245" aria-hidden="true" tabindex="-1"></a><span class="st">    mu[n] = alpha + beta1 * x1[n] + beta2 * x2[n];</span></span>
<span id="cb34-246"><a href="#cb34-246" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb34-247"><a href="#cb34-247" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-248"><a href="#cb34-248" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb34-249"><a href="#cb34-249" aria-hidden="true" tabindex="-1"></a><span class="st">  alpha ~ normal(0, 1);</span></span>
<span id="cb34-250"><a href="#cb34-250" aria-hidden="true" tabindex="-1"></a><span class="st">  beta1 ~ normal(0, 1);</span></span>
<span id="cb34-251"><a href="#cb34-251" aria-hidden="true" tabindex="-1"></a><span class="st">  beta2 ~ normal(0, 1);</span></span>
<span id="cb34-252"><a href="#cb34-252" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma ~ cauchy(0, 1);</span></span>
<span id="cb34-253"><a href="#cb34-253" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ normal(mu, sigma);</span></span>
<span id="cb34-254"><a href="#cb34-254" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-255"><a href="#cb34-255" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb34-256"><a href="#cb34-256" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y_rep;</span></span>
<span id="cb34-257"><a href="#cb34-257" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] log_lik;</span></span>
<span id="cb34-258"><a href="#cb34-258" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1 : N) {</span></span>
<span id="cb34-259"><a href="#cb34-259" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = normal_rng(mu[n], sigma);</span></span>
<span id="cb34-260"><a href="#cb34-260" aria-hidden="true" tabindex="-1"></a><span class="st">    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x2[n] * beta2, sigma);</span></span>
<span id="cb34-261"><a href="#cb34-261" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb34-262"><a href="#cb34-262" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-263"><a href="#cb34-263" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb34-264"><a href="#cb34-264" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">"code/mreg2.stan"</span>)</span>
<span id="cb34-265"><a href="#cb34-265" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-266"><a href="#cb34-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-269"><a href="#cb34-269" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-270"><a href="#cb34-270" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>x2 <span class="ot">&lt;-</span> <span class="fu">scale</span>(df<span class="sc">$</span>mom_age)[, <span class="dv">1</span>]</span>
<span id="cb34-271"><a href="#cb34-271" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-272"><a href="#cb34-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-275"><a href="#cb34-275" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-276"><a href="#cb34-276" aria-hidden="true" tabindex="-1"></a>data2_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb34-277"><a href="#cb34-277" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(df<span class="sc">$</span>kid_score),</span>
<span id="cb34-278"><a href="#cb34-278" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> df<span class="sc">$</span>y,</span>
<span id="cb34-279"><a href="#cb34-279" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> df<span class="sc">$</span>x1,</span>
<span id="cb34-280"><a href="#cb34-280" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> df<span class="sc">$</span>x2</span>
<span id="cb34-281"><a href="#cb34-281" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-282"><a href="#cb34-282" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-283"><a href="#cb34-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-286"><a href="#cb34-286" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-287"><a href="#cb34-287" aria-hidden="true" tabindex="-1"></a>file2 <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"mreg2.stan"</span>)</span>
<span id="cb34-288"><a href="#cb34-288" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-289"><a href="#cb34-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-292"><a href="#cb34-292" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-293"><a href="#cb34-293" aria-hidden="true" tabindex="-1"></a><span class="co"># compile model</span></span>
<span id="cb34-294"><a href="#cb34-294" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file2)</span>
<span id="cb34-295"><a href="#cb34-295" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-296"><a href="#cb34-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-297"><a href="#cb34-297" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message = FALSE, warning=FALSE, results='hide'}</span></span>
<span id="cb34-298"><a href="#cb34-298" aria-hidden="true" tabindex="-1"></a><span class="co"># Running MCMC</span></span>
<span id="cb34-299"><a href="#cb34-299" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> mod2<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb34-300"><a href="#cb34-300" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data2_list,</span>
<span id="cb34-301"><a href="#cb34-301" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb34-302"><a href="#cb34-302" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb34-303"><a href="#cb34-303" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb34-304"><a href="#cb34-304" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb34-305"><a href="#cb34-305" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> 4L,</span>
<span id="cb34-306"><a href="#cb34-306" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb34-307"><a href="#cb34-307" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-308"><a href="#cb34-308" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-309"><a href="#cb34-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-312"><a href="#cb34-312" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-313"><a href="#cb34-313" aria-hidden="true" tabindex="-1"></a>fit2<span class="sc">$</span><span class="fu">summary</span>(<span class="fu">c</span>(<span class="st">"alpha"</span>, <span class="st">"beta1"</span>, <span class="st">"beta2"</span>, <span class="st">"sigma"</span>))</span>
<span id="cb34-314"><a href="#cb34-314" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-315"><a href="#cb34-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-318"><a href="#cb34-318" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-319"><a href="#cb34-319" aria-hidden="true" tabindex="-1"></a>loo2_result <span class="ot">&lt;-</span> fit2<span class="sc">$</span><span class="fu">loo</span>(<span class="at">cores =</span> <span class="dv">4</span>)</span>
<span id="cb34-320"><a href="#cb34-320" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(loo2_result)</span>
<span id="cb34-321"><a href="#cb34-321" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-322"><a href="#cb34-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-323"><a href="#cb34-323" aria-hidden="true" tabindex="-1"></a>Consideriamo infine un terzo modello che utilizza come predittori, oltre al QI della madre, una variabile dicotomica (codificata 0 o 1) che distingue madri che hanno completato le scuole superiori da quelle che non le hanno completate. Nuovamente, la domanda è se l'aggiunta di tale predittore migliori la capacità predittiva del modello.</span>
<span id="cb34-324"><a href="#cb34-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-327"><a href="#cb34-327" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-328"><a href="#cb34-328" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">"</span></span>
<span id="cb34-329"><a href="#cb34-329" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb34-330"><a href="#cb34-330" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb34-331"><a href="#cb34-331" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x1;</span></span>
<span id="cb34-332"><a href="#cb34-332" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x3;</span></span>
<span id="cb34-333"><a href="#cb34-333" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y;</span></span>
<span id="cb34-334"><a href="#cb34-334" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-335"><a href="#cb34-335" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb34-336"><a href="#cb34-336" aria-hidden="true" tabindex="-1"></a><span class="st">  real alpha;</span></span>
<span id="cb34-337"><a href="#cb34-337" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta1;</span></span>
<span id="cb34-338"><a href="#cb34-338" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta3;</span></span>
<span id="cb34-339"><a href="#cb34-339" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span id="cb34-340"><a href="#cb34-340" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-341"><a href="#cb34-341" aria-hidden="true" tabindex="-1"></a><span class="st">transformed parameters {</span></span>
<span id="cb34-342"><a href="#cb34-342" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] mu;</span></span>
<span id="cb34-343"><a href="#cb34-343" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1 : N) {</span></span>
<span id="cb34-344"><a href="#cb34-344" aria-hidden="true" tabindex="-1"></a><span class="st">    mu[n] = alpha + beta1 * x1[n] + beta3 * x3[n];</span></span>
<span id="cb34-345"><a href="#cb34-345" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb34-346"><a href="#cb34-346" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-347"><a href="#cb34-347" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb34-348"><a href="#cb34-348" aria-hidden="true" tabindex="-1"></a><span class="st">  alpha ~ normal(0, 1);</span></span>
<span id="cb34-349"><a href="#cb34-349" aria-hidden="true" tabindex="-1"></a><span class="st">  beta1 ~ normal(0, 1);</span></span>
<span id="cb34-350"><a href="#cb34-350" aria-hidden="true" tabindex="-1"></a><span class="st">  beta3 ~ normal(0, 1);</span></span>
<span id="cb34-351"><a href="#cb34-351" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma ~ cauchy(0, 1);</span></span>
<span id="cb34-352"><a href="#cb34-352" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ normal(mu, sigma);</span></span>
<span id="cb34-353"><a href="#cb34-353" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-354"><a href="#cb34-354" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb34-355"><a href="#cb34-355" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y_rep;</span></span>
<span id="cb34-356"><a href="#cb34-356" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] log_lik;</span></span>
<span id="cb34-357"><a href="#cb34-357" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1 : N) {</span></span>
<span id="cb34-358"><a href="#cb34-358" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = normal_rng(mu[n], sigma);</span></span>
<span id="cb34-359"><a href="#cb34-359" aria-hidden="true" tabindex="-1"></a><span class="st">    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x3[n] * beta3, sigma);</span></span>
<span id="cb34-360"><a href="#cb34-360" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb34-361"><a href="#cb34-361" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-362"><a href="#cb34-362" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb34-363"><a href="#cb34-363" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">"code/mreg3.stan"</span>)</span>
<span id="cb34-364"><a href="#cb34-364" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-365"><a href="#cb34-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-368"><a href="#cb34-368" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-369"><a href="#cb34-369" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>x3 <span class="ot">&lt;-</span> df<span class="sc">$</span>mom_hs</span>
<span id="cb34-370"><a href="#cb34-370" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-371"><a href="#cb34-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-374"><a href="#cb34-374" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-375"><a href="#cb34-375" aria-hidden="true" tabindex="-1"></a>data3_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb34-376"><a href="#cb34-376" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(df<span class="sc">$</span>kid_score),</span>
<span id="cb34-377"><a href="#cb34-377" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> df<span class="sc">$</span>y,</span>
<span id="cb34-378"><a href="#cb34-378" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> df<span class="sc">$</span>x1,</span>
<span id="cb34-379"><a href="#cb34-379" aria-hidden="true" tabindex="-1"></a>  <span class="at">x3 =</span> df<span class="sc">$</span>x3</span>
<span id="cb34-380"><a href="#cb34-380" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-381"><a href="#cb34-381" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-382"><a href="#cb34-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-385"><a href="#cb34-385" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-386"><a href="#cb34-386" aria-hidden="true" tabindex="-1"></a>file3 <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"mreg3.stan"</span>)</span>
<span id="cb34-387"><a href="#cb34-387" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-388"><a href="#cb34-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-391"><a href="#cb34-391" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-392"><a href="#cb34-392" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file3)</span>
<span id="cb34-393"><a href="#cb34-393" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-394"><a href="#cb34-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-395"><a href="#cb34-395" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message = FALSE, warning=FALSE, results='hide'}</span></span>
<span id="cb34-396"><a href="#cb34-396" aria-hidden="true" tabindex="-1"></a>fit3 <span class="ot">&lt;-</span> mod3<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb34-397"><a href="#cb34-397" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data3_list,</span>
<span id="cb34-398"><a href="#cb34-398" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb34-399"><a href="#cb34-399" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb34-400"><a href="#cb34-400" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb34-401"><a href="#cb34-401" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb34-402"><a href="#cb34-402" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> 4L,</span>
<span id="cb34-403"><a href="#cb34-403" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb34-404"><a href="#cb34-404" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-405"><a href="#cb34-405" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-406"><a href="#cb34-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-409"><a href="#cb34-409" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-410"><a href="#cb34-410" aria-hidden="true" tabindex="-1"></a>fit3<span class="sc">$</span><span class="fu">summary</span>(<span class="fu">c</span>(<span class="st">"alpha"</span>, <span class="st">"beta1"</span>, <span class="st">"beta3"</span>, <span class="st">"sigma"</span>))</span>
<span id="cb34-411"><a href="#cb34-411" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-412"><a href="#cb34-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-415"><a href="#cb34-415" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-416"><a href="#cb34-416" aria-hidden="true" tabindex="-1"></a>loo3_result <span class="ot">&lt;-</span> fit3<span class="sc">$</span><span class="fu">loo</span>(<span class="at">cores =</span> <span class="dv">4</span>)</span>
<span id="cb34-417"><a href="#cb34-417" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(loo3_result)</span>
<span id="cb34-418"><a href="#cb34-418" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-419"><a href="#cb34-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-420"><a href="#cb34-420" aria-hidden="true" tabindex="-1"></a>Per eseguire un confronto tra modelli in termini della loro capacità predittiva esaminiamo la differenza di LOO-CV tra coppie di modelli. Le seguenti istruzioni $\mathsf{R}$ producono la quantità <span class="in">`elpd_diff`</span>, ovvero la differenza tra stime della $elpd$ fornite da due modelli. Il primo argomento della funzione <span class="in">`loo_compare()`</span> specifica il modello che viene usato come confronto. Nella prima riga dell'output, il valore <span class="in">`elpd_diff`</span> è 0 (cioè, $x − x = 0$). Nelle righe successive sono riportate le differenze rispetto al modello di confronto (in questo caso, il modello 1). La colonna <span class="in">`se_diff`</span> riporta l'errore standard di tali differenze.</span>
<span id="cb34-421"><a href="#cb34-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-422"><a href="#cb34-422" aria-hidden="true" tabindex="-1"></a>L'incertezza della stima dell'accuratezza *out-of-sample* si distribuisce in maniera approssimativamente normale con media uguale al valore riportato dal software e deviazione standard uguale a ciò che è indicato nell'output come errore standard. Quando il campione è piccolo, questa approssimazione produce una forte sottostima dell'incertezza, ma fornisce comunque una stima migliore di AIC, DIC e WAIC.</span>
<span id="cb34-423"><a href="#cb34-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-426"><a href="#cb34-426" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-427"><a href="#cb34-427" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">loo_compare</span>(loo1_result, loo2_result, loo3_result)</span>
<span id="cb34-428"><a href="#cb34-428" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(w)</span>
<span id="cb34-429"><a href="#cb34-429" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-430"><a href="#cb34-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-431"><a href="#cb34-431" aria-hidden="true" tabindex="-1"></a>Per interpretare l'output, usiamo il criterio suggerito da @gelman1995bayesian: consideriamo "credibile" una differenza se <span class="in">`elpd_diff`</span> è almeno due volte maggiore di <span class="in">`se_diff`</span>. Nel caso presente, dunque, il confronto tra il modello 2 e il modello 1 indica che la quantità <span class="in">`elpd_diff`</span> è molto piccola rispetto al suo errore standard. Questo accade se un predittore è associato in modo trascurabile con la variabile dipendente. I dati presenti, dunque, non offrono alcuna evidenza che aggiungere dell'età della madre come predittore migliori la capacità predittiva del modello. Nel confronto tra modello 3 e modello 1, invece, la quantità <span class="in">`elpd_diff`</span> è maggiore di due volte il valore dell'errore standard. Questo suggerisce un incremento della capacità predittiva del modello quiando il livello di istruzione della madre viene incluso tra i predittori.</span>
<span id="cb34-432"><a href="#cb34-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-433"><a href="#cb34-433" aria-hidden="true" tabindex="-1"></a>È anche possibile calcolare l'intervallo di credibilità per <span class="in">`elpd_diff`</span>:</span>
<span id="cb34-434"><a href="#cb34-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-437"><a href="#cb34-437" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-438"><a href="#cb34-438" aria-hidden="true" tabindex="-1"></a><span class="fl">15.5</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fu">qnorm</span>(.<span class="dv">95</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fl">6.0</span></span>
<span id="cb34-439"><a href="#cb34-439" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-440"><a href="#cb34-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-441"><a href="#cb34-441" aria-hidden="true" tabindex="-1"></a><span class="fu">## Outlier</span></span>
<span id="cb34-442"><a href="#cb34-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-443"><a href="#cb34-443" aria-hidden="true" tabindex="-1"></a>Si è soliti pensare che la maggior parte delle osservazioni del campione sia prodotta da un unico meccanismo generatore dei dati, mentre le rimanenti osservazioni sono la realizzazione di un diverso processo stocastico. Le osservazioni che appartengono a questo secondo gruppo si chiamano *outlier*. È dunque necessario identificare gli outlier e limitare la loro influenza sull'inferenza.<span class="ot">[^info_criterion-2]</span></span>
<span id="cb34-444"><a href="#cb34-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-445"><a href="#cb34-445" aria-hidden="true" tabindex="-1"></a><span class="ot">[^info_criterion-2]: </span>@McElreath_rethinking nota che, spesso, i ricercatori eliminano i valori anomali prima di adattare un modello ai dati, basandosi solo sulla distanza dal valore medio della variabile dipendente misurata in termini di unità di deviazione standard. Secondo @McElreath_rethinking questo non dovrebbe mai essere fatto: un'osservazione può essere considerata come un valore anomalo o un valore influente solo alla luce delle predizioni di un modello (mai prima di avere adattato il modello ai dati). Se ci sono solo pochi valori anomali una strategia possibile è quella di riportare i risultati delle analisi statistiche svolte su tutto il campione dei dati oppure dopo avere eliminato le osservazioni anomale e influenti.</span>
<span id="cb34-446"><a href="#cb34-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-447"><a href="#cb34-447" aria-hidden="true" tabindex="-1"></a>Poniamoci ora il problema di identificare gli outlier con la tecnica PSIS-LOO-CV. Quando PSIS-LOO-CV viene calcolato con il pacchetto <span class="in">`loo`</span>, l'output riporta il parametro di forma della distribuzione di Pareto (valore <span class="in">`k`</span>). Tale valore può essere utilizzato per identificare gli outlier. Infatti, il valore <span class="in">`k`</span> valuta, per ciascun punto del campione, l'approssimazione usata da PSIS-LOO-CV. Se $k &lt; 0.5$, i pesi di importanza vengono stimati in modo accurato; se il valore $k$ di Pareto di un punto è $&gt; 0.7$, i pesi di importanza possono essere inaccurati. Le osservazioni con $k &gt; 0.7$ sono dunque osservazioni outlier.</span>
<span id="cb34-448"><a href="#cb34-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-449"><a href="#cb34-449" aria-hidden="true" tabindex="-1"></a>Per fare un esempio concreto, introduciamo nel campione dell'esempio precedente una singola osservazione outlier.</span>
<span id="cb34-450"><a href="#cb34-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-453"><a href="#cb34-453" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-454"><a href="#cb34-454" aria-hidden="true" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> df</span>
<span id="cb34-455"><a href="#cb34-455" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(df1)</span>
<span id="cb34-456"><a href="#cb34-456" aria-hidden="true" tabindex="-1"></a>df1<span class="sc">$</span>x1[<span class="dv">434</span>] <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb34-457"><a href="#cb34-457" aria-hidden="true" tabindex="-1"></a>df1<span class="sc">$</span>y[<span class="dv">434</span>] <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb34-458"><a href="#cb34-458" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-459"><a href="#cb34-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-460"><a href="#cb34-460" aria-hidden="true" tabindex="-1"></a>Sistemiamo i dati nel formato appropriato per Stan:</span>
<span id="cb34-461"><a href="#cb34-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-464"><a href="#cb34-464" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-465"><a href="#cb34-465" aria-hidden="true" tabindex="-1"></a>data1a_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb34-466"><a href="#cb34-466" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(df1<span class="sc">$</span>kid_score),</span>
<span id="cb34-467"><a href="#cb34-467" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> df1<span class="sc">$</span>y,</span>
<span id="cb34-468"><a href="#cb34-468" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> df1<span class="sc">$</span>x1</span>
<span id="cb34-469"><a href="#cb34-469" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-470"><a href="#cb34-470" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-471"><a href="#cb34-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-472"><a href="#cb34-472" aria-hidden="true" tabindex="-1"></a>Adattiamo nuovamente il modello 1 ad un campione di dati che contiene un outlier.</span>
<span id="cb34-473"><a href="#cb34-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-474"><a href="#cb34-474" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, results='hide'}</span></span>
<span id="cb34-475"><a href="#cb34-475" aria-hidden="true" tabindex="-1"></a>fit1a <span class="ot">&lt;-</span> mod1<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb34-476"><a href="#cb34-476" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data1a_list,</span>
<span id="cb34-477"><a href="#cb34-477" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb34-478"><a href="#cb34-478" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb34-479"><a href="#cb34-479" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb34-480"><a href="#cb34-480" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb34-481"><a href="#cb34-481" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb34-482"><a href="#cb34-482" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-483"><a href="#cb34-483" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-484"><a href="#cb34-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-487"><a href="#cb34-487" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-488"><a href="#cb34-488" aria-hidden="true" tabindex="-1"></a>loo1a_result <span class="ot">&lt;-</span> fit1a<span class="sc">$</span><span class="fu">loo</span>(<span class="at">cores =</span> <span class="dv">4</span>)</span>
<span id="cb34-489"><a href="#cb34-489" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-490"><a href="#cb34-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-491"><a href="#cb34-491" aria-hidden="true" tabindex="-1"></a>Una tabella diagnostica che riassume le stime dei parametri di forma della distribuzione di Pareto si ottiene nel modo seguente:</span>
<span id="cb34-492"><a href="#cb34-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-495"><a href="#cb34-495" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-496"><a href="#cb34-496" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(loo1a_result)</span>
<span id="cb34-497"><a href="#cb34-497" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-498"><a href="#cb34-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-499"><a href="#cb34-499" aria-hidden="true" tabindex="-1"></a>Un grafico che riporta le stime dei parametri di forma della distribuzione di Pareto per ciascuna osservazione è dato da:</span>
<span id="cb34-500"><a href="#cb34-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-503"><a href="#cb34-503" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-504"><a href="#cb34-504" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(loo1a_result)</span>
<span id="cb34-505"><a href="#cb34-505" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-506"><a href="#cb34-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-507"><a href="#cb34-507" aria-hidden="true" tabindex="-1"></a>Il valore <span class="in">`k`</span> stimato da PSIS-LOO-CV mette chiaramente in luce il fatto che il valore introdotto nel campione è un outlier. L'indice dell'osservazione outlier è identificato con:</span>
<span id="cb34-508"><a href="#cb34-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-511"><a href="#cb34-511" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-512"><a href="#cb34-512" aria-hidden="true" tabindex="-1"></a><span class="fu">pareto_k_ids</span>(loo1a_result, <span class="at">threshold =</span> <span class="fl">0.7</span>)</span>
<span id="cb34-513"><a href="#cb34-513" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-514"><a href="#cb34-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-515"><a href="#cb34-515" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regolarizzazione</span></span>
<span id="cb34-516"><a href="#cb34-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-517"><a href="#cb34-517" aria-hidden="true" tabindex="-1"></a>Abbiamo motivato la presente discussione affermando che uno dei problemi più grandi che i ricercatori devono afforntare è quello della generalizzabilità dei loro risultati. @McElreath_rethinking fa notare che un modo per favorire la capacità del modello di generalizzarsi a nuovi campioni è quello di fare in modo che produca un adattamento *peggiore* ai dati del campione presente. Il problema del sovra-adattamento (e quindi di una bassa generalizzabilità) dipende dal fatto che tutte le regolarità presenti nei dati del campione (e dunque, anche quelle che costituiscono un aspetto idiosincratico del campione presente) "vengono egualmente prese sul serio" da un modello che utilizza prior uniformi per i parametri. In tali circostanze, *qualsiasi* valore dei parametri viene considerato plausibile. Un modo per evitare un tale modo di procedere, che sicuramente è inadeguato, è quello di utilizzare dei prior che @McElreath_rethinking chiama "scettici". I priori "scettici" più comuni sono quelli che hanno una funzione di regolarizzazione. Tali prior, se calibrati correttamente, riducono il sovra-adattamento pur consentendo al modello di rappresentare le regolarità che emergono dai dati del campione. Se il prior è "troppo scettico", tuttavia, le regolarità dei dati campionari non vengono rappresentate dal modello; di conseguenza, ciò produce un sotto-adattamento. Il problema è quello di trovare un equilibrio tra gli opposti pericoli del sovra-adattamento e del sotto-adattamento. La buona notizia è che anche un prior "moderatamente scettico" è in grado di fornire un grande aiuto al modello, e questo è tutto quello che possiamo sperare di ottenere dato che, in generale, non ci sono né modelli ottimali né distribuzioni a priori ottimali (ovvero, modelli e distribuzioni a priori che non possono essere migliorati).</span>
<span id="cb34-518"><a href="#cb34-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-519"><a href="#cb34-519" aria-hidden="true" tabindex="-1"></a>Un esempio di una distribuzione a priori di regolarizzazione può essere fornito facendo riferimento al modello lineare, per esempio. Se standardizziamo i dati, un prior $\beta \sim \mathcal{N}(0, 1)$ per il parametro che codifica la pendenza della retta di regressione ci dice che, prima di osservare i dati, il modello "è molto scettico" rispetto ai valori possibili di $\beta$ esterni all'intervallo $<span class="co">[</span><span class="ot">-2, 2</span><span class="co">]</span>$ deviazioni standard. In altri termini, ritiene che sia molto improbabile che un cambiamento di 1 deviazione standard nella $x$ sia associato ad un cambiamento medio superiore a 2 unità di deviazione standard nella $y$.</span>
<span id="cb34-520"><a href="#cb34-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-521"><a href="#cb34-521" aria-hidden="true" tabindex="-1"></a>Ma potremmo anche usare una distribuzione a priori gaussiana con parametro $\sigma$ uguale a 0.5 oppure a 0.2. Quale prior usare dipende dal modello e dai dati -- non c'è una raccomandazione che risulta sempre valida. L'effetto maggiore dei prior "molto scettici" si manifesta nel caso di modelli complessi e nel caso di piccole numerosità campionarie -- ovvero, proprio nei casi in cui il rischio del sovra-adattamento è più grande. Se invece il campione è sufficientemente grande e il modello non è eccessivamente complesso, i prior, quali essi siano, hanno invece un effetto trascurabile sulla stima della distribuzione a posteriori.</span>
<span id="cb34-522"><a href="#cb34-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-523"><a href="#cb34-523" aria-hidden="true" tabindex="-1"></a><span class="fu">## Commenti e considerazioni finali {.unnumbered}</span></span>
<span id="cb34-524"><a href="#cb34-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-525"><a href="#cb34-525" aria-hidden="true" tabindex="-1"></a>In questo Capitolo, utilizzando Stan insieme al pacchetto <span class="in">`loo`</span>, abbiamo imparato ad usare la convalida incrociata K-fold e la convalida incrociata leave-one-out. Abbiamo esaminato alcuni esempi nei quali la convalida incrociata ci consente di distinguere tra due modelli. In generale, la convalida incrociata si dimostra utile utile quando vengono confrontati modelli piuttosto diversi; quando i modelli sono molto simili, invece, risulta spesso difficile distinguerli con le tecniche qui discusse. In particolare, risulta spesso difficile ottenere risultati conclusivi dal confronto di modelli tramite la convalida incrociata se l'effetto è molto piccolo e/o se il campione di dati è piccolo. In questi casi, alcuni ricercatori ritengono che siano più adatti altri metodi di confronto dei modelli, come ad esempio i fattori di Bayes. L'uso dei fattori di Bayes, tuttavia, è controverso, dato che essi dipendono fortemente dalla scelta delle distribuzioni a priori. Se possibile è preferibile utilizzare le procedure descritte in questa parte della dispensa, con campioni di ampiezza adeguata.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>