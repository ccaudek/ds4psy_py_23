<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Data Science per psicologi - 33&nbsp; Modello gerarchico</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./071_mod_hier_sim.html" rel="next">
<link href="./060_anova.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modello gerarchico</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/data_science/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Benvenuti</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">Prefazione</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./basics.html" class="sidebar-item-text sidebar-link">Parte 1: Nozioni di base</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_key_notions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Concetti chiave</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_measurement.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_freq_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_loc_scale.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_penguins.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Manipolazione e visualizzazione dei dati in <span class="math inline">\(\mathsf{R}\)</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./prob.html" class="sidebar-item-text sidebar-link">Parte 2: Il calcolo delle probabilità</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_prob_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">La logica dell’incerto</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_conditional_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Probabilità condizionata: significato, teoremi, eventi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_bayes_theorem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./018_expval_var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Indici di posizione, di varianza e di associazione di variabili casuali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./019_joint_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./020_density_func.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La densità di probabilità</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./distr.html" class="sidebar-item-text sidebar-link">Parte 3: Distribuzioni di v.c. discrete e continue</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./022_discr_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./023_cont_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./024_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">La funzione di verosimiglianza</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./bayes_inference.html" class="sidebar-item-text sidebar-link">Parte 4: Inferenza bayesiana</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./025_intro_bayes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Credibilità, modelli e parametri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./026_subj_prop.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./029_conjugate_families.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./030_balance_prior_post.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./036_posterior_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Approssimazione della distribuzione a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./040_beta_binomial_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Il modello beta-binomiale in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./041_mcmc_diagnostics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./045_summarize_posterior.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./046_bayesian_prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./050_normal_normal_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./regression.html" class="sidebar-item-text sidebar-link">Parte 5: Regressione lineare</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./051_reglin1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./052_reglin2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Regressione lineare bivariata</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./053_reglin3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Modello di regressione in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./054_reglin4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Inferenza sul modello lineare</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./055_reglin5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./056_pred_check.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Predictive checks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./060_anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Confronto tra le medie di tre o più gruppi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./070_mod_hier.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modello gerarchico</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./071_mod_hier_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Modello gerarchico: simulazioni</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./entropy.html" class="sidebar-item-text sidebar-link">Parte 6: Entropia</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./090_entropy.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Entropia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./091_kl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./092_info_criterion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Criterio di informazione e convalida incrociata</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./frequentist_inference.html" class="sidebar-item-text sidebar-link">Parte 7: Inferenza frequentista</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./220_intro_frequentist.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Legge dei grandi numeri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./221_conf_interv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Intervallo fiduciale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./225_distr_camp_mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Distribuzione campionaria</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./226_test_ipotesi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Significatività statistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./227_ttest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza sulle medie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./228_limiti_stat_frequentista.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./999_refs.html" class="sidebar-item-text sidebar-link">Riferimenti bibliografici</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">Appendici</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a01_math_symbols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a02_number_sets.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a03_set_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Insiemi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a04_summation_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Simbolo di somma (sommatorie)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a05_calculus_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a10_markov_chains.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Le catene di Markov</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a15_stan_lang.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Programmare in Stan</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul>
<li><a href="#la-struttura-dei-dati" id="toc-la-struttura-dei-dati" class="nav-link active" data-scroll-target="#la-struttura-dei-dati"><span class="toc-section-number">33.1</span>  La struttura dei dati</a></li>
  <li><a href="#struttura-nested" id="toc-struttura-nested" class="nav-link" data-scroll-target="#struttura-nested"><span class="toc-section-number">33.2</span>  Struttura Nested</a></li>
  <li><a href="#struttura-non-nested" id="toc-struttura-non-nested" class="nav-link" data-scroll-target="#struttura-non-nested"><span class="toc-section-number">33.3</span>  Struttura Non-Nested</a></li>
  <li><a href="#ragioni-di-utilizzo-della-struttura-gerarchica" id="toc-ragioni-di-utilizzo-della-struttura-gerarchica" class="nav-link" data-scroll-target="#ragioni-di-utilizzo-della-struttura-gerarchica"><span class="toc-section-number">33.4</span>  Ragioni di utilizzo della struttura gerarchica</a></li>
  <li>
<a href="#il-problema-delle-8-scuole" id="toc-il-problema-delle-8-scuole" class="nav-link" data-scroll-target="#il-problema-delle-8-scuole"><span class="toc-section-number">33.5</span>  Il problema delle 8 scuole</a>
  <ul class="collapse">
<li><a href="#modello-di-complete-pooling" id="toc-modello-di-complete-pooling" class="nav-link" data-scroll-target="#modello-di-complete-pooling"><span class="toc-section-number">33.5.1</span>  Modello di <em>complete pooling</em></a></li>
  <li><a href="#modello-no-pooling" id="toc-modello-no-pooling" class="nav-link" data-scroll-target="#modello-no-pooling"><span class="toc-section-number">33.5.2</span>  Modello <em>no pooling</em></a></li>
  <li><a href="#modello-partial-pooling" id="toc-modello-partial-pooling" class="nav-link" data-scroll-target="#modello-partial-pooling"><span class="toc-section-number">33.5.3</span>  Modello <em>partial pooling</em></a></li>
  <li><a href="#modello-gerarchico" id="toc-modello-gerarchico" class="nav-link" data-scroll-target="#modello-gerarchico"><span class="toc-section-number">33.5.4</span>  Modello gerarchico</a></li>
  <li><a href="#interpretazione" id="toc-interpretazione" class="nav-link" data-scroll-target="#interpretazione"><span class="toc-section-number">33.5.5</span>  Interpretazione</a></li>
  </ul>
</li>
  <li>
<a href="#modelli-lineari-ad-intercetta-casuale" id="toc-modelli-lineari-ad-intercetta-casuale" class="nav-link" data-scroll-target="#modelli-lineari-ad-intercetta-casuale"><span class="toc-section-number">33.6</span>  Modelli lineari ad intercetta casuale</a>
  <ul class="collapse">
<li><a href="#modello-ad-effetti-fissi" id="toc-modello-ad-effetti-fissi" class="nav-link" data-scroll-target="#modello-ad-effetti-fissi"><span class="toc-section-number">33.6.1</span>  Modello ad effetti fissi</a></li>
  <li><a href="#modello-gerarchico-1" id="toc-modello-gerarchico-1" class="nav-link" data-scroll-target="#modello-gerarchico-1"><span class="toc-section-number">33.6.2</span>  Modello gerarchico</a></li>
  </ul>
</li>
  <li><a href="#commenti-e-considerazioni-finali" id="toc-commenti-e-considerazioni-finali" class="nav-link" data-scroll-target="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-mod-hier-stan" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modello gerarchico</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Codice</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><div class="cell">

</div>
<section id="la-struttura-dei-dati" class="level2" data-number="33.1"><h2 data-number="33.1" class="anchored" data-anchor-id="la-struttura-dei-dati">
<span class="header-section-number">33.1</span> La struttura dei dati</h2>
<p>Ricordiamo che una delle finalità più comuni di un modello è la specificazione delle relazioni di tipo causa-effetto, allo scopo di interpretare e prevedere i fenomeni reali. Per fare questo, è importante mettere in evidenza, da una molteplicità di informazioni ottenute su numerose unità statistiche, gli aspetti essenziali presenti nei dati. La scelta modello statistico da usare per l’analisi dipende dalle caratteristiche e dalla struttura dei dati.</p>
<p>La struttura dei dati può essere semplice o complessa, e ciò condiziona la scelta del modello statistico da usare per l’analisi.</p>
<ul>
<li>I dati a struttura semplice sono quelli per i quali non si rilevano particolari tipi di dipendenze o l’esistenza di particolari raggruppamenti delle osservazioni.</li>
<li>I dati a struttura complessa sono quelli per i quali le unità statistiche si trovano suddivise in sottoinsiemi all’interno dei quali possono essere specificate ipotesi diverse sulle componenti di errore del modello statistico. Tali raggruppamenti si possono presentare a uno o più livelli.</li>
</ul>
<p>Le strutture complesse dei dati possono essere suddivise tra le cosiddette strutture nested e quelle non-nested.</p>
</section><section id="struttura-nested" class="level2" data-number="33.2"><h2 data-number="33.2" class="anchored" data-anchor-id="struttura-nested">
<span class="header-section-number">33.2</span> Struttura Nested</h2>
<p>Una struttura nested è quella in cui la gerarchia comporta l’esistenza di sottoinsiemi nidificati di osservazioni. In termini matematici una struttura nested è una partizione in gruppi di un insieme di unità. Ad esempio, gli studenti della scuola elementare (livello-1) di una città, sono nested nelle classi (livello-2) in cui studiano, a loro volta nested nelle scuole di appartenenza (livello-3), nested nel distretto di riferimento (livello-4). Nel caso di dati che hanno una struttura nested, le osservazioni individuali non risultano generalmente indipendenti: gli studenti di una stessa classe tendono ad avere un livello di formazione simile, a causa dei processi di selezione o a causa della comune storia che condividono. Una caratteristica fondamentale dei dati con struttura nested è dunque che gli individui che fanno parte del medesimo gruppo sono più somiglianti fra loro rispetto a quelli appartenenti a gruppi diversi.</p>
<p>Un caso particolare di struttura nested è quello delle cosiddette <em>misure ripetute</em>. Le misure ripetute sono un esempio di struttura gerarchica che corrisponde alla situazione nella quale la stessa variabile è misurata in più di una occasione per ogni soggetto. Nell’analisi di dati a misure ripetute gli individui possono essere pensati come unità di secondo livello e le osservazioni ripetute come unità di primo livello.</p>
</section><section id="struttura-non-nested" class="level2" data-number="33.3"><h2 data-number="33.3" class="anchored" data-anchor-id="struttura-non-nested">
<span class="header-section-number">33.3</span> Struttura Non-Nested</h2>
<p>I dati hanno struttura non-nested quando non è definibile una partizione. Un esempio potrebbe derivare dai dati sullo studio di una qualche forma di disagio psicologico di un insieme di persone caratterizzate dal tipo di occupazione, il luogo di residenza e il luogo di lavoro. Questo è un caso non-nested in quanto la classificazione delle unità statistiche in base alle diverse variabili sopra considerate non produce la stessa suddivisione. Nell’esempio precedente di struttura non-nested i deti vengono detti <em>cross-classified</em>. I dati hanno struttura cosiddetta cross-classified quando ogni unità è classificata in base a due o più criteri tra loro non ordinati gerarchicamente.</p>
</section><section id="ragioni-di-utilizzo-della-struttura-gerarchica" class="level2" data-number="33.4"><h2 data-number="33.4" class="anchored" data-anchor-id="ragioni-di-utilizzo-della-struttura-gerarchica">
<span class="header-section-number">33.4</span> Ragioni di utilizzo della struttura gerarchica</h2>
<p>È importante includere nella formulazione del modello i vincoli che derivano dalla struttura dei dati perché ignorare la struttura di raggruppamento sottostante porta ad una violazione del presupposto di indipendenza che alla base dei modelli che abbiamo discusso fino a questo punto: le osservazioni all’interno di un gruppo sono infatti fra loro più simili rispetto a quelle di altri gruppi. I dati che hanno una struttura gerarchica, se vengono analizzati con modelli statistici che ignorano la dipendenza tra le osservazioni può produrre conclusioni fuorvianti. La metodologia multilivello fornisce un insieme di strumenti adatti ad analizzare simultaneamente variabili classificate a livelli differenti di gerarchia, con riferimento a modelli statistici che specificano le varie possibili forme di dipendenza. I modelli multilivello sono in grado di rendere conto dei vari livelli di osservazione: quello relativo all’individuo e quello cosiddetto contestuale che deriva da aggregazioni di individui.</p>
<p>Storicamente, le analisi di dati gerarchicamente organizzati sono state inizialmente realizzate mediante le tecniche standard (come l’analisi della varianza o l’analisi di regressione) spostando tutte le variabili su un solo livello di interesse. Ciò avveniva mediante due distinte procedure: aggregazione e disaggregazione. L’aggregazione è lo spostamento di variabili originariamente osservate su un livello basso della gerarchia verso un livello superiore. Al contrario, la disaggregazione è lo spostamento di variabili verso un livello più basso della gerarchia.</p>
<p>Mediante l’aggregazione dei dati (detta pooling) si ignora la struttura gerarchica dei dati. Si ipotizza che le differenze tra i gruppi siano spiegate solo dalle variabili esplicative <span class="math inline">\(X\)</span> (covariate), ignorando i possibili effetti della struttura gerarchica nei dati. Analizzare variabili che appartengono a differenti livelli della gerarchia su un singolo e comune livello può risultare inadeguato e presentare degli inconvenienti, che diventano tanto più gravi quanto più la gerarchia è rilevante nella spiegazione del fenomeno analizzato. In particolare, l’aggregazione comporta una sostanziale perdita di informazioni e, di conseguenza, l’analisi statistica perde precisione.</p>
<p>Dall’altro, quando i dati vengono disaggregati (no pooling), i test statistici ordinari considerano che i valori disaggregati siano, in genere, informazioni indipendenti provenienti dall’insieme della unità di basso livello: i dati appartenenti a cluster diversi vengono analizzati separatamente. Invece, nelle situazioni in cui i dati sono gerarchicamente organizzati, i diversi cluster di dati non sono in genere indipendenti. <!-- Il comportamento degli individui è influenzato dal contesto nel quale sono inseriti e le caratteristiche di un gruppo sono influenzate dagli individui che formano il gruppo stesso: gli individui e il contesto possono essere visti come un sistema gerarchico di individui e gruppi, nel quale gli individui e i gruppi stanno a livelli diversi.  --> I test statistici tradizionali sono basati sull’assunto di indipendenza tra tutte le osservazioni, e se questa ipotesi risulta violata, le stime degli errori standard, calcolate attraverso le procedure statistiche convenzionali, risultano distorte.</p>
<p>I modelli statistici che consentono di ottenere questo risultato si chiamano lineari misti, o modelli lineari gerarchici/multilivello, e sono diventati uno strumento fondamentale della ricerca sperimentale in psicologia, in linguistica e nelle scienze cognitive, dove i progetti di ricerca a misure ripetute sono la norma. In questo Capitolo esploreremo alcune tecniche che consentono di rendere conto della struttura gerarchica presente nei dati e discuteremo due esempi: il famoso problema delle otto scuole e il modello <em>Random Intercept Model</em>.</p>
</section><section id="il-problema-delle-8-scuole" class="level2" data-number="33.5"><h2 data-number="33.5" class="anchored" data-anchor-id="il-problema-delle-8-scuole">
<span class="header-section-number">33.5</span> Il problema delle 8 scuole</h2>
<p>Il classico problema delle otto scuole <span class="citation" data-cites="rubin1981estimation gelman1995bayesian">(<a href="999_refs.html#ref-rubin1981estimation" role="doc-biblioref">Rubin, 1981</a>; questo esempio è anche discusso nel Capitolo 5 di <a href="999_refs.html#ref-gelman1995bayesian" role="doc-biblioref">Gelman et al., 1995</a>)</span> fornisce uno degli esempi più semplici di dati organizzati in maniera gerarchica e viene spesso usato per illustrare l’utilità di modellazione gerarchica. Il problema considera l’efficacia dei programmi di coaching SAT condotti in parallelo in otto scuole.</p>
<blockquote class="blockquote">
<p>Per conto del Servizio Prove Educative è stato condotto uno studio per analizzare gli effetti di speciali programmi di coaching per SAT-V (Scholastic Attitude Test-Verbal) in ciascuna delle otto scuole superiori. La variabile di esito in ogni studio era il punteggio su un’amministrazione speciale del SAT-V, un test a scelta multipla standardizzato somministrato dall’Educational Testing Service e utilizzato per aiutare i college a prendere decisioni di ammissione; i punteggi possono variare tra 200 e 800, con media circa 500 e deviazione standard circa 100. Gli esami SAT sono progettati per resistere a sforzi a breve termine diretti specificamente al miglioramento delle prestazioni del test; invece sono progettati per riflettere le conoscenze acquisite e le abilità sviluppate in molti anni di istruzione. Tuttavia, ciascuna delle otto scuole in questo studio ha considerato il suo programma di coaching a breve termine molto efficace nell’aumentare i punteggi SAT. Inoltre, non vi era alcuna ragione preliminare per ritenere che uno degli otto programmi fosse più efficace di un altro o che alcuni fossero più simili negli effetti l’uno all’altro che a qualsiasi altro.</p>
</blockquote>
<p>Per ciascuna delle otto scuole (<span class="math inline">\(J\)</span> = 8) abbiamo un effetto del trattamento stimato e un errore standard di stima dell’effetto <span class="math inline">\(\sigma_j\)</span>. I dati sono i seguenti.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">schools</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span></span>
<span>  row.names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"A"</span>,<span class="st">"B"</span>,<span class="st">"C"</span>,<span class="st">"D"</span>,<span class="st">"E"</span>,<span class="st">"F"</span>,<span class="st">"G"</span>,<span class="st">"H"</span><span class="op">)</span>,</span>
<span>  effect <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">28.39</span>,<span class="fl">7.94</span>,<span class="op">-</span><span class="fl">2.75</span>,<span class="fl">6.82</span>,<span class="op">-</span><span class="fl">.64</span>,<span class="fl">.63</span>,<span class="fl">18.01</span>,<span class="fl">12.16</span><span class="op">)</span>,</span>
<span>  sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">14.9</span>, <span class="fl">10.2</span>, <span class="fl">16.3</span>, <span class="fl">11.0</span>, <span class="fl">9.4</span>, <span class="fl">11.4</span>, <span class="fl">10.4</span>, <span class="fl">17.6</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">schools</span></span>
<span><span class="co">#&gt; # A tibble: 8 × 3</span></span>
<span><span class="co">#&gt;   row.names effect sigma</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 A          28.4   14.9</span></span>
<span><span class="co">#&gt; 2 B           7.94  10.2</span></span>
<span><span class="co">#&gt; 3 C          -2.75  16.3</span></span>
<span><span class="co">#&gt; 4 D           6.82  11  </span></span>
<span><span class="co">#&gt; 5 E          -0.64   9.4</span></span>
<span><span class="co">#&gt; 6 F           0.63  11.4</span></span>
<span><span class="co">#&gt; 7 G          18.0   10.4</span></span>
<span><span class="co">#&gt; 8 H          12.2   17.6</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Iniziamo calcolando una misura dell’effetto medio ponderato in cui il punteggio di ogni scuola viene ponderato in base alla precisione della misura (uno sul quadrato dell’errore standard).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">schools</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">schools</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">schools_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">schools</span><span class="op">$</span><span class="va">w</span> <span class="op">*</span> <span class="va">schools</span><span class="op">$</span><span class="va">effect</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">schools</span><span class="op">$</span><span class="va">w</span><span class="op">)</span></span>
<span><span class="va">schools_mean</span></span>
<span><span class="co">#&gt; [1] 7.870546</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Un grafico con i dati (media <span class="math inline">\(\pm\)</span> 1 SE) è fornito di seguito.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="070_mod_hier_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Prima di adattare il modello gerarchico bayesiano, consideriamo due metodi non gerarchici più semplici, i quali stimando gli effetti degli otto esperimenti eseguendo un pooling completo dei dati oppure considerando le scuole come indipendenti (no pooling). Vedremo perché nessuno di questi approcci è adeguato per i dati di questo esempio.</p>
<section id="modello-di-complete-pooling" class="level3" data-number="33.5.1"><h3 data-number="33.5.1" class="anchored" data-anchor-id="modello-di-complete-pooling">
<span class="header-section-number">33.5.1</span> Modello di <em>complete pooling</em>
</h3>
<p>Un esame superficiale dei dati potrebbe suggerire che alcuni programmi di coaching hanno effetti moderati (nell’intervallo 18–28 punti), la maggior parte ha piccoli effetti (0–12 punti) e due hanno piccoli effetti negativi; tuttavia, quando prendiamo atto degli errori standard di questi effetti stimati, vediamo che è difficile distinguere statisticamente tra i risultati di questi esperimenti. Potremmo dunque considerare i risultati degli otto esperimenti come esiti (condizionalmente) indipendenti dello stesso processo generativo. Di conseguenza potremmo decidere di procedere con un’<em>analisi aggregata</em> nella quale le otto scuole sono considerate come un unico campione.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_string</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">  data {</span></span>
<span><span class="st">    int&lt;lower=0&gt; J; // # schools</span></span>
<span><span class="st">    array[J] real y; // estimated treatment</span></span>
<span><span class="st">    array[J] real&lt;lower=0&gt; sigma; // std err of effect</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  parameters {</span></span>
<span><span class="st">    real theta; // pooled school effect</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  model {</span></span>
<span><span class="st">    y ~ normal(theta, sigma);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I dati in un formato appropriato per Stan sono i seguenti.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">school8_dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  J <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">schools</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="va">schools</span><span class="op">$</span><span class="va">effect</span>,</span>
<span>  sigma <span class="op">=</span> <span class="va">schools</span><span class="op">$</span><span class="va">sigma</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Compiliamo il modello descritto in precedenza e eseguiamo il campionamento MCMC.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">model_string</span>, con <span class="op">=</span> <span class="st">"code/hmod_2.stan"</span><span class="op">)</span></span>
<span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"hmod_2.stan"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fit2</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">school8_dat</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">20000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">10000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">84735</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Running MCMC with 4 sequential chains...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Chain 1 finished in 0.2 seconds.</span></span>
<span><span class="co">#&gt; Chain 2 finished in 0.2 seconds.</span></span>
<span><span class="co">#&gt; Chain 3 finished in 0.3 seconds.</span></span>
<span><span class="co">#&gt; Chain 4 finished in 0.2 seconds.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; All 4 chains finished successfully.</span></span>
<span><span class="co">#&gt; Mean chain execution time: 0.2 seconds.</span></span>
<span><span class="co">#&gt; Total execution time: 1.4 seconds.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nel caso di un’analisi per dati aggregati, la nostra incertezza sulla misura dell’effetto comune è di circa 20 punti, se utilizziamo un livello di certezza soggettiva del 95%. Visualizziamo la stima a posteriori con l’istruzione seguente, dove</p>
<ul>
<li>ci_level: 0.8 (80% intervals)</li>
<li>outer_level: 0.95 (95% intervals)</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">output2_stanfit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_csv.html">read_stan_csv</a></span><span class="op">(</span><span class="va">fit2</span><span class="op">$</span><span class="fu">output_files</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">output2_stanfit</span><span class="op">)</span> <span class="op">+</span> <span class="fu">xlim</span><span class="op">(</span><span class="op">-</span><span class="fl">50</span>, <span class="fl">60</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="070_mod_hier_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>In base ad un’analisi aggregata (complete pooling) concludiamo che i dati sono realizzazioni indipendenti di una v.c. <span class="math inline">\(\sim \mathcal{N}(\mu = 7.87, \sigma = 4.20)\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit2</span><span class="op">$</span><span class="fu">summary</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 2 × 10</span></span>
<span><span class="co">#&gt;   variable  mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 lp__     -2.79  -2.52 0.713 0.320 -4.23  -2.28  1.00   37470.   51279.</span></span>
<span><span class="co">#&gt; 2 theta     7.87   7.88 4.20  4.23   0.962 14.7   1.00   28992.   44067.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ma è ragionevole concludere quanto detto sopra? Un primo problema dell’analisi aggregata è che è impossibile fare inferenza sui gruppi, ovvero, nel caso presente, sugli effetti dei diversi metodi di coaching (e questa era la motivazione stessa dell’analisi).</p>
<p>Un secondo problema è più strettamente statistico. Se assumiamo che il processo generativo sia <span class="math inline">\(\mathcal{N}(\mu = 7.87, \sigma = 4.20)\)</span>, allora possiamo chiederci quale sia la probabilità di osservare i dati del campione (o valori ancora più estremi). Il valore più estremo del nostro campione è 28.4. Se il modello generativo fosse <span class="math inline">\(\mathcal{N}(\mu = 7.87, \sigma = 4.20)\)</span>, la probabilità di osservare i dati della scuola 1 sarebbe estremamente piccola.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">28.4</span>, <span class="fl">7.87</span>, <span class="fl">4.20</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 5.090814e-07</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Un’analisi aggregata (modello di complete pooling), dunque, non è neppure in grado di rendere conto dei dati del campione osservato (ci dice che un certo dato non dovrebbe verificarsi; ma l’abbiamo osservato). Il modello di complete pooling, dunque, non sembra adeguato per i dati considerati.</p>
<!-- L'intervallo così trovato corrisponde all'intervallo frequentista al 95%. Infatti, dato che, in questo modello, le osservazioni sono ritenute essere v.c. indipendenti, la varianza di una somma è una somma di varianze.  In questo caso $\sigma$ è il reciproco della varianza, per cui la stima della varianza comune è data da: -->
<!-- ```{r} -->
<!-- var <- 1 / (sum(1 / schools$sigma^2)) -->
<!-- var -->
<!-- ``` -->
<!-- L'intervallo frequentista del 95% sarà dunque -->
<!-- ```{r} -->
<!-- n <- 1 -->
<!-- schools_mean + c(-1, 1) * qnorm(0.975) * sqrt(var / n) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- output2_stanfit -->
<!-- ``` -->
</section><section id="modello-no-pooling" class="level3" data-number="33.5.2"><h3 data-number="33.5.2" class="anchored" data-anchor-id="modello-no-pooling">
<span class="header-section-number">33.5.2</span> Modello <em>no pooling</em>
</h3>
<p>Avendo rifiutato il modello compelte pooling, consideriamo ora il modello che si trova all’estremo opposto (modello no pooling). Eseguiamo dunque un’<em>analisi disaggregata</em> nella quale ogni scuola è trattata in maniera indipendente dalle altre. In linguaggio Stan, il modello no pooling può essere formulato nel modo seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_string</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">  data {</span></span>
<span><span class="st">    int&lt;lower=0&gt; J; // # schools</span></span>
<span><span class="st">    array[J] real y; // estimated treatment</span></span>
<span><span class="st">    array[J] real&lt;lower=0&gt; sigma; // std err of effect</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  parameters {</span></span>
<span><span class="st">    array[J] real theta; // school effect</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  model {</span></span>
<span><span class="st">    y ~ normal(theta, sigma);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Eseguiamo l’analisi.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">model_string</span>, con <span class="op">=</span> <span class="st">"code/hmod_1.stan"</span><span class="op">)</span></span>
<span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"hmod_1.stan"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fit1</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">school8_dat</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">20000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">10000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">84735</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Running MCMC with 4 sequential chains...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Chain 1 finished in 0.5 seconds.</span></span>
<span><span class="co">#&gt; Chain 2 finished in 0.4 seconds.</span></span>
<span><span class="co">#&gt; Chain 3 finished in 0.4 seconds.</span></span>
<span><span class="co">#&gt; Chain 4 finished in 0.4 seconds.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; All 4 chains finished successfully.</span></span>
<span><span class="co">#&gt; Mean chain execution time: 0.5 seconds.</span></span>
<span><span class="co">#&gt; Total execution time: 2.2 seconds.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I risultati sono i seguenti.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit1</span><span class="op">$</span><span class="fu">summary</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 9 × 10</span></span>
<span><span class="co">#&gt;   variable   mean median    sd   mad      q5   q95  rhat ess_bulk ess_tail</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 lp__     -3.99  -3.66   2.00  1.85  -7.78  -1.36  1.00   39035.   56040.</span></span>
<span><span class="co">#&gt; 2 theta[1] 28.3   28.3   14.8  14.8    4.04  52.8   1.00  117783.   64274.</span></span>
<span><span class="co">#&gt; 3 theta[2]  7.92   7.91  10.2  10.2   -8.84  24.7   1.00  116382.   62867.</span></span>
<span><span class="co">#&gt; 4 theta[3] -2.80  -2.79  16.3  16.3  -29.6   23.9   1.00  120074.   61773.</span></span>
<span><span class="co">#&gt; 5 theta[4]  6.83   6.85  11.0  11.0  -11.2   24.8   1.00  114806.   63734.</span></span>
<span><span class="co">#&gt; 6 theta[5] -0.686 -0.685  9.36  9.37 -16.0   14.7   1.00  116956.   63114.</span></span>
<span><span class="co">#&gt; 7 theta[6]  0.642  0.618 11.3  11.4  -18.0   19.3   1.00  113520.   62691.</span></span>
<span><span class="co">#&gt; 8 theta[7] 18.0   18.0   10.5  10.5    0.656 35.2   1.00  114082.   61308.</span></span>
<span><span class="co">#&gt; # … with 1 more row</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Visualizziamo l’incertezza delle stime a posteriori.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">output_stanfit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_csv.html">read_stan_csv</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">$</span><span class="fu">output_files</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si vede che le stime degli effetti degli otto esperimenti producono intervalli di credibilità al 95% che sono quasi completamente sovrapposti. L’ampiezza degli intervalli, ad un grado di certezza soggettiva del 95%, è di circa 50 punti.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">output_stanfit</span><span class="op">)</span> <span class="op">+</span> <span class="fu">xlim</span><span class="op">(</span><span class="op">-</span><span class="fl">50</span>, <span class="fl">60</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="070_mod_hier_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Dal momento che ciascuna stima dipende <em>unicamente</em> dai dati di una singola osservazione, l’inferenza sui parametri sconosciuti del modello no pooling è estremamente rumorosa.</p>
</section><section id="modello-partial-pooling" class="level3" data-number="33.5.3"><h3 data-number="33.5.3" class="anchored" data-anchor-id="modello-partial-pooling">
<span class="header-section-number">33.5.3</span> Modello <em>partial pooling</em>
</h3>
<p>Avendo concluso che i modelli complete pooling e non-pooling sono inadeguati, consideriamo ora un modello gerarchico. In generale, i modelli gerarchici sono basati sulla seguente idea: sebbene ogni gruppo sia unico, essendo stato campionato dalla stessa popolazione, tutti i gruppi sono collegati e quindi potrebbero contenere informazioni preziose l’uno sull’altro. Questa informazione gerarchica è fornita dagli <em>iper-parametri</em> del modello.</p>
<p>La struttura ipotizzata da un modello gerarchico per i dati considerati è la seguente. Il modello gerarchico ipotizza che il risultato di ciascuna scuola sia la realizzazione di una v.c. avente media <span class="math inline">\(\theta_j\)</span>. L’oggetto dell’inferenza sono i valori <span class="math inline">\(\theta_j\)</span>, con <span class="math inline">\(i = 1, \dots, 8\)</span>. Il modello gerarchico ipotizza che i parametri <span class="math inline">\(\theta_j\)</span> siano tra loro legati in qualche modo. In maniera più precisa, il modello assume che <span class="math inline">\(\theta_j\)</span> siano realizzazioni casuali dei un unico processo generativo sottostante. Il modello assume che tale processo generativo abbia la seguente forma: <span class="math inline">\(\mathcal{N}(\mu, \tau)\)</span>. I parametri <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\tau\)</span> sono detti <em>iper-parametri</em> e condizionano i valori possibili che i parametri <span class="math inline">\(\theta_j\)</span> possono assumere. Nella versione più semplice di questo modello gerarchico, l’iper-parametro <span class="math inline">\(\mu\)</span> viene considerato ignoto ma <span class="math inline">\(\tau\)</span> viene assunto come conosciuto. Ciò conduce alla formulazione del modello partial pooling. Nel caso presente assumiamo <span class="math inline">\(\tau = 25\)</span>.</p>
<p>Inseriamo in input a Stan l’informazione relativa a <span class="math inline">\(\tau\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">school8_dat2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  J <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">schools</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="va">schools</span><span class="op">$</span><span class="va">effect</span>,</span>
<span>  sigma <span class="op">=</span> <span class="va">schools</span><span class="op">$</span><span class="va">sigma</span>,</span>
<span>  tau <span class="op">=</span> <span class="fl">25</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Formuliamo il modello di partial pooling nel modo seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_string</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">  data {</span></span>
<span><span class="st">    int&lt;lower=0&gt; J; // # schools</span></span>
<span><span class="st">    array[J] real y; // estimated treatment</span></span>
<span><span class="st">    array[J] real&lt;lower=0&gt; sigma; // std err of effect</span></span>
<span><span class="st">    real&lt;lower=0&gt; tau; // variance between schools</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  parameters {</span></span>
<span><span class="st">    array[J] real theta; // school effect</span></span>
<span><span class="st">    real mu; // mean for schools</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  model {</span></span>
<span><span class="st">    mu ~ normal(0, 15);</span></span>
<span><span class="st">    theta ~ normal(mu, tau);</span></span>
<span><span class="st">    y ~ normal(theta, sigma);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Eseguiamo l’analisi.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">model_string</span>, con <span class="op">=</span> <span class="st">"code/hmod_3.stan"</span><span class="op">)</span></span>
<span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"hmod_3.stan"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fit3</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">school8_dat2</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">20000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">10000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">84735</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Running MCMC with 4 sequential chains...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Chain 1 finished in 0.5 seconds.</span></span>
<span><span class="co">#&gt; Chain 2 finished in 0.5 seconds.</span></span>
<span><span class="co">#&gt; Chain 3 finished in 0.5 seconds.</span></span>
<span><span class="co">#&gt; Chain 4 finished in 0.5 seconds.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; All 4 chains finished successfully.</span></span>
<span><span class="co">#&gt; Mean chain execution time: 0.5 seconds.</span></span>
<span><span class="co">#&gt; Total execution time: 2.3 seconds.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Esaminiamo la distribuzione a posteriori delle stime dei parametri.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">output3_stanfit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_csv.html">read_stan_csv</a></span><span class="op">(</span><span class="va">fit3</span><span class="op">$</span><span class="fu">output_files</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">output3_stanfit</span><span class="op">)</span> <span class="op">+</span> <span class="fu">xlim</span><span class="op">(</span><span class="op">-</span><span class="fl">50</span>, <span class="fl">60</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="070_mod_hier_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Per il modello di partial pooling, ad un livello di certezza soggettiva del 95%, le stime a posteriori dei parametri <span class="math inline">\(\theta_j\)</span> sono comprese in un intervallo pari a circa 40 punti. Si noti che, in relazione al modello no pooling, è diminuita la nostra incertezza rispetto alle stime dei parametri <span class="math inline">\(\theta_j\)</span>.</p>
</section><section id="modello-gerarchico" class="level3" data-number="33.5.4"><h3 data-number="33.5.4" class="anchored" data-anchor-id="modello-gerarchico">
<span class="header-section-number">33.5.4</span> Modello gerarchico</h3>
<p>Il modello di partial pooling assume che la dispersione dei parametri <span class="math inline">\(\theta_j\)</span> sia conosciuta. Ma ovviamente ciò non è vero. Arriviamo così alla formulazione del modello gerarchico nel quale vengono stimati entrambi gli iper-parametri <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\tau\)</span>, dove <span class="math inline">\(\mu\)</span> rappresenta l’effetto medio del trattamento e <span class="math inline">\(\tau\)</span> descrive la varianza tra le scuole. Il modello gerarchico è dunque il seguente.</p>
<p><span class="math display">\[
\begin{align}
y_j &amp;\sim \mathcal{N}(\theta_j, \sigma_j), \quad j = 1, \dots, 8\notag\\
\theta_j &amp;\sim \mathcal{N}(\mu, \tau), \quad j = 1, \dots, 8
\end{align}
\]</span></p>
<p>dove ciascun <span class="math inline">\(\sigma_j\)</span> è considerato noto.</p>
<p>Lo scriviamo in linguaggio Stan nel modo seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model_string</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">  data {</span></span>
<span><span class="st">    int&lt;lower=0&gt; J; // # schools</span></span>
<span><span class="st">    array[J] real y; // estimated treatment</span></span>
<span><span class="st">    array[J] real&lt;lower=0&gt; sigma; // std err of effect</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  parameters {</span></span>
<span><span class="st">    array[J] real theta; // school effect</span></span>
<span><span class="st">    real mu; // mean for schools</span></span>
<span><span class="st">    real&lt;lower=0&gt; tau; // variance between schools</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  model {</span></span>
<span><span class="st">    mu ~ normal(0, 15);</span></span>
<span><span class="st">    tau ~ cauchy(0, 30);</span></span>
<span><span class="st">    theta ~ normal(mu, tau);</span></span>
<span><span class="st">    y ~ normal(theta, sigma);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Eseguiamo l’analisi.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">model_string</span>, con <span class="op">=</span> <span class="st">"code/hmod_4.stan"</span><span class="op">)</span></span>
<span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"hmod_4.stan"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fit4</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">school8_dat</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">20000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">10000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">84735</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Running MCMC with 4 sequential chains...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Chain 1 finished in 1.1 seconds.</span></span>
<span><span class="co">#&gt; Chain 2 finished in 1.2 seconds.</span></span>
<span><span class="co">#&gt; Chain 3 finished in 0.9 seconds.</span></span>
<span><span class="co">#&gt; Chain 4 finished in 1.0 seconds.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; All 4 chains finished successfully.</span></span>
<span><span class="co">#&gt; Mean chain execution time: 1.1 seconds.</span></span>
<span><span class="co">#&gt; Total execution time: 4.4 seconds.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Le stime dei parametri sono le seguenti.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">output4_stanfit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_csv.html">read_stan_csv</a></span><span class="op">(</span><span class="va">fit4</span><span class="op">$</span><span class="fu">output_files</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">output4_stanfit</span>, pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"theta"</span>, <span class="st">"mu"</span>, <span class="st">"tau"</span><span class="op">)</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.025</span>, <span class="fl">.5</span>, <span class="fl">.975</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Inference for Stan model: hmod_4-202212211126-1-38dc66.</span></span>
<span><span class="co">#&gt; 4 chains, each with iter=30000; warmup=10000; thin=1; </span></span>
<span><span class="co">#&gt; post-warmup draws per chain=20000, total post-warmup draws=80000.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;           mean se_mean   sd   2.5%  50% 97.5% n_eff Rhat</span></span>
<span><span class="co">#&gt; theta[1] 10.23    0.50 7.93  -2.14 9.06 29.52   248 1.02</span></span>
<span><span class="co">#&gt; theta[2]  7.14    0.26 6.05  -4.70 6.98 19.59   536 1.01</span></span>
<span><span class="co">#&gt; theta[3]  5.61    0.12 7.34 -10.90 5.81 19.56  3766 1.00</span></span>
<span><span class="co">#&gt; theta[4]  6.87    0.30 6.29  -5.61 6.78 19.77   439 1.01</span></span>
<span><span class="co">#&gt; theta[5]  4.89    0.11 6.04  -8.37 5.05 16.10  3163 1.00</span></span>
<span><span class="co">#&gt; theta[6]  5.54    0.18 6.46  -8.42 5.61 17.88  1317 1.01</span></span>
<span><span class="co">#&gt; theta[7]  9.49    0.48 6.66  -1.65 8.86 24.66   193 1.03</span></span>
<span><span class="co">#&gt; theta[8]  7.60    0.22 7.35  -6.79 7.24 23.62  1159 1.01</span></span>
<span><span class="co">#&gt; mu        6.94    0.29 4.71  -2.09 6.92 16.43   272 1.02</span></span>
<span><span class="co">#&gt; tau       5.93    0.39 4.85   0.64 4.74 18.11   154 1.03</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Samples were drawn using NUTS(diag_e) at Wed Dec 21 11:26:35 2022.</span></span>
<span><span class="co">#&gt; For each parameter, n_eff is a crude measure of effective sample size,</span></span>
<span><span class="co">#&gt; and Rhat is the potential scale reduction factor on split chains (at </span></span>
<span><span class="co">#&gt; convergence, Rhat=1).</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Visualizziamo la distribuzione a posteriori delle stime dei parametri e degli iper-parametri.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">output4_stanfit</span><span class="op">)</span> <span class="op">+</span> <span class="fu">xlim</span><span class="op">(</span><span class="op">-</span><span class="fl">50</span>, <span class="fl">60</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="070_mod_hier_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Con un grado di certezza soggettiva del 95%, le stime a posteriori dei parametri <span class="math inline">\(\theta_j\)</span> risultano comprese in un intervallo pari a circa 30 punti. Il modello gerarchico, dunque, produce stime degli effetti <span class="math inline">\(\theta_j\)</span> a cui è associata l’incertezza più piccola rispetto a tutti gli altri casi esaminati in precedenza.</p>
</section><section id="interpretazione" class="level3" data-number="33.5.5"><h3 data-number="33.5.5" class="anchored" data-anchor-id="interpretazione">
<span class="header-section-number">33.5.5</span> Interpretazione</h3>
<p>In conclusione, il modello gerarchico consente di ottenere stime degli effetti <span class="math inline">\(\theta_j\)</span> degli otto esperimenti più precise di quelle ottenute dal modelo non gerarchico no-pooling e dal modello gerarchico di partial pooling. Si noti inoltre che, con <span class="math inline">\(\tau \rightarrow \infty\)</span>, le stime di un modello gerarchico diventano sempre più simili a quelle di un modello no-pooling, vale a dire, ciascuna delle stime dell’effetto del trattamento della scuola diventa via via più indipendente dalle altre stime. Con <span class="math inline">\(\tau \rightarrow 0\)</span>, le stime di un modello gerarchico diventano sempre più simili alle stime di un modello di pooling completo, vale a dire, tutti gli effetti del trattamento della scuola tendono a diventare via via più simili all’effetto medio del gruppo.</p>
</section></section><section id="modelli-lineari-ad-intercetta-casuale" class="level2" data-number="33.6"><h2 data-number="33.6" class="anchored" data-anchor-id="modelli-lineari-ad-intercetta-casuale">
<span class="header-section-number">33.6</span> Modelli lineari ad intercetta casuale</h2>
<p>Esaminiamo ora un modello gerarchico più complesso per l’analisi di un set di dati a misure ripetute con due condizioni. I dati sono stati raccolti da <span class="citation" data-cites="gibson2013processing sorensen2015bayesian">(<a href="999_refs.html#ref-gibson2013processing" role="doc-biblioref">Gibson &amp; Wu, 2013</a>; si veda <a href="999_refs.html#ref-sorensen2015bayesian" role="doc-biblioref">Sorensen &amp; Vasishth, 2015</a>)</span>. La variabile dipendente <code>rt</code> dell’esperimento di <span class="citation" data-cites="gibson2013processing">Gibson &amp; Wu (<a href="999_refs.html#ref-gibson2013processing" role="doc-biblioref">2013</a>)</span> è il tempo di lettura in millisecondi del soggetto di una proposizione relativa in un testo. I tempi di reazione sono stati registrati in due condizioni: in presenza di un sostantivo riferito al soggetto della proposizione, oppure in presenza di un sostantivo riferito all’oggetto della proposizione.</p>
<p>I dati di <span class="citation" data-cites="gibson2013processing">Gibson &amp; Wu (<a href="999_refs.html#ref-gibson2013processing" role="doc-biblioref">2013</a>)</span> provengono da un esperimento con 37 soggetti e 15 item. Gli item erano presentati in un disegno a quadrato latino (ovvero, un disegno nel quale vengono considerate tutte le combinazioni possibili), il che produce 37 <span class="math inline">\(\times\)</span> 15 = 555 dati. Risultano mancanti otto dati di un soggetto (id 27), il che porta ad un totale di 555 − 8 = 547 dati. Le prime righe del data.frame sono mostrate di seguito:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rdat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org//reference/here.html">here</a></span><span class="op">(</span><span class="st">"data"</span>, <span class="st">"gibsonwu2012data.txt"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">rdat</span><span class="op">)</span></span>
<span><span class="co">#&gt;    subj item     type pos word correct   rt region            type2</span></span>
<span><span class="co">#&gt; 7     1   13  obj-ext   6 抓住       - 1140    de1  object relative</span></span>
<span><span class="co">#&gt; 20    1    6 subj-ext   6 男孩       - 1197    de1 subject relative</span></span>
<span><span class="co">#&gt; 32    1    5  obj-ext   6   撞       -  756    de1  object relative</span></span>
<span><span class="co">#&gt; 44    1    9  obj-ext   6 監視       -  643    de1  object relative</span></span>
<span><span class="co">#&gt; 60    1   14 subj-ext   6 機師       -  860    de1 subject relative</span></span>
<span><span class="co">#&gt; 73    1    4 subj-ext   6 男孩       -  868    de1 subject relative</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La manipolazione sperimentale viene descritta dalla variabile <code>type</code> (oppure, in maniera equivalente, dalla variabile <code>type2</code>). Nell’analisi, <code>type</code> viene ricodificata nella colonna <code>so</code> la quale assume valore -0.5 se il sostantivo era riferito al soggetto e +0.5 se il sostantivo era riferito all’oggetto della frase.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rdat</span><span class="op">$</span><span class="va">so</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">rdat</span><span class="op">$</span><span class="va">type</span> <span class="op">==</span> <span class="st">"subj-ext"</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">rdat</span><span class="op">$</span><span class="va">so</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1]  0.5 -0.5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcoliamo la media dei tempi di reazione su scala logaritmica e per poi ritrasformare il risultato sulla scala originale:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rdat</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">type2</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">summarise</span><span class="op">(</span></span>
<span>    avg <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">rt</span><span class="op">)</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 2 × 2</span></span>
<span><span class="co">#&gt;   type2              avg</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;            &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 object relative   551.</span></span>
<span><span class="co">#&gt; 2 subject relative  589.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Quando il sostantivo si riferisce al soggetto, i tempi di reazione sono più lenti di circa 30 ms.</p>
<p>Questa descrizione dei dati, però non tiene conto né delle differenze tra i soggetti né delle differenze tra gli item. Per tenere in considerazioni queste diverse fonti della variabilità dei dati è necessario utilizzare un modello gerarchico.</p>
<section id="modello-ad-effetti-fissi" class="level3" data-number="33.6.1"><h3 data-number="33.6.1" class="anchored" data-anchor-id="modello-ad-effetti-fissi">
<span class="header-section-number">33.6.1</span> Modello ad effetti fissi</h3>
<p>Iniziamo con un modello “ad effetti fissi” che non tiene conto della struttura gerarchica dei dati, ovvero del fatto che c’è una covariazione all’interno dei cluster definiti dalle variabili “soggetto” e “item”.</p>
<p>Ipotizziamo dunque di descrivere i dati mediante il seguente modello di regressione lineare:</p>
<span class="math display">\[\begin{equation}
\log rt_i = \beta_0 + \beta_1 so_i + \varepsilon_i.
\end{equation}\]</span>
<p>Questo è il caso nel quale usiamo il modello lineare per fare inferenza sulla differenza tra le medie di due gruppi. In precedenza abbiamo codificato i due gruppi con 0 e 1. In tali circostanze <span class="math inline">\(\alpha\)</span> fornisce una stima del valore atteso della media del gruppo codificato con <span class="math inline">\(x = 0\)</span> e il parametro <span class="math inline">\(\beta\)</span> fornisce una stima del valore atteso della differenza tra le medie dei due gruppi.</p>
<p>La codifica -0.5 e +0.5 per le due modalità della variabile <code>so</code> ha un effetto simile. Il parametro <span class="math inline">\(\alpha\)</span> del modello di regressione lineare fornisce una stima del valore atteso della media di tutti i valori <span class="math inline">\(y\)</span> (trascurando la classificazione in gruppi) mentre, come in precedenza, il parametro <span class="math inline">\(\beta\)</span> fornisce una stima del valore atteso della differenza tra le medie dei due gruppi.</p>
<p>I tempi di reazione (variabile dipendente <code>rt</code>, ovvero tempo di lettura) hanno una distribuzione caratterizzata da una forte asimmetria positiva. Se trasformiamo i dati in maniera logaritmica, i dati trasformati si distribuiscono in maniera approssimativamente Normale. In maniera equivalente, si può dire che i dati grezzi seguono la distribuzione lognormale.</p>
<p>Il modello di regressione lineare assume dunque la forma seguente:</p>
<span class="math display">\[\begin{equation}
rt \sim \mbox{LogNormal}(\beta_0 + \beta_1 so,\sigma).
\end{equation}\]</span>
<p>In tale modello <span class="math inline">\(\beta_0\)</span> corrisponde al valore atteso della media generale di <span class="math inline">\(\log\)</span> <code>rt</code> e <span class="math inline">\(\beta_1 so\)</span> codifica la differenza <span class="math inline">\(\E(\log rt_{o}) - \E(\log rt_{s})\)</span> quando si passa dalla condizione nella quale il sostantivo è riferito all’oggetto alla condizione nella quale il sostantivo è riferito al soggetto – valori negativi significano che i tempi di reazioni sono maggiori nella condizione <code>s</code> che nella condizione <code>o</code>.</p>
<p>Ricordiamo che questo non è un modello gerarchico, ma un semplice modello di regressione lineare nel quale assumiamo che la componente erratica del modello segua una distribuzione lognormale.</p>
<p>In un tale modello useremo le seguenti distribuzioni a priori:</p>
<span class="math display">\[\begin{equation}
\begin{aligned}
\beta[1] &amp;\sim Normal(6, 1.5) \\
\beta[2] &amp;\sim Normal(0, 1.0) \\
\sigma &amp;\sim Cauchy(0, 1)\\
\end{aligned}
\end{equation}\]</span>
<!-- https://bayesball.github.io/BOOK/bayesian-hierarchical-modeling.html#hierarchical-normal-modeling -->
<!-- https://vasishth.github.io/bayescogsci/book/sec-trial.html -->
<p>In Stan, il modello precedente è specificato nel modo seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">modelString</span> <span class="op">=</span> <span class="st">"</span></span>
<span><span class="st">  data {</span></span>
<span><span class="st">    int&lt;lower=1&gt; N; //number of data points</span></span>
<span><span class="st">    array[N] real rt; //reading time</span></span>
<span><span class="st">    array[N] real&lt;lower=-0.5, upper=0.5&gt; so; //predictor</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  parameters {</span></span>
<span><span class="st">    vector[2] beta; //fixed intercept and slope</span></span>
<span><span class="st">    real&lt;lower=0&gt; sigma_e; //error sd</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  model {</span></span>
<span><span class="st">    real mu;</span></span>
<span><span class="st">    // likelihood</span></span>
<span><span class="st">    beta[1] ~ normal(6, 1.5);</span></span>
<span><span class="st">    beta[2] ~ normal(0, 1);</span></span>
<span><span class="st">    sigma_e ~ cauchy(0, 1);</span></span>
<span><span class="st">    for (i in 1 : N) {</span></span>
<span><span class="st">      mu = beta[1] + beta[2] * so[i];</span></span>
<span><span class="st">      rt[i] ~ lognormal(mu, sigma_e);</span></span>
<span><span class="st">    }</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">modelString</span>, con <span class="op">=</span> <span class="st">"code/fixeff_model.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Compiliamo il modello.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"fixeff_model.stan"</span><span class="op">)</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I dati sono contenuti nella lista <code>stan_dat</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">stan_dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  rt <span class="op">=</span> <span class="va">rdat</span><span class="op">$</span><span class="va">rt</span>,</span>
<span>  so <span class="op">=</span> <span class="va">rdat</span><span class="op">$</span><span class="va">so</span>,</span>
<span>  N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">rdat</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Eseguiamo il campionamento MCMC.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit3</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">stan_dat</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">4000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">2000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="va">SEED</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Otteniamo dunque le seguenti medie a posteriori.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit3</span><span class="op">$</span><span class="fu">summary</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 4 × 10</span></span>
<span><span class="co">#&gt;   variable       mean     median      sd     mad       q5      q95  rhat ess_b…¹</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 lp__     -2614.     -2614.     1.22    0.993   -2.62e+3 -2.61e+3  1.00   8108.</span></span>
<span><span class="co">#&gt; 2 beta[1]      6.35       6.34   0.0121  0.0121   6.33e+0  6.37e+0  1.00  16919.</span></span>
<span><span class="co">#&gt; 3 beta[2]     -0.0653    -0.0652 0.0241  0.0237  -1.05e-1 -2.52e-2  1.00  15675.</span></span>
<span><span class="co">#&gt; 4 sigma_e      0.629      0.629  0.00850 0.00861  6.15e-1  6.43e-1  1.00  16349.</span></span>
<span><span class="co">#&gt; # … with 1 more variable: ess_tail &lt;dbl&gt;, and abbreviated variable name</span></span>
<span><span class="co">#&gt; #   ¹​ess_bulk</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Trasformiamo <code>fit3</code> in un oggetto di classe <code>stanfit</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">stanfit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_csv.html">read_stan_csv</a></span><span class="op">(</span><span class="va">fit3</span><span class="op">$</span><span class="fu">output_files</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcoliamo gli intervalli di credibilità al 95%.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ci95</span> <span class="op">&lt;-</span> <span class="fu">rstanarm</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstantools/reference/posterior_interval.html">posterior_interval</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">stanfit</span><span class="op">)</span>,</span>
<span>  prob <span class="op">=</span> <span class="fl">0.95</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">ci95</span>, <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt;              2.5%     97.5%</span></span>
<span><span class="co">#&gt; beta[1]     6.321     6.369</span></span>
<span><span class="co">#&gt; beta[2]    -0.113    -0.017</span></span>
<span><span class="co">#&gt; sigma_e     0.613     0.646</span></span>
<span><span class="co">#&gt; lp__    -2617.020 -2612.420</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Se esponenziamo i dati su scala lognormale ritorniamo alla scala dei dati grezzi. L’effetto medio, sulla scala in millisecondi, si trova dunque nel modo seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract</span><span class="op">(</span><span class="va">stanfit</span>, permuted <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">post</span><span class="op">$</span><span class="va">beta</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">beta</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">post</span><span class="op">$</span><span class="va">beta</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -35.99588</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Se ignoriamo la struttura gerarchica dei dati, concludiamo che l’effetto della manipolazione sperimentale corrisponde ad una differenza medie nel tempo di lettura nelle due condizioni di 36 ms, con tempi di lettura maggiore quando il sostantivo era riferito al soggetto della proposizione.</p>
</section><section id="modello-gerarchico-1" class="level3" data-number="33.6.2"><h3 data-number="33.6.2" class="anchored" data-anchor-id="modello-gerarchico-1">
<span class="header-section-number">33.6.2</span> Modello gerarchico</h3>
<p>Un modello non gerarchico (detto ad effetti fissi) è inappropriato per il campione di <span class="citation" data-cites="gibson2013processing">Gibson &amp; Wu (<a href="999_refs.html#ref-gibson2013processing" role="doc-biblioref">2013</a>)</span> perché non tiene conto del fatto che i dati sono a misure ripetute, ovvero, con più ripetizioni per ogni soggetto e per ogni item. Il modello ad effetti usato sopra viola l’assunzione di indipendenza degli errori. Inoltre, i coefficienti di effetti fissi <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_1\)</span> rappresentano le medie calcolate aggregando i dati sulla dimensione dei soggetti e degli item. Così facendo, non si tiene in considerazione il fatto che alcuni soggetti sono più veloci e altri più lenti della media, e il fatto che alcuni item sono stati letti più velocemente e altri in maniera più lenta della media. Ovvero, il modello non considera informazioni che sono presenti nei dati.</p>
<p>Un modello gerarchico, invece, rende conto delle diverse fonti di variabilità che derivano da questo disegno sperimentale, ovvero la variabilità dovuta alle differenze tra i soggetti e la variabilità dovuta alle differenze tra gli item. Per rendere conto di queste fonti di variabilità nei dati, vengono aggiunti al modello di regressione lineare due nuovi termini: <span class="math inline">\(u_{0j}\)</span> e <span class="math inline">\(w_{0k}\)</span>. Tali termini “aggiustano” <span class="math inline">\(\beta_0\)</span> in modo tale da stimare una componente specifica della variabile risposta dovuta al soggetto <span class="math inline">\(j\)</span>-esimo e all’item <span class="math inline">\(k\)</span>-esimo.</p>
<p>Questa formulazione del modello scompone parzialmente la componente d’errore <span class="math inline">\(\varepsilon_i\)</span> nella somma dei termini <span class="math inline">\(u_{0j}\)</span> e <span class="math inline">\(w_{0k}\)</span>. Geometricamente, i termini <span class="math inline">\(u_{0j}\)</span> e <span class="math inline">\(w_{0k}\)</span> corrispondono ad aggiustamenti dell’intercetta <span class="math inline">\(\beta_0\)</span> che sono specifici per il soggetto <span class="math inline">\(j\)</span>-esimo e per l’item <span class="math inline">\(k\)</span>-esimo.</p>
<p>Se il soggetto <span class="math inline">\(j\)</span>-esimo è più lento della media di tutti i soggetti, allora il parametro <span class="math inline">\(u_j\)</span> sarà un numero positivo. Se l’item <span class="math inline">\(k\)</span>-esimo viene letto più velocemente del tempo di lettura medio di tutti gli item, allora il parametro <span class="math inline">\(w_k\)</span> sarà un numero negativo. Viene stimato un aggiustamento <span class="math inline">\(u_{0j}\)</span> per ogni soggetto <span class="math inline">\(j\)</span>-esimo e un aggiustamento <span class="math inline">\(w_{0k}\)</span> per ogni item <span class="math inline">\(k\)</span>-esimo. I parametri <span class="math inline">\(u_{0j}\)</span> e <span class="math inline">\(w_{0k}\)</span> sono chiamati <em>random intercepts</em> o <em>varying intercepts</em> <span class="citation" data-cites="gelman2020regression">(<a href="999_refs.html#ref-gelman2020regression" role="doc-biblioref">Gelman et al., 2020</a>)</span>. L’aggiustamento di <span class="math inline">\(\beta_0\)</span> mediante <span class="math inline">\(u_{0j}\)</span> e <span class="math inline">\(w_{0k}\)</span> consente dunque di tenere in considerazione la struttura gerarchica dei dati, ovvero consente di stimare la quota di variabilità dovuta ai soggetti e agli item.</p>
<p>Il random intercept model assume che gli aggiustamenti <span class="math inline">\(u_{0j}\)</span> e <span class="math inline">\(w_{0k}\)</span> siano distribuiti normalmente attorno allo zero con una deviazione standard sconosciuta:</p>
<p><span class="math display">\[
u_0 ∼ \mathcal{N}(0, \sigma_u),
\]</span></p>
<p><span class="math display">\[
w_0 ∼ \mathcal{N}(0, \sigma_w).
\]</span></p>
<p>Il modello include dunque tre fonti di varianza:</p>
<ul>
<li>la deviazione standard degli errori <span class="math inline">\(\sigma_e\)</span>,</li>
<li>la deviazione standard delle <em>random intercepts</em> per i soggetti, <span class="math inline">\(\sigma_u\)</span>,</li>
<li>la deviazione standard delle <em>random intercepts</em> per gli item, <span class="math inline">\(\sigma_w\)</span>.</li>
</ul>
<p>Queste tre fonti di variabilità sono dette <em>componenti della varianza</em>. Possiamo dunque scrivere il modello nel modo seguente:</p>
<span class="math display">\[\begin{equation}
\log rt_{ijk} = \beta_0 + \beta_1 so_i + u_{0j} + w_{0k} + \varepsilon_{ijk}.
\end{equation}\]</span>
<p>Il coefficiente <span class="math inline">\(\beta_1\)</span> è il parametro di interesse primario. Come conseguenza della codifica usata, avrà il valore <span class="math inline">\(-\beta_1\)</span> nella condizione in cui il sostantivo è riferito al soggetto e <span class="math inline">\(+\beta_1\)</span> nella condizione in cui il sostantivo è riferito all’oggetto della frase.</p>
<p>In Stan il modello viene formulato nel modo seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">modelString</span> <span class="op">=</span> <span class="st">"</span></span>
<span><span class="st">  data {</span></span>
<span><span class="st">    int&lt;lower=1&gt; N; //number of data points</span></span>
<span><span class="st">    array[N] real rt; //reading time</span></span>
<span><span class="st">    array[N] real&lt;lower=-0.5, upper=0.5&gt; so; //predictor</span></span>
<span><span class="st">    int&lt;lower=1&gt; J; //number of subjects</span></span>
<span><span class="st">    int&lt;lower=1&gt; K; //number of items</span></span>
<span><span class="st">    array[N] int&lt;lower=1, upper=J&gt; subj; //subject id</span></span>
<span><span class="st">    array[N] int&lt;lower=1, upper=K&gt; item; //item id</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  parameters {</span></span>
<span><span class="st">    vector[2] beta; //fixed intercept and slope</span></span>
<span><span class="st">    vector[J] u; //subject intercepts</span></span>
<span><span class="st">    vector[K] w; //item intercepts</span></span>
<span><span class="st">    real&lt;lower=0&gt; sigma_e; //error sd</span></span>
<span><span class="st">    real&lt;lower=0&gt; sigma_u; //subj sd</span></span>
<span><span class="st">    real&lt;lower=0&gt; sigma_w; //item sd</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  model {</span></span>
<span><span class="st">    real mu;</span></span>
<span><span class="st">    //priors</span></span>
<span><span class="st">    u ~ normal(0, sigma_u); //subj random effects</span></span>
<span><span class="st">    w ~ normal(0, sigma_w); //item random effects</span></span>
<span><span class="st">    // likelihood</span></span>
<span><span class="st">    for (i in 1 : N) {</span></span>
<span><span class="st">      mu = beta[1] + u[subj[i]] + w[item[i]] + beta[2] * so[i];</span></span>
<span><span class="st">      rt[i] ~ lognormal(mu, sigma_e);</span></span>
<span><span class="st">    }</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">modelString</span>, con <span class="op">=</span> <span class="st">"code/random_intercepts_model.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Compiliamo il modello.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"random_intercepts_model.stan"</span><span class="op">)</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I dati nel formato appropriato per Stan sono i seguenti.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">stan_dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  subj <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">rdat</span><span class="op">$</span><span class="va">subj</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  item <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">rdat</span><span class="op">$</span><span class="va">item</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  rt <span class="op">=</span> <span class="va">rdat</span><span class="op">$</span><span class="va">rt</span>,</span>
<span>  so <span class="op">=</span> <span class="va">rdat</span><span class="op">$</span><span class="va">so</span>,</span>
<span>  N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">rdat</span><span class="op">)</span>,</span>
<span>  J <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">rdat</span><span class="op">$</span><span class="va">subj</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  K <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">rdat</span><span class="op">$</span><span class="va">item</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Eseguiamo il campionamento MCMC.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit4</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">stan_dat</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">4000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">2000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="va">SEED</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Trasformiamo l’oggetto <code>fit4</code> in un oggetto di classe <code>stanfit</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">output4_stanfit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_csv.html">read_stan_csv</a></span><span class="op">(</span><span class="va">fit4</span><span class="op">$</span><span class="fu">output_files</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Le medie a posteriori dei parametri si ottengono nel modo seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit4</span><span class="op">$</span><span class="fu">summary</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"beta"</span>, <span class="st">"sigma_e"</span>, <span class="st">"sigma_w"</span>, <span class="st">"sigma_u"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 5 × 10</span></span>
<span><span class="co">#&gt;   variable    mean  median      sd     mad      q5     q95  rhat ess_b…¹ ess_t…²</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 beta[1]   6.35    6.35   0.0512  0.0511   6.26    6.43    1.00   1413.   2607.</span></span>
<span><span class="co">#&gt; 2 beta[2]  -0.0604 -0.0604 0.0220  0.0218  -0.0974 -0.0243  1.00  17390.  12616.</span></span>
<span><span class="co">#&gt; 3 sigma_e   0.577   0.577  0.00792 0.00784  0.564   0.590   1.00  17746.  12770.</span></span>
<span><span class="co">#&gt; 4 sigma_w   0.120   0.115  0.0291  0.0263   0.0806  0.173   1.00   8584.   8022.</span></span>
<span><span class="co">#&gt; 5 sigma_u   0.238   0.235  0.0319  0.0304   0.191   0.293   1.00  11445.  10961.</span></span>
<span><span class="co">#&gt; # … with abbreviated variable names ¹​ess_bulk, ²​ess_tail</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Gli intervalli di credibilità al 95% sono i seguenti.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ci95</span> <span class="op">&lt;-</span> <span class="fu">rstanarm</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstantools/reference/posterior_interval.html">posterior_interval</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">output4_stanfit</span><span class="op">)</span>,</span>
<span>  prob <span class="op">=</span> <span class="fl">0.95</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">ci95</span>, <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt;              2.5%     97.5%</span></span>
<span><span class="co">#&gt; beta[1]     6.247     6.447</span></span>
<span><span class="co">#&gt; beta[2]    -0.104    -0.017</span></span>
<span><span class="co">#&gt; u[1]       -0.208     0.081</span></span>
<span><span class="co">#&gt; u[2]       -0.304    -0.012</span></span>
<span><span class="co">#&gt; u[3]       -0.127     0.163</span></span>
<span><span class="co">#&gt; u[4]       -0.212     0.079</span></span>
<span><span class="co">#&gt; u[5]       -0.079     0.216</span></span>
<span><span class="co">#&gt; u[6]       -0.049     0.239</span></span>
<span><span class="co">#&gt; u[7]       -0.162     0.131</span></span>
<span><span class="co">#&gt; u[8]       -0.124     0.168</span></span>
<span><span class="co">#&gt; u[9]       -0.097     0.196</span></span>
<span><span class="co">#&gt; u[10]      -0.009     0.283</span></span>
<span><span class="co">#&gt; u[11]       0.450     0.745</span></span>
<span><span class="co">#&gt; u[12]       0.149     0.443</span></span>
<span><span class="co">#&gt; u[13]      -0.169     0.123</span></span>
<span><span class="co">#&gt; u[14]      -0.151     0.140</span></span>
<span><span class="co">#&gt; u[15]       0.035     0.324</span></span>
<span><span class="co">#&gt; u[16]      -0.199     0.089</span></span>
<span><span class="co">#&gt; u[17]      -0.716    -0.418</span></span>
<span><span class="co">#&gt; u[18]      -0.417    -0.127</span></span>
<span><span class="co">#&gt; u[19]      -0.295     0.003</span></span>
<span><span class="co">#&gt; u[20]       0.162     0.452</span></span>
<span><span class="co">#&gt; u[21]       0.050     0.341</span></span>
<span><span class="co">#&gt; u[22]       0.123     0.418</span></span>
<span><span class="co">#&gt; u[23]      -0.197     0.096</span></span>
<span><span class="co">#&gt; u[24]      -0.084     0.293</span></span>
<span><span class="co">#&gt; u[25]       0.000     0.292</span></span>
<span><span class="co">#&gt; u[26]      -0.494    -0.203</span></span>
<span><span class="co">#&gt; u[27]      -0.233     0.059</span></span>
<span><span class="co">#&gt; u[28]      -0.332    -0.038</span></span>
<span><span class="co">#&gt; u[29]      -0.423    -0.127</span></span>
<span><span class="co">#&gt; u[30]      -0.406    -0.113</span></span>
<span><span class="co">#&gt; u[31]      -0.100     0.188</span></span>
<span><span class="co">#&gt; u[32]      -0.178     0.113</span></span>
<span><span class="co">#&gt; u[33]      -0.239     0.056</span></span>
<span><span class="co">#&gt; u[34]       0.257     0.554</span></span>
<span><span class="co">#&gt; u[35]      -0.396    -0.104</span></span>
<span><span class="co">#&gt; u[36]      -0.144     0.145</span></span>
<span><span class="co">#&gt; u[37]      -0.171     0.118</span></span>
<span><span class="co">#&gt; w[1]       -0.133     0.061</span></span>
<span><span class="co">#&gt; w[2]       -0.118     0.075</span></span>
<span><span class="co">#&gt; w[3]       -0.101     0.093</span></span>
<span><span class="co">#&gt; w[4]       -0.213    -0.015</span></span>
<span><span class="co">#&gt; w[5]       -0.006     0.190</span></span>
<span><span class="co">#&gt; w[6]       -0.141     0.056</span></span>
<span><span class="co">#&gt; w[7]       -0.281    -0.082</span></span>
<span><span class="co">#&gt; w[8]        0.115     0.315</span></span>
<span><span class="co">#&gt; w[9]       -0.185     0.009</span></span>
<span><span class="co">#&gt; w[10]      -0.041     0.153</span></span>
<span><span class="co">#&gt; w[11]      -0.136     0.058</span></span>
<span><span class="co">#&gt; w[12]      -0.030     0.165</span></span>
<span><span class="co">#&gt; w[13]      -0.176     0.018</span></span>
<span><span class="co">#&gt; w[14]       0.036     0.235</span></span>
<span><span class="co">#&gt; w[15]      -0.041     0.155</span></span>
<span><span class="co">#&gt; sigma_e     0.562     0.593</span></span>
<span><span class="co">#&gt; sigma_u     0.183     0.309</span></span>
<span><span class="co">#&gt; sigma_w     0.076     0.188</span></span>
<span><span class="co">#&gt; lp__    -2332.580 -2311.210</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si noti il grande numero di parametri che vengono stimati dal modello gerarchico, anche nel caso del modello a intercette casuali, ovvero, nel caso del modello gerarchico più semplice. Questo esempio fa capire la necessità di utilizzare gli algoritmi MCMC: con un numero di parametri da stimare così grande è fuori considerazione l’idea di stimare i parametri mediante un metodo numerico basato su griglia. Inoltre, nel caso di un modello così complesso, una soluzione analitica della distribuzione a posteriori dei parametri non è disponibile.</p>
<p>Nel caso presente, la stima dell’effetto della manipolazione sperimentale ottenuta mediante un modello gerarchico ad intercette random è molto simile alla stima ottenuta con il modello che analizza i dati aggregati.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract</span><span class="op">(</span><span class="va">output4_stanfit</span>, permuted <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">post</span><span class="op">$</span><span class="va">beta</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">beta</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">post</span><span class="op">$</span><span class="va">beta</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -33.43351</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>L’intervallo di credibilità a posteriori per il modello gerarchico ad intercette random, in questo campione, è leggermente più piccolo di quello ottenuto mediante l’analisi dei dati aggregati.</p>
<p>Si noti che la varianza trovata con il modello per dati aggregati</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fl">0.6291826</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="co">#&gt; [1] 0.3958707</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>viene ora decomposta nella somma di tre componenti</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fl">0.57721890</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="fl">0.11961706</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="fl">0.23762983</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="co">#&gt; [1] 0.4039578</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Quindi, il modello gerarchico ci fornisce più informazioni di un’analisi basata sui dati aggregati. Per esempio, l’analisi presente ci consente di dire che la variabilità dei tempi di reazione dovuta alle differenze tra i soggetti è di entità circa doppia rispetto alla variabilità attribuibile alle differenze tra gli item.</p>
</section></section><section id="commenti-e-considerazioni-finali" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="commenti-e-considerazioni-finali">Commenti e considerazioni finali</h2>
<p>La descrizione dettagliata della soluzione del problema delle otto scuole ha messo in evidenza un aspetto importante che deriva dall’uso dei modelli gerarchici: in un modello gerarchico, le stime degli effetti (qui chiamate <span class="math inline">\(\theta_j\)</span>, ovvero l’effetto del diverso tipo di coaching per ciascuna scuola) assumono valori più simili alla media generale di quanto non lo facciano quando gli effetti <span class="math inline">\(\theta_j\)</span> vengono stimati da un modello no pooling. Questo fenomeno è detto <em>effetto shrinkage</em>.</p>
<p>È importante considerare due caratteristiche dell’effetto shrinkage.</p>
<ul>
<li>L’effetto shrinkage aumenta quando diminuisce il numero di osservazioni in ciascun gruppo <span class="math inline">\(j\)</span>-esimo. Cioè, ci affidiamo sempre di più alle tendenze globali per stimare le proprietà di un gruppo per il quale abbiamo pochi dati.</li>
<li>L’effetto shrinkage aumenta quando è è grande la variabilità all’interno dei gruppi, <span class="math inline">\(\sigma_y\)</span>, rispetto alla variabilità tra i gruppi, <span class="math inline">\(\sigma_\mu\)</span>. Cioè, ci affidiamo sempre di più alle tendenze globali per per stimare le proprietà di un gruppo quando è difficile distinguere le proprietà di un gruppo da quelle di un altro gruppo.</li>
</ul>
<p>Questo ci fa capire che, trovando un equilibrio tra pooling completo e no pooling, i modelli gerarchici consentono di:</p>
<ul>
<li>generalizzare le osservazioni sui nostri gruppi campionati alla popolazione più ampia; - prendere in prestito informazioni da tutti i gruppi campionati quando si vogliono conoscere le proprietà di un singolo gruppo campionato.</li>
</ul>
<p>Le stime prodotte dai modelli con pooling completo tendono ad avere una distorsione (bias) alta e una varianza piccola; le stime prodotte dai modelli senza pooling tendono ad avere una distorsione bassa e una varianza grande. I modelli gerarchici offrono un equilibrio tra questi due estremi:</p>
<ul>
<li>a differenza dei modelli a pooling completo, i modelli gerarchici tengono conto delle tendenze specifiche dei gruppi e quindi offrono una minore distorsione del fenomeno da descrivere;</li>
<li>a differenza dei modelli no pooling, i modelli gerarchici tengono conto delle tendenze globali e quindi offrono delle stime meno variabili da campione a campione.</li>
</ul>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography" style="display: none">
<div id="ref-gelman1995bayesian" class="csl-entry" role="doc-biblioentry">
Gelman, A., Carlin, J. B., Stern, H. S., &amp; Rubin, D. B. (1995). <em>Bayesian data analysis</em>. Chapman; Hall/CRC.
</div>
<div id="ref-gelman2020regression" class="csl-entry" role="doc-biblioentry">
Gelman, A., Hill, J., &amp; Vehtari, A. (2020). <em>Regression and other stories</em>. Cambridge University Press.
</div>
<div id="ref-gibson2013processing" class="csl-entry" role="doc-biblioentry">
Gibson, E., &amp; Wu, H.-H. I. (2013). Processing chinese relative clauses in context. <em>Language and Cognitive Processes</em>, <em>28</em>(1-2), 125–155.
</div>
<div id="ref-rubin1981estimation" class="csl-entry" role="doc-biblioentry">
Rubin, D. B. (1981). Estimation in parallel randomized experiments. <em>Journal of Educational Statistics</em>, <em>6</em>(4), 377–401.
</div>
<div id="ref-sorensen2015bayesian" class="csl-entry" role="doc-biblioentry">
Sorensen, T., &amp; Vasishth, S. (2015). Bayesian linear mixed models using stan: A tutorial for psychologists, linguists, and cognitive scientists. <em>arXiv Preprint arXiv:1506.06201</em>.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./060_anova.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Confronto tra le medie di tre o più gruppi</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./071_mod_hier_sim.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Modello gerarchico: simulazioni</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb43" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Modello gerarchico {#sec-mod-hier-stan}</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c070, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE}</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_stan_options.R"</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="fu">## La struttura dei dati</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>Ricordiamo che una delle finalità più comuni di un modello è la specificazione delle relazioni di tipo causa-effetto, allo scopo di interpretare e prevedere i fenomeni reali. Per fare questo, è importante mettere in evidenza, da una molteplicità di informazioni ottenute su numerose unità statistiche, gli aspetti essenziali presenti nei dati. La scelta modello statistico da usare per l'analisi dipende dalle caratteristiche e dalla struttura dei dati.</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>La struttura dei dati può essere semplice o complessa, e ciò condiziona la scelta del modello statistico da usare per l'analisi.</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>I dati a struttura semplice sono quelli per i quali non si rilevano particolari tipi di dipendenze o l'esistenza di particolari raggruppamenti delle osservazioni.</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>I dati a struttura complessa sono quelli per i quali le unità statistiche si trovano suddivise in sottoinsiemi all'interno dei quali possono essere specificate ipotesi diverse sulle componenti di errore del modello statistico. Tali raggruppamenti si possono presentare a uno o più livelli.</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>Le strutture complesse dei dati possono essere suddivise tra le cosiddette strutture nested e quelle non-nested.</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a><span class="fu">## Struttura Nested</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>Una struttura nested è quella in cui la gerarchia comporta l'esistenza di sottoinsiemi nidificati di osservazioni. In termini matematici una struttura nested è una partizione in gruppi di un insieme di unità. Ad esempio, gli studenti della scuola elementare (livello-1) di una città, sono nested nelle classi (livello-2) in cui studiano, a loro volta nested nelle scuole di appartenenza (livello-3), nested nel distretto di riferimento (livello-4). Nel caso di dati che hanno una struttura nested, le osservazioni individuali non risultano generalmente indipendenti: gli studenti di una stessa classe tendono ad avere un livello di formazione simile, a causa dei processi di selezione o a causa della comune storia che condividono. Una caratteristica fondamentale dei dati con struttura nested è dunque che gli individui che fanno parte del medesimo gruppo sono più somiglianti fra loro rispetto a quelli appartenenti a gruppi diversi.</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>Un caso particolare di struttura nested è quello delle cosiddette *misure ripetute*. Le misure ripetute sono un esempio di struttura gerarchica che corrisponde alla situazione nella quale la stessa variabile è misurata in più di una occasione per ogni soggetto. Nell'analisi di dati a misure ripetute gli individui possono essere pensati come unità di secondo livello e le osservazioni ripetute come unità di primo livello.</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a><span class="fu">## Struttura Non-Nested</span></span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>I dati hanno struttura non-nested quando non è definibile una partizione. Un esempio potrebbe derivare dai dati sullo studio di una qualche forma di disagio psicologico di un insieme di persone caratterizzate dal tipo di occupazione, il luogo di residenza e il luogo di lavoro. Questo è un caso non-nested in quanto la classificazione delle unità statistiche in base alle diverse variabili sopra considerate non produce la stessa suddivisione. Nell'esempio precedente di struttura non-nested i deti vengono detti *cross-classified*. I dati hanno struttura cosiddetta cross-classified quando ogni unità è classificata in base a due o più criteri tra loro non ordinati gerarchicamente.</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## Ragioni di utilizzo della struttura gerarchica</span></span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>È importante includere nella formulazione del modello i vincoli che derivano dalla struttura dei dati perché ignorare la struttura di raggruppamento sottostante porta ad una violazione del presupposto di indipendenza che alla base dei modelli che abbiamo discusso fino a questo punto: le osservazioni all'interno di un gruppo sono infatti fra loro più simili rispetto a quelle di altri gruppi. I dati che hanno una struttura gerarchica, se vengono analizzati con modelli statistici che ignorano la dipendenza tra le osservazioni può produrre conclusioni fuorvianti. La metodologia multilivello fornisce un insieme di strumenti adatti ad analizzare simultaneamente variabili classificate a livelli differenti di gerarchia, con riferimento a modelli statistici che specificano le varie possibili forme di dipendenza. I modelli multilivello sono in grado di rendere conto dei vari livelli di osservazione: quello relativo all'individuo e quello cosiddetto contestuale che deriva da aggregazioni di individui.</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>Storicamente, le analisi di dati gerarchicamente organizzati sono state inizialmente realizzate mediante le tecniche standard (come l'analisi della varianza o l'analisi di regressione) spostando tutte le variabili su un solo livello di interesse. Ciò avveniva mediante due distinte procedure: aggregazione e disaggregazione. L'aggregazione è lo spostamento di variabili originariamente osservate su un livello basso della gerarchia verso un livello superiore. Al contrario, la disaggregazione è lo spostamento di variabili verso un livello più basso della gerarchia.</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>Mediante l'aggregazione dei dati (detta pooling) si ignora la struttura gerarchica dei dati. Si ipotizza che le differenze tra i gruppi siano spiegate solo dalle variabili esplicative $X$ (covariate), ignorando i possibili effetti della struttura gerarchica nei dati. Analizzare variabili che appartengono a differenti livelli della gerarchia su un singolo e comune livello può risultare inadeguato e presentare degli inconvenienti, che diventano tanto più gravi quanto più la gerarchia è rilevante nella spiegazione del fenomeno analizzato. In particolare, l'aggregazione comporta una sostanziale perdita di informazioni e, di conseguenza, l'analisi statistica perde precisione.</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>Dall'altro, quando i dati vengono disaggregati (no pooling), i test statistici ordinari considerano che i valori disaggregati siano, in genere, informazioni indipendenti provenienti dall'insieme della unità di basso livello: i dati appartenenti a cluster diversi vengono analizzati separatamente. Invece, nelle situazioni in cui i dati sono gerarchicamente organizzati, i diversi cluster di dati non sono in genere indipendenti. <span class="co">&lt;!-- Il comportamento degli individui è influenzato dal contesto nel quale sono inseriti e le caratteristiche di un gruppo sono influenzate dagli individui che formano il gruppo stesso: gli individui e il contesto possono essere visti come un sistema gerarchico di individui e gruppi, nel quale gli individui e i gruppi stanno a livelli diversi.  --&gt;</span> I test statistici tradizionali sono basati sull'assunto di indipendenza tra tutte le osservazioni, e se questa ipotesi risulta violata, le stime degli errori standard, calcolate attraverso le procedure statistiche convenzionali, risultano distorte.</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>I modelli statistici che consentono di ottenere questo risultato si chiamano lineari misti, o modelli lineari gerarchici/multilivello, e sono diventati uno strumento fondamentale della ricerca sperimentale in psicologia, in linguistica e nelle scienze cognitive, dove i progetti di ricerca a misure ripetute sono la norma. In questo Capitolo esploreremo alcune tecniche che consentono di rendere conto della struttura gerarchica presente nei dati e discuteremo due esempi: il famoso problema delle otto scuole e il modello *Random Intercept Model*.</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a><span class="fu">## Il problema delle 8 scuole</span></span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>Il classico problema delle otto scuole <span class="co">[</span><span class="ot">@rubin1981estimation; questo esempio è anche discusso nel Capitolo 5 di @gelman1995bayesian</span><span class="co">]</span> fornisce uno degli esempi più semplici di dati organizzati in maniera gerarchica e viene spesso usato per illustrare l'utilità di modellazione gerarchica. Il problema considera l'efficacia dei programmi di coaching SAT condotti in parallelo in otto scuole.</span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Per conto del Servizio Prove Educative è stato condotto uno studio per analizzare gli effetti di speciali programmi di coaching per SAT-V (Scholastic Attitude Test-Verbal) in ciascuna delle otto scuole superiori. La variabile di esito in ogni studio era il punteggio su un'amministrazione speciale del SAT-V, un test a scelta multipla standardizzato somministrato dall'Educational Testing Service e utilizzato per aiutare i college a prendere decisioni di ammissione; i punteggi possono variare tra 200 e 800, con media circa 500 e deviazione standard circa 100. Gli esami SAT sono progettati per resistere a sforzi a breve termine diretti specificamente al miglioramento delle prestazioni del test; invece sono progettati per riflettere le conoscenze acquisite e le abilità sviluppate in molti anni di istruzione. Tuttavia, ciascuna delle otto scuole in questo studio ha considerato il suo programma di coaching a breve termine molto efficace nell'aumentare i punteggi SAT. Inoltre, non vi era alcuna ragione preliminare per ritenere che uno degli otto programmi fosse più efficace di un altro o che alcuni fossero più simili negli effetti l'uno all'altro che a qualsiasi altro.</span></span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a>Per ciascuna delle otto scuole ($J$ = 8) abbiamo un effetto del trattamento stimato e un errore standard di stima dell'effetto $\sigma_j$. I dati sono i seguenti.</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a>schools <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a>  <span class="at">row.names =</span> <span class="fu">c</span>(<span class="st">"A"</span>,<span class="st">"B"</span>,<span class="st">"C"</span>,<span class="st">"D"</span>,<span class="st">"E"</span>,<span class="st">"F"</span>,<span class="st">"G"</span>,<span class="st">"H"</span>),</span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a>  <span class="at">effect =</span> <span class="fu">c</span>(<span class="fl">28.39</span>,<span class="fl">7.94</span>,<span class="sc">-</span><span class="fl">2.75</span>,<span class="fl">6.82</span>,<span class="sc">-</span>.<span class="dv">64</span>,.<span class="dv">63</span>,<span class="fl">18.01</span>,<span class="fl">12.16</span>),</span>
<span id="cb43-55"><a href="#cb43-55" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="fu">c</span>(<span class="fl">14.9</span>, <span class="fl">10.2</span>, <span class="fl">16.3</span>, <span class="fl">11.0</span>, <span class="fl">9.4</span>, <span class="fl">11.4</span>, <span class="fl">10.4</span>, <span class="fl">17.6</span>)</span>
<span id="cb43-56"><a href="#cb43-56" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-57"><a href="#cb43-57" aria-hidden="true" tabindex="-1"></a>schools</span>
<span id="cb43-58"><a href="#cb43-58" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-59"><a href="#cb43-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-60"><a href="#cb43-60" aria-hidden="true" tabindex="-1"></a>Iniziamo calcolando una misura dell'effetto medio ponderato in cui il punteggio di ogni scuola viene ponderato in base alla precisione della misura (uno sul quadrato dell'errore standard).</span>
<span id="cb43-61"><a href="#cb43-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-64"><a href="#cb43-64" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-65"><a href="#cb43-65" aria-hidden="true" tabindex="-1"></a>schools<span class="sc">$</span>w <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> schools<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb43-66"><a href="#cb43-66" aria-hidden="true" tabindex="-1"></a>schools_mean <span class="ot">&lt;-</span> <span class="fu">sum</span>(schools<span class="sc">$</span>w <span class="sc">*</span> schools<span class="sc">$</span>effect) <span class="sc">/</span> <span class="fu">sum</span>(schools<span class="sc">$</span>w)</span>
<span id="cb43-67"><a href="#cb43-67" aria-hidden="true" tabindex="-1"></a>schools_mean</span>
<span id="cb43-68"><a href="#cb43-68" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-69"><a href="#cb43-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-70"><a href="#cb43-70" aria-hidden="true" tabindex="-1"></a>Un grafico con i dati (media $\pm$ 1 SE) è fornito di seguito.</span>
<span id="cb43-71"><a href="#cb43-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-72"><a href="#cb43-72" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE}</span></span>
<span id="cb43-73"><a href="#cb43-73" aria-hidden="true" tabindex="-1"></a>ord <span class="ot">&lt;-</span> <span class="fu">order</span>(schools<span class="sc">$</span>effect)</span>
<span id="cb43-74"><a href="#cb43-74" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(schools<span class="sc">$</span>effect[ord[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">8</span>)]]<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span>schools<span class="sc">$</span>sigma[ord[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">8</span>)]],</span>
<span id="cb43-75"><a href="#cb43-75" aria-hidden="true" tabindex="-1"></a>     <span class="fu">c</span>(<span class="fu">nrow</span>(schools),<span class="dv">1</span>),<span class="at">main =</span> <span class="st">"8 Schools data."</span>,<span class="at">type=</span><span class="st">"n"</span>,<span class="at">yaxt=</span><span class="st">"n"</span>,</span>
<span id="cb43-76"><a href="#cb43-76" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Effect Size"</span>,<span class="at">ylab=</span><span class="st">"School"</span>)</span>
<span id="cb43-77"><a href="#cb43-77" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(schools<span class="sc">$</span>effect[ord],<span class="fu">nrow</span>(schools)<span class="sc">:</span><span class="dv">1</span>,<span class="at">pch=</span><span class="fu">rownames</span>(schools)[ord])</span>
<span id="cb43-78"><a href="#cb43-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-79"><a href="#cb43-79" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(schools<span class="sc">$</span>effect[ord]<span class="sc">-</span><span class="dv">1</span><span class="sc">*</span>schools<span class="sc">$</span>sigma[ord],<span class="fu">nrow</span>(schools)<span class="sc">:</span><span class="dv">1</span>,</span>
<span id="cb43-80"><a href="#cb43-80" aria-hidden="true" tabindex="-1"></a>         schools<span class="sc">$</span>effect[ord]<span class="sc">+</span><span class="dv">1</span><span class="sc">*</span>schools<span class="sc">$</span>sigma[ord],<span class="fu">nrow</span>(schools)<span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb43-81"><a href="#cb43-81" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span>schools_mean,<span class="at">col=</span><span class="st">"blue"</span>)</span>
<span id="cb43-82"><a href="#cb43-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-83"><a href="#cb43-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-84"><a href="#cb43-84" aria-hidden="true" tabindex="-1"></a>Prima di adattare il modello gerarchico bayesiano, consideriamo due metodi non gerarchici più semplici, i quali stimando gli effetti degli otto esperimenti eseguendo un pooling completo dei dati oppure considerando le scuole come indipendenti (no pooling). Vedremo perché nessuno di questi approcci è adeguato per i dati di questo esempio.</span>
<span id="cb43-85"><a href="#cb43-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-86"><a href="#cb43-86" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modello di *complete pooling*</span></span>
<span id="cb43-87"><a href="#cb43-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-88"><a href="#cb43-88" aria-hidden="true" tabindex="-1"></a>Un esame superficiale dei dati potrebbe suggerire che alcuni programmi di coaching hanno effetti moderati (nell'intervallo 18--28 punti), la maggior parte ha piccoli effetti (0--12 punti) e due hanno piccoli effetti negativi; tuttavia, quando prendiamo atto degli errori standard di questi effetti stimati, vediamo che è difficile distinguere statisticamente tra i risultati di questi esperimenti. Potremmo dunque considerare i risultati degli otto esperimenti come esiti (condizionalmente) indipendenti dello stesso processo generativo. Di conseguenza potremmo decidere di procedere con un'*analisi aggregata* nella quale le otto scuole sono considerate come un unico campione.</span>
<span id="cb43-89"><a href="#cb43-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-92"><a href="#cb43-92" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-93"><a href="#cb43-93" aria-hidden="true" tabindex="-1"></a>model_string <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb43-94"><a href="#cb43-94" aria-hidden="true" tabindex="-1"></a><span class="st">  data {</span></span>
<span id="cb43-95"><a href="#cb43-95" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=0&gt; J; // # schools</span></span>
<span id="cb43-96"><a href="#cb43-96" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real y; // estimated treatment</span></span>
<span id="cb43-97"><a href="#cb43-97" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real&lt;lower=0&gt; sigma; // std err of effect</span></span>
<span id="cb43-98"><a href="#cb43-98" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-99"><a href="#cb43-99" aria-hidden="true" tabindex="-1"></a><span class="st">  parameters {</span></span>
<span id="cb43-100"><a href="#cb43-100" aria-hidden="true" tabindex="-1"></a><span class="st">    real theta; // pooled school effect</span></span>
<span id="cb43-101"><a href="#cb43-101" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-102"><a href="#cb43-102" aria-hidden="true" tabindex="-1"></a><span class="st">  model {</span></span>
<span id="cb43-103"><a href="#cb43-103" aria-hidden="true" tabindex="-1"></a><span class="st">    y ~ normal(theta, sigma);</span></span>
<span id="cb43-104"><a href="#cb43-104" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-105"><a href="#cb43-105" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb43-106"><a href="#cb43-106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-107"><a href="#cb43-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-108"><a href="#cb43-108" aria-hidden="true" tabindex="-1"></a>I dati in un formato appropriato per Stan sono i seguenti.</span>
<span id="cb43-109"><a href="#cb43-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-112"><a href="#cb43-112" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-113"><a href="#cb43-113" aria-hidden="true" tabindex="-1"></a>school8_dat <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb43-114"><a href="#cb43-114" aria-hidden="true" tabindex="-1"></a>  <span class="at">J =</span> <span class="fu">nrow</span>(schools),</span>
<span id="cb43-115"><a href="#cb43-115" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> schools<span class="sc">$</span>effect,</span>
<span id="cb43-116"><a href="#cb43-116" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> schools<span class="sc">$</span>sigma</span>
<span id="cb43-117"><a href="#cb43-117" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-118"><a href="#cb43-118" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-119"><a href="#cb43-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-120"><a href="#cb43-120" aria-hidden="true" tabindex="-1"></a>Compiliamo il modello descritto in precedenza e eseguiamo il campionamento MCMC.</span>
<span id="cb43-121"><a href="#cb43-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-124"><a href="#cb43-124" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-125"><a href="#cb43-125" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(model_string, <span class="at">con =</span> <span class="st">"code/hmod_2.stan"</span>)</span>
<span id="cb43-126"><a href="#cb43-126" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"hmod_2.stan"</span>)</span>
<span id="cb43-127"><a href="#cb43-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-128"><a href="#cb43-128" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb43-129"><a href="#cb43-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-130"><a href="#cb43-130" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb43-131"><a href="#cb43-131" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> school8_dat,</span>
<span id="cb43-132"><a href="#cb43-132" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 20000L,</span>
<span id="cb43-133"><a href="#cb43-133" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 10000L,</span>
<span id="cb43-134"><a href="#cb43-134" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">84735</span>,</span>
<span id="cb43-135"><a href="#cb43-135" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb43-136"><a href="#cb43-136" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb43-137"><a href="#cb43-137" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-138"><a href="#cb43-138" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-139"><a href="#cb43-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-140"><a href="#cb43-140" aria-hidden="true" tabindex="-1"></a>Nel caso di un'analisi per dati aggregati, la nostra incertezza sulla misura dell'effetto comune è di circa 20 punti, se utilizziamo un livello di certezza soggettiva del 95%. Visualizziamo la stima a posteriori con l'istruzione seguente, dove</span>
<span id="cb43-141"><a href="#cb43-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-142"><a href="#cb43-142" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>ci_level: 0.8 (80% intervals)</span>
<span id="cb43-143"><a href="#cb43-143" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>outer_level: 0.95 (95% intervals)</span>
<span id="cb43-144"><a href="#cb43-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-147"><a href="#cb43-147" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-148"><a href="#cb43-148" aria-hidden="true" tabindex="-1"></a>output2_stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit2<span class="sc">$</span><span class="fu">output_files</span>()) </span>
<span id="cb43-149"><a href="#cb43-149" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(output2_stanfit) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="sc">-</span><span class="dv">50</span>, <span class="dv">60</span>)</span>
<span id="cb43-150"><a href="#cb43-150" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-151"><a href="#cb43-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-152"><a href="#cb43-152" aria-hidden="true" tabindex="-1"></a>In base ad un'analisi aggregata (complete pooling) concludiamo che i dati sono realizzazioni indipendenti di una v.c. $\sim \mathcal{N}(\mu = 7.87, \sigma = 4.20)$.</span>
<span id="cb43-153"><a href="#cb43-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-156"><a href="#cb43-156" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-157"><a href="#cb43-157" aria-hidden="true" tabindex="-1"></a>fit2<span class="sc">$</span><span class="fu">summary</span>()</span>
<span id="cb43-158"><a href="#cb43-158" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-159"><a href="#cb43-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-160"><a href="#cb43-160" aria-hidden="true" tabindex="-1"></a>Ma è ragionevole concludere quanto detto sopra? Un primo problema dell'analisi aggregata è che è impossibile fare inferenza sui gruppi, ovvero, nel caso presente, sugli effetti dei diversi metodi di coaching (e questa era la motivazione stessa dell'analisi).</span>
<span id="cb43-161"><a href="#cb43-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-162"><a href="#cb43-162" aria-hidden="true" tabindex="-1"></a>Un secondo problema è più strettamente statistico. Se assumiamo che il processo generativo sia $\mathcal{N}(\mu = 7.87, \sigma = 4.20)$, allora possiamo chiederci quale sia la probabilità di osservare i dati del campione (o valori ancora più estremi). Il valore più estremo del nostro campione è 28.4. Se il modello generativo fosse $\mathcal{N}(\mu = 7.87, \sigma = 4.20)$, la probabilità di osservare i dati della scuola 1 sarebbe estremamente piccola.</span>
<span id="cb43-163"><a href="#cb43-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-166"><a href="#cb43-166" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-167"><a href="#cb43-167" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">28.4</span>, <span class="fl">7.87</span>, <span class="fl">4.20</span>)</span>
<span id="cb43-168"><a href="#cb43-168" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-169"><a href="#cb43-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-170"><a href="#cb43-170" aria-hidden="true" tabindex="-1"></a>Un'analisi aggregata (modello di complete pooling), dunque, non è neppure in grado di rendere conto dei dati del campione osservato (ci dice che un certo dato non dovrebbe verificarsi; ma l'abbiamo osservato). Il modello di complete pooling, dunque, non sembra adeguato per i dati considerati.</span>
<span id="cb43-171"><a href="#cb43-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-172"><a href="#cb43-172" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- L'intervallo così trovato corrisponde all'intervallo frequentista al 95%. Infatti, dato che, in questo modello, le osservazioni sono ritenute essere v.c. indipendenti, la varianza di una somma è una somma di varianze.  In questo caso $\sigma$ è il reciproco della varianza, per cui la stima della varianza comune è data da: --&gt;</span></span>
<span id="cb43-173"><a href="#cb43-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-174"><a href="#cb43-174" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb43-175"><a href="#cb43-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-176"><a href="#cb43-176" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- var &lt;- 1 / (sum(1 / schools$sigma^2)) --&gt;</span></span>
<span id="cb43-177"><a href="#cb43-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-178"><a href="#cb43-178" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- var --&gt;</span></span>
<span id="cb43-179"><a href="#cb43-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-180"><a href="#cb43-180" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb43-181"><a href="#cb43-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-182"><a href="#cb43-182" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- L'intervallo frequentista del 95% sarà dunque --&gt;</span></span>
<span id="cb43-183"><a href="#cb43-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-184"><a href="#cb43-184" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb43-185"><a href="#cb43-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-186"><a href="#cb43-186" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- n &lt;- 1 --&gt;</span></span>
<span id="cb43-187"><a href="#cb43-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-188"><a href="#cb43-188" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- schools_mean + c(-1, 1) * qnorm(0.975) * sqrt(var / n) --&gt;</span></span>
<span id="cb43-189"><a href="#cb43-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-190"><a href="#cb43-190" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb43-191"><a href="#cb43-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-192"><a href="#cb43-192" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb43-193"><a href="#cb43-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-194"><a href="#cb43-194" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- output2_stanfit --&gt;</span></span>
<span id="cb43-195"><a href="#cb43-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-196"><a href="#cb43-196" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb43-197"><a href="#cb43-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-198"><a href="#cb43-198" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modello *no pooling*</span></span>
<span id="cb43-199"><a href="#cb43-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-200"><a href="#cb43-200" aria-hidden="true" tabindex="-1"></a>Avendo rifiutato il modello compelte pooling, consideriamo ora il modello che si trova all'estremo opposto (modello no pooling). Eseguiamo dunque un'*analisi disaggregata* nella quale ogni scuola è trattata in maniera indipendente dalle altre. In linguaggio Stan, il modello no pooling può essere formulato nel modo seguente.</span>
<span id="cb43-201"><a href="#cb43-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-204"><a href="#cb43-204" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-205"><a href="#cb43-205" aria-hidden="true" tabindex="-1"></a>model_string <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb43-206"><a href="#cb43-206" aria-hidden="true" tabindex="-1"></a><span class="st">  data {</span></span>
<span id="cb43-207"><a href="#cb43-207" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=0&gt; J; // # schools</span></span>
<span id="cb43-208"><a href="#cb43-208" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real y; // estimated treatment</span></span>
<span id="cb43-209"><a href="#cb43-209" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real&lt;lower=0&gt; sigma; // std err of effect</span></span>
<span id="cb43-210"><a href="#cb43-210" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-211"><a href="#cb43-211" aria-hidden="true" tabindex="-1"></a><span class="st">  parameters {</span></span>
<span id="cb43-212"><a href="#cb43-212" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real theta; // school effect</span></span>
<span id="cb43-213"><a href="#cb43-213" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-214"><a href="#cb43-214" aria-hidden="true" tabindex="-1"></a><span class="st">  model {</span></span>
<span id="cb43-215"><a href="#cb43-215" aria-hidden="true" tabindex="-1"></a><span class="st">    y ~ normal(theta, sigma);</span></span>
<span id="cb43-216"><a href="#cb43-216" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-217"><a href="#cb43-217" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb43-218"><a href="#cb43-218" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-219"><a href="#cb43-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-220"><a href="#cb43-220" aria-hidden="true" tabindex="-1"></a>Eseguiamo l'analisi.</span>
<span id="cb43-221"><a href="#cb43-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-224"><a href="#cb43-224" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-225"><a href="#cb43-225" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(model_string, <span class="at">con =</span> <span class="st">"code/hmod_1.stan"</span>)</span>
<span id="cb43-226"><a href="#cb43-226" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"hmod_1.stan"</span>)</span>
<span id="cb43-227"><a href="#cb43-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-228"><a href="#cb43-228" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb43-229"><a href="#cb43-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-230"><a href="#cb43-230" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb43-231"><a href="#cb43-231" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> school8_dat,</span>
<span id="cb43-232"><a href="#cb43-232" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 20000L,</span>
<span id="cb43-233"><a href="#cb43-233" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 10000L,</span>
<span id="cb43-234"><a href="#cb43-234" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">84735</span>,</span>
<span id="cb43-235"><a href="#cb43-235" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb43-236"><a href="#cb43-236" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb43-237"><a href="#cb43-237" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-238"><a href="#cb43-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-239"><a href="#cb43-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-240"><a href="#cb43-240" aria-hidden="true" tabindex="-1"></a>I risultati sono i seguenti.</span>
<span id="cb43-241"><a href="#cb43-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-244"><a href="#cb43-244" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-245"><a href="#cb43-245" aria-hidden="true" tabindex="-1"></a>fit1<span class="sc">$</span><span class="fu">summary</span>()</span>
<span id="cb43-246"><a href="#cb43-246" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-247"><a href="#cb43-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-248"><a href="#cb43-248" aria-hidden="true" tabindex="-1"></a>Visualizziamo l'incertezza delle stime a posteriori.</span>
<span id="cb43-249"><a href="#cb43-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-252"><a href="#cb43-252" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-253"><a href="#cb43-253" aria-hidden="true" tabindex="-1"></a>output_stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit1<span class="sc">$</span><span class="fu">output_files</span>()) </span>
<span id="cb43-254"><a href="#cb43-254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-255"><a href="#cb43-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-256"><a href="#cb43-256" aria-hidden="true" tabindex="-1"></a>Si vede che le stime degli effetti degli otto esperimenti producono intervalli di credibilità al 95% che sono quasi completamente sovrapposti. L'ampiezza degli intervalli, ad un grado di certezza soggettiva del 95%, è di circa 50 punti.</span>
<span id="cb43-257"><a href="#cb43-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-260"><a href="#cb43-260" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-261"><a href="#cb43-261" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(output_stanfit) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="sc">-</span><span class="dv">50</span>, <span class="dv">60</span>)</span>
<span id="cb43-262"><a href="#cb43-262" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-263"><a href="#cb43-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-264"><a href="#cb43-264" aria-hidden="true" tabindex="-1"></a>Dal momento che ciascuna stima dipende *unicamente* dai dati di una singola osservazione, l'inferenza sui parametri sconosciuti del modello no pooling è estremamente rumorosa.</span>
<span id="cb43-265"><a href="#cb43-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-266"><a href="#cb43-266" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modello *partial pooling*</span></span>
<span id="cb43-267"><a href="#cb43-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-268"><a href="#cb43-268" aria-hidden="true" tabindex="-1"></a>Avendo concluso che i modelli complete pooling e non-pooling sono inadeguati, consideriamo ora un modello gerarchico. In generale, i modelli gerarchici sono basati sulla seguente idea: sebbene ogni gruppo sia unico, essendo stato campionato dalla stessa popolazione, tutti i gruppi sono collegati e quindi potrebbero contenere informazioni preziose l'uno sull'altro. Questa informazione gerarchica è fornita dagli *iper-parametri* del modello.</span>
<span id="cb43-269"><a href="#cb43-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-270"><a href="#cb43-270" aria-hidden="true" tabindex="-1"></a>La struttura ipotizzata da un modello gerarchico per i dati considerati è la seguente. Il modello gerarchico ipotizza che il risultato di ciascuna scuola sia la realizzazione di una v.c. avente media $\theta_j$. L'oggetto dell'inferenza sono i valori $\theta_j$, con $i = 1, \dots, 8$. Il modello gerarchico ipotizza che i parametri $\theta_j$ siano tra loro legati in qualche modo. In maniera più precisa, il modello assume che $\theta_j$ siano realizzazioni casuali dei un unico processo generativo sottostante. Il modello assume che tale processo generativo abbia la seguente forma: $\mathcal{N}(\mu, \tau)$. I parametri $\mu$ e $\tau$ sono detti *iper-parametri* e condizionano i valori possibili che i parametri $\theta_j$ possono assumere. Nella versione più semplice di questo modello gerarchico, l'iper-parametro $\mu$ viene considerato ignoto ma $\tau$ viene assunto come conosciuto. Ciò conduce alla formulazione del modello partial pooling. Nel caso presente assumiamo $\tau = 25$.</span>
<span id="cb43-271"><a href="#cb43-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-272"><a href="#cb43-272" aria-hidden="true" tabindex="-1"></a>Inseriamo in input a Stan l'informazione relativa a $\tau$.</span>
<span id="cb43-273"><a href="#cb43-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-276"><a href="#cb43-276" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-277"><a href="#cb43-277" aria-hidden="true" tabindex="-1"></a>school8_dat2 <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb43-278"><a href="#cb43-278" aria-hidden="true" tabindex="-1"></a>  <span class="at">J =</span> <span class="fu">nrow</span>(schools),</span>
<span id="cb43-279"><a href="#cb43-279" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> schools<span class="sc">$</span>effect,</span>
<span id="cb43-280"><a href="#cb43-280" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> schools<span class="sc">$</span>sigma,</span>
<span id="cb43-281"><a href="#cb43-281" aria-hidden="true" tabindex="-1"></a>  <span class="at">tau =</span> <span class="dv">25</span></span>
<span id="cb43-282"><a href="#cb43-282" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-283"><a href="#cb43-283" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-284"><a href="#cb43-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-285"><a href="#cb43-285" aria-hidden="true" tabindex="-1"></a>Formuliamo il modello di partial pooling nel modo seguente.</span>
<span id="cb43-286"><a href="#cb43-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-289"><a href="#cb43-289" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-290"><a href="#cb43-290" aria-hidden="true" tabindex="-1"></a>model_string <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb43-291"><a href="#cb43-291" aria-hidden="true" tabindex="-1"></a><span class="st">  data {</span></span>
<span id="cb43-292"><a href="#cb43-292" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=0&gt; J; // # schools</span></span>
<span id="cb43-293"><a href="#cb43-293" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real y; // estimated treatment</span></span>
<span id="cb43-294"><a href="#cb43-294" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real&lt;lower=0&gt; sigma; // std err of effect</span></span>
<span id="cb43-295"><a href="#cb43-295" aria-hidden="true" tabindex="-1"></a><span class="st">    real&lt;lower=0&gt; tau; // variance between schools</span></span>
<span id="cb43-296"><a href="#cb43-296" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-297"><a href="#cb43-297" aria-hidden="true" tabindex="-1"></a><span class="st">  parameters {</span></span>
<span id="cb43-298"><a href="#cb43-298" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real theta; // school effect</span></span>
<span id="cb43-299"><a href="#cb43-299" aria-hidden="true" tabindex="-1"></a><span class="st">    real mu; // mean for schools</span></span>
<span id="cb43-300"><a href="#cb43-300" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-301"><a href="#cb43-301" aria-hidden="true" tabindex="-1"></a><span class="st">  model {</span></span>
<span id="cb43-302"><a href="#cb43-302" aria-hidden="true" tabindex="-1"></a><span class="st">    mu ~ normal(0, 15);</span></span>
<span id="cb43-303"><a href="#cb43-303" aria-hidden="true" tabindex="-1"></a><span class="st">    theta ~ normal(mu, tau);</span></span>
<span id="cb43-304"><a href="#cb43-304" aria-hidden="true" tabindex="-1"></a><span class="st">    y ~ normal(theta, sigma);</span></span>
<span id="cb43-305"><a href="#cb43-305" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-306"><a href="#cb43-306" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb43-307"><a href="#cb43-307" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-308"><a href="#cb43-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-309"><a href="#cb43-309" aria-hidden="true" tabindex="-1"></a>Eseguiamo l'analisi.</span>
<span id="cb43-310"><a href="#cb43-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-313"><a href="#cb43-313" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-314"><a href="#cb43-314" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(model_string, <span class="at">con =</span> <span class="st">"code/hmod_3.stan"</span>)</span>
<span id="cb43-315"><a href="#cb43-315" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"hmod_3.stan"</span>)</span>
<span id="cb43-316"><a href="#cb43-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-317"><a href="#cb43-317" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb43-318"><a href="#cb43-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-319"><a href="#cb43-319" aria-hidden="true" tabindex="-1"></a>fit3 <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb43-320"><a href="#cb43-320" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> school8_dat2,</span>
<span id="cb43-321"><a href="#cb43-321" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 20000L,</span>
<span id="cb43-322"><a href="#cb43-322" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 10000L,</span>
<span id="cb43-323"><a href="#cb43-323" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">84735</span>,</span>
<span id="cb43-324"><a href="#cb43-324" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb43-325"><a href="#cb43-325" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb43-326"><a href="#cb43-326" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-327"><a href="#cb43-327" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-328"><a href="#cb43-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-329"><a href="#cb43-329" aria-hidden="true" tabindex="-1"></a>Esaminiamo la distribuzione a posteriori delle stime dei parametri.</span>
<span id="cb43-330"><a href="#cb43-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-333"><a href="#cb43-333" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-334"><a href="#cb43-334" aria-hidden="true" tabindex="-1"></a>output3_stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit3<span class="sc">$</span><span class="fu">output_files</span>()) </span>
<span id="cb43-335"><a href="#cb43-335" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(output3_stanfit) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="sc">-</span><span class="dv">50</span>, <span class="dv">60</span>)</span>
<span id="cb43-336"><a href="#cb43-336" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-337"><a href="#cb43-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-338"><a href="#cb43-338" aria-hidden="true" tabindex="-1"></a>Per il modello di partial pooling, ad un livello di certezza soggettiva del 95%, le stime a posteriori dei parametri $\theta_j$ sono comprese in un intervallo pari a circa 40 punti. Si noti che, in relazione al modello no pooling, è diminuita la nostra incertezza rispetto alle stime dei parametri $\theta_j$.</span>
<span id="cb43-339"><a href="#cb43-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-340"><a href="#cb43-340" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modello gerarchico</span></span>
<span id="cb43-341"><a href="#cb43-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-342"><a href="#cb43-342" aria-hidden="true" tabindex="-1"></a>Il modello di partial pooling assume che la dispersione dei parametri $\theta_j$ sia conosciuta. Ma ovviamente ciò non è vero. Arriviamo così alla formulazione del modello gerarchico nel quale vengono stimati entrambi gli iper-parametri $\mu$ e $\tau$, dove $\mu$ rappresenta l'effetto medio del trattamento e $\tau$ descrive la varianza tra le scuole. Il modello gerarchico è dunque il seguente.</span>
<span id="cb43-343"><a href="#cb43-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-344"><a href="#cb43-344" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb43-345"><a href="#cb43-345" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb43-346"><a href="#cb43-346" aria-hidden="true" tabindex="-1"></a>y_j &amp;\sim \mathcal{N}(\theta_j, \sigma_j), \quad j = 1, \dots, 8\notag<span class="sc">\\</span></span>
<span id="cb43-347"><a href="#cb43-347" aria-hidden="true" tabindex="-1"></a>\theta_j &amp;\sim \mathcal{N}(\mu, \tau), \quad j = 1, \dots, 8</span>
<span id="cb43-348"><a href="#cb43-348" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb43-349"><a href="#cb43-349" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb43-350"><a href="#cb43-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-351"><a href="#cb43-351" aria-hidden="true" tabindex="-1"></a>dove ciascun $\sigma_j$ è considerato noto.</span>
<span id="cb43-352"><a href="#cb43-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-353"><a href="#cb43-353" aria-hidden="true" tabindex="-1"></a>Lo scriviamo in linguaggio Stan nel modo seguente.</span>
<span id="cb43-354"><a href="#cb43-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-357"><a href="#cb43-357" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-358"><a href="#cb43-358" aria-hidden="true" tabindex="-1"></a>model_string <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb43-359"><a href="#cb43-359" aria-hidden="true" tabindex="-1"></a><span class="st">  data {</span></span>
<span id="cb43-360"><a href="#cb43-360" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=0&gt; J; // # schools</span></span>
<span id="cb43-361"><a href="#cb43-361" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real y; // estimated treatment</span></span>
<span id="cb43-362"><a href="#cb43-362" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real&lt;lower=0&gt; sigma; // std err of effect</span></span>
<span id="cb43-363"><a href="#cb43-363" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-364"><a href="#cb43-364" aria-hidden="true" tabindex="-1"></a><span class="st">  parameters {</span></span>
<span id="cb43-365"><a href="#cb43-365" aria-hidden="true" tabindex="-1"></a><span class="st">    array[J] real theta; // school effect</span></span>
<span id="cb43-366"><a href="#cb43-366" aria-hidden="true" tabindex="-1"></a><span class="st">    real mu; // mean for schools</span></span>
<span id="cb43-367"><a href="#cb43-367" aria-hidden="true" tabindex="-1"></a><span class="st">    real&lt;lower=0&gt; tau; // variance between schools</span></span>
<span id="cb43-368"><a href="#cb43-368" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-369"><a href="#cb43-369" aria-hidden="true" tabindex="-1"></a><span class="st">  model {</span></span>
<span id="cb43-370"><a href="#cb43-370" aria-hidden="true" tabindex="-1"></a><span class="st">    mu ~ normal(0, 15);</span></span>
<span id="cb43-371"><a href="#cb43-371" aria-hidden="true" tabindex="-1"></a><span class="st">    tau ~ cauchy(0, 30);</span></span>
<span id="cb43-372"><a href="#cb43-372" aria-hidden="true" tabindex="-1"></a><span class="st">    theta ~ normal(mu, tau);</span></span>
<span id="cb43-373"><a href="#cb43-373" aria-hidden="true" tabindex="-1"></a><span class="st">    y ~ normal(theta, sigma);</span></span>
<span id="cb43-374"><a href="#cb43-374" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-375"><a href="#cb43-375" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb43-376"><a href="#cb43-376" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-377"><a href="#cb43-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-378"><a href="#cb43-378" aria-hidden="true" tabindex="-1"></a>Eseguiamo l'analisi.</span>
<span id="cb43-379"><a href="#cb43-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-382"><a href="#cb43-382" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-383"><a href="#cb43-383" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(model_string, <span class="at">con =</span> <span class="st">"code/hmod_4.stan"</span>)</span>
<span id="cb43-384"><a href="#cb43-384" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"hmod_4.stan"</span>)</span>
<span id="cb43-385"><a href="#cb43-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-386"><a href="#cb43-386" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb43-387"><a href="#cb43-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-388"><a href="#cb43-388" aria-hidden="true" tabindex="-1"></a>fit4 <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb43-389"><a href="#cb43-389" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> school8_dat,</span>
<span id="cb43-390"><a href="#cb43-390" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 20000L,</span>
<span id="cb43-391"><a href="#cb43-391" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 10000L,</span>
<span id="cb43-392"><a href="#cb43-392" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">84735</span>,</span>
<span id="cb43-393"><a href="#cb43-393" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb43-394"><a href="#cb43-394" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb43-395"><a href="#cb43-395" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-396"><a href="#cb43-396" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-397"><a href="#cb43-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-398"><a href="#cb43-398" aria-hidden="true" tabindex="-1"></a>Le stime dei parametri sono le seguenti.</span>
<span id="cb43-399"><a href="#cb43-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-402"><a href="#cb43-402" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-403"><a href="#cb43-403" aria-hidden="true" tabindex="-1"></a>output4_stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit4<span class="sc">$</span><span class="fu">output_files</span>()) </span>
<span id="cb43-404"><a href="#cb43-404" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(output4_stanfit, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">"theta"</span>, <span class="st">"mu"</span>, <span class="st">"tau"</span>), <span class="at">probs =</span> <span class="fu">c</span>(.<span class="dv">025</span>, .<span class="dv">5</span>, .<span class="dv">975</span>))</span>
<span id="cb43-405"><a href="#cb43-405" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-406"><a href="#cb43-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-407"><a href="#cb43-407" aria-hidden="true" tabindex="-1"></a>Visualizziamo la distribuzione a posteriori delle stime dei parametri e degli iper-parametri.</span>
<span id="cb43-408"><a href="#cb43-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-411"><a href="#cb43-411" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-412"><a href="#cb43-412" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(output4_stanfit) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="sc">-</span><span class="dv">50</span>, <span class="dv">60</span>)</span>
<span id="cb43-413"><a href="#cb43-413" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-414"><a href="#cb43-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-415"><a href="#cb43-415" aria-hidden="true" tabindex="-1"></a>Con un grado di certezza soggettiva del 95%, le stime a posteriori dei parametri $\theta_j$ risultano comprese in un intervallo pari a circa 30 punti. Il modello gerarchico, dunque, produce stime degli effetti $\theta_j$ a cui è associata l'incertezza più piccola rispetto a tutti gli altri casi esaminati in precedenza.</span>
<span id="cb43-416"><a href="#cb43-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-417"><a href="#cb43-417" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretazione</span></span>
<span id="cb43-418"><a href="#cb43-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-419"><a href="#cb43-419" aria-hidden="true" tabindex="-1"></a>In conclusione, il modello gerarchico consente di ottenere stime degli effetti $\theta_j$ degli otto esperimenti più precise di quelle ottenute dal modelo non gerarchico no-pooling e dal modello gerarchico di partial pooling. Si noti inoltre che, con $\tau \rightarrow \infty$, le stime di un modello gerarchico diventano sempre più simili a quelle di un modello no-pooling, vale a dire, ciascuna delle stime dell'effetto del trattamento della scuola diventa via via più indipendente dalle altre stime. Con $\tau \rightarrow 0$, le stime di un modello gerarchico diventano sempre più simili alle stime di un modello di pooling completo, vale a dire, tutti gli effetti del trattamento della scuola tendono a diventare via via più simili all'effetto medio del gruppo.</span>
<span id="cb43-420"><a href="#cb43-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-421"><a href="#cb43-421" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modelli lineari ad intercetta casuale</span></span>
<span id="cb43-422"><a href="#cb43-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-423"><a href="#cb43-423" aria-hidden="true" tabindex="-1"></a>Esaminiamo ora un modello gerarchico più complesso per l'analisi di un set di dati a misure ripetute con due condizioni. I dati sono stati raccolti da <span class="co">[</span><span class="ot">@gibson2013processing; si veda @sorensen2015bayesian</span><span class="co">]</span>. La variabile dipendente <span class="in">`rt`</span> dell'esperimento di @gibson2013processing è il tempo di lettura in millisecondi del soggetto di una proposizione relativa in un testo. I tempi di reazione sono stati registrati in due condizioni: in presenza di un sostantivo riferito al soggetto della proposizione, oppure in presenza di un sostantivo riferito all'oggetto della proposizione.</span>
<span id="cb43-424"><a href="#cb43-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-425"><a href="#cb43-425" aria-hidden="true" tabindex="-1"></a>I dati di @gibson2013processing provengono da un esperimento con 37 soggetti e 15 item. Gli item erano presentati in un disegno a quadrato latino (ovvero, un disegno nel quale vengono considerate tutte le combinazioni possibili), il che produce 37 $\times$ 15 = 555 dati. Risultano mancanti otto dati di un soggetto (id 27), il che porta ad un totale di 555 − 8 = 547 dati. Le prime righe del data.frame sono mostrate di seguito:</span>
<span id="cb43-426"><a href="#cb43-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-429"><a href="#cb43-429" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-430"><a href="#cb43-430" aria-hidden="true" tabindex="-1"></a>rdat <span class="ot">&lt;-</span> <span class="fu">read.table</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"data"</span>, <span class="st">"gibsonwu2012data.txt"</span>))</span>
<span id="cb43-431"><a href="#cb43-431" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(rdat)</span>
<span id="cb43-432"><a href="#cb43-432" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-433"><a href="#cb43-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-434"><a href="#cb43-434" aria-hidden="true" tabindex="-1"></a>La manipolazione sperimentale viene descritta dalla variabile <span class="in">`type`</span> (oppure, in maniera equivalente, dalla variabile <span class="in">`type2`</span>). Nell'analisi, <span class="in">`type`</span> viene ricodificata nella colonna <span class="in">`so`</span> la quale assume valore -0.5 se il sostantivo era riferito al soggetto e +0.5 se il sostantivo era riferito all'oggetto della frase.</span>
<span id="cb43-435"><a href="#cb43-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-438"><a href="#cb43-438" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-439"><a href="#cb43-439" aria-hidden="true" tabindex="-1"></a>rdat<span class="sc">$</span>so <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(rdat<span class="sc">$</span>type <span class="sc">==</span> <span class="st">"subj-ext"</span>, <span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>)</span>
<span id="cb43-440"><a href="#cb43-440" aria-hidden="true" tabindex="-1"></a><span class="fu">unique</span>(rdat<span class="sc">$</span>so)</span>
<span id="cb43-441"><a href="#cb43-441" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-442"><a href="#cb43-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-443"><a href="#cb43-443" aria-hidden="true" tabindex="-1"></a>Calcoliamo la media dei tempi di reazione su scala logaritmica e per poi ritrasformare il risultato sulla scala originale:</span>
<span id="cb43-444"><a href="#cb43-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-447"><a href="#cb43-447" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-448"><a href="#cb43-448" aria-hidden="true" tabindex="-1"></a>rdat <span class="sc">%&gt;%</span> </span>
<span id="cb43-449"><a href="#cb43-449" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(type2) <span class="sc">%&gt;%</span> </span>
<span id="cb43-450"><a href="#cb43-450" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb43-451"><a href="#cb43-451" aria-hidden="true" tabindex="-1"></a>    <span class="at">avg =</span> <span class="fu">exp</span>(<span class="fu">mean</span>(<span class="fu">log</span>(rt), <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span>
<span id="cb43-452"><a href="#cb43-452" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb43-453"><a href="#cb43-453" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-454"><a href="#cb43-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-455"><a href="#cb43-455" aria-hidden="true" tabindex="-1"></a>Quando il sostantivo si riferisce al soggetto, i tempi di reazione sono più lenti di circa 30 ms.</span>
<span id="cb43-456"><a href="#cb43-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-457"><a href="#cb43-457" aria-hidden="true" tabindex="-1"></a>Questa descrizione dei dati, però non tiene conto né delle differenze tra i soggetti né delle differenze tra gli item. Per tenere in considerazioni queste diverse fonti della variabilità dei dati è necessario utilizzare un modello gerarchico.</span>
<span id="cb43-458"><a href="#cb43-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-459"><a href="#cb43-459" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modello ad effetti fissi</span></span>
<span id="cb43-460"><a href="#cb43-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-461"><a href="#cb43-461" aria-hidden="true" tabindex="-1"></a>Iniziamo con un modello "ad effetti fissi" che non tiene conto della struttura gerarchica dei dati, ovvero del fatto che c'è una covariazione all'interno dei cluster definiti dalle variabili "soggetto" e "item".</span>
<span id="cb43-462"><a href="#cb43-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-463"><a href="#cb43-463" aria-hidden="true" tabindex="-1"></a>Ipotizziamo dunque di descrivere i dati mediante il seguente modello di regressione lineare:</span>
<span id="cb43-464"><a href="#cb43-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-465"><a href="#cb43-465" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb43-466"><a href="#cb43-466" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb43-467"><a href="#cb43-467" aria-hidden="true" tabindex="-1"></a><span class="in">\log rt_i = \beta_0 + \beta_1 so_i + \varepsilon_i.</span></span>
<span id="cb43-468"><a href="#cb43-468" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb43-469"><a href="#cb43-469" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-470"><a href="#cb43-470" aria-hidden="true" tabindex="-1"></a>Questo è il caso nel quale usiamo il modello lineare per fare inferenza sulla differenza tra le medie di due gruppi. In precedenza abbiamo codificato i due gruppi con 0 e 1. In tali circostanze $\alpha$ fornisce una stima del valore atteso della media del gruppo codificato con $x = 0$ e il parametro $\beta$ fornisce una stima del valore atteso della differenza tra le medie dei due gruppi.</span>
<span id="cb43-471"><a href="#cb43-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-472"><a href="#cb43-472" aria-hidden="true" tabindex="-1"></a>La codifica -0.5 e +0.5 per le due modalità della variabile <span class="in">`so`</span> ha un effetto simile. Il parametro $\alpha$ del modello di regressione lineare fornisce una stima del valore atteso della media di tutti i valori $y$ (trascurando la classificazione in gruppi) mentre, come in precedenza, il parametro $\beta$ fornisce una stima del valore atteso della differenza tra le medie dei due gruppi.</span>
<span id="cb43-473"><a href="#cb43-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-474"><a href="#cb43-474" aria-hidden="true" tabindex="-1"></a>I tempi di reazione (variabile dipendente <span class="in">`rt`</span>, ovvero tempo di lettura) hanno una distribuzione caratterizzata da una forte asimmetria positiva. Se trasformiamo i dati in maniera logaritmica, i dati trasformati si distribuiscono in maniera approssimativamente Normale. In maniera equivalente, si può dire che i dati grezzi seguono la distribuzione lognormale.</span>
<span id="cb43-475"><a href="#cb43-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-476"><a href="#cb43-476" aria-hidden="true" tabindex="-1"></a>Il modello di regressione lineare assume dunque la forma seguente:</span>
<span id="cb43-477"><a href="#cb43-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-478"><a href="#cb43-478" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb43-479"><a href="#cb43-479" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb43-480"><a href="#cb43-480" aria-hidden="true" tabindex="-1"></a><span class="in">rt \sim \mbox{LogNormal}(\beta_0 + \beta_1 so,\sigma).</span></span>
<span id="cb43-481"><a href="#cb43-481" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb43-482"><a href="#cb43-482" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-483"><a href="#cb43-483" aria-hidden="true" tabindex="-1"></a>In tale modello $\beta_0$ corrisponde al valore atteso della media generale di $\log$ <span class="in">`rt`</span> e $\beta_1 so$ codifica la differenza $\E(\log rt_{o}) - \E(\log rt_{s})$ quando si passa dalla condizione nella quale il sostantivo è riferito all'oggetto alla condizione nella quale il sostantivo è riferito al soggetto -- valori negativi significano che i tempi di reazioni sono maggiori nella condizione <span class="in">`s`</span> che nella condizione <span class="in">`o`</span>.</span>
<span id="cb43-484"><a href="#cb43-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-485"><a href="#cb43-485" aria-hidden="true" tabindex="-1"></a>Ricordiamo che questo non è un modello gerarchico, ma un semplice modello di regressione lineare nel quale assumiamo che la componente erratica del modello segua una distribuzione lognormale.</span>
<span id="cb43-486"><a href="#cb43-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-487"><a href="#cb43-487" aria-hidden="true" tabindex="-1"></a>In un tale modello useremo le seguenti distribuzioni a priori:</span>
<span id="cb43-488"><a href="#cb43-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-489"><a href="#cb43-489" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb43-490"><a href="#cb43-490" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb43-491"><a href="#cb43-491" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{aligned}</span></span>
<span id="cb43-492"><a href="#cb43-492" aria-hidden="true" tabindex="-1"></a><span class="in">\beta[1] &amp;\sim Normal(6, 1.5) \\</span></span>
<span id="cb43-493"><a href="#cb43-493" aria-hidden="true" tabindex="-1"></a><span class="in">\beta[2] &amp;\sim Normal(0, 1.0) \\</span></span>
<span id="cb43-494"><a href="#cb43-494" aria-hidden="true" tabindex="-1"></a><span class="in">\sigma &amp;\sim Cauchy(0, 1)\\</span></span>
<span id="cb43-495"><a href="#cb43-495" aria-hidden="true" tabindex="-1"></a><span class="in">\end{aligned}</span></span>
<span id="cb43-496"><a href="#cb43-496" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb43-497"><a href="#cb43-497" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-498"><a href="#cb43-498" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- https://bayesball.github.io/BOOK/bayesian-hierarchical-modeling.html#hierarchical-normal-modeling --&gt;</span></span>
<span id="cb43-499"><a href="#cb43-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-500"><a href="#cb43-500" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- https://vasishth.github.io/bayescogsci/book/sec-trial.html --&gt;</span></span>
<span id="cb43-501"><a href="#cb43-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-502"><a href="#cb43-502" aria-hidden="true" tabindex="-1"></a>In Stan, il modello precedente è specificato nel modo seguente.</span>
<span id="cb43-503"><a href="#cb43-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-506"><a href="#cb43-506" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-507"><a href="#cb43-507" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">"</span></span>
<span id="cb43-508"><a href="#cb43-508" aria-hidden="true" tabindex="-1"></a><span class="st">  data {</span></span>
<span id="cb43-509"><a href="#cb43-509" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; N; //number of data points</span></span>
<span id="cb43-510"><a href="#cb43-510" aria-hidden="true" tabindex="-1"></a><span class="st">    array[N] real rt; //reading time</span></span>
<span id="cb43-511"><a href="#cb43-511" aria-hidden="true" tabindex="-1"></a><span class="st">    array[N] real&lt;lower=-0.5, upper=0.5&gt; so; //predictor</span></span>
<span id="cb43-512"><a href="#cb43-512" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-513"><a href="#cb43-513" aria-hidden="true" tabindex="-1"></a><span class="st">  parameters {</span></span>
<span id="cb43-514"><a href="#cb43-514" aria-hidden="true" tabindex="-1"></a><span class="st">    vector[2] beta; //fixed intercept and slope</span></span>
<span id="cb43-515"><a href="#cb43-515" aria-hidden="true" tabindex="-1"></a><span class="st">    real&lt;lower=0&gt; sigma_e; //error sd</span></span>
<span id="cb43-516"><a href="#cb43-516" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-517"><a href="#cb43-517" aria-hidden="true" tabindex="-1"></a><span class="st">  model {</span></span>
<span id="cb43-518"><a href="#cb43-518" aria-hidden="true" tabindex="-1"></a><span class="st">    real mu;</span></span>
<span id="cb43-519"><a href="#cb43-519" aria-hidden="true" tabindex="-1"></a><span class="st">    // likelihood</span></span>
<span id="cb43-520"><a href="#cb43-520" aria-hidden="true" tabindex="-1"></a><span class="st">    beta[1] ~ normal(6, 1.5);</span></span>
<span id="cb43-521"><a href="#cb43-521" aria-hidden="true" tabindex="-1"></a><span class="st">    beta[2] ~ normal(0, 1);</span></span>
<span id="cb43-522"><a href="#cb43-522" aria-hidden="true" tabindex="-1"></a><span class="st">    sigma_e ~ cauchy(0, 1);</span></span>
<span id="cb43-523"><a href="#cb43-523" aria-hidden="true" tabindex="-1"></a><span class="st">    for (i in 1 : N) {</span></span>
<span id="cb43-524"><a href="#cb43-524" aria-hidden="true" tabindex="-1"></a><span class="st">      mu = beta[1] + beta[2] * so[i];</span></span>
<span id="cb43-525"><a href="#cb43-525" aria-hidden="true" tabindex="-1"></a><span class="st">      rt[i] ~ lognormal(mu, sigma_e);</span></span>
<span id="cb43-526"><a href="#cb43-526" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb43-527"><a href="#cb43-527" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-528"><a href="#cb43-528" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb43-529"><a href="#cb43-529" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">"code/fixeff_model.stan"</span>)</span>
<span id="cb43-530"><a href="#cb43-530" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-531"><a href="#cb43-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-532"><a href="#cb43-532" aria-hidden="true" tabindex="-1"></a>Compiliamo il modello.</span>
<span id="cb43-533"><a href="#cb43-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-536"><a href="#cb43-536" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-537"><a href="#cb43-537" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"fixeff_model.stan"</span>)</span>
<span id="cb43-538"><a href="#cb43-538" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb43-539"><a href="#cb43-539" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-540"><a href="#cb43-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-541"><a href="#cb43-541" aria-hidden="true" tabindex="-1"></a>I dati sono contenuti nella lista <span class="in">`stan_dat`</span>.</span>
<span id="cb43-542"><a href="#cb43-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-545"><a href="#cb43-545" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-546"><a href="#cb43-546" aria-hidden="true" tabindex="-1"></a>stan_dat <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb43-547"><a href="#cb43-547" aria-hidden="true" tabindex="-1"></a>  <span class="at">rt =</span> rdat<span class="sc">$</span>rt,</span>
<span id="cb43-548"><a href="#cb43-548" aria-hidden="true" tabindex="-1"></a>  <span class="at">so =</span> rdat<span class="sc">$</span>so,</span>
<span id="cb43-549"><a href="#cb43-549" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">nrow</span>(rdat)</span>
<span id="cb43-550"><a href="#cb43-550" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-551"><a href="#cb43-551" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-552"><a href="#cb43-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-553"><a href="#cb43-553" aria-hidden="true" tabindex="-1"></a>Eseguiamo il campionamento MCMC.</span>
<span id="cb43-554"><a href="#cb43-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-555"><a href="#cb43-555" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE, warning=FALSE, error=FALSE, results='hide'}</span></span>
<span id="cb43-556"><a href="#cb43-556" aria-hidden="true" tabindex="-1"></a>fit3 <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb43-557"><a href="#cb43-557" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> stan_dat,</span>
<span id="cb43-558"><a href="#cb43-558" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb43-559"><a href="#cb43-559" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb43-560"><a href="#cb43-560" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb43-561"><a href="#cb43-561" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb43-562"><a href="#cb43-562" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb43-563"><a href="#cb43-563" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-564"><a href="#cb43-564" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-565"><a href="#cb43-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-566"><a href="#cb43-566" aria-hidden="true" tabindex="-1"></a>Otteniamo dunque le seguenti medie a posteriori.</span>
<span id="cb43-567"><a href="#cb43-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-570"><a href="#cb43-570" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-571"><a href="#cb43-571" aria-hidden="true" tabindex="-1"></a>fit3<span class="sc">$</span><span class="fu">summary</span>()</span>
<span id="cb43-572"><a href="#cb43-572" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-573"><a href="#cb43-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-574"><a href="#cb43-574" aria-hidden="true" tabindex="-1"></a>Trasformiamo <span class="in">`fit3`</span> in un oggetto di classe <span class="in">`stanfit`</span>.</span>
<span id="cb43-575"><a href="#cb43-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-578"><a href="#cb43-578" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-579"><a href="#cb43-579" aria-hidden="true" tabindex="-1"></a>stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit3<span class="sc">$</span><span class="fu">output_files</span>())</span>
<span id="cb43-580"><a href="#cb43-580" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-581"><a href="#cb43-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-582"><a href="#cb43-582" aria-hidden="true" tabindex="-1"></a>Calcoliamo gli intervalli di credibilità al 95%.</span>
<span id="cb43-583"><a href="#cb43-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-586"><a href="#cb43-586" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-587"><a href="#cb43-587" aria-hidden="true" tabindex="-1"></a>ci95 <span class="ot">&lt;-</span> rstanarm<span class="sc">::</span><span class="fu">posterior_interval</span>(</span>
<span id="cb43-588"><a href="#cb43-588" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>(stanfit),</span>
<span id="cb43-589"><a href="#cb43-589" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> <span class="fl">0.95</span></span>
<span id="cb43-590"><a href="#cb43-590" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-591"><a href="#cb43-591" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(ci95, <span class="dv">3</span>)</span>
<span id="cb43-592"><a href="#cb43-592" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-593"><a href="#cb43-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-594"><a href="#cb43-594" aria-hidden="true" tabindex="-1"></a>Se esponenziamo i dati su scala lognormale ritorniamo alla scala dei dati grezzi. L'effetto medio, sulla scala in millisecondi, si trova dunque nel modo seguente.</span>
<span id="cb43-595"><a href="#cb43-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-598"><a href="#cb43-598" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-599"><a href="#cb43-599" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract</span>(stanfit, <span class="at">permuted =</span> <span class="cn">TRUE</span>)</span>
<span id="cb43-600"><a href="#cb43-600" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">mean</span>(post<span class="sc">$</span>beta[, <span class="dv">1</span>] <span class="sc">+</span> post<span class="sc">$</span>beta[, <span class="dv">2</span>])) <span class="sc">-</span> <span class="fu">exp</span>(<span class="fu">mean</span>(post<span class="sc">$</span>beta[, <span class="dv">1</span>]))</span>
<span id="cb43-601"><a href="#cb43-601" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-602"><a href="#cb43-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-603"><a href="#cb43-603" aria-hidden="true" tabindex="-1"></a>Se ignoriamo la struttura gerarchica dei dati, concludiamo che l'effetto della manipolazione sperimentale corrisponde ad una differenza medie nel tempo di lettura nelle due condizioni di 36 ms, con tempi di lettura maggiore quando il sostantivo era riferito al soggetto della proposizione.</span>
<span id="cb43-604"><a href="#cb43-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-605"><a href="#cb43-605" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modello gerarchico</span></span>
<span id="cb43-606"><a href="#cb43-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-607"><a href="#cb43-607" aria-hidden="true" tabindex="-1"></a>Un modello non gerarchico (detto ad effetti fissi) è inappropriato per il campione di @gibson2013processing perché non tiene conto del fatto che i dati sono a misure ripetute, ovvero, con più ripetizioni per ogni soggetto e per ogni item. Il modello ad effetti usato sopra viola l'assunzione di indipendenza degli errori. Inoltre, i coefficienti di effetti fissi $\beta_0$ e $\beta_1$ rappresentano le medie calcolate aggregando i dati sulla dimensione dei soggetti e degli item. Così facendo, non si tiene in considerazione il fatto che alcuni soggetti sono più veloci e altri più lenti della media, e il fatto che alcuni item sono stati letti più velocemente e altri in maniera più lenta della media. Ovvero, il modello non considera informazioni che sono presenti nei dati.</span>
<span id="cb43-608"><a href="#cb43-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-609"><a href="#cb43-609" aria-hidden="true" tabindex="-1"></a>Un modello gerarchico, invece, rende conto delle diverse fonti di variabilità che derivano da questo disegno sperimentale, ovvero la variabilità dovuta alle differenze tra i soggetti e la variabilità dovuta alle differenze tra gli item. Per rendere conto di queste fonti di variabilità nei dati, vengono aggiunti al modello di regressione lineare due nuovi termini: $u_{0j}$ e $w_{0k}$. Tali termini "aggiustano" $\beta_0$ in modo tale da stimare una componente specifica della variabile risposta dovuta al soggetto $j$-esimo e all'item $k$-esimo.</span>
<span id="cb43-610"><a href="#cb43-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-611"><a href="#cb43-611" aria-hidden="true" tabindex="-1"></a>Questa formulazione del modello scompone parzialmente la componente d'errore $\varepsilon_i$ nella somma dei termini $u_{0j}$ e $w_{0k}$. Geometricamente, i termini $u_{0j}$ e $w_{0k}$ corrispondono ad aggiustamenti dell'intercetta $\beta_0$ che sono specifici per il soggetto $j$-esimo e per l'item $k$-esimo.</span>
<span id="cb43-612"><a href="#cb43-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-613"><a href="#cb43-613" aria-hidden="true" tabindex="-1"></a>Se il soggetto $j$-esimo è più lento della media di tutti i soggetti, allora il parametro $u_j$ sarà un numero positivo. Se l'item $k$-esimo viene letto più velocemente del tempo di lettura medio di tutti gli item, allora il parametro $w_k$ sarà un numero negativo. Viene stimato un aggiustamento $u_{0j}$ per ogni soggetto $j$-esimo e un aggiustamento $w_{0k}$ per ogni item $k$-esimo. I parametri $u_{0j}$ e $w_{0k}$ sono chiamati *random intercepts* o *varying intercepts* <span class="co">[</span><span class="ot">@gelman2020regression</span><span class="co">]</span>. L'aggiustamento di $\beta_0$ mediante $u_{0j}$ e $w_{0k}$ consente dunque di tenere in considerazione la struttura gerarchica dei dati, ovvero consente di stimare la quota di variabilità dovuta ai soggetti e agli item.</span>
<span id="cb43-614"><a href="#cb43-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-615"><a href="#cb43-615" aria-hidden="true" tabindex="-1"></a>Il random intercept model assume che gli aggiustamenti $u_{0j}$ e $w_{0k}$ siano distribuiti normalmente attorno allo zero con una deviazione standard sconosciuta:</span>
<span id="cb43-616"><a href="#cb43-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-617"><a href="#cb43-617" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb43-618"><a href="#cb43-618" aria-hidden="true" tabindex="-1"></a>u_0 ∼ \mathcal{N}(0, \sigma_u),</span>
<span id="cb43-619"><a href="#cb43-619" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb43-620"><a href="#cb43-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-621"><a href="#cb43-621" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb43-622"><a href="#cb43-622" aria-hidden="true" tabindex="-1"></a>w_0 ∼ \mathcal{N}(0, \sigma_w).</span>
<span id="cb43-623"><a href="#cb43-623" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb43-624"><a href="#cb43-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-625"><a href="#cb43-625" aria-hidden="true" tabindex="-1"></a>Il modello include dunque tre fonti di varianza:</span>
<span id="cb43-626"><a href="#cb43-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-627"><a href="#cb43-627" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la deviazione standard degli errori $\sigma_e$,</span>
<span id="cb43-628"><a href="#cb43-628" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la deviazione standard delle *random intercepts* per i soggetti, $\sigma_u$,</span>
<span id="cb43-629"><a href="#cb43-629" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la deviazione standard delle *random intercepts* per gli item, $\sigma_w$.</span>
<span id="cb43-630"><a href="#cb43-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-631"><a href="#cb43-631" aria-hidden="true" tabindex="-1"></a>Queste tre fonti di variabilità sono dette *componenti della varianza*. Possiamo dunque scrivere il modello nel modo seguente:</span>
<span id="cb43-632"><a href="#cb43-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-633"><a href="#cb43-633" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb43-634"><a href="#cb43-634" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb43-635"><a href="#cb43-635" aria-hidden="true" tabindex="-1"></a><span class="in">\log rt_{ijk} = \beta_0 + \beta_1 so_i + u_{0j} + w_{0k} + \varepsilon_{ijk}.</span></span>
<span id="cb43-636"><a href="#cb43-636" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb43-637"><a href="#cb43-637" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-638"><a href="#cb43-638" aria-hidden="true" tabindex="-1"></a>Il coefficiente $\beta_1$ è il parametro di interesse primario. Come conseguenza della codifica usata, avrà il valore $-\beta_1$ nella condizione in cui il sostantivo è riferito al soggetto e $+\beta_1$ nella condizione in cui il sostantivo è riferito all'oggetto della frase.</span>
<span id="cb43-639"><a href="#cb43-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-640"><a href="#cb43-640" aria-hidden="true" tabindex="-1"></a>In Stan il modello viene formulato nel modo seguente.</span>
<span id="cb43-641"><a href="#cb43-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-644"><a href="#cb43-644" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-645"><a href="#cb43-645" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">"</span></span>
<span id="cb43-646"><a href="#cb43-646" aria-hidden="true" tabindex="-1"></a><span class="st">  data {</span></span>
<span id="cb43-647"><a href="#cb43-647" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; N; //number of data points</span></span>
<span id="cb43-648"><a href="#cb43-648" aria-hidden="true" tabindex="-1"></a><span class="st">    array[N] real rt; //reading time</span></span>
<span id="cb43-649"><a href="#cb43-649" aria-hidden="true" tabindex="-1"></a><span class="st">    array[N] real&lt;lower=-0.5, upper=0.5&gt; so; //predictor</span></span>
<span id="cb43-650"><a href="#cb43-650" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; J; //number of subjects</span></span>
<span id="cb43-651"><a href="#cb43-651" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; K; //number of items</span></span>
<span id="cb43-652"><a href="#cb43-652" aria-hidden="true" tabindex="-1"></a><span class="st">    array[N] int&lt;lower=1, upper=J&gt; subj; //subject id</span></span>
<span id="cb43-653"><a href="#cb43-653" aria-hidden="true" tabindex="-1"></a><span class="st">    array[N] int&lt;lower=1, upper=K&gt; item; //item id</span></span>
<span id="cb43-654"><a href="#cb43-654" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-655"><a href="#cb43-655" aria-hidden="true" tabindex="-1"></a><span class="st">  parameters {</span></span>
<span id="cb43-656"><a href="#cb43-656" aria-hidden="true" tabindex="-1"></a><span class="st">    vector[2] beta; //fixed intercept and slope</span></span>
<span id="cb43-657"><a href="#cb43-657" aria-hidden="true" tabindex="-1"></a><span class="st">    vector[J] u; //subject intercepts</span></span>
<span id="cb43-658"><a href="#cb43-658" aria-hidden="true" tabindex="-1"></a><span class="st">    vector[K] w; //item intercepts</span></span>
<span id="cb43-659"><a href="#cb43-659" aria-hidden="true" tabindex="-1"></a><span class="st">    real&lt;lower=0&gt; sigma_e; //error sd</span></span>
<span id="cb43-660"><a href="#cb43-660" aria-hidden="true" tabindex="-1"></a><span class="st">    real&lt;lower=0&gt; sigma_u; //subj sd</span></span>
<span id="cb43-661"><a href="#cb43-661" aria-hidden="true" tabindex="-1"></a><span class="st">    real&lt;lower=0&gt; sigma_w; //item sd</span></span>
<span id="cb43-662"><a href="#cb43-662" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-663"><a href="#cb43-663" aria-hidden="true" tabindex="-1"></a><span class="st">  model {</span></span>
<span id="cb43-664"><a href="#cb43-664" aria-hidden="true" tabindex="-1"></a><span class="st">    real mu;</span></span>
<span id="cb43-665"><a href="#cb43-665" aria-hidden="true" tabindex="-1"></a><span class="st">    //priors</span></span>
<span id="cb43-666"><a href="#cb43-666" aria-hidden="true" tabindex="-1"></a><span class="st">    u ~ normal(0, sigma_u); //subj random effects</span></span>
<span id="cb43-667"><a href="#cb43-667" aria-hidden="true" tabindex="-1"></a><span class="st">    w ~ normal(0, sigma_w); //item random effects</span></span>
<span id="cb43-668"><a href="#cb43-668" aria-hidden="true" tabindex="-1"></a><span class="st">    // likelihood</span></span>
<span id="cb43-669"><a href="#cb43-669" aria-hidden="true" tabindex="-1"></a><span class="st">    for (i in 1 : N) {</span></span>
<span id="cb43-670"><a href="#cb43-670" aria-hidden="true" tabindex="-1"></a><span class="st">      mu = beta[1] + u[subj[i]] + w[item[i]] + beta[2] * so[i];</span></span>
<span id="cb43-671"><a href="#cb43-671" aria-hidden="true" tabindex="-1"></a><span class="st">      rt[i] ~ lognormal(mu, sigma_e);</span></span>
<span id="cb43-672"><a href="#cb43-672" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb43-673"><a href="#cb43-673" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb43-674"><a href="#cb43-674" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb43-675"><a href="#cb43-675" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">"code/random_intercepts_model.stan"</span>)</span>
<span id="cb43-676"><a href="#cb43-676" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-677"><a href="#cb43-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-678"><a href="#cb43-678" aria-hidden="true" tabindex="-1"></a>Compiliamo il modello.</span>
<span id="cb43-679"><a href="#cb43-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-682"><a href="#cb43-682" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-683"><a href="#cb43-683" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"random_intercepts_model.stan"</span>)</span>
<span id="cb43-684"><a href="#cb43-684" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb43-685"><a href="#cb43-685" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-686"><a href="#cb43-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-687"><a href="#cb43-687" aria-hidden="true" tabindex="-1"></a>I dati nel formato appropriato per Stan sono i seguenti.</span>
<span id="cb43-688"><a href="#cb43-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-691"><a href="#cb43-691" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-692"><a href="#cb43-692" aria-hidden="true" tabindex="-1"></a>stan_dat <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb43-693"><a href="#cb43-693" aria-hidden="true" tabindex="-1"></a>  <span class="at">subj =</span> <span class="fu">as.integer</span>(<span class="fu">as.factor</span>(rdat<span class="sc">$</span>subj)),</span>
<span id="cb43-694"><a href="#cb43-694" aria-hidden="true" tabindex="-1"></a>  <span class="at">item =</span> <span class="fu">as.integer</span>(<span class="fu">as.factor</span>(rdat<span class="sc">$</span>item)),</span>
<span id="cb43-695"><a href="#cb43-695" aria-hidden="true" tabindex="-1"></a>  <span class="at">rt =</span> rdat<span class="sc">$</span>rt,</span>
<span id="cb43-696"><a href="#cb43-696" aria-hidden="true" tabindex="-1"></a>  <span class="at">so =</span> rdat<span class="sc">$</span>so,</span>
<span id="cb43-697"><a href="#cb43-697" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">nrow</span>(rdat),</span>
<span id="cb43-698"><a href="#cb43-698" aria-hidden="true" tabindex="-1"></a>  <span class="at">J =</span> <span class="fu">length</span>(<span class="fu">unique</span>(rdat<span class="sc">$</span>subj)),</span>
<span id="cb43-699"><a href="#cb43-699" aria-hidden="true" tabindex="-1"></a>  <span class="at">K =</span> <span class="fu">length</span>(<span class="fu">unique</span>(rdat<span class="sc">$</span>item))</span>
<span id="cb43-700"><a href="#cb43-700" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-701"><a href="#cb43-701" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-702"><a href="#cb43-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-703"><a href="#cb43-703" aria-hidden="true" tabindex="-1"></a>Eseguiamo il campionamento MCMC.</span>
<span id="cb43-704"><a href="#cb43-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-705"><a href="#cb43-705" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE, warning=FALSE, error=FALSE, results='hide'}</span></span>
<span id="cb43-706"><a href="#cb43-706" aria-hidden="true" tabindex="-1"></a>fit4 <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb43-707"><a href="#cb43-707" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> stan_dat,</span>
<span id="cb43-708"><a href="#cb43-708" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb43-709"><a href="#cb43-709" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb43-710"><a href="#cb43-710" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb43-711"><a href="#cb43-711" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb43-712"><a href="#cb43-712" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb43-713"><a href="#cb43-713" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-714"><a href="#cb43-714" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-715"><a href="#cb43-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-716"><a href="#cb43-716" aria-hidden="true" tabindex="-1"></a>Trasformiamo l'oggetto <span class="in">`fit4`</span> in un oggetto di classe <span class="in">`stanfit`</span>.</span>
<span id="cb43-717"><a href="#cb43-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-720"><a href="#cb43-720" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-721"><a href="#cb43-721" aria-hidden="true" tabindex="-1"></a>output4_stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit4<span class="sc">$</span><span class="fu">output_files</span>())</span>
<span id="cb43-722"><a href="#cb43-722" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-723"><a href="#cb43-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-724"><a href="#cb43-724" aria-hidden="true" tabindex="-1"></a>Le medie a posteriori dei parametri si ottengono nel modo seguente.</span>
<span id="cb43-725"><a href="#cb43-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-728"><a href="#cb43-728" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-729"><a href="#cb43-729" aria-hidden="true" tabindex="-1"></a>fit4<span class="sc">$</span><span class="fu">summary</span>(<span class="fu">c</span>(<span class="st">"beta"</span>, <span class="st">"sigma_e"</span>, <span class="st">"sigma_w"</span>, <span class="st">"sigma_u"</span>))</span>
<span id="cb43-730"><a href="#cb43-730" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-731"><a href="#cb43-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-732"><a href="#cb43-732" aria-hidden="true" tabindex="-1"></a>Gli intervalli di credibilità al 95% sono i seguenti.</span>
<span id="cb43-733"><a href="#cb43-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-736"><a href="#cb43-736" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-737"><a href="#cb43-737" aria-hidden="true" tabindex="-1"></a>ci95 <span class="ot">&lt;-</span> rstanarm<span class="sc">::</span><span class="fu">posterior_interval</span>(</span>
<span id="cb43-738"><a href="#cb43-738" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>(output4_stanfit),</span>
<span id="cb43-739"><a href="#cb43-739" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> <span class="fl">0.95</span></span>
<span id="cb43-740"><a href="#cb43-740" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-741"><a href="#cb43-741" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(ci95, <span class="dv">3</span>)</span>
<span id="cb43-742"><a href="#cb43-742" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-743"><a href="#cb43-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-744"><a href="#cb43-744" aria-hidden="true" tabindex="-1"></a>Si noti il grande numero di parametri che vengono stimati dal modello gerarchico, anche nel caso del modello a intercette casuali, ovvero, nel caso del modello gerarchico più semplice. Questo esempio fa capire la necessità di utilizzare gli algoritmi MCMC: con un numero di parametri da stimare così grande è fuori considerazione l'idea di stimare i parametri mediante un metodo numerico basato su griglia. Inoltre, nel caso di un modello così complesso, una soluzione analitica della distribuzione a posteriori dei parametri non è disponibile.</span>
<span id="cb43-745"><a href="#cb43-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-746"><a href="#cb43-746" aria-hidden="true" tabindex="-1"></a>Nel caso presente, la stima dell'effetto della manipolazione sperimentale ottenuta mediante un modello gerarchico ad intercette random è molto simile alla stima ottenuta con il modello che analizza i dati aggregati.</span>
<span id="cb43-747"><a href="#cb43-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-750"><a href="#cb43-750" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-751"><a href="#cb43-751" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract</span>(output4_stanfit, <span class="at">permuted =</span> <span class="cn">TRUE</span>)</span>
<span id="cb43-752"><a href="#cb43-752" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">mean</span>(post<span class="sc">$</span>beta[, <span class="dv">1</span>] <span class="sc">+</span> post<span class="sc">$</span>beta[, <span class="dv">2</span>])) <span class="sc">-</span> <span class="fu">exp</span>(<span class="fu">mean</span>(post<span class="sc">$</span>beta[, <span class="dv">1</span>]))</span>
<span id="cb43-753"><a href="#cb43-753" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-754"><a href="#cb43-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-755"><a href="#cb43-755" aria-hidden="true" tabindex="-1"></a>L'intervallo di credibilità a posteriori per il modello gerarchico ad intercette random, in questo campione, è leggermente più piccolo di quello ottenuto mediante l'analisi dei dati aggregati.</span>
<span id="cb43-756"><a href="#cb43-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-757"><a href="#cb43-757" aria-hidden="true" tabindex="-1"></a>Si noti che la varianza trovata con il modello per dati aggregati</span>
<span id="cb43-758"><a href="#cb43-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-761"><a href="#cb43-761" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-762"><a href="#cb43-762" aria-hidden="true" tabindex="-1"></a><span class="fl">0.6291826</span><span class="sc">^</span><span class="dv">2</span></span>
<span id="cb43-763"><a href="#cb43-763" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-764"><a href="#cb43-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-765"><a href="#cb43-765" aria-hidden="true" tabindex="-1"></a>viene ora decomposta nella somma di tre componenti</span>
<span id="cb43-766"><a href="#cb43-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-769"><a href="#cb43-769" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb43-770"><a href="#cb43-770" aria-hidden="true" tabindex="-1"></a><span class="fl">0.57721890</span><span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.11961706</span><span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.23762983</span><span class="sc">^</span><span class="dv">2</span></span>
<span id="cb43-771"><a href="#cb43-771" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb43-772"><a href="#cb43-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-773"><a href="#cb43-773" aria-hidden="true" tabindex="-1"></a>Quindi, il modello gerarchico ci fornisce più informazioni di un'analisi basata sui dati aggregati. Per esempio, l'analisi presente ci consente di dire che la variabilità dei tempi di reazione dovuta alle differenze tra i soggetti è di entità circa doppia rispetto alla variabilità attribuibile alle differenze tra gli item.</span>
<span id="cb43-774"><a href="#cb43-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-775"><a href="#cb43-775" aria-hidden="true" tabindex="-1"></a><span class="fu">## Commenti e considerazioni finali {.unnumbered}</span></span>
<span id="cb43-776"><a href="#cb43-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-777"><a href="#cb43-777" aria-hidden="true" tabindex="-1"></a>La descrizione dettagliata della soluzione del problema delle otto scuole ha messo in evidenza un aspetto importante che deriva dall'uso dei modelli gerarchici: in un modello gerarchico, le stime degli effetti (qui chiamate $\theta_j$, ovvero l'effetto del diverso tipo di coaching per ciascuna scuola) assumono valori più simili alla media generale di quanto non lo facciano quando gli effetti $\theta_j$ vengono stimati da un modello no pooling. Questo fenomeno è detto *effetto shrinkage*.</span>
<span id="cb43-778"><a href="#cb43-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-779"><a href="#cb43-779" aria-hidden="true" tabindex="-1"></a>È importante considerare due caratteristiche dell'effetto shrinkage.</span>
<span id="cb43-780"><a href="#cb43-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-781"><a href="#cb43-781" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>L'effetto shrinkage aumenta quando diminuisce il numero di osservazioni in ciascun gruppo $j$-esimo. Cioè, ci affidiamo sempre di più alle tendenze globali per stimare le proprietà di un gruppo per il quale abbiamo pochi dati.</span>
<span id="cb43-782"><a href="#cb43-782" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>L'effetto shrinkage aumenta quando è è grande la variabilità all'interno dei gruppi, $\sigma_y$, rispetto alla variabilità tra i gruppi, $\sigma_\mu$. Cioè, ci affidiamo sempre di più alle tendenze globali per per stimare le proprietà di un gruppo quando è difficile distinguere le proprietà di un gruppo da quelle di un altro gruppo.</span>
<span id="cb43-783"><a href="#cb43-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-784"><a href="#cb43-784" aria-hidden="true" tabindex="-1"></a>Questo ci fa capire che, trovando un equilibrio tra pooling completo e no pooling, i modelli gerarchici consentono di:</span>
<span id="cb43-785"><a href="#cb43-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-786"><a href="#cb43-786" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>generalizzare le osservazioni sui nostri gruppi campionati alla popolazione più ampia; - prendere in prestito informazioni da tutti i gruppi campionati quando si vogliono conoscere le proprietà di un singolo gruppo campionato.</span>
<span id="cb43-787"><a href="#cb43-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-788"><a href="#cb43-788" aria-hidden="true" tabindex="-1"></a>Le stime prodotte dai modelli con pooling completo tendono ad avere una distorsione (bias) alta e una varianza piccola; le stime prodotte dai modelli senza pooling tendono ad avere una distorsione bassa e una varianza grande. I modelli gerarchici offrono un equilibrio tra questi due estremi:</span>
<span id="cb43-789"><a href="#cb43-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-790"><a href="#cb43-790" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>a differenza dei modelli a pooling completo, i modelli gerarchici tengono conto delle tendenze specifiche dei gruppi e quindi offrono una minore distorsione del fenomeno da descrivere;</span>
<span id="cb43-791"><a href="#cb43-791" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>a differenza dei modelli no pooling, i modelli gerarchici tengono conto delle tendenze globali e quindi offrono delle stime meno variabili da campione a campione.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>