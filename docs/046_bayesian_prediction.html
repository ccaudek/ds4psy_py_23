<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Data Science per psicologi - 24&nbsp; La predizione bayesiana</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./050_normal_normal_mod.html" rel="next">
<link href="./045_summarize_posterior.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/data_science/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Benvenuti</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">Prefazione</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./basics.html" class="sidebar-item-text sidebar-link">Parte 1: Nozioni di base</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_key_notions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Concetti chiave</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_measurement.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_freq_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_loc_scale.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_penguins.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Manipolazione e visualizzazione dei dati in <span class="math inline">\(\mathsf{R}\)</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./prob.html" class="sidebar-item-text sidebar-link">Parte 2: Il calcolo delle probabilità</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_prob_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">La logica dell’incerto</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_conditional_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Probabilità condizionata: significato, teoremi, eventi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_bayes_theorem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./018_expval_var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Indici di posizione, di varianza e di associazione di variabili casuali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./019_joint_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./020_density_func.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La densità di probabilità</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./distr.html" class="sidebar-item-text sidebar-link">Parte 3: Distribuzioni di v.c. discrete e continue</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./022_discr_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./023_cont_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./024_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">La funzione di verosimiglianza</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./bayes_inference.html" class="sidebar-item-text sidebar-link">Parte 4: Inferenza bayesiana</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./025_intro_bayes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Credibilità, modelli e parametri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./026_subj_prop.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./029_conjugate_families.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./030_balance_prior_post.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./036_posterior_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Approssimazione della distribuzione a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./040_beta_binomial_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Il modello beta-binomiale in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./041_mcmc_diagnostics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./045_summarize_posterior.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./046_bayesian_prediction.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./050_normal_normal_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./regression.html" class="sidebar-item-text sidebar-link">Parte 5: Regressione lineare</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./051_reglin1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./052_reglin2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Regressione lineare bivariata</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./053_reglin3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Modello di regressione in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./054_reglin4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Inferenza sul modello lineare</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./055_reglin5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./056_pred_check.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Predictive checks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./060_anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Confronto tra le medie di tre o più gruppi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./070_mod_hier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modello gerarchico</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./071_mod_hier_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Modello gerarchico: simulazioni</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./entropy.html" class="sidebar-item-text sidebar-link">Parte 6: Entropia</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./090_entropy.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Entropia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./091_kl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./092_info_criterion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Criterio di informazione e convalida incrociata</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./frequentist_inference.html" class="sidebar-item-text sidebar-link">Parte 7: Inferenza frequentista</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./220_intro_frequentist.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Legge dei grandi numeri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./221_conf_interv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Intervallo fiduciale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./225_distr_camp_mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Distribuzione campionaria</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./226_test_ipotesi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Significatività statistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./227_ttest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza sulle medie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./228_limiti_stat_frequentista.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./999_refs.html" class="sidebar-item-text sidebar-link">Riferimenti bibliografici</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">Appendici</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a01_math_symbols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a02_number_sets.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a03_set_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Insiemi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a04_summation_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Simbolo di somma (sommatorie)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a05_calculus_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a10_markov_chains.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Le catene di Markov</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a15_stan_lang.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Programmare in Stan</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul>
<li><a href="#la-distribuzione-predittiva-a-posteriori" id="toc-la-distribuzione-predittiva-a-posteriori" class="nav-link active" data-scroll-target="#la-distribuzione-predittiva-a-posteriori"><span class="toc-section-number">24.1</span>  La distribuzione predittiva a posteriori</a></li>
  <li><a href="#soluzione-analitica" id="toc-soluzione-analitica" class="nav-link" data-scroll-target="#soluzione-analitica"><span class="toc-section-number">24.2</span>  Soluzione analitica</a></li>
  <li><a href="#la-distribuzione-predittiva-a-posteriori-mediante-simulazione" id="toc-la-distribuzione-predittiva-a-posteriori-mediante-simulazione" class="nav-link" data-scroll-target="#la-distribuzione-predittiva-a-posteriori-mediante-simulazione"><span class="toc-section-number">24.3</span>  La distribuzione predittiva a posteriori mediante simulazione</a></li>
  <li><a href="#la-distribuzione-predittiva-a-posteriori-mediante-mcmc" id="toc-la-distribuzione-predittiva-a-posteriori-mediante-mcmc" class="nav-link" data-scroll-target="#la-distribuzione-predittiva-a-posteriori-mediante-mcmc"><span class="toc-section-number">24.4</span>  La distribuzione predittiva a posteriori mediante MCMC</a></li>
  <li>
<a href="#i-metodi-per-la-valutazione-del-modello" id="toc-i-metodi-per-la-valutazione-del-modello" class="nav-link" data-scroll-target="#i-metodi-per-la-valutazione-del-modello"><span class="toc-section-number">24.5</span>  I metodi per la valutazione del modello</a>
  <ul class="collapse">
<li><a href="#posterior-predictive-checks" id="toc-posterior-predictive-checks" class="nav-link" data-scroll-target="#posterior-predictive-checks"><span class="toc-section-number">24.5.1</span>  Posterior predictive checks</a></li>
  </ul>
</li>
  <li><a href="#distribuzione-predittiva-a-priori" id="toc-distribuzione-predittiva-a-priori" class="nav-link" data-scroll-target="#distribuzione-predittiva-a-priori"><span class="toc-section-number">24.6</span>  Distribuzione predittiva a priori</a></li>
  <li><a href="#commenti-e-considerazioni-finali" id="toc-commenti-e-considerazioni-finali" class="nav-link" data-scroll-target="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-prediction" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Codice</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><p>Oltre ad una sintesi della distribuzione a posteriori attraverso il computo di indici caratteristici e alla verifica di ipotesi, un altro compito dell’analisi bayesiana è la predizione di nuovi dati futuri. Dopo aver osservato i dati di un campione e dopo avere ricavato le distribuzioni a posteriori dei parametri, è infatti possibile ottenere delle indicazioni sulle proprietà di dati futuri. L’uso più immediato della stima della distribuzione dei possibili valori futuri della variabile di esito è la verifica del modello in esame. Infatti, il modo più diretto per testare un modello è quello di utilizzare il modello corrente per fare previsioni sui possibili dati futuri per poi confrontare i dati predetti con i dati che sono stati effettivamente osservati nel campione corrente. Questa pratica va sotto il nome di <em>controllo predittivo a posteriori</em>. In questo capitolo ci focalizzeremo sul problema della predizione bayesiana esaminando il caso più semplice, ovvero lo schema beta-binomiale. In seguito estenderemo questa discussione al caso generale.</p>
<section id="la-distribuzione-predittiva-a-posteriori" class="level2" data-number="24.1"><h2 data-number="24.1" class="anchored" data-anchor-id="la-distribuzione-predittiva-a-posteriori">
<span class="header-section-number">24.1</span> La distribuzione predittiva a posteriori</h2>
<p>Una volta costruita la distribuzione a posteriori del parametro o dei parametri sconosciuti, potremmo essere interessati a utilizzare il modello bayesiano allo scopo di prevedere la probabilità di risultati futuri basandoci sui dati già osservati. Questo tipo di analisi inferenziale va sotto il nome di <em>analisi predittiva</em>.</p>
<p>L’esempio che considereremo qui nei dettagli riguarda il caso beta-binomiale, nel quale la distribuzione a priori per il parametro ignoto <span class="math inline">\(\theta\)</span> (ovvero, la probabilità di successo) è una distribuzione Beta, la verosimiglianza è binomiale e i dati sono costituiti dal numero <span class="math inline">\(y\)</span> di successi in <span class="math inline">\(n\)</span> prove Bernoulliane indipendenti. Nell’esempio che discuteremo useremo un’altra volta i dati del campione di pazienti clinici depressi di <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span>. Supponendo di volere esaminare in futuro altri <span class="math inline">\(m\)</span> pazienti clinici, ci chiediamo: quanti di essi manifesteranno una depressione grave?</p>
<p>Siamo dunque interessati a predire i risultati che si potrebbero osservare in nuovi campioni di <span class="math inline">\(m = 30\)</span> osservazioni. Denotiamo con <span class="math inline">\(\tilde{y}\)</span> la manifestazione della variabile casuale <span class="math inline">\(\tilde{Y}\)</span>. In un nuovo campione di <span class="math inline">\(m\)</span> osservazioni, <span class="math inline">\(\tilde{y}\)</span> assumerà il valore <span class="math inline">\(\tilde{y}_1\)</span> (ad es., 12), in un altro campione assumerà il valore <span class="math inline">\(\tilde{y}_2\)</span> (ad es., 23), e così via. Siamo interessati a descrivere la probabilità che <span class="math inline">\(\tilde{y}\)</span> assuma i valori <span class="math inline">\(0, 1, 2, \dots, 29, 30\)</span>. Tale distribuzione (in questo caso) di massa di probabilità si chiama <em>distribuzione predittiva a posteriori</em> <span class="math inline">\(p(\tilde{Y} = \tilde{y} \mid Y = y)\)</span> e corrisponde alla probabilità assegnata a ciascuno dei possibili valori <span class="math inline">\(\tilde{y}\)</span> (<span class="math inline">\(0, 1, 2, \dots, 29, 30\)</span>) nei possibili campioni futuri di <span class="math inline">\(m\)</span> osservazioni.</p>
<p>In questo Capitolo ci porremo il problema di trovare la distribuzione predittiva a posteriori nel caso beta-binomiale. Useremo tre metodi diversi:</p>
<ul>
<li>la soluzione analitica,</li>
<li>i risultati di una simulazione,</li>
<li>il campionamento MCMC.</li>
</ul>
<p>I tre metodi producono risultati equivalenti. In seguito useremo il metodo MCMC perché ci consente di trovare facilmente la risposta cercata, anche quando una soluzione analitica non è disponibile.</p>
</section><section id="soluzione-analitica" class="level2" data-number="24.2"><h2 data-number="24.2" class="anchored" data-anchor-id="soluzione-analitica">
<span class="header-section-number">24.2</span> Soluzione analitica</h2>
<p>Nel caso dell’esempio in discussione, la distribuzione di <span class="math inline">\(\tilde{Y}\)</span> dipende da <span class="math inline">\(\theta\)</span> e ciò che sappiamo di <span class="math inline">\(\theta\)</span> è sintetizzato nella distribuzione a posteriori <span class="math inline">\(p(\theta \mid y)\)</span>. Usando la regola della catena, possiamo scrivere la distribuzione congiunta di <span class="math inline">\(\tilde{y}\)</span> e <span class="math inline">\(\theta\)</span> nel modo seguente</p>
<p><span class="math display">\[
p(\tilde{y}, \theta \mid y) = p(\tilde{y} \mid \theta, y) p(\theta \mid y).
\]</span></p>
<p>Assumendo che le osservazioni future <span class="math inline">\(\tilde{y}\)</span> e passate <span class="math inline">\(y\)</span> siano condizionalmente indipendenti dato <span class="math inline">\(\theta\)</span>, l’espressione precedente può essere scritta come</p>
<p><span class="math display">\[
p(\tilde{y}, \theta \mid y) = p(\tilde{y} \mid \theta) p(\theta \mid y).
\]</span></p>
<p>La distribuzione predittiva a posteriori viene ottenuta dalla distribuzione congiunta di <span class="math inline">\(\tilde{y}\)</span> e <span class="math inline">\(\theta\)</span> integrando rispetto a <span class="math inline">\(\theta\)</span>:</p>
<p><span id="eq-post-pred-distr"><span class="math display">\[
p(\tilde{y} \mid y) = \int_{\theta} p(\tilde{y} \mid \theta) p(\theta \mid y) \,\operatorname {d}\!\theta.
\tag{24.1}\]</span></span></p>
<p>Nel caso dello schema beta-binomiale, la funzione <span class="math inline">\(p(\tilde{y} \mid \theta)\)</span> è binomiale di parametri <span class="math inline">\(m\)</span> e <span class="math inline">\(\theta\)</span>, e la distribuzione a posteriori <span class="math inline">\(p(\theta \mid y)\)</span> è una <span class="math inline">\(\mbox{Beta}(\alpha + y, \beta + n - y)\)</span>. Risolvendo l’integrale otteniamo:</p>
<p><span id="eq-post-yprime-an-sol-betabin"><span class="math display">\[
\begin{align}
p(\tilde{y} \mid y) &amp;= \int_0^1 p(\tilde{y} \mid \theta)
p(\theta \mid y)\,\operatorname {d}\!\theta \notag\\
&amp;= \int_0^1 \begin{pmatrix}m\\\tilde{y}\end{pmatrix}
\theta^{\tilde{y}}
(1-\theta)^{m-\tilde{y}} \, \mbox{Beta}(a+y,b+n-y) \, d\theta \notag\\
&amp;= \begin{pmatrix}{m}\\\tilde{y}\end{pmatrix} \int_0^1 \theta^{\tilde{y}}
(1-\theta)^{m-\tilde{y}} \frac{1}{B(a+y, b+n-y)}\theta^{a+y-1}(1-\theta)^{b+n-y-1}\notag\\
&amp;= \begin{pmatrix}{ m }\\\tilde{y}\end{pmatrix} \frac{1}{B(a+y, b+n-y)}\int_0^1 \theta^{\tilde{y}+a+y-1}(1-\theta)^{m-\tilde{y}+b+n-y-1}\notag\\
&amp;= \begin{pmatrix}{ m }\\\tilde{y}\end{pmatrix} \frac{B(\tilde{y}+a+y,b+n-y+m-\tilde{y})}{B(a+y, b+n-y)} \; .
\end{align}
\tag{24.2}\]</span></span></p>
<p>In conclusione, per lo schema beta-binomiale, la distribuzione predittiva a posteriori corrisponde ad una distribuzione di probabilità discreta chiamata <em>distribuzione beta-binomiale</em> di parametri <span class="math inline">\(m\)</span>, <span class="math inline">\(\alpha+y\)</span> e <span class="math inline">\(\beta+n-y\)</span>.</p>
<p><span id="eq-beta-binomial-distr"><span class="math display">\[
f(\tilde{y} \mid y) = \binom{m}{\tilde{y}} \frac{B(a+ y + \tilde{y}, b + n - y + m - \tilde{y})}{B(a+y, b+n-y)},
\tag{24.3}\]</span></span></p>
<p>Nell’esempio relativo allo studio di <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span>, la verosimiglianza è binomiale, i dati sono costituiti da 23 successi su 30 prove e la distribuzione a priori su <span class="math inline">\(\theta\)</span> è <span class="math inline">\(\mbox{Beta}(2, 10)\)</span>. Di conseguenza, la distribuzione a posteriori è <span class="math inline">\(\mbox{Beta}(25, 17)\)</span>. Vogliamo calcolare la distribuzione predittiva a posteriori per un nuovo campione, poniamo, di <span class="math inline">\(m = 30\)</span> osservazioni (ma, in generale, <span class="math inline">\(m\)</span> può essere diverso da <span class="math inline">\(n\)</span>).</p>
<p>In base all’<a href="#eq-beta-binomial-distr">Equazione&nbsp;<span>24.3</span></a> sappiamo che la distribuzione predittiva a posteriori è una distribuzione beta-binomiale di parametri <span class="math inline">\(m\)</span>, <span class="math inline">\(\alpha+y\)</span> e <span class="math inline">\(\beta+n-y\)</span>, dove <span class="math inline">\(m\)</span> è il numero di prove nel nuovo campione, <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> sono i parametri della distribuzione a priori, e <span class="math inline">\(y\)</span> e <span class="math inline">\(n\)</span> sono le proprietà del campione corrente. Nel caso dell’esempio in discussione, <span class="math inline">\(m = 30\)</span>, <span class="math inline">\(\alpha = 2 + 23 = 25\)</span>, <span class="math inline">\(\beta = 10 + 30 - 23 = 17\)</span>. Possiamo svolgere i calcoli necessario usando le funzioni del pacchetto <code>extraDistr</code>. Per i parametri specificati sopra, un grafico della distribuzione predittiva a posteriori si ottiene nel modo seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prob</span> <span class="op">&lt;-</span> <span class="fu">extraDistr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/extraDistr/man/BetaBinom.html">dbbinom</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">30</span>, <span class="fl">30</span>, <span class="fl">25</span>, <span class="fl">17</span><span class="op">)</span></span>
<span><span class="fu">tibble</span><span class="op">(</span>Y<span class="op">=</span><span class="fl">0</span><span class="op">:</span><span class="fl">30</span>, Probability <span class="op">=</span> <span class="va">prob</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ProbBayes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ProbBayes/man/prob_plot.html">prob_plot</a></span><span class="op">(</span>Color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>La distribuzione predittiva a posteriori illustrata nella figura precedente ci dice qual è la plausibilità relativa di osservare <span class="math inline">\(0, 1, \dots, 30\)</span> successi su <span class="math inline">\(m = 30\)</span> prove in un futuro campione di osservazioni, alla luce dei dati che abbiamo osservato nel campione corrente (23 successi in 30 prove) e tenuto conto delle nostre opinioni a priori sulla plausibilità dei possibili valori <span class="math inline">\(\theta\)</span> (ovvero, <span class="math inline">\(\mbox{Beta}(2, 10)\)</span>).</p>
<p>Esaminando la distribuzione predittiva notiamo che, nei possibili campioni futuri di 30 osservazioni, il valore <span class="math inline">\(\tilde{y}\)</span> più plausibile è 18. Tuttavia, <span class="math inline">\(\tilde{y}\)</span> può assumere anche altri valori e la distribuzione predittiva ci informa sulla <em>plausibilità relativa</em> di ciascuno dei possibili valori futuri <span class="math inline">\(\tilde{y}\)</span> – nel presente esempio, <span class="math inline">\(\tilde{y}\)</span> corrisponde al numero di pazienti clinici (su 30) che manifesteranno una depressione grave.</p>
<p>È desiderabile costruire un intervallo che contiene le realizzazioni <span class="math inline">\(\tilde{y}\)</span> ad un livello specificato di probabilità. Supponiamo che il livello di probabilità richiesto sia 0.89. L’intervallo si costruisce aggiungendo valori <span class="math inline">\(\tilde{y}\)</span> all’intervallo (partendo da quello con la probabilità maggiore) fino a che il contenuto di probabilità dell’insieme eccede la soglia richiesta, nel caso present di 0.89. La procedura è implementata nella funzione <code>discint()</code> del pacchetto <code>LearnBayes</code>. Per i dati dell’esempio otteniamo</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">LearnBayes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/LearnBayes/man/discint.html">discint</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">30</span>, <span class="va">prob</span><span class="op">)</span>, <span class="fl">0.89</span><span class="op">)</span></span>
<span><span class="co">#&gt; $prob</span></span>
<span><span class="co">#&gt; [1] 0.9152885</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $set</span></span>
<span><span class="co">#&gt;  [1] 12 13 14 15 16 17 18 19 20 21 22 23</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sulla base delle informazioni disponibili, possiamo dunque prevedere, con un livello di certezza soggettiva che eccede la soglia di 0.91, che in un futuro campione di 30 soggetti clinici depressi, il numero di pazienti con depressione grave sarà compreso tra 12 e 23.</p>
<p><span class="math display">\[
P(12 \leq \tilde{y} \leq 23) = 0.9145.
\]</span></p>
<p>In conclusione, per il caso beta-binomiale, possiamo dire che la predizione bayesiana di una nuova osservazione futura è la realizzazione di una distribuzione beta-binomiale di parametri <span class="math inline">\(m\)</span>, <span class="math inline">\(\alpha + y\)</span>, e <span class="math inline">\(\beta + n - y\)</span>, dove <span class="math inline">\(m\)</span> è il numero di prove nel nuovo campione, <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> sono i parametri della distribuzione a priori, e <span class="math inline">\(y\)</span> e <span class="math inline">\(n\)</span> sono le caratteristiche del campione.</p>
</section><section id="la-distribuzione-predittiva-a-posteriori-mediante-simulazione" class="level2" data-number="24.3"><h2 data-number="24.3" class="anchored" data-anchor-id="la-distribuzione-predittiva-a-posteriori-mediante-simulazione">
<span class="header-section-number">24.3</span> La distribuzione predittiva a posteriori mediante simulazione</h2>
<p>In situazioni dove è difficile derivare l’esatta distribuzione predittiva a posteriori è possibile ottenere un campione casuale di valori della distribuzione predittiva posteriori mediante simulazione. Facciamo un esempio riferito al caso che stiamo discutendo. È possibile svolgere la simulazione richiesta in due fasi. Supponiamo di volere ottenere un campione casuale di <span class="math inline">\(n\)</span> osservazioni dalla distribuzione predittiva a posteriori. A tal fine dobbiamo (1) estrarre <span class="math inline">\(n\)</span> valori a caso del parametro <span class="math inline">\(\theta\)</span> dalla distribuzione a posteriori <span class="math inline">\(p(\theta \mid y)\)</span>: (2) con tali valori del parametro <span class="math inline">\(\theta\)</span> generiamo <span class="math inline">\(n\)</span> valori casuali <span class="math inline">\(\tilde{y}\)</span>; a tal fine usiamo il modello binomiale di parametri <span class="math inline">\(m\)</span> e <span class="math inline">\(\theta_i\)</span> (con <span class="math inline">\(i = 1, \dots, n\)</span>). Otteniamo così <span class="math inline">\(n\)</span> realizzazioni casuali di <span class="math inline">\(n\)</span> distribuzioni binomiali aventi i parametri specificati sopra.</p>
<p>Vediamo come si fa in pratica con <span class="math inline">\(\mathsf{R}\)</span>. Per l’esempio che stiamo discutendo, la distribuzione a posteriori è una <span class="math inline">\(\mbox{Beta}(25, 17)\)</span>. Estraiamo 100,000 valori a caso da tale distribuzione.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">12345</span><span class="op">)</span></span>
<span><span class="va">nrep</span> <span class="op">&lt;-</span> <span class="fl">1e5</span></span>
<span><span class="va">a</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">23</span></span>
<span><span class="va">pred_p_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">rbeta</a></span><span class="op">(</span><span class="va">nrep</span>, <span class="va">a</span> <span class="op">+</span> <span class="va">y</span>, <span class="va">b</span> <span class="op">+</span> <span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I primi 10 valori così ottenuti sono riportati di seguito.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pred_p_sim</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span></span>
<span><span class="co">#&gt;  [1] 0.5435206 0.5319551 0.6045577 0.6337146 0.7552324 0.5393935 0.6187069</span></span>
<span><span class="co">#&gt;  [8] 0.6193819 0.6736216 0.6051480</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per ciascuno dei valori <span class="math inline">\(\theta_i\)</span>, con <span class="math inline">\(i = 1, \dots, 100,000\)</span>, estraggo a caso un valore dalla distribuzione binomiale di parametri <span class="math inline">\(n = 30\)</span> e <span class="math inline">\(\theta_i\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pred_y_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">nrep</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">nrep</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">pred_y_sim</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">30</span>, <span class="va">pred_p_sim</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="co"># In maniera equivalente posso fare:</span></span>
<span><span class="co"># pred_y_sim &lt;- rbinom(1e5, n, pred_p_sim)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcolo la proporzione di volte in cui sono stati osservai i valori <span class="math inline">\(\tilde{y} = 0, 1, \dots, 30\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ppd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">pred_y_sim</span><span class="op">)</span> <span class="op">/</span> <span class="va">nrep</span></span>
<span><span class="va">ppd</span></span>
<span><span class="co">#&gt; pred_y_sim</span></span>
<span><span class="co">#&gt;       3       4       5       6       7       8       9      10      11      12 </span></span>
<span><span class="co">#&gt; 0.00002 0.00004 0.00011 0.00036 0.00096 0.00241 0.00533 0.01000 0.01753 0.02882 </span></span>
<span><span class="co">#&gt;      13      14      15      16      17      18      19      20      21      22 </span></span>
<span><span class="co">#&gt; 0.04290 0.06110 0.07812 0.09476 0.10763 0.11311 0.10821 0.09765 0.07982 0.06185 </span></span>
<span><span class="co">#&gt;      23      24      25      26      27      28      29      30 </span></span>
<span><span class="co">#&gt; 0.04156 0.02536 0.01299 0.00630 0.00224 0.00064 0.00016 0.00002</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcolo l’intervallo di valori <span class="math inline">\(\tilde{y}\)</span> a cui è associata una probabilità di 0.89 (per fare un confronto con il risultato ottenuto in precedenza).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">LearnBayes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/LearnBayes/man/discint.html">discint</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fl">3</span><span class="op">:</span><span class="fl">30</span>, <span class="va">ppd</span><span class="op">)</span>, <span class="fl">0.89</span><span class="op">)</span> </span>
<span><span class="co">#&gt; $prob</span></span>
<span><span class="co">#&gt;      12 </span></span>
<span><span class="co">#&gt; 0.91553 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $set</span></span>
<span><span class="co">#&gt; 12 13 14 15 16 17 18 19 20 21 22 23 </span></span>
<span><span class="co">#&gt; 12 13 14 15 16 17 18 19 20 21 22 23</span></span>
<span><span class="co"># i risultati minori di 3 non sono stati calcolati</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Confronto i risultati della simulazione con i valori esatti della distribuzione predittiva a posteriori. Di seguito riporto i risultati esatti.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prob30</span> <span class="op">&lt;-</span> <span class="fu">extraDistr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/extraDistr/man/BetaBinom.html">dbbinom</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">30</span>, <span class="fl">30</span>, <span class="fl">25</span>, <span class="fl">17</span><span class="op">)</span></span>
<span><span class="fu">LearnBayes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/LearnBayes/man/discint.html">discint</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">30</span>, <span class="va">prob30</span><span class="op">)</span>, <span class="fl">0.89</span><span class="op">)</span></span>
<span><span class="co">#&gt; $prob</span></span>
<span><span class="co">#&gt; [1] 0.9152885</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $set</span></span>
<span><span class="co">#&gt;  [1] 12 13 14 15 16 17 18 19 20 21 22 23</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Un grafico con la distribuzione predittiva a posteriori esatta è fornito nella figura seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">tibble</span><span class="op">(</span>Y<span class="op">=</span><span class="fl">0</span><span class="op">:</span><span class="fl">30</span>, Probability <span class="op">=</span> <span class="va">prob30</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ProbBayes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ProbBayes/man/prob_plot.html">prob_plot</a></span><span class="op">(</span>Color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Una rappresentazione della distribuzione a posteriori ottenuta mediante simulazione è il seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">tibble</span><span class="op">(</span>Y<span class="op">=</span><span class="fl">0</span><span class="op">:</span><span class="fl">30</span>, Probability <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="va">ppd</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ProbBayes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ProbBayes/man/prob_plot.html">prob_plot</a></span><span class="op">(</span>Color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Si noti che i risultati della simulazione sono indistinguibili dalla soluzione esatta.</p>
</section><section id="la-distribuzione-predittiva-a-posteriori-mediante-mcmc" class="level2" data-number="24.4"><h2 data-number="24.4" class="anchored" data-anchor-id="la-distribuzione-predittiva-a-posteriori-mediante-mcmc">
<span class="header-section-number">24.4</span> La distribuzione predittiva a posteriori mediante MCMC</h2>
<p>Il metodo basato su simulazione che abbiamo discusso sopra si basa sulla stessa logica usata dai metodi MCMC per ottenere un’approssimazione della distribuzione predittiva a posteriori. Mediante i metodi MCMC, le stime delle possibili osservazioni future <span class="math inline">\(p(\tilde{y} \mid y)\)</span>, chiamate <span class="math inline">\(p(y^{rep} \mid y)\)</span>, si ottengono nel modo seguente:</p>
<ul>
<li>campionare <span class="math inline">\(\theta_i \sim p(\theta \mid y)\)</span>, ovvero scegliere un valore a caso del parametro dalla distribuzione a posteriori;</li>
<li>campionare <span class="math inline">\(y^{rep} \sim p(y^{rep} \mid \theta_i)\)</span>, ovvero scegliere un’osservazione a caso dalla funzione di verosimiglianza condizionata al valore del parametro definito nel passo precedente.</li>
</ul>
<p>Se i due passaggi descritti sopra vengono ripetuti un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva a posteriori che, in teoria potrebbe essere ottenuta per via analitica.</p>
<div id="exr-post-pred-check-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 24.1 </strong></span>Utilizziamo il codice Stan per generare <span class="math inline">\(p(y^{rep} \mid y)\)</span> nel caso dell’inferenza su una proporzione.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">modelString</span> <span class="op">=</span> <span class="st">"</span></span>
<span><span class="st">data {</span></span>
<span><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span><span class="st">  array[N] int&lt;lower=0, upper=1&gt; y;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">parameters {</span></span>
<span><span class="st">  real&lt;lower=0, upper=1&gt; theta;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">model {</span></span>
<span><span class="st">  theta ~ beta(2, 10);</span></span>
<span><span class="st">  y ~ bernoulli(theta);</span></span>
<span><span class="st">}</span></span>
<span><span class="st">generated quantities {</span></span>
<span><span class="st">  array[N] int y_rep;</span></span>
<span><span class="st">  for (n in 1 : N) {</span></span>
<span><span class="st">    y_rep[n] = bernoulli_rng(theta);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">modelString</span>, con <span class="op">=</span> <span class="st">"code/betabin23-30-2-10.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si noti che nel nel blocco <code>generated quantities</code> sono state aggiunte le istruzioni necessarie per simulare <span class="math inline">\(y^{rep}\)</span>, ovvero, <code>y_rep[n] = bernoulli_rng(theta)</code>. Una tale istruzione ci dice di generare un valore casuale di una variabile Bernoulliana di parametro <span class="math inline">\(\theta\)</span>. Il valore <span class="math inline">\(\theta\)</span> è preso a caso dalla distribuzione a posteriori <span class="math inline">\(p(\theta \mid y)\)</span>. Il ciclo <code>for</code> specifica che tale operazione va ripetuta 30 volte per <em>ciascuna</em> iterazione MCMC.</p>
<p>I dati dell’esempio sono forniti in formato <code>list</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">data_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  N <span class="op">=</span> <span class="fl">30</span>,</span>
<span>  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">23</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">7</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Compiliamo il codice Stan.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"betabin23-30-2-10.stan"</span><span class="op">)</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Eseguiamo il campionamento MCMC.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">data_list</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">4000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">2000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="va">SEED</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per comodità, trasformiamo l’oggetto <code>fit</code> in un oggetto di classe <code>stanfit</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">stanfit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_csv.html">read_stan_csv</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="fu">output_files</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Il contenuto dell’oggetto <code>stanfit</code> può essere esaminato mediante la funzione <code>extract()</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">list_of_draws</span> <span class="op">&lt;-</span> <span class="fu">extract</span><span class="op">(</span><span class="va">stanfit</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">list_of_draws</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "theta" "y_rep" "lp__"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Dall’oggetto <code>list_of_draws</code> recuperiamo <code>y_rep</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">y_bern</span> <span class="op">&lt;-</span> <span class="va">list_of_draws</span><span class="op">$</span><span class="va">y_rep</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">y_bern</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 16000    30</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">y_bern</span><span class="op">)</span></span>
<span><span class="co">#&gt;           </span></span>
<span><span class="co">#&gt; iterations [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]</span></span>
<span><span class="co">#&gt;       [1,]    1    1    1    1    0    1    1    1    1     1     1     1     1</span></span>
<span><span class="co">#&gt;       [2,]    0    1    0    1    1    1    0    0    1     0     0     0     0</span></span>
<span><span class="co">#&gt;       [3,]    0    1    0    1    1    1    0    0    1     1     1     0     1</span></span>
<span><span class="co">#&gt;       [4,]    1    0    0    1    1    0    0    1    0     1     1     1     0</span></span>
<span><span class="co">#&gt;       [5,]    0    0    0    1    1    0    1    1    0     1     0     0     1</span></span>
<span><span class="co">#&gt;       [6,]    1    1    1    1    1    1    0    1    0     1     1     1     0</span></span>
<span><span class="co">#&gt;           </span></span>
<span><span class="co">#&gt; iterations [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24]</span></span>
<span><span class="co">#&gt;       [1,]     0     1     1     1     1     1     0     0     1     0     1</span></span>
<span><span class="co">#&gt;       [2,]     1     0     0     1     0     1     1     1     0     0     0</span></span>
<span><span class="co">#&gt;       [3,]     0     0     1     0     1     1     0     1     0     0     1</span></span>
<span><span class="co">#&gt;       [4,]     0     1     0     1     0     1     0     0     1     0     1</span></span>
<span><span class="co">#&gt;       [5,]     0     0     1     1     1     1     1     0     1     0     1</span></span>
<span><span class="co">#&gt;       [6,]     1     1     0     1     0     1     1     0     0     1     0</span></span>
<span><span class="co">#&gt;           </span></span>
<span><span class="co">#&gt; iterations [,25] [,26] [,27] [,28] [,29] [,30]</span></span>
<span><span class="co">#&gt;       [1,]     1     1     1     1     1     1</span></span>
<span><span class="co">#&gt;       [2,]     0     1     1     0     1     1</span></span>
<span><span class="co">#&gt;       [3,]     1     1     1     1     1     0</span></span>
<span><span class="co">#&gt;       [4,]     0     1     1     0     0     1</span></span>
<span><span class="co">#&gt;       [5,]     0     0     0     0     1     0</span></span>
<span><span class="co">#&gt;       [6,]     0     0     1     0     1     1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Dato che il codice Stan definisce un modello per i dati grezzi (ovvero, per ciascuna singola prova Bernoulliana del campione), ogni riga della matrice <code>y_bern</code> ha 30 colonne, ciascuna delle quali corrisponde ad un campione (<span class="math inline">\(n\)</span> = 16,000 in questa simulazione) di possibili valori futuri <span class="math inline">\(y_i \in \{0, 1\}\)</span>. In altre parole, abbiamo generato 16,000 campioni casuali di 30 osservazioni possibili osservazioni future.</p>
<p>Per ottenere una stima della distribuzione predittiva a posteriori <span class="math inline">\(p(\tilde{y} \mid y)\)</span>, ovvero, per ottenere una stima della probabilità associata a ciascuno dei possibili numeri di successi, <span class="math inline">\(\tilde{y}\)</span>, in <span class="math inline">\(m = 30\)</span> nuove prove future, è sufficiente calcolare la proporzione di valori 1 in ciascuna riga della matrice <code>y_bern</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">tibble</span><span class="op">(</span>y_rep <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">y_bern</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">y_rep</span>, <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Si noti che l’istogramma così ottenuto è equivalente a quello trovato nella simulazione precedente.</p>
</div>
</section><section id="i-metodi-per-la-valutazione-del-modello" class="level2" data-number="24.5"><h2 data-number="24.5" class="anchored" data-anchor-id="i-metodi-per-la-valutazione-del-modello">
<span class="header-section-number">24.5</span> I metodi per la valutazione del modello</h2>
<section id="posterior-predictive-checks" class="level3" data-number="24.5.1"><h3 data-number="24.5.1" class="anchored" data-anchor-id="posterior-predictive-checks">
<span class="header-section-number">24.5.1</span> Posterior predictive checks</h3>
<p>La distribuzione predittiva a posteriori viene utilizzata per eseguire i cosiddetti <em>controlli predittivi a posteriori</em> (<em>Posterior Predictive Checks</em>, PPC). Nella distribuzione predittiva a posteriori, viene generato un campione di dati possibili futuri utilizzando le proprietà del modello adattato. È ovvio che tali dati possibili futuri devono almento essere coerenti con i dati del campione presente. I PPC eseguono un confronto grafico tra <span class="math inline">\(p(y^{rep} \mid y)\)</span> e i dati osservati <span class="math inline">\(y\)</span>: confrontando visivamente gli aspetti chiave dei dati previsti futuri <span class="math inline">\(y^{rep}\)</span> e dei dati osservati <span class="math inline">\(y\)</span> è possibile determinare se il modello è adeguato.</p>
<p>Oltre al confronto visivo tra le distribuzioni <span class="math inline">\(p(y)\)</span> e <span class="math inline">\(p(y^{rep})\)</span> è anche possibile un confronto tra la distribuzione di varie statistiche descrittive, i cui valori sono calcolati su diversi campioni <span class="math inline">\(y^{rep}\)</span>, e le corrispondenti statistiche calcolate sui dati osservati. Vengono solitamente considerate statistiche descrittive quali la media, la varianza, la deviazione standard, il minimo o il massimo, ma sono possibili confronti di questo tipo per qualunque altra statistica.</p>
<div id="exr-post-pred-check-2" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 24.2 </strong></span>Esaminiamo ora un set di dati che non seguono la distribuzione normale <span class="citation" data-cites="gelman2020regression">(<a href="999_refs.html#ref-gelman2020regression" role="doc-biblioref">Gelman et al., 2020</a>)</span>. I dati corrispondono ad una serie di misurazioni prese da Simon Newcomb nel 1882 come parte di un esperimento per stimare la velocità della luce. A questi dati verrà (inappropriatamente) adattata una distribuzione normale. L’obiettivo dell’esempio è quello di mostrare come i PPC possono rivelare la mancanza di adattamento di un modello ai dati.</p>
<p>I PPC mostrano che il modo più semplice per verificare l’adattamento del modello è quello di visualizzare <span class="math inline">\(y^{rep}\)</span> insieme ai dati effettivi. Iniziamo a caricare i dati.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">"MASS"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"newcomb"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Visualizziamo la distribuzione dei dati con un istogramma.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">tibble</span><span class="op">(</span><span class="va">newcomb</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">newcomb</span>, <span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Creiamo un oggetto di tipo <code>list</code> dove inserire i dati.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">data_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  y <span class="op">=</span> <span class="va">newcomb</span>,</span>
<span>  N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">newcomb</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Utilizziamo il seguente codice Stan per il modello normale.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">modelString</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">data {</span></span>
<span><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span><span class="st">  vector[N] y;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">parameters {</span></span>
<span><span class="st">  real mu;</span></span>
<span><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">model {</span></span>
<span><span class="st">  mu ~ normal(25, 10);</span></span>
<span><span class="st">  sigma ~ cauchy(0, 10);</span></span>
<span><span class="st">  y ~ normal(mu, sigma);</span></span>
<span><span class="st">}</span></span>
<span><span class="st">generated quantities {</span></span>
<span><span class="st">  vector[N] y_rep;</span></span>
<span><span class="st">  for (n in 1 : N) {</span></span>
<span><span class="st">    y_rep[n] = normal_rng(mu, sigma);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">modelString</span>, con <span class="op">=</span> <span class="st">"code/newcomb.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Adattiamo il modello ai dati.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"newcomb.stan"</span><span class="op">)</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">data_list</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">4000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">2000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="va">SEED</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Otteniamo le stime dei parametri <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span><span class="op">$</span><span class="fu">summary</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mu"</span>, <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 2 × 10</span></span>
<span><span class="co">#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 mu        26.2   26.2 1.33  1.30  24.0   28.4  1.00   13305.   11189.</span></span>
<span><span class="co">#&gt; 2 sigma     10.9   10.8 0.958 0.943  9.40  12.5  1.00   12614.   10352.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Trasformiamo l’oggetto <code>fit</code> in un formato <code>stanfit</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">stanfit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_csv.html">read_stan_csv</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="fu">output_files</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Rappresentiamo graficamente la distribuzione a posteriori di <span class="math inline">\(\mu\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mu_draws</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">stanfit</span>, pars <span class="op">=</span> <span class="st">"mu"</span><span class="op">)</span></span>
<span><span class="fu">mcmc_areas</span><span class="op">(</span><span class="va">mu_draws</span>, prob <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span> <span class="co"># color 95% interval</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-27-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>La media campionaria è pari a 26.21.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">newcomb</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 26.21212</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Anche se trova la media giusta, il modello non è comunque adeguato a prevedere le altre proprietà della <span class="math inline">\(y\)</span>. Estraiamo <span class="math inline">\(y^{rep}\)</span> dall’oggetto <code>stanfit</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">y_rep</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">stanfit</span>, pars <span class="op">=</span> <span class="st">"y_rep"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">y_rep</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 16000    66</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I valori <code>y_rep</code> sono i dati della distribuzione predittiva a posteriori che sono stati simulati usando gli stessi valori <span class="math inline">\(X\)</span> dei predittori utilizzati per adattare il modello. Il confronto tra l’istogramma della <span class="math inline">\(y\)</span> e gli istogrammi di diversi campioni <span class="math inline">\(y^{rep}\)</span> mostra una scarsa corrispondenza tra i due.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ppc_hist</span><span class="op">(</span><span class="va">data_list</span><span class="op">$</span><span class="va">y</span>, <span class="va">y_rep</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">8</span>, <span class="op">]</span>, binwidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-30-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Alla stessa conclusione si giunge tramite un confronto tra la funzione di densità empirica della <span class="math inline">\(y\)</span> e quella di diversi campioni <span class="math inline">\(y^{rep}\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ppc_dens_overlay</span><span class="op">(</span><span class="va">data_list</span><span class="op">$</span><span class="va">y</span>, <span class="va">y_rep</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">50</span>, <span class="op">]</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-31-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Generiamo ora i PPC per la media e il minimo della distribuzione.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ppc_stat_2d</span><span class="op">(</span><span class="va">data_list</span><span class="op">$</span><span class="va">y</span>, <span class="va">y_rep</span>, stat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mean"</span>, <span class="st">"min"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-32-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>In conclusione, possiamo dire che mentre la media viene riprodotta accuratamente dal modello, ciò non è vero per il minimo della distribuzione. L’origine di questa mancanza di adattamento è il fatto che la distribuzione delle misurazioni della velocità della luce è asimmetrica negativa.</p>
<p>Dato che ci sono poche osservazioni nella coda negativa della distribuzione, solo per fare un esempio, utilizzeremo ora un secondo modello che ipotizza una distribuzione <span class="math inline">\(t\)</span> di Student.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">modelString</span> <span class="op">=</span> <span class="st">"</span></span>
<span><span class="st">data {</span></span>
<span><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span><span class="st">  vector[N] y;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">parameters {</span></span>
<span><span class="st">  real mu;</span></span>
<span><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span><span class="st">  real&lt;lower=0&gt; nu;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">model {</span></span>
<span><span class="st">  mu ~ normal(25, 10);</span></span>
<span><span class="st">  sigma ~ cauchy(0, 10);</span></span>
<span><span class="st">  nu ~ cauchy(0, 10);</span></span>
<span><span class="st">  y ~ student_t(nu, mu, sigma);</span></span>
<span><span class="st">}</span></span>
<span><span class="st">generated quantities {</span></span>
<span><span class="st">  vector[N] y_rep;</span></span>
<span><span class="st">  for (n in 1 : N) {</span></span>
<span><span class="st">    y_rep[n] = student_t_rng(nu, mu, sigma);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span><span class="op">(</span><span class="va">modelString</span>, con <span class="op">=</span> <span class="st">"code/newcomb2.stan"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Adattiamo questo secondo modello ai dati.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"newcomb2.stan"</span><span class="op">)</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu">cmdstan_model</span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="va">mod</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">data_list</span>,</span>
<span>  iter_sampling <span class="op">=</span> <span class="fl">4000L</span>,</span>
<span>  iter_warmup <span class="op">=</span> <span class="fl">2000L</span>,</span>
<span>  seed <span class="op">=</span> <span class="va">SEED</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4L</span>,</span>
<span>  refresh <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Running MCMC with 4 sequential chains...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Chain 1 finished in 0.2 seconds.</span></span>
<span><span class="co">#&gt; Chain 2 finished in 0.3 seconds.</span></span>
<span><span class="co">#&gt; Chain 3 finished in 0.3 seconds.</span></span>
<span><span class="co">#&gt; Chain 4 finished in 0.4 seconds.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; All 4 chains finished successfully.</span></span>
<span><span class="co">#&gt; Mean chain execution time: 0.3 seconds.</span></span>
<span><span class="co">#&gt; Total execution time: 1.5 seconds.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per questo secondo modello il confronto tra la funzione di densità empirica della <span class="math inline">\(y\)</span> e quella di diversi campioni <span class="math inline">\(y^{rep}\)</span> risulta adeguato.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">stanfit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_csv.html">read_stan_csv</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="fu">output_files</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y_rep</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">stanfit</span>, pars <span class="op">=</span> <span class="st">"y_rep"</span><span class="op">)</span></span>
<span><span class="fu">ppc_dens_overlay</span><span class="op">(</span><span class="va">data_list</span><span class="op">$</span><span class="va">y</span>, <span class="va">y_rep</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">50</span>, <span class="op">]</span><span class="op">)</span> <span class="op">+</span> <span class="fu">xlim</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-35-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Inoltre, anche la statistica “minimo della distribuzione” viene ben predetta dal modello.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ppc_stat_2d</span><span class="op">(</span><span class="va">data_list</span><span class="op">$</span><span class="va">y</span>, <span class="va">y_rep</span>, stat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mean"</span>, <span class="st">"min"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-36-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>In conclusione, per le misurazioni della velocità della luce di Newcomb l’accuratezza predittiva del modello basato sulla distribuzione <span class="math inline">\(t\)</span> di Student è chiaramente migliore di quella del modello normale.</p>
</div>
</section></section><section id="distribuzione-predittiva-a-priori" class="level2" data-number="24.6"><h2 data-number="24.6" class="anchored" data-anchor-id="distribuzione-predittiva-a-priori">
<span class="header-section-number">24.6</span> Distribuzione predittiva a priori</h2>
<p>Nella sezione precedente abbiamo visto come la distribuzione predittiva è stata usata per generare nuovi dati previsti futuri. Più precisamente, mediante l’<a href="#eq-post-pred-distr">Equazione&nbsp;<span>24.1</span></a> abbiamo descritto la nostra incertezza sulla distribuzione di future osservazioni di dati, data la distribuzione a posteriori di <span class="math inline">\(\theta\)</span>, ovvero tenendo conto della scelta del modello e della stima dei parametri mediante i dati osservati.</p>
<p><span class="math display">\[
p(\tilde{y} \mid y) = \int_{\theta} p(\tilde{y} \mid \theta) p(\theta \mid y) \,\operatorname {d}\!\theta\notag
\]</span></p>
<p>Si noti che, nell’<a href="#eq-post-pred-distr">Equazione&nbsp;<span>24.1</span></a>, <span class="math inline">\(\tilde{y}\)</span> è condizionato da <span class="math inline">\(y\)</span> ma non da ciò che è incognito, ovvero <span class="math inline">\(\theta\)</span>. La distribuzione predittiva a posteriori è ottenuta mediante marginalizzazione sopra i parametri incogniti <span class="math inline">\(\theta\)</span>.</p>
<p>In un modello bayesiano dove <span class="math inline">\(\theta\)</span> ha una distribuzione a priori <span class="math inline">\(p(\theta)\)</span> e per <span class="math inline">\(y\)</span> possiamo definire la funzione di verosimiglianza <span class="math inline">\(p(y \mid \theta)\)</span> possiamo scrivere la distribuzione congiunta <span class="math inline">\(p(y, \theta)\)</span> come il prodotto della verosimiglianza e della distribuzione a priori:</p>
<p><span class="math display">\[
p(y, \theta) = p(y \mid \theta)p(\theta).
\]</span></p>
<p>Una rappresentazione alternativa della distribuzione congiunta <span class="math inline">\(p(y, \theta)\)</span> è</p>
<p><span class="math display">\[
p(y, \theta) = p(\theta \mid y)p(y).
\]</span></p>
<p>Il primo termine in questo prodotto, la densità <span class="math inline">\(p(\theta \mid y)\)</span>, è la densità a posteriori di <span class="math inline">\(\theta\)</span> date le osservazioni <span class="math inline">\(y\)</span>. Il secondo termine in questo prodotto, <span class="math inline">\(p(y)\)</span>, è la <em>distribuzione predittiva a priori</em> che rappresenta la distribuzione dei dati futuri previsti dal modello prima di avere osservato il campione <span class="math inline">\(y\)</span>. Se risulta che i dati osservati <span class="math inline">\(y\)</span> non sono coerenti con la distribuzione predittiva a priori, ciò significa che il modello bayesiano non è specificato correttamente. In altre parole, questo ci dice che, in base al modello bayesiano che abbiamo formulato, è improbabile che si verifichino i dati che sono stati effettivamente osservati. Ovviamente, questo vuol dire che il modello è inadeguato.</p>
<p>La distribuzione predittiva a priori può essere ricavata facilmente se l’inferenza bayesiana viene svolta mediante i metodi MCMC. Per fare un esempio consideriamo nuovamente i dati di <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span>, con 23 successi in 30 prove. Nella discussione precedente abbiamo svolto l’aggiornamento bayesiano imponendo su <span class="math inline">\(\theta\)</span> una distribuzione a priori <span class="math inline">\(\mbox{Beta}(2, 10)\)</span>.</p>
<p>Nel caso di una verosimiglianza binomiale e di una distribuzione a priori Beta, la distribuzione predittiva a priori può essere costruita mediante la funzione <code><a href="https://rdrr.io/pkg/LearnBayes/man/pbetap.html">LearnBayes::pbetap()</a></code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span></span>
<span>  y <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">30</span>,</span>
<span>  Probability <span class="op">=</span> <span class="fu">LearnBayes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/LearnBayes/man/pbetap.html">pbetap</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fl">30</span>, <span class="fl">0</span><span class="op">:</span><span class="fl">30</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ProbBayes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ProbBayes/man/prob_plot.html">prob_plot</a></span><span class="op">(</span>Color <span class="op">=</span> <span class="st">"gray"</span>, Size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="fu">tibble</span><span class="op">(</span>y <span class="op">=</span> <span class="fl">23</span>, Probability <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-37-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>La distribuzione predittiva a priori assegna livelli diversi di credibilità a ciascuno dei possibili risultati dell’esperimento casuale, ovvero il fatto di osservare 0, 1, , 30 successi in 30 prove Bernoulliane.</p>
<p>Nella distribuzione predittiva a priori riportata nel grafico precedente ho evidenziato il punto <span class="math inline">\(y = 23\)</span>, ovvero il numero di successi nel campione. Il grafico mostra che la distribuzione predittiva a priori assegna una credibilità quasi nulla all’evento <span class="math inline">\(y = 23\)</span>, ovvero ai dati che sono stati effettivamente osservati. Questo indica chiaramente che la distribuzione a priori <span class="math inline">\(\mbox{Beta}(2, 10)\)</span> non è adeguata per i dati che stiamo analizzando, così come avevamo in precedenza anticipato.</p>
<p>Se viene invece utilizzata una distribuzione a priori debolmente informativa, o vero <span class="math inline">\(\mbox{Beta}(2, 2)\)</span>, la distribuzione predittiva a priori assume la forma seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span></span>
<span>  y <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">30</span>,</span>
<span>  Probability <span class="op">=</span> <span class="fu">LearnBayes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/LearnBayes/man/pbetap.html">pbetap</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>, <span class="fl">30</span>, <span class="fl">0</span><span class="op">:</span><span class="fl">30</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ProbBayes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ProbBayes/man/prob_plot.html">prob_plot</a></span><span class="op">(</span>Color <span class="op">=</span> <span class="st">"gray"</span>, Size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="fu">tibble</span><span class="op">(</span>y <span class="op">=</span> <span class="fl">23</span>, Probability <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="046_bayesian_prediction_files/figure-html/unnamed-chunk-38-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>In questo secondo caso al valore <span class="math inline">\(y\)</span> osservato viene assegnata una credibilità piuttosto alta. Ciò significa che una <span class="math inline">\(\mbox{Beta}(2, 2)\)</span> fornisce un’adeguata distribuzione a priori per i dati a disposizione.</p>
<p>Nella discussione dell’analisi dei dati di <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span>, la <span class="math inline">\(\mbox{Beta}(2, 10)\)</span> è stata utilizzata quale distribuzione a priori solo per evidenziare le proprietà dell’aggiornamento bayesiano (la differenza tra la distribuzione a priori e la distribuzione a posteriori). La discussione presente chiarisce che la <span class="math inline">\(\mbox{Beta}(2, 10)\)</span> non è una buona scelta per la distribuzione a priori: sarebbe molto migliore la scelta di una <span class="math inline">\(\mbox{Beta}(2, 2)\)</span>.</p>
</section><section id="commenti-e-considerazioni-finali" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="commenti-e-considerazioni-finali">Commenti e considerazioni finali</h2>
<p>Questo capitolo discute la predizione bayesiana e ne mostra un’applicazione nel caso dei controlli predittivi a posteriori. A questo proposito è necessario notare un punto importante: un buona corrispondenza tra <span class="math inline">\(y\)</span> e <span class="math inline">\(y^{rep}\)</span> costituisce una condizione necessaria ma non sufficiente per la validità del modello. Infatti, i PPC non sono in grado di garantire la generalizzabilità del modello a nuovi campioni di dati. D’altra parte, invece, se i PPC mostrano un cattivo adattamento del modello ai dati previsti futuri, questo ci dice chiaramente che il modello è specificato in maniera errata.</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography" style="display: none">
<div id="ref-gelman2020regression" class="csl-entry" role="doc-biblioentry">
Gelman, A., Hill, J., &amp; Vehtari, A. (2020). <em>Regression and other stories</em>. Cambridge University Press.
</div>
<div id="ref-zetschefuture2019" class="csl-entry" role="doc-biblioentry">
Zetsche, U., Bürkner, P.-C., &amp; Renneberg, B. (2019). Future expectations in clinical depression: <span>Biased</span> or realistic? <em>Journal of Abnormal Psychology</em>, <em>128</em>(7), 678–688.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./045_summarize_posterior.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./050_normal_normal_mod.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb38" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># La predizione bayesiana {#sec-prediction}</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include = FALSE}</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_stan_options.R"</span>)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co"># check_cmdstan_toolchain(fix = TRUE, quiet = TRUE)</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># register_knitr_engine()</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>Oltre ad una sintesi della distribuzione a posteriori attraverso il computo di indici caratteristici e alla verifica di ipotesi, un altro compito dell'analisi bayesiana è la predizione di nuovi dati futuri. Dopo aver osservato i dati di un campione e dopo avere ricavato le distribuzioni a posteriori dei parametri, è infatti possibile ottenere delle indicazioni sulle proprietà di dati futuri. L'uso più immediato della stima della distribuzione dei possibili valori futuri della variabile di esito è la verifica del modello in esame. Infatti, il modo più diretto per testare un modello è quello di utilizzare il modello corrente per fare previsioni sui possibili dati futuri per poi confrontare i dati predetti con i dati che sono stati effettivamente osservati nel campione corrente. Questa pratica va sotto il nome di *controllo predittivo a posteriori*. In questo capitolo ci focalizzeremo sul problema della predizione bayesiana esaminando il caso più semplice, ovvero lo schema beta-binomiale. In seguito estenderemo questa discussione al caso generale.</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="fu">## La distribuzione predittiva a posteriori</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>Una volta costruita la distribuzione a posteriori del parametro o dei parametri sconosciuti, potremmo essere interessati a utilizzare il modello bayesiano allo scopo di prevedere la probabilità di risultati futuri basandoci sui dati già osservati. Questo tipo di analisi inferenziale va sotto il nome di *analisi predittiva*.</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>L'esempio che considereremo qui nei dettagli riguarda il caso beta-binomiale, nel quale la distribuzione a priori per il parametro ignoto $\theta$ (ovvero, la probabilità di successo) è una distribuzione Beta, la verosimiglianza è binomiale e i dati sono costituiti dal numero $y$ di successi in $n$ prove Bernoulliane indipendenti. Nell'esempio che discuteremo useremo un'altra volta i dati del campione di pazienti clinici depressi di @zetschefuture2019. Supponendo di volere esaminare in futuro altri $m$ pazienti clinici, ci chiediamo: quanti di essi manifesteranno una depressione grave?</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>Siamo dunque interessati a predire i risultati che si potrebbero osservare in nuovi campioni di $m = 30$ osservazioni. Denotiamo con $\tilde{y}$ la manifestazione della variabile casuale $\tilde{Y}$. In un nuovo campione di $m$ osservazioni, $\tilde{y}$ assumerà il valore $\tilde{y}_1$ (ad es., 12), in un altro campione assumerà il valore $\tilde{y}_2$ (ad es., 23), e così via. Siamo interessati a descrivere la probabilità che $\tilde{y}$ assuma i valori $0, 1, 2, \dots, 29, 30$. Tale distribuzione (in questo caso) di massa di probabilità si chiama *distribuzione predittiva a posteriori* $p(\tilde{Y} = \tilde{y} \mid Y = y)$ e corrisponde alla probabilità assegnata a ciascuno dei possibili valori $\tilde{y}$ ($0, 1, 2, \dots, 29, 30$) nei possibili campioni futuri di $m$ osservazioni.</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>In questo Capitolo ci porremo il problema di trovare la distribuzione predittiva a posteriori nel caso beta-binomiale. Useremo tre metodi diversi:</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la soluzione analitica,</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>i risultati di una simulazione,</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>il campionamento MCMC.</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>I tre metodi producono risultati equivalenti. In seguito useremo il metodo MCMC perché ci consente di trovare facilmente la risposta cercata, anche quando una soluzione analitica non è disponibile.</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a><span class="fu">## Soluzione analitica</span></span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>Nel caso dell'esempio in discussione, la distribuzione di $\tilde{Y}$ dipende da $\theta$ e ciò che sappiamo di $\theta$ è sintetizzato nella distribuzione a posteriori $p(\theta \mid y)$. Usando la regola della catena, possiamo scrivere la distribuzione congiunta di $\tilde{y}$ e $\theta$ nel modo seguente</span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a>p(\tilde{y}, \theta \mid y) = p(\tilde{y} \mid \theta, y) p(\theta \mid y).</span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a>Assumendo che le osservazioni future $\tilde{y}$ e passate $y$ siano condizionalmente indipendenti dato $\theta$, l'espressione precedente può essere scritta come</span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-38"><a href="#cb38-38" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-39"><a href="#cb38-39" aria-hidden="true" tabindex="-1"></a>p(\tilde{y}, \theta \mid y) = p(\tilde{y} \mid \theta) p(\theta \mid y).</span>
<span id="cb38-40"><a href="#cb38-40" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-41"><a href="#cb38-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-42"><a href="#cb38-42" aria-hidden="true" tabindex="-1"></a>La distribuzione predittiva a posteriori viene ottenuta dalla distribuzione congiunta di $\tilde{y}$ e $\theta$ integrando rispetto a $\theta$:</span>
<span id="cb38-43"><a href="#cb38-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-44"><a href="#cb38-44" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-45"><a href="#cb38-45" aria-hidden="true" tabindex="-1"></a>p(\tilde{y} \mid y) = \int_{\theta} p(\tilde{y} \mid \theta) p(\theta \mid y) \,\operatorname {d}<span class="sc">\!</span>\theta.</span>
<span id="cb38-46"><a href="#cb38-46" aria-hidden="true" tabindex="-1"></a>$$ {#eq-post-pred-distr}</span>
<span id="cb38-47"><a href="#cb38-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-48"><a href="#cb38-48" aria-hidden="true" tabindex="-1"></a>Nel caso dello schema beta-binomiale, la funzione $p(\tilde{y} \mid \theta)$ è binomiale di parametri $m$ e $\theta$, e la distribuzione a posteriori $p(\theta \mid y)$ è una $\mbox{Beta}(\alpha + y, \beta + n - y)$. Risolvendo l'integrale otteniamo:</span>
<span id="cb38-49"><a href="#cb38-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-50"><a href="#cb38-50" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-51"><a href="#cb38-51" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb38-52"><a href="#cb38-52" aria-hidden="true" tabindex="-1"></a>p(\tilde{y} \mid y) &amp;= \int_0^1 p(\tilde{y} \mid \theta)</span>
<span id="cb38-53"><a href="#cb38-53" aria-hidden="true" tabindex="-1"></a>p(\theta \mid y)\,\operatorname {d}<span class="sc">\!</span>\theta \notag<span class="sc">\\</span></span>
<span id="cb38-54"><a href="#cb38-54" aria-hidden="true" tabindex="-1"></a> &amp;= \int_0^1 \begin{pmatrix}m<span class="sc">\\</span>\tilde{y}\end{pmatrix}</span>
<span id="cb38-55"><a href="#cb38-55" aria-hidden="true" tabindex="-1"></a> \theta^{\tilde{y}}</span>
<span id="cb38-56"><a href="#cb38-56" aria-hidden="true" tabindex="-1"></a>(1-\theta)^{m-\tilde{y}} \, \mbox{Beta}(a+y,b+n-y) \, d\theta \notag<span class="sc">\\</span></span>
<span id="cb38-57"><a href="#cb38-57" aria-hidden="true" tabindex="-1"></a>&amp;= \begin{pmatrix}{m}<span class="sc">\\</span>\tilde{y}\end{pmatrix} \int_0^1 \theta^{\tilde{y}}</span>
<span id="cb38-58"><a href="#cb38-58" aria-hidden="true" tabindex="-1"></a>(1-\theta)^{m-\tilde{y}} \frac{1}{B(a+y, b+n-y)}\theta^{a+y-1}(1-\theta)^{b+n-y-1}\notag<span class="sc">\\</span></span>
<span id="cb38-59"><a href="#cb38-59" aria-hidden="true" tabindex="-1"></a>&amp;= \begin{pmatrix}{ m }<span class="sc">\\</span>\tilde{y}\end{pmatrix} \frac{1}{B(a+y, b+n-y)}\int_0^1 \theta^{\tilde{y}+a+y-1}(1-\theta)^{m-\tilde{y}+b+n-y-1}\notag<span class="sc">\\</span></span>
<span id="cb38-60"><a href="#cb38-60" aria-hidden="true" tabindex="-1"></a>&amp;= \begin{pmatrix}{ m }<span class="sc">\\</span>\tilde{y}\end{pmatrix} \frac{B(\tilde{y}+a+y,b+n-y+m-\tilde{y})}{B(a+y, b+n-y)} \; .</span>
<span id="cb38-61"><a href="#cb38-61" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb38-62"><a href="#cb38-62" aria-hidden="true" tabindex="-1"></a>$$ {#eq-post-yprime-an-sol-betabin}</span>
<span id="cb38-63"><a href="#cb38-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-64"><a href="#cb38-64" aria-hidden="true" tabindex="-1"></a>In conclusione, per lo schema beta-binomiale, la distribuzione predittiva a posteriori corrisponde ad una distribuzione di probabilità discreta chiamata *distribuzione beta-binomiale* di parametri $m$, $\alpha+y$ e $\beta+n-y$.</span>
<span id="cb38-65"><a href="#cb38-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-66"><a href="#cb38-66" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-67"><a href="#cb38-67" aria-hidden="true" tabindex="-1"></a>f(\tilde{y} \mid y) = \binom{m}{\tilde{y}} \frac{B(a+ y + \tilde{y}, b + n - y + m - \tilde{y})}{B(a+y, b+n-y)},</span>
<span id="cb38-68"><a href="#cb38-68" aria-hidden="true" tabindex="-1"></a>$$ {#eq-beta-binomial-distr}</span>
<span id="cb38-69"><a href="#cb38-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-70"><a href="#cb38-70" aria-hidden="true" tabindex="-1"></a>Nell'esempio relativo allo studio di @zetschefuture2019, la verosimiglianza è binomiale, i dati sono costituiti da 23 successi su 30 prove e la distribuzione a priori su $\theta$ è $\mbox{Beta}(2, 10)$. Di conseguenza, la distribuzione a posteriori è $\mbox{Beta}(25, 17)$. Vogliamo calcolare la distribuzione predittiva a posteriori per un nuovo campione, poniamo, di $m = 30$ osservazioni (ma, in generale, $m$ può essere diverso da $n$).</span>
<span id="cb38-71"><a href="#cb38-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-72"><a href="#cb38-72" aria-hidden="true" tabindex="-1"></a>In base all'@eq-beta-binomial-distr sappiamo che la distribuzione predittiva a posteriori è una distribuzione beta-binomiale di parametri $m$, $\alpha+y$ e $\beta+n-y$, dove $m$ è il numero di prove nel nuovo campione, $\alpha$ e $\beta$ sono i parametri della distribuzione a priori, e $y$ e $n$ sono le proprietà del campione corrente. Nel caso dell'esempio in discussione, $m = 30$, $\alpha = 2 + 23 = 25$, $\beta = 10 + 30 - 23 = 17$. Possiamo svolgere i calcoli necessario usando le funzioni del pacchetto <span class="in">`extraDistr`</span>. Per i parametri specificati sopra, un grafico della distribuzione predittiva a posteriori si ottiene nel modo seguente.</span>
<span id="cb38-73"><a href="#cb38-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-76"><a href="#cb38-76" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-77"><a href="#cb38-77" aria-hidden="true" tabindex="-1"></a>prob <span class="ot">&lt;-</span> extraDistr<span class="sc">::</span><span class="fu">dbbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, <span class="dv">30</span>, <span class="dv">25</span>, <span class="dv">17</span>)</span>
<span id="cb38-78"><a href="#cb38-78" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">Y=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, <span class="at">Probability =</span> prob) <span class="sc">%&gt;%</span> </span>
<span id="cb38-79"><a href="#cb38-79" aria-hidden="true" tabindex="-1"></a>  ProbBayes<span class="sc">::</span><span class="fu">prob_plot</span>(<span class="at">Color =</span> <span class="st">"black"</span>)</span>
<span id="cb38-80"><a href="#cb38-80" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-81"><a href="#cb38-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-82"><a href="#cb38-82" aria-hidden="true" tabindex="-1"></a>La distribuzione predittiva a posteriori illustrata nella figura precedente ci dice qual è la plausibilità relativa di osservare $0, 1, \dots, 30$ successi su $m = 30$ prove in un futuro campione di osservazioni, alla luce dei dati che abbiamo osservato nel campione corrente (23 successi in 30 prove) e tenuto conto delle nostre opinioni a priori sulla plausibilità dei possibili valori $\theta$ (ovvero, $\mbox{Beta}(2, 10)$).</span>
<span id="cb38-83"><a href="#cb38-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-84"><a href="#cb38-84" aria-hidden="true" tabindex="-1"></a>Esaminando la distribuzione predittiva notiamo che, nei possibili campioni futuri di 30 osservazioni, il valore $\tilde{y}$ più plausibile è 18. Tuttavia, $\tilde{y}$ può assumere anche altri valori e la distribuzione predittiva ci informa sulla *plausibilità relativa* di ciascuno dei possibili valori futuri $\tilde{y}$ -- nel presente esempio, $\tilde{y}$ corrisponde al numero di pazienti clinici (su 30) che manifesteranno una depressione grave.</span>
<span id="cb38-85"><a href="#cb38-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-86"><a href="#cb38-86" aria-hidden="true" tabindex="-1"></a>È desiderabile costruire un intervallo che contiene le realizzazioni $\tilde{y}$ ad un livello specificato di probabilità. Supponiamo che il livello di probabilità richiesto sia 0.89. L'intervallo si costruisce aggiungendo valori $\tilde{y}$ all'intervallo (partendo da quello con la probabilità maggiore) fino a che il contenuto di probabilità dell'insieme eccede la soglia richiesta, nel caso present di 0.89. La procedura è implementata nella funzione <span class="in">`discint()`</span> del pacchetto <span class="in">`LearnBayes`</span>. Per i dati dell'esempio otteniamo</span>
<span id="cb38-87"><a href="#cb38-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-90"><a href="#cb38-90" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-91"><a href="#cb38-91" aria-hidden="true" tabindex="-1"></a>LearnBayes<span class="sc">::</span><span class="fu">discint</span>(<span class="fu">cbind</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, prob), <span class="fl">0.89</span>)</span>
<span id="cb38-92"><a href="#cb38-92" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-93"><a href="#cb38-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-94"><a href="#cb38-94" aria-hidden="true" tabindex="-1"></a>Sulla base delle informazioni disponibili, possiamo dunque prevedere, con un livello di certezza soggettiva che eccede la soglia di 0.91, che in un futuro campione di 30 soggetti clinici depressi, il numero di pazienti con depressione grave sarà compreso tra 12 e 23.</span>
<span id="cb38-95"><a href="#cb38-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-96"><a href="#cb38-96" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-97"><a href="#cb38-97" aria-hidden="true" tabindex="-1"></a>P(12 \leq \tilde{y} \leq 23) = 0.9145.</span>
<span id="cb38-98"><a href="#cb38-98" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-99"><a href="#cb38-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-100"><a href="#cb38-100" aria-hidden="true" tabindex="-1"></a>In conclusione, per il caso beta-binomiale, possiamo dire che la predizione bayesiana di una nuova osservazione futura è la realizzazione di una distribuzione beta-binomiale di parametri $m$, $\alpha + y$, e $\beta + n - y$, dove $m$ è il numero di prove nel nuovo campione, $\alpha$ e $\beta$ sono i parametri della distribuzione a priori, e $y$ e $n$ sono le caratteristiche del campione.</span>
<span id="cb38-101"><a href="#cb38-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-102"><a href="#cb38-102" aria-hidden="true" tabindex="-1"></a><span class="fu">## La distribuzione predittiva a posteriori mediante simulazione</span></span>
<span id="cb38-103"><a href="#cb38-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-104"><a href="#cb38-104" aria-hidden="true" tabindex="-1"></a>In situazioni dove è difficile derivare l'esatta distribuzione predittiva a posteriori è possibile ottenere un campione casuale di valori della distribuzione predittiva posteriori mediante simulazione. Facciamo un esempio riferito al caso che stiamo discutendo. È possibile svolgere la simulazione richiesta in due fasi. Supponiamo di volere ottenere un campione casuale di $n$ osservazioni dalla distribuzione predittiva a posteriori. A tal fine dobbiamo (1) estrarre $n$ valori a caso del parametro $\theta$ dalla distribuzione a posteriori $p(\theta \mid y)$: (2) con tali valori del parametro $\theta$ generiamo $n$ valori casuali $\tilde{y}$; a tal fine usiamo il modello binomiale di parametri $m$ e $\theta_i$ (con $i = 1, \dots, n$). Otteniamo così $n$ realizzazioni casuali di $n$ distribuzioni binomiali aventi i parametri specificati sopra.</span>
<span id="cb38-105"><a href="#cb38-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-106"><a href="#cb38-106" aria-hidden="true" tabindex="-1"></a>Vediamo come si fa in pratica con $\mathsf{R}$. Per l'esempio che stiamo discutendo, la distribuzione a posteriori è una $\mbox{Beta}(25, 17)$. Estraiamo 100,000 valori a caso da tale distribuzione.</span>
<span id="cb38-107"><a href="#cb38-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-110"><a href="#cb38-110" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-111"><a href="#cb38-111" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb38-112"><a href="#cb38-112" aria-hidden="true" tabindex="-1"></a>nrep <span class="ot">&lt;-</span> <span class="fl">1e5</span></span>
<span id="cb38-113"><a href="#cb38-113" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb38-114"><a href="#cb38-114" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb38-115"><a href="#cb38-115" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb38-116"><a href="#cb38-116" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">23</span></span>
<span id="cb38-117"><a href="#cb38-117" aria-hidden="true" tabindex="-1"></a>pred_p_sim <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(nrep, a <span class="sc">+</span> y, b <span class="sc">+</span> n <span class="sc">-</span> y)</span>
<span id="cb38-118"><a href="#cb38-118" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-119"><a href="#cb38-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-120"><a href="#cb38-120" aria-hidden="true" tabindex="-1"></a>I primi 10 valori così ottenuti sono riportati di seguito.</span>
<span id="cb38-121"><a href="#cb38-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-124"><a href="#cb38-124" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-125"><a href="#cb38-125" aria-hidden="true" tabindex="-1"></a>pred_p_sim[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span>
<span id="cb38-126"><a href="#cb38-126" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-127"><a href="#cb38-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-128"><a href="#cb38-128" aria-hidden="true" tabindex="-1"></a>Per ciascuno dei valori $\theta_i$, con $i = 1, \dots, 100,000$, estraggo a caso un valore dalla distribuzione binomiale di parametri $n = 30$ e $\theta_i$.</span>
<span id="cb38-129"><a href="#cb38-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-132"><a href="#cb38-132" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-133"><a href="#cb38-133" aria-hidden="true" tabindex="-1"></a>pred_y_sim <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nrep)</span>
<span id="cb38-134"><a href="#cb38-134" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nrep) {</span>
<span id="cb38-135"><a href="#cb38-135" aria-hidden="true" tabindex="-1"></a>  pred_y_sim[i] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">30</span>, pred_p_sim[i])</span>
<span id="cb38-136"><a href="#cb38-136" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-137"><a href="#cb38-137" aria-hidden="true" tabindex="-1"></a><span class="co"># In maniera equivalente posso fare:</span></span>
<span id="cb38-138"><a href="#cb38-138" aria-hidden="true" tabindex="-1"></a><span class="co"># pred_y_sim &lt;- rbinom(1e5, n, pred_p_sim)</span></span>
<span id="cb38-139"><a href="#cb38-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-140"><a href="#cb38-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-141"><a href="#cb38-141" aria-hidden="true" tabindex="-1"></a>Calcolo la proporzione di volte in cui sono stati osservai i valori $\tilde{y} = 0, 1, \dots, 30$.</span>
<span id="cb38-142"><a href="#cb38-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-145"><a href="#cb38-145" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-146"><a href="#cb38-146" aria-hidden="true" tabindex="-1"></a>ppd <span class="ot">&lt;-</span> <span class="fu">table</span>(pred_y_sim) <span class="sc">/</span> nrep</span>
<span id="cb38-147"><a href="#cb38-147" aria-hidden="true" tabindex="-1"></a>ppd</span>
<span id="cb38-148"><a href="#cb38-148" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-149"><a href="#cb38-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-150"><a href="#cb38-150" aria-hidden="true" tabindex="-1"></a>Calcolo l'intervallo di valori $\tilde{y}$ a cui è associata una probabilità di 0.89 (per fare un confronto con il risultato ottenuto in precedenza).</span>
<span id="cb38-151"><a href="#cb38-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-154"><a href="#cb38-154" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-155"><a href="#cb38-155" aria-hidden="true" tabindex="-1"></a>LearnBayes<span class="sc">::</span><span class="fu">discint</span>(<span class="fu">cbind</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">30</span>, ppd), <span class="fl">0.89</span>) </span>
<span id="cb38-156"><a href="#cb38-156" aria-hidden="true" tabindex="-1"></a><span class="co"># i risultati minori di 3 non sono stati calcolati</span></span>
<span id="cb38-157"><a href="#cb38-157" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-158"><a href="#cb38-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-159"><a href="#cb38-159" aria-hidden="true" tabindex="-1"></a>Confronto i risultati della simulazione con i valori esatti della distribuzione predittiva a posteriori. Di seguito riporto i risultati esatti.</span>
<span id="cb38-160"><a href="#cb38-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-163"><a href="#cb38-163" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-164"><a href="#cb38-164" aria-hidden="true" tabindex="-1"></a>prob30 <span class="ot">&lt;-</span> extraDistr<span class="sc">::</span><span class="fu">dbbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, <span class="dv">30</span>, <span class="dv">25</span>, <span class="dv">17</span>)</span>
<span id="cb38-165"><a href="#cb38-165" aria-hidden="true" tabindex="-1"></a>LearnBayes<span class="sc">::</span><span class="fu">discint</span>(<span class="fu">cbind</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, prob30), <span class="fl">0.89</span>)</span>
<span id="cb38-166"><a href="#cb38-166" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-167"><a href="#cb38-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-168"><a href="#cb38-168" aria-hidden="true" tabindex="-1"></a>Un grafico con la distribuzione predittiva a posteriori esatta è fornito nella figura seguente.</span>
<span id="cb38-169"><a href="#cb38-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-172"><a href="#cb38-172" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-173"><a href="#cb38-173" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">Y=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, <span class="at">Probability =</span> prob30) <span class="sc">%&gt;%</span> </span>
<span id="cb38-174"><a href="#cb38-174" aria-hidden="true" tabindex="-1"></a>  ProbBayes<span class="sc">::</span><span class="fu">prob_plot</span>(<span class="at">Color =</span> <span class="st">"black"</span>)</span>
<span id="cb38-175"><a href="#cb38-175" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-176"><a href="#cb38-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-177"><a href="#cb38-177" aria-hidden="true" tabindex="-1"></a>Una rappresentazione della distribuzione a posteriori ottenuta mediante simulazione è il seguente.</span>
<span id="cb38-178"><a href="#cb38-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-181"><a href="#cb38-181" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-182"><a href="#cb38-182" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">Y=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>, <span class="at">Probability =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, ppd)) <span class="sc">%&gt;%</span> </span>
<span id="cb38-183"><a href="#cb38-183" aria-hidden="true" tabindex="-1"></a>  ProbBayes<span class="sc">::</span><span class="fu">prob_plot</span>(<span class="at">Color =</span> <span class="st">"black"</span>)</span>
<span id="cb38-184"><a href="#cb38-184" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-185"><a href="#cb38-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-186"><a href="#cb38-186" aria-hidden="true" tabindex="-1"></a>Si noti che i risultati della simulazione sono indistinguibili dalla soluzione esatta.</span>
<span id="cb38-187"><a href="#cb38-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-188"><a href="#cb38-188" aria-hidden="true" tabindex="-1"></a><span class="fu">## La distribuzione predittiva a posteriori mediante MCMC</span></span>
<span id="cb38-189"><a href="#cb38-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-190"><a href="#cb38-190" aria-hidden="true" tabindex="-1"></a>Il metodo basato su simulazione che abbiamo discusso sopra si basa sulla stessa logica usata dai metodi MCMC per ottenere un'approssimazione della distribuzione predittiva a posteriori. Mediante i metodi MCMC, le stime delle possibili osservazioni future $p(\tilde{y} \mid y)$, chiamate $p(y^{rep} \mid y)$, si ottengono nel modo seguente:</span>
<span id="cb38-191"><a href="#cb38-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-192"><a href="#cb38-192" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>campionare $\theta_i \sim p(\theta \mid y)$, ovvero scegliere un valore a caso del parametro dalla distribuzione a posteriori;</span>
<span id="cb38-193"><a href="#cb38-193" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>campionare $y^{rep} \sim p(y^{rep} \mid \theta_i)$, ovvero scegliere un'osservazione a caso dalla funzione di verosimiglianza condizionata al valore del parametro definito nel passo precedente.</span>
<span id="cb38-194"><a href="#cb38-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-195"><a href="#cb38-195" aria-hidden="true" tabindex="-1"></a>Se i due passaggi descritti sopra vengono ripetuti un numero sufficiente di volte, l'istogramma risultante approssimerà la distribuzione predittiva a posteriori che, in teoria potrebbe essere ottenuta per via analitica.</span>
<span id="cb38-196"><a href="#cb38-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-197"><a href="#cb38-197" aria-hidden="true" tabindex="-1"></a>::: {#exr-post-pred-check-1}</span>
<span id="cb38-198"><a href="#cb38-198" aria-hidden="true" tabindex="-1"></a>Utilizziamo il codice Stan per generare $p(y^{rep} \mid y)$ nel caso dell'inferenza su una proporzione.</span>
<span id="cb38-199"><a href="#cb38-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-202"><a href="#cb38-202" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-203"><a href="#cb38-203" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">"</span></span>
<span id="cb38-204"><a href="#cb38-204" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb38-205"><a href="#cb38-205" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb38-206"><a href="#cb38-206" aria-hidden="true" tabindex="-1"></a><span class="st">  array[N] int&lt;lower=0, upper=1&gt; y;</span></span>
<span id="cb38-207"><a href="#cb38-207" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-208"><a href="#cb38-208" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb38-209"><a href="#cb38-209" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0, upper=1&gt; theta;</span></span>
<span id="cb38-210"><a href="#cb38-210" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-211"><a href="#cb38-211" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb38-212"><a href="#cb38-212" aria-hidden="true" tabindex="-1"></a><span class="st">  theta ~ beta(2, 10);</span></span>
<span id="cb38-213"><a href="#cb38-213" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ bernoulli(theta);</span></span>
<span id="cb38-214"><a href="#cb38-214" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-215"><a href="#cb38-215" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb38-216"><a href="#cb38-216" aria-hidden="true" tabindex="-1"></a><span class="st">  array[N] int y_rep;</span></span>
<span id="cb38-217"><a href="#cb38-217" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1 : N) {</span></span>
<span id="cb38-218"><a href="#cb38-218" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = bernoulli_rng(theta);</span></span>
<span id="cb38-219"><a href="#cb38-219" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb38-220"><a href="#cb38-220" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-221"><a href="#cb38-221" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb38-222"><a href="#cb38-222" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">"code/betabin23-30-2-10.stan"</span>)</span>
<span id="cb38-223"><a href="#cb38-223" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-224"><a href="#cb38-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-225"><a href="#cb38-225" aria-hidden="true" tabindex="-1"></a>Si noti che nel nel blocco <span class="in">`generated quantities`</span> sono state aggiunte le istruzioni necessarie per simulare $y^{rep}$, ovvero, <span class="in">`y_rep[n] = bernoulli_rng(theta)`</span>. Una tale istruzione ci dice di generare un valore casuale di una variabile Bernoulliana di parametro $\theta$. Il valore $\theta$ è preso a caso dalla distribuzione a posteriori $p(\theta \mid y)$. Il ciclo <span class="in">`for`</span> specifica che tale operazione va ripetuta 30 volte per *ciascuna* iterazione MCMC.</span>
<span id="cb38-226"><a href="#cb38-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-227"><a href="#cb38-227" aria-hidden="true" tabindex="-1"></a>I dati dell'esempio sono forniti in formato <span class="in">`list`</span>.</span>
<span id="cb38-228"><a href="#cb38-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-231"><a href="#cb38-231" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-232"><a href="#cb38-232" aria-hidden="true" tabindex="-1"></a>data_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb38-233"><a href="#cb38-233" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="dv">30</span>,</span>
<span id="cb38-234"><a href="#cb38-234" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">23</span>), <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">7</span>))</span>
<span id="cb38-235"><a href="#cb38-235" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-236"><a href="#cb38-236" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-237"><a href="#cb38-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-238"><a href="#cb38-238" aria-hidden="true" tabindex="-1"></a>Compiliamo il codice Stan.</span>
<span id="cb38-239"><a href="#cb38-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-240"><a href="#cb38-240" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE, comment=FALSE, error=FALSE, results='hide'}</span></span>
<span id="cb38-241"><a href="#cb38-241" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"betabin23-30-2-10.stan"</span>)</span>
<span id="cb38-242"><a href="#cb38-242" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb38-243"><a href="#cb38-243" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-244"><a href="#cb38-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-245"><a href="#cb38-245" aria-hidden="true" tabindex="-1"></a>Eseguiamo il campionamento MCMC.</span>
<span id="cb38-246"><a href="#cb38-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-247"><a href="#cb38-247" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE, comment=FALSE, error=FALSE, results='hide'}</span></span>
<span id="cb38-248"><a href="#cb38-248" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb38-249"><a href="#cb38-249" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data_list,</span>
<span id="cb38-250"><a href="#cb38-250" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb38-251"><a href="#cb38-251" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb38-252"><a href="#cb38-252" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb38-253"><a href="#cb38-253" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb38-254"><a href="#cb38-254" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb38-255"><a href="#cb38-255" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-256"><a href="#cb38-256" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-257"><a href="#cb38-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-258"><a href="#cb38-258" aria-hidden="true" tabindex="-1"></a>\noindent Per comodità, trasformiamo l'oggetto <span class="in">`fit`</span> in un oggetto di classe <span class="in">`stanfit`</span>.</span>
<span id="cb38-259"><a href="#cb38-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-262"><a href="#cb38-262" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-263"><a href="#cb38-263" aria-hidden="true" tabindex="-1"></a>stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit<span class="sc">$</span><span class="fu">output_files</span>())</span>
<span id="cb38-264"><a href="#cb38-264" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-265"><a href="#cb38-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-266"><a href="#cb38-266" aria-hidden="true" tabindex="-1"></a>\noindent Il contenuto dell'oggetto <span class="in">`stanfit`</span> può essere esaminato mediante la funzione <span class="in">`extract()`</span>.</span>
<span id="cb38-267"><a href="#cb38-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-270"><a href="#cb38-270" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-271"><a href="#cb38-271" aria-hidden="true" tabindex="-1"></a>list_of_draws <span class="ot">&lt;-</span> <span class="fu">extract</span>(stanfit)</span>
<span id="cb38-272"><a href="#cb38-272" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">names</span>(list_of_draws))</span>
<span id="cb38-273"><a href="#cb38-273" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-274"><a href="#cb38-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-275"><a href="#cb38-275" aria-hidden="true" tabindex="-1"></a>\noindent Dall'oggetto <span class="in">`list_of_draws`</span> recuperiamo <span class="in">`y_rep`</span>.</span>
<span id="cb38-276"><a href="#cb38-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-279"><a href="#cb38-279" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-280"><a href="#cb38-280" aria-hidden="true" tabindex="-1"></a>y_bern <span class="ot">&lt;-</span> list_of_draws<span class="sc">$</span>y_rep</span>
<span id="cb38-281"><a href="#cb38-281" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(y_bern)</span>
<span id="cb38-282"><a href="#cb38-282" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(y_bern)</span>
<span id="cb38-283"><a href="#cb38-283" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-284"><a href="#cb38-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-285"><a href="#cb38-285" aria-hidden="true" tabindex="-1"></a>Dato che il codice Stan definisce un modello per i dati grezzi (ovvero, per ciascuna singola prova Bernoulliana del campione), ogni riga della matrice <span class="in">`y_bern`</span> ha 30 colonne, ciascuna delle quali corrisponde ad un campione ($n$ = 16,000 in questa simulazione) di possibili valori futuri $y_i \in <span class="sc">\{</span>0, 1<span class="sc">\}</span>$. In altre parole, abbiamo generato 16,000 campioni casuali di 30 osservazioni possibili osservazioni future.</span>
<span id="cb38-286"><a href="#cb38-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-287"><a href="#cb38-287" aria-hidden="true" tabindex="-1"></a>Per ottenere una stima della distribuzione predittiva a posteriori $p(\tilde{y} \mid y)$, ovvero, per ottenere una stima della probabilità associata a ciascuno dei possibili numeri di successi, $\tilde{y}$, in $m = 30$ nuove prove future, è sufficiente calcolare la proporzione di valori 1 in ciascuna riga della matrice <span class="in">`y_bern`</span>.</span>
<span id="cb38-288"><a href="#cb38-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-291"><a href="#cb38-291" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-292"><a href="#cb38-292" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">y_rep =</span> <span class="fu">rowSums</span>(y_bern)) <span class="sc">%&gt;%</span></span>
<span id="cb38-293"><a href="#cb38-293" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> y_rep, <span class="fu">after_stat</span>(density))) <span class="sc">+</span></span>
<span id="cb38-294"><a href="#cb38-294" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="dv">1</span>)</span>
<span id="cb38-295"><a href="#cb38-295" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-296"><a href="#cb38-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-297"><a href="#cb38-297" aria-hidden="true" tabindex="-1"></a>Si noti che l'istogramma così ottenuto è equivalente a quello trovato nella simulazione precedente.</span>
<span id="cb38-298"><a href="#cb38-298" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb38-299"><a href="#cb38-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-300"><a href="#cb38-300" aria-hidden="true" tabindex="-1"></a><span class="fu">## I metodi per la valutazione del modello</span></span>
<span id="cb38-301"><a href="#cb38-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-302"><a href="#cb38-302" aria-hidden="true" tabindex="-1"></a><span class="fu">### Posterior predictive checks</span></span>
<span id="cb38-303"><a href="#cb38-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-304"><a href="#cb38-304" aria-hidden="true" tabindex="-1"></a>La distribuzione predittiva a posteriori viene utilizzata per eseguire i cosiddetti *controlli predittivi a posteriori* (*Posterior Predictive Checks*, PPC). Nella distribuzione predittiva a posteriori, viene generato un campione di dati possibili futuri utilizzando le proprietà del modello adattato. È ovvio che tali dati possibili futuri devono almento essere coerenti con i dati del campione presente. I PPC eseguono un confronto grafico tra $p(y^{rep} \mid y)$ e i dati osservati $y$: confrontando visivamente gli aspetti chiave dei dati previsti futuri $y^{rep}$ e dei dati osservati $y$ è possibile determinare se il modello è adeguato.</span>
<span id="cb38-305"><a href="#cb38-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-306"><a href="#cb38-306" aria-hidden="true" tabindex="-1"></a>Oltre al confronto visivo tra le distribuzioni $p(y)$ e $p(y^{rep})$ è anche possibile un confronto tra la distribuzione di varie statistiche descrittive, i cui valori sono calcolati su diversi campioni $y^{rep}$, e le corrispondenti statistiche calcolate sui dati osservati. Vengono solitamente considerate statistiche descrittive quali la media, la varianza, la deviazione standard, il minimo o il massimo, ma sono possibili confronti di questo tipo per qualunque altra statistica.</span>
<span id="cb38-307"><a href="#cb38-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-308"><a href="#cb38-308" aria-hidden="true" tabindex="-1"></a>::: {#exr-post-pred-check-2}</span>
<span id="cb38-309"><a href="#cb38-309" aria-hidden="true" tabindex="-1"></a>Esaminiamo ora un set di dati che non seguono la distribuzione normale <span class="co">[</span><span class="ot">@gelman2020regression</span><span class="co">]</span>. I dati corrispondono ad una serie di misurazioni prese da Simon Newcomb nel 1882 come parte di un esperimento per stimare la velocità della luce. A questi dati verrà (inappropriatamente) adattata una distribuzione normale. L'obiettivo dell'esempio è quello di mostrare come i PPC possono rivelare la mancanza di adattamento di un modello ai dati.</span>
<span id="cb38-310"><a href="#cb38-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-311"><a href="#cb38-311" aria-hidden="true" tabindex="-1"></a>I PPC mostrano che il modo più semplice per verificare l'adattamento del modello è quello di visualizzare $y^{rep}$ insieme ai dati effettivi. Iniziamo a caricare i dati.</span>
<span id="cb38-312"><a href="#cb38-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-315"><a href="#cb38-315" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-316"><a href="#cb38-316" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"MASS"</span>)</span>
<span id="cb38-317"><a href="#cb38-317" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"newcomb"</span>)</span>
<span id="cb38-318"><a href="#cb38-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-319"><a href="#cb38-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-320"><a href="#cb38-320" aria-hidden="true" tabindex="-1"></a>Visualizziamo la distribuzione dei dati con un istogramma.</span>
<span id="cb38-321"><a href="#cb38-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-324"><a href="#cb38-324" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-325"><a href="#cb38-325" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(newcomb) <span class="sc">%&gt;%</span></span>
<span id="cb38-326"><a href="#cb38-326" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> newcomb, <span class="fu">after_stat</span>(density))) <span class="sc">+</span></span>
<span id="cb38-327"><a href="#cb38-327" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="dv">1</span>)</span>
<span id="cb38-328"><a href="#cb38-328" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-329"><a href="#cb38-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-330"><a href="#cb38-330" aria-hidden="true" tabindex="-1"></a>Creiamo un oggetto di tipo <span class="in">`list`</span> dove inserire i dati.</span>
<span id="cb38-331"><a href="#cb38-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-334"><a href="#cb38-334" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-335"><a href="#cb38-335" aria-hidden="true" tabindex="-1"></a>data_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb38-336"><a href="#cb38-336" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> newcomb,</span>
<span id="cb38-337"><a href="#cb38-337" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(newcomb)</span>
<span id="cb38-338"><a href="#cb38-338" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-339"><a href="#cb38-339" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-340"><a href="#cb38-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-341"><a href="#cb38-341" aria-hidden="true" tabindex="-1"></a>Utilizziamo il seguente codice Stan per il modello normale.</span>
<span id="cb38-342"><a href="#cb38-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-345"><a href="#cb38-345" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-346"><a href="#cb38-346" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb38-347"><a href="#cb38-347" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb38-348"><a href="#cb38-348" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb38-349"><a href="#cb38-349" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y;</span></span>
<span id="cb38-350"><a href="#cb38-350" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-351"><a href="#cb38-351" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb38-352"><a href="#cb38-352" aria-hidden="true" tabindex="-1"></a><span class="st">  real mu;</span></span>
<span id="cb38-353"><a href="#cb38-353" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span id="cb38-354"><a href="#cb38-354" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-355"><a href="#cb38-355" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb38-356"><a href="#cb38-356" aria-hidden="true" tabindex="-1"></a><span class="st">  mu ~ normal(25, 10);</span></span>
<span id="cb38-357"><a href="#cb38-357" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma ~ cauchy(0, 10);</span></span>
<span id="cb38-358"><a href="#cb38-358" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ normal(mu, sigma);</span></span>
<span id="cb38-359"><a href="#cb38-359" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-360"><a href="#cb38-360" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb38-361"><a href="#cb38-361" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y_rep;</span></span>
<span id="cb38-362"><a href="#cb38-362" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1 : N) {</span></span>
<span id="cb38-363"><a href="#cb38-363" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = normal_rng(mu, sigma);</span></span>
<span id="cb38-364"><a href="#cb38-364" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb38-365"><a href="#cb38-365" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-366"><a href="#cb38-366" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb38-367"><a href="#cb38-367" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">"code/newcomb.stan"</span>)</span>
<span id="cb38-368"><a href="#cb38-368" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-369"><a href="#cb38-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-370"><a href="#cb38-370" aria-hidden="true" tabindex="-1"></a>Adattiamo il modello ai dati.</span>
<span id="cb38-371"><a href="#cb38-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-372"><a href="#cb38-372" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, results='hide'}</span></span>
<span id="cb38-373"><a href="#cb38-373" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"newcomb.stan"</span>)</span>
<span id="cb38-374"><a href="#cb38-374" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb38-375"><a href="#cb38-375" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb38-376"><a href="#cb38-376" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data_list,</span>
<span id="cb38-377"><a href="#cb38-377" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb38-378"><a href="#cb38-378" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb38-379"><a href="#cb38-379" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb38-380"><a href="#cb38-380" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb38-381"><a href="#cb38-381" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb38-382"><a href="#cb38-382" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-383"><a href="#cb38-383" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-384"><a href="#cb38-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-385"><a href="#cb38-385" aria-hidden="true" tabindex="-1"></a>Otteniamo le stime dei parametri $\mu$ e $\sigma$.</span>
<span id="cb38-386"><a href="#cb38-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-389"><a href="#cb38-389" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-390"><a href="#cb38-390" aria-hidden="true" tabindex="-1"></a>fit<span class="sc">$</span><span class="fu">summary</span>(<span class="fu">c</span>(<span class="st">"mu"</span>, <span class="st">"sigma"</span>))</span>
<span id="cb38-391"><a href="#cb38-391" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-392"><a href="#cb38-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-393"><a href="#cb38-393" aria-hidden="true" tabindex="-1"></a>Trasformiamo l'oggetto <span class="in">`fit`</span> in un formato <span class="in">`stanfit`</span>.</span>
<span id="cb38-394"><a href="#cb38-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-397"><a href="#cb38-397" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-398"><a href="#cb38-398" aria-hidden="true" tabindex="-1"></a>stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit<span class="sc">$</span><span class="fu">output_files</span>())</span>
<span id="cb38-399"><a href="#cb38-399" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-400"><a href="#cb38-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-401"><a href="#cb38-401" aria-hidden="true" tabindex="-1"></a>Rappresentiamo graficamente la distribuzione a posteriori di $\mu$.</span>
<span id="cb38-402"><a href="#cb38-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-405"><a href="#cb38-405" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-406"><a href="#cb38-406" aria-hidden="true" tabindex="-1"></a>mu_draws <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(stanfit, <span class="at">pars =</span> <span class="st">"mu"</span>)</span>
<span id="cb38-407"><a href="#cb38-407" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_areas</span>(mu_draws, <span class="at">prob =</span> <span class="fl">0.95</span>) <span class="co"># color 95% interval</span></span>
<span id="cb38-408"><a href="#cb38-408" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-409"><a href="#cb38-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-410"><a href="#cb38-410" aria-hidden="true" tabindex="-1"></a>La media campionaria è pari a 26.21.</span>
<span id="cb38-411"><a href="#cb38-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-414"><a href="#cb38-414" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-415"><a href="#cb38-415" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(newcomb)</span>
<span id="cb38-416"><a href="#cb38-416" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-417"><a href="#cb38-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-418"><a href="#cb38-418" aria-hidden="true" tabindex="-1"></a>Anche se trova la media giusta, il modello non è comunque adeguato a prevedere le altre proprietà della $y$. Estraiamo $y^{rep}$ dall'oggetto <span class="in">`stanfit`</span>.</span>
<span id="cb38-419"><a href="#cb38-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-422"><a href="#cb38-422" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-423"><a href="#cb38-423" aria-hidden="true" tabindex="-1"></a>y_rep <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(stanfit, <span class="at">pars =</span> <span class="st">"y_rep"</span>)</span>
<span id="cb38-424"><a href="#cb38-424" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(y_rep)</span>
<span id="cb38-425"><a href="#cb38-425" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-426"><a href="#cb38-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-427"><a href="#cb38-427" aria-hidden="true" tabindex="-1"></a>I valori <span class="in">`y_rep`</span> sono i dati della distribuzione predittiva a posteriori che sono stati simulati usando gli stessi valori $X$ dei predittori utilizzati per adattare il modello. Il confronto tra l'istogramma della $y$ e gli istogrammi di diversi campioni $y^{rep}$ mostra una scarsa corrispondenza tra i due.</span>
<span id="cb38-428"><a href="#cb38-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-431"><a href="#cb38-431" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-432"><a href="#cb38-432" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_hist</span>(data_list<span class="sc">$</span>y, y_rep[<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>, ], <span class="at">binwidth =</span> <span class="dv">1</span>)</span>
<span id="cb38-433"><a href="#cb38-433" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-434"><a href="#cb38-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-435"><a href="#cb38-435" aria-hidden="true" tabindex="-1"></a>Alla stessa conclusione si giunge tramite un confronto tra la funzione di densità empirica della $y$ e quella di diversi campioni $y^{rep}$.</span>
<span id="cb38-436"><a href="#cb38-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-439"><a href="#cb38-439" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-440"><a href="#cb38-440" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_dens_overlay</span>(data_list<span class="sc">$</span>y, y_rep[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, ])</span>
<span id="cb38-441"><a href="#cb38-441" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-442"><a href="#cb38-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-443"><a href="#cb38-443" aria-hidden="true" tabindex="-1"></a>Generiamo ora i PPC per la media e il minimo della distribuzione.</span>
<span id="cb38-444"><a href="#cb38-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-447"><a href="#cb38-447" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-448"><a href="#cb38-448" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_stat_2d</span>(data_list<span class="sc">$</span>y, y_rep, <span class="at">stat =</span> <span class="fu">c</span>(<span class="st">"mean"</span>, <span class="st">"min"</span>))</span>
<span id="cb38-449"><a href="#cb38-449" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-450"><a href="#cb38-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-451"><a href="#cb38-451" aria-hidden="true" tabindex="-1"></a>In conclusione, possiamo dire che mentre la media viene riprodotta accuratamente dal modello, ciò non è vero per il minimo della distribuzione. L'origine di questa mancanza di adattamento è il fatto che la distribuzione delle misurazioni della velocità della luce è asimmetrica negativa.</span>
<span id="cb38-452"><a href="#cb38-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-453"><a href="#cb38-453" aria-hidden="true" tabindex="-1"></a>Dato che ci sono poche osservazioni nella coda negativa della distribuzione, solo per fare un esempio, utilizzeremo ora un secondo modello che ipotizza una distribuzione $t$ di Student.</span>
<span id="cb38-454"><a href="#cb38-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-457"><a href="#cb38-457" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-458"><a href="#cb38-458" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">"</span></span>
<span id="cb38-459"><a href="#cb38-459" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb38-460"><a href="#cb38-460" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb38-461"><a href="#cb38-461" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y;</span></span>
<span id="cb38-462"><a href="#cb38-462" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-463"><a href="#cb38-463" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb38-464"><a href="#cb38-464" aria-hidden="true" tabindex="-1"></a><span class="st">  real mu;</span></span>
<span id="cb38-465"><a href="#cb38-465" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span id="cb38-466"><a href="#cb38-466" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; nu;</span></span>
<span id="cb38-467"><a href="#cb38-467" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-468"><a href="#cb38-468" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb38-469"><a href="#cb38-469" aria-hidden="true" tabindex="-1"></a><span class="st">  mu ~ normal(25, 10);</span></span>
<span id="cb38-470"><a href="#cb38-470" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma ~ cauchy(0, 10);</span></span>
<span id="cb38-471"><a href="#cb38-471" aria-hidden="true" tabindex="-1"></a><span class="st">  nu ~ cauchy(0, 10);</span></span>
<span id="cb38-472"><a href="#cb38-472" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ student_t(nu, mu, sigma);</span></span>
<span id="cb38-473"><a href="#cb38-473" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-474"><a href="#cb38-474" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb38-475"><a href="#cb38-475" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y_rep;</span></span>
<span id="cb38-476"><a href="#cb38-476" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1 : N) {</span></span>
<span id="cb38-477"><a href="#cb38-477" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = student_t_rng(nu, mu, sigma);</span></span>
<span id="cb38-478"><a href="#cb38-478" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb38-479"><a href="#cb38-479" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb38-480"><a href="#cb38-480" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb38-481"><a href="#cb38-481" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">"code/newcomb2.stan"</span>)</span>
<span id="cb38-482"><a href="#cb38-482" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-483"><a href="#cb38-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-484"><a href="#cb38-484" aria-hidden="true" tabindex="-1"></a>Adattiamo questo secondo modello ai dati.</span>
<span id="cb38-485"><a href="#cb38-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-488"><a href="#cb38-488" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-489"><a href="#cb38-489" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">"code"</span>, <span class="st">"newcomb2.stan"</span>)</span>
<span id="cb38-490"><a href="#cb38-490" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb38-491"><a href="#cb38-491" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb38-492"><a href="#cb38-492" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data_list,</span>
<span id="cb38-493"><a href="#cb38-493" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb38-494"><a href="#cb38-494" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb38-495"><a href="#cb38-495" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb38-496"><a href="#cb38-496" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb38-497"><a href="#cb38-497" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span></span>
<span id="cb38-498"><a href="#cb38-498" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-499"><a href="#cb38-499" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-500"><a href="#cb38-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-501"><a href="#cb38-501" aria-hidden="true" tabindex="-1"></a>Per questo secondo modello il confronto tra la funzione di densità empirica della $y$ e quella di diversi campioni $y^{rep}$ risulta adeguato.</span>
<span id="cb38-502"><a href="#cb38-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-505"><a href="#cb38-505" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-506"><a href="#cb38-506" aria-hidden="true" tabindex="-1"></a>stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit<span class="sc">$</span><span class="fu">output_files</span>())</span>
<span id="cb38-507"><a href="#cb38-507" aria-hidden="true" tabindex="-1"></a>y_rep <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(stanfit, <span class="at">pars =</span> <span class="st">"y_rep"</span>)</span>
<span id="cb38-508"><a href="#cb38-508" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_dens_overlay</span>(data_list<span class="sc">$</span>y, y_rep[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, ]) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb38-509"><a href="#cb38-509" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-510"><a href="#cb38-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-511"><a href="#cb38-511" aria-hidden="true" tabindex="-1"></a>Inoltre, anche la statistica "minimo della distribuzione" viene ben predetta dal modello.</span>
<span id="cb38-512"><a href="#cb38-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-515"><a href="#cb38-515" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-516"><a href="#cb38-516" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_stat_2d</span>(data_list<span class="sc">$</span>y, y_rep, <span class="at">stat =</span> <span class="fu">c</span>(<span class="st">"mean"</span>, <span class="st">"min"</span>))</span>
<span id="cb38-517"><a href="#cb38-517" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-518"><a href="#cb38-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-519"><a href="#cb38-519" aria-hidden="true" tabindex="-1"></a>In conclusione, per le misurazioni della velocità della luce di Newcomb l'accuratezza predittiva del modello basato sulla distribuzione $t$ di Student è chiaramente migliore di quella del modello normale.</span>
<span id="cb38-520"><a href="#cb38-520" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb38-521"><a href="#cb38-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-522"><a href="#cb38-522" aria-hidden="true" tabindex="-1"></a><span class="fu">## Distribuzione predittiva a priori</span></span>
<span id="cb38-523"><a href="#cb38-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-524"><a href="#cb38-524" aria-hidden="true" tabindex="-1"></a>Nella sezione precedente abbiamo visto come la distribuzione predittiva è stata usata per generare nuovi dati previsti futuri. Più precisamente, mediante l'@eq-post-pred-distr abbiamo descritto la nostra incertezza sulla distribuzione di future osservazioni di dati, data la distribuzione a posteriori di $\theta$, ovvero tenendo conto della scelta del modello e della stima dei parametri mediante i dati osservati.</span>
<span id="cb38-525"><a href="#cb38-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-526"><a href="#cb38-526" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-527"><a href="#cb38-527" aria-hidden="true" tabindex="-1"></a>p(\tilde{y} \mid y) = \int_{\theta} p(\tilde{y} \mid \theta) p(\theta \mid y) \,\operatorname {d}<span class="sc">\!</span>\theta\notag</span>
<span id="cb38-528"><a href="#cb38-528" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-529"><a href="#cb38-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-530"><a href="#cb38-530" aria-hidden="true" tabindex="-1"></a>Si noti che, nell'@eq-post-pred-distr, $\tilde{y}$ è condizionato da $y$ ma non da ciò che è incognito, ovvero $\theta$. La distribuzione predittiva a posteriori è ottenuta mediante marginalizzazione sopra i parametri incogniti $\theta$.</span>
<span id="cb38-531"><a href="#cb38-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-532"><a href="#cb38-532" aria-hidden="true" tabindex="-1"></a>In un modello bayesiano dove $\theta$ ha una distribuzione a priori $p(\theta)$ e per $y$ possiamo definire la funzione di verosimiglianza $p(y \mid \theta)$ possiamo scrivere la distribuzione congiunta $p(y, \theta)$ come il prodotto della verosimiglianza e della distribuzione a priori:</span>
<span id="cb38-533"><a href="#cb38-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-534"><a href="#cb38-534" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-535"><a href="#cb38-535" aria-hidden="true" tabindex="-1"></a>p(y, \theta) = p(y \mid \theta)p(\theta).</span>
<span id="cb38-536"><a href="#cb38-536" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-537"><a href="#cb38-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-538"><a href="#cb38-538" aria-hidden="true" tabindex="-1"></a>Una rappresentazione alternativa della distribuzione congiunta $p(y, \theta)$ è</span>
<span id="cb38-539"><a href="#cb38-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-540"><a href="#cb38-540" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-541"><a href="#cb38-541" aria-hidden="true" tabindex="-1"></a>p(y, \theta) = p(\theta \mid y)p(y).</span>
<span id="cb38-542"><a href="#cb38-542" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb38-543"><a href="#cb38-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-544"><a href="#cb38-544" aria-hidden="true" tabindex="-1"></a>Il primo termine in questo prodotto, la densità $p(\theta \mid y)$, è la densità a posteriori di $\theta$ date le osservazioni $y$. Il secondo termine in questo prodotto, $p(y)$, è la *distribuzione predittiva a priori* che rappresenta la distribuzione dei dati futuri previsti dal modello prima di avere osservato il campione $y$. Se risulta che i dati osservati $y$ non sono coerenti con la distribuzione predittiva a priori, ciò significa che il modello bayesiano non è specificato correttamente. In altre parole, questo ci dice che, in base al modello bayesiano che abbiamo formulato, è improbabile che si verifichino i dati che sono stati effettivamente osservati. Ovviamente, questo vuol dire che il modello è inadeguato.</span>
<span id="cb38-545"><a href="#cb38-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-546"><a href="#cb38-546" aria-hidden="true" tabindex="-1"></a>La distribuzione predittiva a priori può essere ricavata facilmente se l'inferenza bayesiana viene svolta mediante i metodi MCMC. Per fare un esempio consideriamo nuovamente i dati di @zetschefuture2019, con 23 successi in 30 prove. Nella discussione precedente abbiamo svolto l'aggiornamento bayesiano imponendo su $\theta$ una distribuzione a priori $\mbox{Beta}(2, 10)$.</span>
<span id="cb38-547"><a href="#cb38-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-548"><a href="#cb38-548" aria-hidden="true" tabindex="-1"></a>Nel caso di una verosimiglianza binomiale e di una distribuzione a priori Beta, la distribuzione predittiva a priori può essere costruita mediante la funzione <span class="in">`LearnBayes::pbetap()`</span>.</span>
<span id="cb38-549"><a href="#cb38-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-552"><a href="#cb38-552" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-553"><a href="#cb38-553" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb38-554"><a href="#cb38-554" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>,</span>
<span id="cb38-555"><a href="#cb38-555" aria-hidden="true" tabindex="-1"></a>  <span class="at">Probability =</span> LearnBayes<span class="sc">::</span><span class="fu">pbetap</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">10</span>), <span class="dv">30</span>, <span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>)</span>
<span id="cb38-556"><a href="#cb38-556" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-557"><a href="#cb38-557" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span> </span>
<span id="cb38-558"><a href="#cb38-558" aria-hidden="true" tabindex="-1"></a>  ProbBayes<span class="sc">::</span><span class="fu">prob_plot</span>(<span class="at">Color =</span> <span class="st">"gray"</span>, <span class="at">Size =</span> <span class="dv">3</span>) <span class="sc">+</span> </span>
<span id="cb38-559"><a href="#cb38-559" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">y =</span> <span class="dv">23</span>, <span class="at">Probability =</span> <span class="dv">0</span>), <span class="at">size =</span> <span class="dv">3</span>) </span>
<span id="cb38-560"><a href="#cb38-560" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-561"><a href="#cb38-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-562"><a href="#cb38-562" aria-hidden="true" tabindex="-1"></a>La distribuzione predittiva a priori assegna livelli diversi di credibilità a ciascuno dei possibili risultati dell'esperimento casuale, ovvero il fatto di osservare 0, 1, \dots, 30 successi in 30 prove Bernoulliane.</span>
<span id="cb38-563"><a href="#cb38-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-564"><a href="#cb38-564" aria-hidden="true" tabindex="-1"></a>Nella distribuzione predittiva a priori riportata nel grafico precedente ho evidenziato il punto $y = 23$, ovvero il numero di successi nel campione. Il grafico mostra che la distribuzione predittiva a priori assegna una credibilità quasi nulla all'evento $y = 23$, ovvero ai dati che sono stati effettivamente osservati. Questo indica chiaramente che la distribuzione a priori $\mbox{Beta}(2, 10)$ non è adeguata per i dati che stiamo analizzando, così come avevamo in precedenza anticipato.</span>
<span id="cb38-565"><a href="#cb38-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-566"><a href="#cb38-566" aria-hidden="true" tabindex="-1"></a>Se viene invece utilizzata una distribuzione a priori debolmente informativa, o vero $\mbox{Beta}(2, 2)$, la distribuzione predittiva a priori assume la forma seguente.</span>
<span id="cb38-567"><a href="#cb38-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-570"><a href="#cb38-570" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb38-571"><a href="#cb38-571" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb38-572"><a href="#cb38-572" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>,</span>
<span id="cb38-573"><a href="#cb38-573" aria-hidden="true" tabindex="-1"></a>  <span class="at">Probability =</span> LearnBayes<span class="sc">::</span><span class="fu">pbetap</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">30</span>, <span class="dv">0</span><span class="sc">:</span><span class="dv">30</span>)</span>
<span id="cb38-574"><a href="#cb38-574" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-575"><a href="#cb38-575" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span> </span>
<span id="cb38-576"><a href="#cb38-576" aria-hidden="true" tabindex="-1"></a>  ProbBayes<span class="sc">::</span><span class="fu">prob_plot</span>(<span class="at">Color =</span> <span class="st">"gray"</span>, <span class="at">Size =</span> <span class="dv">3</span>) <span class="sc">+</span> </span>
<span id="cb38-577"><a href="#cb38-577" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">y =</span> <span class="dv">23</span>, <span class="at">Probability =</span> <span class="dv">0</span>), <span class="at">size =</span> <span class="dv">3</span>) </span>
<span id="cb38-578"><a href="#cb38-578" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb38-579"><a href="#cb38-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-580"><a href="#cb38-580" aria-hidden="true" tabindex="-1"></a>In questo secondo caso al valore $y$ osservato viene assegnata una credibilità piuttosto alta. Ciò significa che una $\mbox{Beta}(2, 2)$ fornisce un'adeguata distribuzione a priori per i dati a disposizione.</span>
<span id="cb38-581"><a href="#cb38-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-582"><a href="#cb38-582" aria-hidden="true" tabindex="-1"></a>Nella discussione dell'analisi dei dati di @zetschefuture2019, la $\mbox{Beta}(2, 10)$ è stata utilizzata quale distribuzione a priori solo per evidenziare le proprietà dell'aggiornamento bayesiano (la differenza tra la distribuzione a priori e la distribuzione a posteriori). La discussione presente chiarisce che la $\mbox{Beta}(2, 10)$ non è una buona scelta per la distribuzione a priori: sarebbe molto migliore la scelta di una $\mbox{Beta}(2, 2)$.</span>
<span id="cb38-583"><a href="#cb38-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-584"><a href="#cb38-584" aria-hidden="true" tabindex="-1"></a><span class="fu">## Commenti e considerazioni finali {.unnumbered}</span></span>
<span id="cb38-585"><a href="#cb38-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-586"><a href="#cb38-586" aria-hidden="true" tabindex="-1"></a>Questo capitolo discute la predizione bayesiana e ne mostra un'applicazione nel caso dei controlli predittivi a posteriori. A questo proposito è necessario notare un punto importante: un buona corrispondenza tra $y$ e $y^{rep}$ costituisce una condizione necessaria ma non sufficiente per la validità del modello. Infatti, i PPC non sono in grado di garantire la generalizzabilità del modello a nuovi campioni di dati. D'altra parte, invece, se i PPC mostrano un cattivo adattamento del modello ai dati previsti futuri, questo ci dice chiaramente che il modello è specificato in maniera errata.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>