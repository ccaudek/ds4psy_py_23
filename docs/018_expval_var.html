<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Data Science per psicologi - 10&nbsp; Indici di posizione, di varianza e di associazione di variabili casuali</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./019_joint_prob.html" rel="next">
<link href="./017_bayes_theorem.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Indici di posizione, di varianza e di associazione di variabili casuali</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/data_science/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Benvenuti</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">Prefazione</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./basics.html" class="sidebar-item-text sidebar-link">Parte 1: Nozioni di base</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_key_notions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Concetti chiave</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_measurement.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_freq_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_loc_scale.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_penguins.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Manipolazione e visualizzazione dei dati in <span class="math inline">\(\mathsf{R}\)</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./prob.html" class="sidebar-item-text sidebar-link">Parte 2: Il calcolo delle probabilità</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_prob_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">La logica dell’incerto</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_conditional_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Probabilità condizionata: significato, teoremi, eventi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_bayes_theorem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./018_expval_var.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Indici di posizione, di varianza e di associazione di variabili casuali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./019_joint_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./020_density_func.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La densità di probabilità</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./distr.html" class="sidebar-item-text sidebar-link">Parte 3: Distribuzioni di v.c. discrete e continue</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./022_discr_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./023_cont_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./024_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">La funzione di verosimiglianza</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./bayes_inference.html" class="sidebar-item-text sidebar-link">Parte 4: Inferenza bayesiana</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./025_intro_bayes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Credibilità, modelli e parametri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./026_subj_prop.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./029_conjugate_families.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./030_balance_prior_post.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./036_posterior_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Approssimazione della distribuzione a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./040_beta_binomial_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Il modello beta-binomiale in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./041_mcmc_diagnostics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./045_summarize_posterior.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./046_bayesian_prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./050_normal_normal_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./regression.html" class="sidebar-item-text sidebar-link">Parte 5: Regressione lineare</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./051_reglin1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./052_reglin2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Regressione lineare bivariata</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./053_reglin3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Modello di regressione in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./054_reglin4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Inferenza sul modello lineare</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./055_reglin5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./056_pred_check.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Predictive checks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./060_anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Confronto tra le medie di tre o più gruppi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./070_mod_hier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modello gerarchico</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./071_mod_hier_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Modello gerarchico: simulazioni</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./entropy.html" class="sidebar-item-text sidebar-link">Parte 6: Entropia</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./090_entropy.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Entropia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./091_kl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./092_info_criterion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Criterio di informazione e convalida incrociata</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./frequentist_inference.html" class="sidebar-item-text sidebar-link">Parte 7: Inferenza frequentista</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./220_intro_frequentist.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Legge dei grandi numeri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./221_conf_interv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Intervallo fiduciale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./225_distr_camp_mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Distribuzione campionaria</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./226_test_ipotesi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Significatività statistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./227_ttest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza sulle medie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./228_limiti_stat_frequentista.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./999_refs.html" class="sidebar-item-text sidebar-link">Riferimenti bibliografici</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">Appendici</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a01_math_symbols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a02_number_sets.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a03_set_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Insiemi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a04_summation_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Simbolo di somma (sommatorie)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a05_calculus_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a10_markov_chains.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Le catene di Markov</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a15_stan_lang.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Programmare in Stan</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul>
<li>
<a href="#valore-atteso" id="toc-valore-atteso" class="nav-link active" data-scroll-target="#valore-atteso"><span class="toc-section-number">10.1</span>  Valore atteso</a>
  <ul class="collapse">
<li><a href="#interpretazione" id="toc-interpretazione" class="nav-link" data-scroll-target="#interpretazione"><span class="toc-section-number">10.1.1</span>  Interpretazione</a></li>
  <li><a href="#propriet%C3%A0-del-valore-atteso" id="toc-proprietà-del-valore-atteso" class="nav-link" data-scroll-target="#propriet%C3%A0-del-valore-atteso"><span class="toc-section-number">10.1.2</span>  Proprietà del valore atteso</a></li>
  <li><a href="#variabili-casuali-continue" id="toc-variabili-casuali-continue" class="nav-link" data-scroll-target="#variabili-casuali-continue"><span class="toc-section-number">10.1.3</span>  Variabili casuali continue</a></li>
  </ul>
</li>
  <li>
<a href="#varianza" id="toc-varianza" class="nav-link" data-scroll-target="#varianza"><span class="toc-section-number">10.2</span>  Varianza</a>
  <ul class="collapse">
<li><a href="#formula-alternativa-per-la-varianza" id="toc-formula-alternativa-per-la-varianza" class="nav-link" data-scroll-target="#formula-alternativa-per-la-varianza"><span class="toc-section-number">10.2.1</span>  Formula alternativa per la varianza</a></li>
  <li><a href="#variabili-casuali-continue-1" id="toc-variabili-casuali-continue-1" class="nav-link" data-scroll-target="#variabili-casuali-continue-1"><span class="toc-section-number">10.2.2</span>  Variabili casuali continue</a></li>
  </ul>
</li>
  <li><a href="#deviazione-standard" id="toc-deviazione-standard" class="nav-link" data-scroll-target="#deviazione-standard"><span class="toc-section-number">10.3</span>  Deviazione standard</a></li>
  <li><a href="#standardizzazione" id="toc-standardizzazione" class="nav-link" data-scroll-target="#standardizzazione"><span class="toc-section-number">10.4</span>  Standardizzazione</a></li>
  <li><a href="#momenti-di-variabili-casuali" id="toc-momenti-di-variabili-casuali" class="nav-link" data-scroll-target="#momenti-di-variabili-casuali"><span class="toc-section-number">10.5</span>  Momenti di variabili casuali</a></li>
  <li><a href="#covarianza" id="toc-covarianza" class="nav-link" data-scroll-target="#covarianza"><span class="toc-section-number">10.6</span>  Covarianza</a></li>
  <li><a href="#correlazione" id="toc-correlazione" class="nav-link" data-scroll-target="#correlazione"><span class="toc-section-number">10.7</span>  Correlazione</a></li>
  <li>
<a href="#propriet%C3%A0" id="toc-proprietà" class="nav-link" data-scroll-target="#propriet%C3%A0"><span class="toc-section-number">10.8</span>  Proprietà</a>
  <ul class="collapse">
<li><a href="#incorrelazione" id="toc-incorrelazione" class="nav-link" data-scroll-target="#incorrelazione"><span class="toc-section-number">10.8.1</span>  Incorrelazione</a></li>
  </ul>
</li>
  <li><a href="#conclusioni" id="toc-conclusioni" class="nav-link" data-scroll-target="#conclusioni">Conclusioni</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="ch-expval-var-rv" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Indici di posizione, di varianza e di associazione di variabili casuali</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Codice</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><p>Spesso risulta utile fornire una rappresentazione sintetica della distribuzione di una variabile casuale attraverso degli indicatori caratteristici piuttosto che fare riferimento ad una sua rappresentazione completa mediante la funzione di ripartizione, o la funzione di massa o di densità di probabilità. Una descrizione più sintetica di una variabile casuale, tramite pochi valori, ci consente di cogliere le caratteristiche essenziali della distribuzione, quali: la posizione, cioè il baricentro della distribuzione di probabilità; la variabilità, cioè la dispersione della distribuzione di probabilità attorno ad un centro; la forma della distribuzione di probabilità, considerando la simmetria e la curtosi (pesantezza delle code). In questo Capitolo introdurremo quegli indici sintetici che descrivono il centro di una distribuzione di probabilità e la sua variabilità.</p>
<section id="valore-atteso" class="level2" data-number="10.1"><h2 data-number="10.1" class="anchored" data-anchor-id="valore-atteso">
<span class="header-section-number">10.1</span> Valore atteso</h2>
<p>Quando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual è il suo “valore tipico”. La nozione di “valore tipico”, tuttavia, è ambigua. Infatti, essa può essere definita in almeno tre modi diversi:</p>
<ul>
<li>la <em>media</em> (somma dei valori divisa per il numero dei valori),</li>
<li>la <em>mediana</em> (il valore centrale della distribuzione, quando la variabile è ordinata in senso crescente o decrescente),</li>
<li>la <em>moda</em> (il valore che ricorre più spesso).</li>
</ul>
<p>Per esempio, la media di <span class="math inline">\(\{3, 1, 4, 1, 5\}\)</span> è <span class="math inline">\(\frac{3+1+4+1+5}{5} = 2.8\)</span>, la mediana è <span class="math inline">\(3\)</span> e la moda è <span class="math inline">\(1\)</span>. Tuttavia, la teoria delle probabilità si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per “valore tipico” quando facciamo riferimento alle variabili casuali. Giungiamo così alla seguente definizione. <!-- Supponiamo di ripetere un esperimento casuale molte volte in modo tale che ciascun valore $Y$ si presenti con una frequenza approssimativamente uguale alla sua probabilità. Per esempio, possiamo lanciare una coppia di dadi e osservare i valori di $S$ = "somma dei punti" e di $P$ = "prodotto dei punti". Ci poniamo il problema di definire il "risultato tipico" di questo esperimento in modo tale che esso corrisponda al valore medio dei valori della variabile casuale, quando l'esperimento casuale viene ripetuto tante volte.  --></p>
<div id="def-exp-val-discr" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 10.1 </strong></span>Sia <span class="math inline">\(Y\)</span> è una variabile casuale discreta che assume i valori <span class="math inline">\(y_1, \dots, y_n\)</span> con distribuzione <span class="math inline">\(P(Y = y_i) = p(y_i)\)</span>. Per definizione il <em>valore atteso</em> di <span class="math inline">\(Y\)</span>, <span class="math inline">\(\mathbb{E}(Y)\)</span>, è</p>
<p><span id="eq-expval-discr"><span class="math display">\[
\mathbb{E}(Y) = \sum_{i=1}^n y_i \cdot p(y_i).
\tag{10.1}\]</span></span></p>
</div>
<p>A parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale è definito come la somma di tutti i valori che la variabile casuale può prendere, ciascuno pesato dalla probabilità con cui il valore è preso.</p>
<div id="exr-exp-val-discr" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 10.1 </strong></span>Si calcoli il valore atteso della variabile casuale <span class="math inline">\(Y\)</span> corrispondente al lancio di una moneta equilibrata (testa: <em>Y</em> = 1; croce: <em>Y</em> = 0).</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span><span class="math display">\[
\mathbb{E}(Y) = \sum_{i=1}^{2} y_i \cdot P(y_i) = 0 \cdot \frac{1}{5} + 1 \cdot \frac{1}{5} = 0.5.
\]</span></p>
</div>
<div id="exr-exp-val-discr-2" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 10.2 </strong></span>Si calcoli il valore atteso della variabile casuale <span class="math inline">\(Y\)</span> corrispondente ai punti ottenuti dal lancio di un dado equilibrato.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span><span class="math display">\[
\mathbb{E}(Y) = \sum_{i=1}^{6} y_i \cdot P(y_i) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + \dots + 6 \cdot \frac{1}{6} = \frac{21}{6} = 3.5.
\]</span></p>
</div>
<section id="interpretazione" class="level3" data-number="10.1.1"><h3 data-number="10.1.1" class="anchored" data-anchor-id="interpretazione">
<span class="header-section-number">10.1.1</span> Interpretazione</h3>
<p>Che interpretazione può essere assegnata alla nozione di valore atteso? Bruno de Finetti adottò lo stesso termine di <em>previsione</em> (e lo stesso simbolo) tanto per la probabilità che per il valore atteso. Si può pertanto dire che, dal punto di vista bayesiano, il valore atteso è l’estensione naturale della nozione di probabilità soggettiva.</p>
</section><section id="proprietà-del-valore-atteso" class="level3" data-number="10.1.2"><h3 data-number="10.1.2" class="anchored" data-anchor-id="proprietà-del-valore-atteso">
<span class="header-section-number">10.1.2</span> Proprietà del valore atteso</h3>
<p>La proprietà più importante del valore atteso è la linearità: il valore atteso di una somma di variabili casuali è uguale alla somma dei lori rispettivi valori attesi:</p>
<p><span id="eq-prop-expval-linearity"><span class="math display">\[
\mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y).
\tag{10.2}\]</span></span></p>
<p>L’<a href="#eq-prop-expval-linearity">Equazione&nbsp;<span>10.2</span></a> sembra ragionevole quando <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono indipendenti, ma è anche vera quando <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono associati. Abbiamo anche che</p>
<p><span id="eq-prop-expval-const"><span class="math display">\[
\mathbb{E}(cY) = c \mathbb{E}(Y).
\tag{10.3}\]</span></span></p>
<p>L’<a href="#eq-prop-expval-const">Equazione&nbsp;<span>10.3</span></a> ci dice che possiamo estrarre una costante dall’operatore di valore atteso. Tale proprietà si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono indipendenti, abbiamo che</p>
<p><span id="eq-expval-prod-ind-rv"><span class="math display">\[
\mathbb{E}(X Y) = \mathbb{E}(X) \mathbb{E}(Y).
\tag{10.4}\]</span></span></p>
<div id="exr-exp-val-discr-3" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 10.3 </strong></span>Si considerino le seguenti variabili casuali: <span class="math inline">\(Y\)</span>, ovvero il numero che si ottiene dal lancio di un dado equilibrato, e <span class="math inline">\(Y\)</span>, il numero di teste prodotto dal lancio di una moneta equilibrata. Si trovi il valore atteso di <span class="math inline">\(X+Y\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>Per risolvere il problema iniziamo a costruire lo spazio campionario dell’esperimento casuale consistente nel lancio di un dado e di una moneta.</p>
<table class="table">
<colgroup>
<col style="width: 31%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;"><span class="math inline">\(x \textbackslash y\)</span></th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">5</th>
<th style="text-align: center;">6</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">(0, 1)</td>
<td style="text-align: center;">(0, 2)</td>
<td style="text-align: center;">(0, 3)</td>
<td style="text-align: center;">(0, 4)</td>
<td style="text-align: center;">(0, 5)</td>
<td style="text-align: center;">(0, 6)</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">(1, 1)</td>
<td style="text-align: center;">(1, 2)</td>
<td style="text-align: center;">(1, 3)</td>
<td style="text-align: center;">(1, 4)</td>
<td style="text-align: center;">(1, 5)</td>
<td style="text-align: center;">(1, 6)</td>
</tr>
</tbody>
</table>
<p>ovvero</p>
<table class="table">
<thead><tr class="header">
<th style="text-align: center;"><span class="math inline">\(x \textbackslash y\)</span></th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">5</th>
<th style="text-align: center;">6</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
</tr>
</tbody>
</table>
<p>Il risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campionario avrà la stessa probabilità di verificarsi, ovvero <span class="math inline">\(P(\omega) = \frac{1}{12}\)</span>. Il valore atteso di <span class="math inline">\(X+Y\)</span> è dunque uguale a:</p>
<p><span class="math display">\[
\mathbb{E}(X+Y) = 1 \cdot \frac{1}{12} + 2 \cdot \frac{1}{12} + \dots + 7 \cdot \frac{1}{12} = 4.0.
\]</span></p>
<p>Possiamo ottenere lo stesso risultato usanlo l’<a href="#eq-prop-expval-linearity">Equazione&nbsp;<span>10.2</span></a>:</p>
<p><span class="math display">\[
\mathbb{E}(X+Y) = \mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.
\]</span></p>
</div>
<div id="exr-exp-val-discr-4" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 10.4 </strong></span>Si considerino le variabili casuali <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> definite nel caso del lancio di tre monete equilibrate, dove <span class="math inline">\(X\)</span> conta il numero delle teste nei tre lanci e <span class="math inline">\(Y\)</span> conta il numero delle teste al primo lancio. Si calcoli il valore atteso del prodotto delle variabili casuali <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>La distribuzione di probabilità congiunta <span class="math inline">\(P(X, Y)\)</span> è fornita nella tabella seguente.</p>
<table class="table">
<thead><tr class="header">
<th style="text-align: center;"><span class="math inline">\(x \textbackslash y\)</span></th>
<th style="text-align: center;">0</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;"><span class="math inline">\(p(Y)\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1/8</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1/8</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">2/8</td>
<td style="text-align: center;">1/8</td>
<td style="text-align: center;">3/8</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2</td>
<td style="text-align: center;">1/8</td>
<td style="text-align: center;">2/8</td>
<td style="text-align: center;">3/8</td>
</tr>
<tr class="even">
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1/8</td>
<td style="text-align: center;">1/8</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(p(y)\)</span></td>
<td style="text-align: center;">4/8</td>
<td style="text-align: center;">4/8</td>
<td style="text-align: center;">1.0</td>
</tr>
</tbody>
</table>
<p>Il calcolo del valore atteso di <span class="math inline">\(XY\)</span> si riduce a</p>
<p><span class="math display">\[
\mathbb{E}(XY) = 1 \cdot \frac{1}{8} + 2 \cdot \frac{2}{8} + 3 \cdot \frac{1}{8} = 1.0.
\]</span></p>
<p>Si noti che le variabili casuali <span class="math inline">\(Y\)</span> e <span class="math inline">\(Y\)</span> non sono indipendenti. Dunque non possiamo usare l’<a href="#eq-expval-prod-ind-rv">Equazione&nbsp;<span>10.4</span></a>. Infatti, il valore atteso di <span class="math inline">\(X\)</span> è</p>
<p><span class="math display">\[
\mathbb{E}(X) = 1 \cdot \frac{3}{8} + 2 \cdot \frac{3}{8} + 3 \cdot \frac{1}{8} = 1.5
\]</span></p>
<p>e il valore atteso di <span class="math inline">\(Y\)</span> è</p>
<p><span class="math display">\[
\mathbb{E}(Y) = 0 \cdot \frac{4}{8} + 1 \cdot \frac{4}{8} = 0.5.
\]</span></p>
<p>Perciò</p>
<p><span class="math display">\[
1.5 \cdot 0.5 \neq 1.0.
\]</span></p>
<p>In altri termini, se <span class="math inline">\(\mathbb{E}(X Y) \neq \mathbb{E}(X) \mathbb{E}(Y)\)</span>, allora le variabili causuali <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> non sono indipendenti (cioè sono associate).</p>
</div>
</section><section id="variabili-casuali-continue" class="level3" data-number="10.1.3"><h3 data-number="10.1.3" class="anchored" data-anchor-id="variabili-casuali-continue">
<span class="header-section-number">10.1.3</span> Variabili casuali continue</h3>
<p>Nel caso di una variabile casuale continua <span class="math inline">\(Y\)</span> il valore atteso diventa:</p>
<p><span id="eq-def-ev-rv-cont"><span class="math display">\[
\mathbb{E}(Y) = \int_{-\infty}^{+\infty} y p(y) \,\operatorname{d}\!y.
\tag{10.5}\]</span></span></p>
<p>Anche in questo caso il valore atteso è una media ponderata della <span class="math inline">\(y\)</span>, nella quale ciascun possibile valore <span class="math inline">\(y\)</span> è ponderato per il corrispondente valore della densità <span class="math inline">\(p(y)\)</span>. Possiamo leggere l’integrale pensando che <span class="math inline">\(y\)</span> rappresenti l’ampiezza delle barre infinitamente strette di un istogramma, con la densità <span class="math inline">\(p(y)\)</span> che corrisponde all’altezza di tali barre e la notazione <span class="math inline">\(\int_{-\infty}^{+\infty}\)</span> che corrisponde ad una somma.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<section id="moda" class="level4" data-number="10.1.3.1"><h4 data-number="10.1.3.1" class="anchored" data-anchor-id="moda">
<span class="header-section-number">10.1.3.1</span> Moda</h4>
<p>Un’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di <span class="math inline">\(Y\)</span> individua il valore <span class="math inline">\(y\)</span> più plausibile, ovvero il valore <span class="math inline">\(y\)</span> che massimizza la funzione di densità <span class="math inline">\(p(y)\)</span>:</p>
<p><span id="eq-def-mode"><span class="math display">\[
\mbox{Mo}(Y) = \mbox{argmax}_y p(y).
\tag{10.6}\]</span></span></p>
<div class="callout-note callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>La notazione <span class="math inline">\(\mbox{argmax}_y p(y)\)</span> significa: il valore <span class="math inline">\(y\)</span> tale per cui la funzione <span class="math inline">\(p(y)\)</span> assume il suo valore massimo.</p>
</div>
</div>
</div>
</section></section></section><section id="varianza" class="level2" data-number="10.2"><h2 data-number="10.2" class="anchored" data-anchor-id="varianza">
<span class="header-section-number">10.2</span> Varianza</h2>
<p>La seconda più importante proprietà di una variabile casuale, dopo che conosciamo il suo valore atteso, è la <em>varianza</em>.</p>
<div id="def-var-rv-definition" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 10.2 </strong></span>Se <span class="math inline">\(Y\)</span> è una variabile casuale discreta con distribuzione <span class="math inline">\(p(y)\)</span>, per definizione la varianza di <span class="math inline">\(Y\)</span>, <span class="math inline">\(\mathbb{V}(Y)\)</span>, è</p>
<p><span id="eq-def-var-rv"><span class="math display">\[
\mathbb{V}(Y) = \mathbb{E}\Big[\big(Y - \mathbb{E}(Y)\big)^2\Big].
\tag{10.7}\]</span></span></p>
</div>
<p>A parole: la varianza è la deviazione media quadratica della variabile dalla sua media.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Se denotiamo <span class="math inline">\(\mathbb{E}(Y) = \mu\)</span>, la varianza <span class="math inline">\(\mathbb{V}(Y)\)</span> diventa il valore atteso di <span class="math inline">\((Y - \mu)^2\)</span>.</p>
<div id="exr-var-discr-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 10.5 </strong></span>Posta <span class="math inline">\(S\)</span> uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di <span class="math inline">\(S\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>La variabile casuale <span class="math inline">\(S\)</span> ha la seguente distribuzione di probabilità:</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;"><span class="math inline">\(s\)</span></th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">5</th>
<th style="text-align: center;">6</th>
<th style="text-align: center;">7</th>
<th style="text-align: center;">8</th>
<th style="text-align: center;">9</th>
<th style="text-align: center;">10</th>
<th style="text-align: center;">11</th>
<th style="text-align: center;">12</th>
</tr></thead>
<tbody><tr class="odd">
<td style="text-align: center;"><span class="math inline">\(P(S = s)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{2}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{3}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{4}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{5}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{6}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{5}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{4}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{3}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{2}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{36}\)</span></td>
</tr></tbody>
</table>
<p>Essendo <span class="math inline">\(\mathbb{E}(S) = 7\)</span>, la varianza diventa</p>
<p><span class="math display">\[
\begin{align}
\mathbb{V}(S) &amp;= \sum \left(s - \mathbb{E}(S)\right)^2 \cdot P(s) \notag\\
&amp;= (2 - 7)^2 \cdot 0.0278 + (3-7)^2 \cdot 0.0556 + \dots + (12 - 7)^2 \cdot 0.0278 \notag\\
&amp;= 5.8333.\notag
\end{align}
\]</span></p>
</div>
<section id="formula-alternativa-per-la-varianza" class="level3" data-number="10.2.1"><h3 data-number="10.2.1" class="anchored" data-anchor-id="formula-alternativa-per-la-varianza">
<span class="header-section-number">10.2.1</span> Formula alternativa per la varianza</h3>
<p>C’è un modo più semplice per calcolare la varianza:</p>
<p><span class="math display">\[
\begin{align}
\mathbb{E}\Big[\big(Y - \mathbb{E}(Y)\big)^2\Big] &amp;= \mathbb{E}\big(Y^2 - 2Y\mathbb{E}(Y) + \mathbb{E}(Y)^2\big)\notag\\
&amp;= \mathbb{E}(Y^2) - 2\mathbb{E}(Y)\mathbb{E}(Y) + \mathbb{E}(Y)^2,
\end{align}
\]</span></p>
<p>dato che <span class="math inline">\(\mathbb{E}(Y)\)</span> è una costante. Pertanto</p>
<p><span id="eq-def-alt-var-rv"><span class="math display">\[
\mathbb{V}(Y) = \mathbb{E}(Y^2) - \big(\mathbb{E}(Y) \big)^2.
\tag{10.8}\]</span></span></p>
<p>A parole: la varianza è la media dei quadrati meno il quadrato della media della variabile.</p>
<div id="exr-var-discr-2" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 10.6 </strong></span>Consideriamo la variabile casuale <span class="math inline">\(Y\)</span> che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di <span class="math inline">\(Y\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>Il valore atteso di <span class="math inline">\(Y\)</span> è</p>
<p><span class="math display">\[
\mathbb{E}(Y) = 0 \cdot 0.2 + 1 \cdot 0.8 = 0.8.
\]</span></p>
<p>Usando la formula tradizionale della varianza otteniamo:</p>
<p><span class="math display">\[
\mathbb{V}(Y) = (0 - 0.8)^2 \cdot 0.2 + (1 - 0.8)^2 \cdot 0.8 = 0.16.
\]</span></p>
<p>Lo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di <span class="math inline">\(Y^2\)</span> è</p>
<p><span class="math display">\[
\mathbb{E}(Y^2) = 0^2 \cdot 0.2 + 1^2 \cdot 0.8 = 0.8.
\]</span></p>
<p>e la varianza diventa</p>
<p><span class="math display">\[
\mathbb{V}(Y) = \mathbb{E}(Y^2) - \big(\mathbb{E}(Y) \big)^2 = 0.8 - 0.8^2 = 0.16.
\]</span></p>
</div>
</section><section id="variabili-casuali-continue-1" class="level3" data-number="10.2.2"><h3 data-number="10.2.2" class="anchored" data-anchor-id="variabili-casuali-continue-1">
<span class="header-section-number">10.2.2</span> Variabili casuali continue</h3>
<p>Nel caso di una variabile casuale continua <span class="math inline">\(Y\)</span>, la varianza diventa:</p>
<p><span id="eq-def-var-rv-cont"><span class="math display">\[
\mathbb{V}(Y) = \int_{-\infty}^{+\infty} \large[y - \mathbb{E}(Y)\large]^2 p(y) \,\operatorname {d}\!y.
\tag{10.9}\]</span></span></p>
<p>Come nel caso discreto, la varianza di una v.c. continua <span class="math inline">\(Y\)</span> misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori <span class="math inline">\(y\)</span> dalla loro media.</p>
</section></section><section id="deviazione-standard" class="level2" data-number="10.3"><h2 data-number="10.3" class="anchored" data-anchor-id="deviazione-standard">
<span class="header-section-number">10.3</span> Deviazione standard</h2>
<p>Quando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell’unità di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato <em>deviazione standard</em> e solitamente è denotato dalla lettera greca <span class="math inline">\(\sigma\)</span>.</p>
<div id="def-sd-vc" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 10.3 </strong></span>Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:</p>
<p><span id="eq-def-sd"><span class="math display">\[
\sigma_Y = \sqrt{\mathbb{V}(Y)}.
\tag{10.10}\]</span></span></p>
</div>
<p>Come nella statistica descrittiva, la deviazione standard di una variabile casuale misura approssimativamente la distanza tipica o prevista dei possibili valori <span class="math inline">\(y\)</span> dalla loro media.</p>
<div id="exr-sd-discr-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 10.7 </strong></span>Per i dadi equilibrati dell’<a href="#exr-var-discr-1">Esercizio&nbsp;<span>10.5</span></a>, la deviazione standard della variabile casuale <span class="math inline">\(S\)</span> è uguale a <span class="math inline">\(\sqrt{5.833} = 2.415\)</span>.</p>
</div>
</section><section id="standardizzazione" class="level2" data-number="10.4"><h2 data-number="10.4" class="anchored" data-anchor-id="standardizzazione">
<span class="header-section-number">10.4</span> Standardizzazione</h2>
<div id="def-standardization" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 10.4 </strong></span>Data una variabile casuale <span class="math inline">\(Y\)</span>, si dice <em>variabile standardizzata</em> di <span class="math inline">\(Y\)</span> l’espressione</p>
<p><span id="eq-standardization"><span class="math display">\[
Z = \frac{Y - \mathbb{E}(Y)}{\sigma_Y}.
\tag{10.11}\]</span></span></p>
</div>
<p>Solitamente, una variabile standardizzata viene denotata con la lettera <span class="math inline">\(Z\)</span>.</p>
</section><section id="momenti-di-variabili-casuali" class="level2" data-number="10.5"><h2 data-number="10.5" class="anchored" data-anchor-id="momenti-di-variabili-casuali">
<span class="header-section-number">10.5</span> Momenti di variabili casuali</h2>
<div class="definition">
<p>Si chiama <em>momento</em> di ordine <span class="math inline">\(q\)</span> di una v.c. <span class="math inline">\(X\)</span>, dotata di densità <span class="math inline">\(p(x)\)</span>, la quantità</p>
<p><span id="eq-moments-cont"><span class="math display">\[
\mathbb{E}(X^q) = \int_{-\infty}^{+\infty} x^q p(x) \; dx.
\tag{10.12}\]</span></span></p>
<p>Se <span class="math inline">\(X\)</span> è una v.c. discreta, i suoi momenti valgono:</p>
<p><span id="eq-moments-discr"><span class="math display">\[
\mathbb{E}(X^q) = \sum_i x_i^q P(x_i).
\tag{10.13}\]</span></span></p>
</div>
<p>I momenti sono importanti parametri indicatori di certe proprietà di <span class="math inline">\(X\)</span>. I più noti sono senza dubbio quelli per <span class="math inline">\(q = 1\)</span> e <span class="math inline">\(q = 2\)</span>. Il momento del primo ordine corrisponde al valore atteso di <span class="math inline">\(X\)</span>. Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di <span class="math inline">\(X\)</span>, operando una traslazione <span class="math inline">\(x_0 = x − \mathbb{E}(X)\)</span> che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza.</p>
</section><section id="covarianza" class="level2" data-number="10.6"><h2 data-number="10.6" class="anchored" data-anchor-id="covarianza">
<span class="header-section-number">10.6</span> Covarianza</h2>
<p>La covarianza quantifica la tendenza delle variabili casuali <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> a “variare assieme”. Per esempio, l’altezza e il peso delle giraffe producono una covarianza positiva perché all’aumentare di una di queste due quantità tende ad aumentare anche l’altra. La covarianza misura la forza e la direzione del legame lineare tra due variabili casuali <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span>. Si utilizza la notazione <span class="math inline">\(\mbox{Cov}(X,Y)=\sigma_{xy}\)</span>.</p>
<div id="def-covariance-rv" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 10.5 </strong></span>Date due variabili casuali <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, chiamiamo covarianza tra <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> il numero</p>
<p><span id="eq-cov-def-rv"><span class="math display">\[
\mbox{Cov}(X,Y) = \mathbb{E}\Bigl(\bigl(X - \mathbb{E}(X)\bigr) \bigl(Y - \mathbb{E}(Y)\bigr)\Bigr),
\tag{10.14}\]</span></span></p>
<p>dove <span class="math inline">\(\mathbb{E}(X)\)</span> e <span class="math inline">\(\mathbb{E}(Y)\)</span> sono i valori attesi di <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span>.</p>
</div>
<p>In maniera esplicita,</p>
<p><span id="eq-cov_def"><span class="math display">\[
\mbox{Cov}(X,Y) = \sum_{(x,y) \in \Omega} (x - \mu_X) (y - \mu_Y) f(x, y).
\tag{10.15}\]</span></span></p>
<p>La definizione è analoga, algebricamente, a quella di varianza e risulta infatti</p>
<p><span class="math display">\[
\mathbb{V}(x) = \mbox{Cov}(X, X)
\]</span></p>
<p>e</p>
<p><span id="eq-cov_vc_alt"><span class="math display">\[
\mbox{Cov}(X,Y) = \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X).
\tag{10.16}\]</span></span></p>
<div class="proof">
<p><span class="proof-title"><em>Dimostrazione</em>. </span>L’<a href="#eq-cov_vc_alt">Equazione&nbsp;<span>10.16</span></a> si ricava nel modo seguente:</p>
<p><span class="math display">\[
\begin{align}
\mbox{Cov}(X,Y) &amp;= \mathbb{E}\Bigl(\bigl(X-\mathbb{E}(X)\bigr) \bigl(Y-\mathbb{E}(Y)\bigr)\Bigr)\notag\\
          %&amp;= \mathbb{E}(XY) - \mathbb{E}(Y)X -\mathbb{E}(X)Y + \mathbb{E}(X)\mathbb{E}(Y) )\notag\\
          &amp;= \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X) - \mathbb{E}(X)\mathbb{E}(Y) + \mathbb{E}(X)\mathbb{E}(Y)\notag\\
          &amp;= \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X)\notag.
\end{align}
\]</span></p>
</div>
<div id="exr-cov-rv-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 10.8 </strong></span>Consideriamo le variabili casuali definite nell’<a href="#exr-exp-val-discr-4">Esercizio&nbsp;<span>10.4</span></a>. Si calcoli la covarianza di <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>Abbiamo che <span class="math inline">\(\mu_X = 1.5\)</span> e <span class="math inline">\(\mu_Y = 0.5\)</span>. Ne segue che la covarianza di <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> è:</p>
<p><span class="math display">\[
\begin{align}
\mbox{Cov}(X,Y) &amp;= \sum_{(x,y) \in \Omega} (x - \mu_X) (y - \mu_Y) f(x, y)\notag\\
&amp;= (0-1.5)(0-0.5)\cdot \frac{1}{8} + (0-1.5)(1-0.5) \cdot 0 \\
   &amp;\qquad + (1-1.5)(0-0.5)\cdot \frac{2}{8} + (1-1.5)(1-0.5) \cdot \frac{1}{8} \notag\\
    &amp;\qquad+ (2-1.5)(0-0.5) \cdot \frac{1}{8} + (2-1.5)(1-0.5) \cdot \frac{2}{8} \\
   &amp;\qquad+ (3-1.5)(0-0.5) \cdot 0 +  (3-1.5)(1-0.5)\cdot\frac{1}{8} \notag\\
   &amp;= \frac{1}{4}. \notag
\end{align}
\]</span></p>
<p>Lo stesso risultato può essere trovato usando l’<a href="#eq-cov_vc_alt">Equazione&nbsp;<span>10.16</span></a>. Iniziamo a calcolare il valore atteso del prodotto <span class="math inline">\(XY\)</span>:</p>
<p><span class="math display">\[
\mathbb{E}(XY) = 0 \cdot\frac{4}{8} + 1 \cdot\frac{1}{8} + 2 \cdot\frac{2}{8} + 3 \cdot\frac{1}{8} = 1.0.
\]</span></p>
<p>Dunque, la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> diventa</p>
<p><span class="math display">\[
\begin{align}
\mbox{Cov}(X,Y) &amp;= \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y)\notag\\
&amp;= 1 -  1.5\cdot 0.5 \notag\\
&amp;= 0.25.\notag
\end{align}
\]</span></p>
</div>
</section><section id="correlazione" class="level2" data-number="10.7"><h2 data-number="10.7" class="anchored" data-anchor-id="correlazione">
<span class="header-section-number">10.7</span> Correlazione</h2>
<p>La covarianza dipende dall’unità di misura delle due variabili e quindi non consente di stabilire l’intensità della relazione. Una misura standardizzata della relazione che intercorre fra due variabili è invece rappresentata dalla correlazione. La correlazione si ottiene dividendo la covarianza per le deviazioni standard delle due variabili aleatorie.</p>
<div id="def-cor-rv-def" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 10.6 </strong></span>Il coefficiente di correlazione tra <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> è il numero definito da</p>
<p><span id="eq-cor-rv-def"><span class="math display">\[
\rho(X,Y) =\frac{\mbox{Cov}(X,Y)}{\sqrt{\mathbb{V}(X)\mathbb{V}(Y)}}.
\tag{10.17}\]</span></span></p>
</div>
<p>Si può anche scrivere <span class="math inline">\(\rho_{X,Y}\)</span> al posto di <span class="math inline">\(\rho(X,Y)\)</span>.</p>
<p>Il coefficiente di correlazione <span class="math inline">\(\rho_{xy}\)</span> è un numero puro, cioè non dipende dall’unità di misura delle variabili, e assume valori compresi tra -1 e +1.</p>
</section><section id="proprietà" class="level2" data-number="10.8"><h2 data-number="10.8" class="anchored" data-anchor-id="proprietà">
<span class="header-section-number">10.8</span> Proprietà</h2>
<ul>
<li>La covarianza tra una variabile aleatoria <span class="math inline">\(X\)</span> e una costante <span class="math inline">\(c\)</span> è nulla: <span class="math inline">\(\mbox{Cov}(c,X) = 0;\)</span>
</li>
<li>la covarianza è simmetrica: <span class="math inline">\(\mbox{Cov}(X,Y) = \mbox{Cov}(Y,X);\)</span>
</li>
<li>vale <span class="math inline">\(-1 \leq \rho(X,Y) \leq 1;\)</span>
</li>
<li>la correlazione non dipende dall’unità di misura: <span class="math inline">\(\rho(aX, bY) = \rho(X,Y), \quad \forall a, b &gt; 0;\)</span>
</li>
<li>se <span class="math inline">\(Y = a + bX\)</span> è una funzione lineare di <span class="math inline">\(X\)</span> con costanti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>, allora <span class="math inline">\(\rho(X,Y) = \pm 1\)</span>, a seconda del segno di <span class="math inline">\(b\)</span>;</li>
<li>la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, ciascuna moltiplicata per una costante, è uguale al prodotto delle costanti per la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>: <span class="math inline">\(\mbox{Cov}(aX,bY) = ab \;\mbox{Cov}(X,Y)\)</span>;</li>
<li>vale <span class="math inline">\(\mathbb{V}(X \pm Y) = \mathbb{V}(X) + \mathbb{V}(Y) \pm 2 \cdot \mbox{Cov}(X,Y)\)</span>;</li>
<li>vale <span class="math inline">\(\mbox{Cov}(X + Y, Z) = \mbox{Cov}(X,Z) + \mbox{Cov}(Y,Z);\)</span>
</li>
<li>per una sequenza di variabili aleatorie <span class="math inline">\(X_1, \dots, X_n\)</span>, si ha <span class="math display">\[\mathbb{V}\left( \sum_{i=1}^n X_i\right) = \sum_{i=1}^n \mathbb{V}(X_i) + 2\sum_{i,j: i&lt;j}cov(X_i, X_j);\]</span>
</li>
<li>vale <span class="math inline">\(\mbox{Cov}\left(\sum_{i=1}^n a_i X_i, \sum_{j=1}^m b_jY_j\right) = \sum_{i=1}^n \sum_{j=1}^m a_j b_j\mbox{Cov}(X_j, Y_j);\)</span>
</li>
<li>se <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> sono indipendenti, allora <span class="math display">\[\mbox{Cov}\left(\sum_{i=1}^n a_i X_i, \sum_{j=1}^n b_jX_j\right) = \sum_{i=1}^n a_i b_i \mathbb{V}(X_i).\]</span>
</li>
</ul>
<section id="incorrelazione" class="level3" data-number="10.8.1"><h3 data-number="10.8.1" class="anchored" data-anchor-id="incorrelazione">
<span class="header-section-number">10.8.1</span> Incorrelazione</h3>
<div id="def-incorrelation-def" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 10.7 </strong></span>Si dice che <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> sono incorrelate, o linermente indipendenti, se la loro covarianza è nulla,</p>
<p><span id="eq-incorrelation-def"><span class="math display">\[
\sigma_{XY} = \mathbb{E} \big[(X - \mu_X) (y-\mu_u) \big] = 0,
\tag{10.18}\]</span></span></p>
<p>che si può anche scrivere come</p>
<p><span class="math display">\[
\rho_{XY} = 0, \quad \mathbb{E}(XY) = \mathbb{E}(X) \mathbb{E}(Y).
\]</span></p>
</div>
<p>Si introduce così un secondo tipo di indipendenza, più debole, dopo quello di indipendenza stocastica. Viceversa, però, se <span class="math inline">\(\mbox{Cov}(X, Y) = 0\)</span>, non è detto che <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> siano indipendenti.</p>
<div id="exr-incorrelation-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 10.9 </strong></span>Siano <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> due variabili aleatorie discrete avente una distribuzione di massa di probabilità congiunta pari a</p>
<p><span class="math display">\[
f_{XY}(x,y) = \frac{1}{4} \quad (x,y) \in \{(0,0), (1,1), (1, -1), (2,0) \}
\]</span></p>
<p>e zero altrimenti. Le due variabili aleatorie <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono mutuamente indipendenti?</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>La distribuzione marginale della <span class="math inline">\(X\)</span> è</p>
<p><span class="math display">\[
\begin{cases}
X = 0, \quad  P_X = 1/4, \\
X = 1, \quad P_X = 2/4, \\
X = 2, \quad P_X = 1/4.
\end{cases}
\]</span></p>
<p><span class="math display">\[
\mathbb{E}(X) = 0 \frac{1}{4} + 1 \frac{2}{4} + 2 \frac{1}{4} = 1.
\]</span></p>
<p><span class="math display">\[
\mathbb{E}(X^2) = 0^2 \frac{1}{4} + 1^2 \frac{2}{4} + 2^2 \frac{1}{4} = \frac{3}{2}.
\]</span></p>
<p><span class="math display">\[
\mathbb{V}(X) = \frac{3}{2} - 1^2 = \frac{1}{2}.
\]</span></p>
<p>La distribuzione marginale della <span class="math inline">\(Y\)</span> è</p>
<p><span class="math display">\[
\begin{cases}
Y = -1, \quad  P_Y = 1/4, \\
Y = 0, \quad P_Y = 2/4, \\
Y = 1, \quad P_Y = 1/4.
\end{cases}
\]</span></p>
<p><span class="math display">\[
\mathbb{E}(Y) = 0 \frac{2}{4} + 1 \frac{1}{4} + (-1) \frac{1}{4} = 0.
\]</span></p>
<p><span class="math display">\[
\mathbb{E}(Y^2) = 0^2 \frac{2}{4} + 1^2 \frac{1}{4} + (-1)^2 \frac{1}{4} = \frac{1}{2}.
\]</span></p>
<p><span class="math display">\[
\mathbb{V}(X) = \frac{1}{2} - 0^2 = \frac{1}{2}.
\]</span></p>
<p>Calcoliamo ora la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>:</p>
<p><span class="math display">\[
\mathbb{E}(XY) = \sum_x\sum_y xy f_{XY} (x,y) =
(0\cdot 0)\frac{1}{4} +
(1\cdot 1)\frac{1}{4} +
(1\cdot -1)\frac{1}{4} +
(2\cdot 0)\frac{1}{4} = 0.
\]</span></p>
<p><span class="math display">\[
\mbox{Cov}(X,Y) = \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y) = 0 - 1\cdot0 = 0.
\]</span></p>
<p>Quindi le due variabili aleatorie hanno covarianza pari a zero. Tuttavia, esse non sono indipendenti, in quanto non è vero che</p>
<p><span class="math display">\[
f_{XY} (x,y) = f_X(x) f_Y(y)
\]</span></p>
<p>per tutti gli <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</p>
</div>
<p>In conclusione, anche se la condizione di indipendenza implica una covarianza nulla, l’esempio precedente mostra come l’inverso non sia necessariamente vero: la covarianza può essere zero anche se due variabili casuali non sono indipendenti.</p>
</section></section><section id="conclusioni" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="conclusioni">Conclusioni</h2>
<p>La densità di probabilità congiunta bivariata tiene simultaneamente conto del comportamento di due variabili casuali <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> e di come esse si influenzano. Se <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono legate linearmente, allora il coefficiente di correlazione</p>
<span class="math display">\[\begin{equation}
\rho = \frac{\mbox{Cov}(X, Y)}{\sigma_X \sigma_Y}\notag
\end{equation}\]</span>
<p>fornisce l’indice maggiormente utilizzato per descrivere l’intensità e il segno dell’associazione lineare. Nel caso di un’associazione lineare perfetta, <span class="math inline">\(Y = a + bX\)</span>, avremo <span class="math inline">\(\rho = 1\)</span> con <span class="math inline">\(b\)</span> positivo ed <span class="math inline">\(\rho = -1\)</span> con <span class="math inline">\(b\)</span> negativo. Se il coefficiente di correlazione è pari a 0 le variabili si dicono incorrelate. Condizione sufficiente (ma non necessaria) affinché <span class="math inline">\(\rho = 0\)</span> è che le due variabili siano tra loro indipendenti.</p>


<!-- -->

</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>Per il significato della notazione di integrale, si veda la <a href="a05_calculus_notation.html"><span>Appendix&nbsp;E</span></a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Data una variabile casuale <span class="math inline">\(Y\)</span> con valore atteso <span class="math inline">\(\mathbb{E}(Y)\)</span>, le “distanze” tra i valori di <span class="math inline">\(Y\)</span> e il valore atteso <span class="math inline">\(\mathbb{E}(Y)\)</span> definiscono la variabile casuale <span class="math inline">\(Y - \mathbb{E}(Y)\)</span> chiamata <em>scarto</em>, oppure <em>deviazione</em> oppure <em>variabile casuale centrata</em>. La variabile <span class="math inline">\(Y - \mathbb{E}(Y)\)</span> equivale ad una traslazione di sistema di riferimento che porta il valore atteso nell’origine degli assi. Si può dimostrare facilmente che il valore atteso della variabile scarto <span class="math inline">\(Y - \mathbb{E}(Y)\)</span> vale zero, dunque la media di tale variabile non può essere usata per quantificare la “dispersione” dei valori di <span class="math inline">\(Y\)</span> relativamente al suo valore medio. Occorre rendere sempre positivi i valori di <span class="math inline">\(Y - \mathbb{E}(Y)\)</span> e tale risultato viene ottenuto considerando la variabile casuale <span class="math inline">\(\left(Y - \mathbb{E}(Y)\right)^2\)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./017_bayes_theorem.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./019_joint_prob.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Indici di posizione, di varianza e di associazione di variabili casuali {#ch-expval-var-rv}</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c020, include = FALSE}</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>Spesso risulta utile fornire una rappresentazione sintetica della distribuzione di una variabile casuale attraverso degli indicatori caratteristici piuttosto che fare riferimento ad una sua rappresentazione completa mediante la funzione di ripartizione, o la funzione di massa o di densità di probabilità. Una descrizione più sintetica di una variabile casuale, tramite pochi valori, ci consente di cogliere le caratteristiche essenziali della distribuzione, quali: la posizione, cioè il baricentro della distribuzione di probabilità; la variabilità, cioè la dispersione della distribuzione di probabilità attorno ad un centro; la forma della distribuzione di probabilità, considerando la simmetria e la curtosi (pesantezza delle code). In questo Capitolo introdurremo quegli indici sintetici che descrivono il centro di una distribuzione di probabilità e la sua variabilità.</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">## Valore atteso</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>Quando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual è il suo "valore tipico". La nozione di "valore tipico", tuttavia, è ambigua. Infatti, essa può essere definita in almeno tre modi diversi:</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la *media* (somma dei valori divisa per il numero dei valori),</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la *mediana* (il valore centrale della distribuzione, quando la variabile è ordinata in senso crescente o decrescente),</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la *moda* (il valore che ricorre più spesso).</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>Per esempio, la media di $<span class="sc">\{</span>3, 1, 4, 1, 5<span class="sc">\}</span>$ è $\frac{3+1+4+1+5}{5} = 2.8$, la mediana è $3$ e la moda è $1$. Tuttavia, la teoria delle probabilità si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per "valore tipico" quando facciamo riferimento alle variabili casuali. Giungiamo così alla seguente definizione. <span class="co">&lt;!-- Supponiamo di ripetere un esperimento casuale molte volte in modo tale che ciascun valore $Y$ si presenti con una frequenza approssimativamente uguale alla sua probabilità. Per esempio, possiamo lanciare una coppia di dadi e osservare i valori di $S$ = "somma dei punti" e di $P$ = "prodotto dei punti". Ci poniamo il problema di definire il "risultato tipico" di questo esperimento in modo tale che esso corrisponda al valore medio dei valori della variabile casuale, quando l'esperimento casuale viene ripetuto tante volte.  --&gt;</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>::: {#def-exp-val-discr}</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>Sia $Y$ è una variabile casuale discreta che assume i valori $y_1, \dots, y_n$ con distribuzione $P(Y = y_i) = p(y_i)$. Per definizione il *valore atteso* di $Y$, $\mathbb{E}(Y)$, è</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(Y) = \sum_{i=1}^n y_i \cdot p(y_i).</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>$$ {#eq-expval-discr}</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>A parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale è definito come la somma di tutti i valori che la variabile casuale può prendere, ciascuno pesato dalla probabilità con cui il valore è preso.</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>::: {#exr-exp-val-discr}</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>Si calcoli il valore atteso della variabile casuale $Y$ corrispondente al lancio di una moneta equilibrata (testa: *Y* = 1; croce: *Y* = 0).</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>::: solution</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(Y) = \sum_{i=1}^{2} y_i \cdot P(y_i) = 0 \cdot \frac{1}{5} + 1 \cdot \frac{1}{5} = 0.5.</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>::: {#exr-exp-val-discr-2}</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>Si calcoli il valore atteso della variabile casuale $Y$ corrispondente ai punti ottenuti dal lancio di un dado equilibrato.</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>::: solution</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(Y) = \sum_{i=1}^{6} y_i \cdot P(y_i) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + \dots + 6 \cdot \frac{1}{6} = \frac{21}{6} = 3.5.</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretazione</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>Che interpretazione può essere assegnata alla nozione di valore atteso? Bruno de Finetti adottò lo stesso termine di *previsione* (e lo stesso simbolo) tanto per la probabilità che per il valore atteso. Si può pertanto dire che, dal punto di vista bayesiano, il valore atteso è l'estensione naturale della nozione di probabilità soggettiva.</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="fu">### Proprietà del valore atteso</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>La proprietà più importante del valore atteso è la linearità: il valore atteso di una somma di variabili casuali è uguale alla somma dei lori rispettivi valori attesi:</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y).</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>$$ {#eq-prop-expval-linearity}</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>L'@eq-prop-expval-linearity sembra ragionevole quando $X$ e $Y$ sono indipendenti, ma è anche vera quando $X$ e $Y$ sono associati. Abbiamo anche che</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(cY) = c \mathbb{E}(Y).</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>$$ {#eq-prop-expval-const}</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>L'@eq-prop-expval-const ci dice che possiamo estrarre una costante dall'operatore di valore atteso. Tale proprietà si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali $X$ e $Y$ sono indipendenti, abbiamo che</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(X Y) = \mathbb{E}(X) \mathbb{E}(Y). </span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>$$ {#eq-expval-prod-ind-rv}</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>::: {#exr-exp-val-discr-3}</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>Si considerino le seguenti variabili casuali: $Y$, ovvero il numero che si ottiene dal lancio di un dado equilibrato, e $Y$, il numero di teste prodotto dal lancio di una moneta equilibrata. Si trovi il valore atteso di $X+Y$.</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>::: solution</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>Per risolvere il problema iniziamo a costruire lo spazio campionario dell'esperimento casuale consistente nel lancio di un dado e di una moneta.</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>| $x \textbackslash y$ |   1    |   2    |   3    |   4    |   5    |   6    |</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>|:--------------------:|:------:|:------:|:------:|:------:|:------:|:------:|</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>|          0           | (0, 1) | (0, 2) | (0, 3) | (0, 4) | (0, 5) | (0, 6) |</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>|          1           | (1, 1) | (1, 2) | (1, 3) | (1, 4) | (1, 5) | (1, 6) |</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>ovvero</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>| $x \textbackslash y$ |  1  |  2  |  3  |  4  |  5  |  6  |</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>|:--------------------:|:---:|:---:|:---:|:---:|:---:|:---:|</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>|          0           |  1  |  2  |  3  |  4  |  5  |  6  |</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>|          1           |  2  |  3  |  4  |  5  |  6  |  7  |</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>Il risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campionario avrà la stessa probabilità di verificarsi, ovvero $P(\omega) = \frac{1}{12}$. Il valore atteso di $X+Y$ è dunque uguale a:</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(X+Y) = 1 \cdot \frac{1}{12} + 2 \cdot \frac{1}{12} + \dots + 7 \cdot \frac{1}{12} = 4.0.</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>Possiamo ottenere lo stesso risultato usanlo l'@eq-prop-expval-linearity:</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(X+Y) = \mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>::: {#exr-exp-val-discr-4}</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>Si considerino le variabili casuali $X$ e $Y$ definite nel caso del lancio di tre monete equilibrate, dove $X$ conta il numero delle teste nei tre lanci e $Y$ conta il numero delle teste al primo lancio. Si calcoli il valore atteso del prodotto delle variabili casuali $X$ e $Y$.</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>::: solution</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>La distribuzione di probabilità congiunta $P(X, Y)$ è fornita nella tabella seguente.</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>| $x \textbackslash y$ |  0  |  1  | $p(Y)$ |</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>|:--------------------:|:---:|:---:|:------:|</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>|          0           | 1/8 |  0  |  1/8   |</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>|          1           | 2/8 | 1/8 |  3/8   |</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>|          2           | 1/8 | 2/8 |  3/8   |</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>|          3           |  0  | 1/8 |  1/8   |</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>|        $p(y)$        | 4/8 | 4/8 |  1.0   |</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>Il calcolo del valore atteso di $XY$ si riduce a</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(XY) = 1 \cdot \frac{1}{8} + 2 \cdot \frac{2}{8} + 3 \cdot \frac{1}{8} = 1.0.</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>Si noti che le variabili casuali $Y$ e $Y$ non sono indipendenti. Dunque non possiamo usare l'@eq-expval-prod-ind-rv. Infatti, il valore atteso di $X$ è</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(X) = 1 \cdot \frac{3}{8} + 2 \cdot \frac{3}{8} + 3 \cdot \frac{1}{8} = 1.5</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>e il valore atteso di $Y$ è</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(Y) = 0 \cdot \frac{4}{8} + 1 \cdot \frac{4}{8} = 0.5.</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>Perciò</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>1.5 \cdot 0.5 \neq 1.0.</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>In altri termini, se $\mathbb{E}(X Y) \neq \mathbb{E}(X) \mathbb{E}(Y)$, allora le variabili causuali $X$ e $Y$ non sono indipendenti (cioè sono associate).</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="fu">### Variabili casuali continue</span></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>Nel caso di una variabile casuale continua $Y$ il valore atteso diventa:</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(Y) = \int_{-\infty}^{+\infty} y p(y) \,\operatorname{d}<span class="sc">\!</span>y.</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>$$ {#eq-def-ev-rv-cont}</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>Anche in questo caso il valore atteso è una media ponderata della $y$, nella quale ciascun possibile valore $y$ è ponderato per il corrispondente valore della densità $p(y)$. Possiamo leggere l'integrale pensando che $y$ rappresenti l'ampiezza delle barre infinitamente strette di un istogramma, con la densità $p(y)$ che corrisponde all'altezza di tali barre e la notazione $\int_{-\infty}^{+\infty}$ che corrisponde ad una somma.<span class="ot">[^018_expval_var-1]</span></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="ot">[^018_expval_var-1]: </span>Per il significato della notazione di integrale, si veda la @sec-calculus.</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Moda</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>Un'altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di $Y$ individua il valore $y$ più plausibile, ovvero il valore $y$ che massimizza la funzione di densità $p(y)$:</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>\mbox{Mo}(Y) = \mbox{argmax}_y p(y).</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>$$ {#eq-def-mode}</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>La notazione $\mbox{argmax}_y p(y)$ significa: il valore $y$ tale per cui la funzione $p(y)$ assume il suo valore massimo.</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a><span class="fu">## Varianza</span></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>La seconda più importante proprietà di una variabile casuale, dopo che conosciamo il suo valore atteso, è la *varianza*.</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>::: {#def-var-rv-definition}</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>Se $Y$ è una variabile casuale discreta con distribuzione $p(y)$, per definizione la varianza di $Y$, $\mathbb{V}(Y)$, è</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>\mathbb{V}(Y) = \mathbb{E}\Big<span class="co">[</span><span class="ot">\big(Y - \mathbb{E}(Y)\big)^2\Big</span><span class="co">]</span>.</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>$$ {#eq-def-var-rv}</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>A parole: la varianza è la deviazione media quadratica della variabile dalla sua media.<span class="ot">[^018_expval_var-2]</span> Se denotiamo $\mathbb{E}(Y) = \mu$, la varianza $\mathbb{V}(Y)$ diventa il valore atteso di $(Y - \mu)^2$.</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a><span class="ot">[^018_expval_var-2]: </span>Data una variabile casuale $Y$ con valore atteso $\mathbb{E}(Y)$, le "distanze" tra i valori di $Y$ e il valore atteso $\mathbb{E}(Y)$ definiscono la variabile casuale $Y - \mathbb{E}(Y)$ chiamata *scarto*, oppure *deviazione* oppure *variabile casuale centrata*. La variabile $Y - \mathbb{E}(Y)$ equivale ad una traslazione di sistema di riferimento che porta il valore atteso nell'origine degli assi. Si può dimostrare facilmente che il valore atteso della variabile scarto $Y - \mathbb{E}(Y)$ vale zero, dunque la media di tale variabile non può essere usata per quantificare la "dispersione" dei valori di $Y$ relativamente al suo valore medio. Occorre rendere sempre positivi i valori di $Y - \mathbb{E}(Y)$ e tale risultato viene ottenuto considerando la variabile casuale $\left(Y - \mathbb{E}(Y)\right)^2$.</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>::: {#exr-var-discr-1}</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>Posta $S$ uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di $S$.</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>::: solution</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>La variabile casuale $S$ ha la seguente distribuzione di probabilità:</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>|    $s$     |       2        |       3        |       4        |       5        |       6        |       7        |       8        |       9        |       10       |       11       |       12       |</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>|:----------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>| $P(S = s)$ | $\frac{1}{36}$ | $\frac{2}{36}$ | $\frac{3}{36}$ | $\frac{4}{36}$ | $\frac{5}{36}$ | $\frac{6}{36}$ | $\frac{5}{36}$ | $\frac{4}{36}$ | $\frac{3}{36}$ | $\frac{2}{36}$ | $\frac{1}{36}$ |</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>Essendo $\mathbb{E}(S) = 7$, la varianza diventa</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>\mathbb{V}(S) &amp;= \sum \left(s - \mathbb{E}(S)\right)^2 \cdot P(s) \notag<span class="sc">\\</span></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>&amp;= (2 - 7)^2 \cdot 0.0278 + (3-7)^2 \cdot 0.0556 + \dots + (12 - 7)^2 \cdot 0.0278 \notag<span class="sc">\\</span></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>&amp;= 5.8333.\notag</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a><span class="fu">### Formula alternativa per la varianza</span></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>C'è un modo più semplice per calcolare la varianza:</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>\mathbb{E}\Big<span class="co">[</span><span class="ot">\big(Y - \mathbb{E}(Y)\big)^2\Big</span><span class="co">]</span> &amp;= \mathbb{E}\big(Y^2 - 2Y\mathbb{E}(Y) + \mathbb{E}(Y)^2\big)\notag<span class="sc">\\</span></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>&amp;= \mathbb{E}(Y^2) - 2\mathbb{E}(Y)\mathbb{E}(Y) + \mathbb{E}(Y)^2,</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>dato che $\mathbb{E}(Y)$ è una costante. Pertanto</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>\mathbb{V}(Y) = \mathbb{E}(Y^2) - \big(\mathbb{E}(Y) \big)^2.</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>$$ {#eq-def-alt-var-rv}</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>A parole: la varianza è la media dei quadrati meno il quadrato della media della variabile.</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>::: {#exr-var-discr-2}</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>Consideriamo la variabile casuale $Y$ che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di $Y$.</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>::: solution</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>Il valore atteso di $Y$ è</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(Y) = 0 \cdot 0.2 + 1 \cdot 0.8 = 0.8.</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>Usando la formula tradizionale della varianza otteniamo:</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>\mathbb{V}(Y) = (0 - 0.8)^2 \cdot 0.2 + (1 - 0.8)^2 \cdot 0.8 = 0.16.</span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>Lo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di $Y^2$ è</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(Y^2) = 0^2 \cdot 0.2 + 1^2 \cdot 0.8 = 0.8.</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>e la varianza diventa</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>\mathbb{V}(Y) = \mathbb{E}(Y^2) - \big(\mathbb{E}(Y) \big)^2 = 0.8 - 0.8^2 = 0.16.</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a><span class="fu">### Variabili casuali continue</span></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>Nel caso di una variabile casuale continua $Y$, la varianza diventa:</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>\mathbb{V}(Y) = \int_{-\infty}^{+\infty} \large<span class="co">[</span><span class="ot">y - \mathbb{E}(Y)\large</span><span class="co">]</span>^2 p(y) \,\operatorname {d}<span class="sc">\!</span>y.</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>$$ {#eq-def-var-rv-cont}</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>Come nel caso discreto, la varianza di una v.c. continua $Y$ misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori $y$ dalla loro media.</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a><span class="fu">## Deviazione standard</span></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>Quando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell'unità di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato *deviazione standard* e solitamente è denotato dalla lettera greca $\sigma$.</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>::: {#def-sd-vc}</span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>\sigma_Y = \sqrt{\mathbb{V}(Y)}.</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a>$$ {#eq-def-sd}</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>Come nella statistica descrittiva, la deviazione standard di una variabile casuale misura approssimativamente la distanza tipica o prevista dei possibili valori $y$ dalla loro media.</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>::: {#exr-sd-discr-1}</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>Per i dadi equilibrati dell'@exr-var-discr-1, la deviazione standard della variabile casuale $S$ è uguale a $\sqrt{5.833} = 2.415$.</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a><span class="fu">## Standardizzazione</span></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a>::: {#def-standardization}</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>Data una variabile casuale $Y$, si dice *variabile standardizzata* di $Y$ l'espressione</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a>Z = \frac{Y - \mathbb{E}(Y)}{\sigma_Y}.</span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>$$ {#eq-standardization}</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>Solitamente, una variabile standardizzata viene denotata con la lettera $Z$.</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a><span class="fu">## Momenti di variabili casuali</span></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a>::: definition</span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a>Si chiama *momento* di ordine $q$ di una v.c. $X$, dotata di densità $p(x)$, la quantità</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(X^q) = \int_{-\infty}^{+\infty} x^q p(x) \; dx.</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a>$$ {#eq-moments-cont}</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a>Se $X$ è una v.c. discreta, i suoi momenti valgono:</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(X^q) = \sum_i x_i^q P(x_i).</span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>$$ {#eq-moments-discr}</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>I momenti sono importanti parametri indicatori di certe proprietà di $X$. I più noti sono senza dubbio quelli per $q = 1$ e $q = 2$. Il momento del primo ordine corrisponde al valore atteso di $X$. Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di $X$, operando una traslazione $x_0 = x − \mathbb{E}(X)$ che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza.</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a><span class="fu">## Covarianza</span></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>La covarianza quantifica la tendenza delle variabili casuali $X$ e $Y$ a "variare assieme". Per esempio, l'altezza e il peso delle giraffe producono una covarianza positiva perché all'aumentare di una di queste due quantità tende ad aumentare anche l'altra. La covarianza misura la forza e la direzione del legame lineare tra due variabili casuali $X$ ed $Y$. Si utilizza la notazione $\mbox{Cov}(X,Y)=\sigma_{xy}$.</span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>::: {#def-covariance-rv}</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a>Date due variabili casuali $X$, $Y$, chiamiamo covarianza tra $X$ ed $Y$ il numero</span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a>\mbox{Cov}(X,Y) = \mathbb{E}\Bigl(\bigl(X - \mathbb{E}(X)\bigr) \bigl(Y - \mathbb{E}(Y)\bigr)\Bigr),</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cov-def-rv}</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>dove $\mathbb{E}(X)$ e $\mathbb{E}(Y)$ sono i valori attesi di $X$ ed $Y$.</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a>In maniera esplicita,</span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a>\mbox{Cov}(X,Y) = \sum_{(x,y) \in \Omega} (x - \mu_X) (y - \mu_Y) f(x, y).</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cov_def}</span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>La definizione è analoga, algebricamente, a quella di varianza e risulta infatti</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a>\mathbb{V}(x) = \mbox{Cov}(X, X)</span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a>e</span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a>\mbox{Cov}(X,Y) = \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X).</span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cov_vc_alt}</span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a>::: proof</span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a>L'@eq-cov_vc_alt si ricava nel modo seguente:</span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a>\mbox{Cov}(X,Y) &amp;= \mathbb{E}\Bigl(\bigl(X-\mathbb{E}(X)\bigr) \bigl(Y-\mathbb{E}(Y)\bigr)\Bigr)\notag<span class="sc">\\</span></span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a>          %&amp;= \mathbb{E}(XY) - \mathbb{E}(Y)X -\mathbb{E}(X)Y + \mathbb{E}(X)\mathbb{E}(Y) )\notag<span class="sc">\\</span></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a>          &amp;= \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X) - \mathbb{E}(X)\mathbb{E}(Y) + \mathbb{E}(X)\mathbb{E}(Y)\notag<span class="sc">\\</span></span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a>          &amp;= \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X)\notag.</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a>::: {#exr-cov-rv-1}</span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a>Consideriamo le variabili casuali definite nell'@exr-exp-val-discr-4. Si calcoli la covarianza di $X$ e $Y$.</span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a>::: solution</span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a>Abbiamo che $\mu_X = 1.5$ e $\mu_Y = 0.5$. Ne segue che la covarianza di $X$ e $Y$ è:</span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a>\mbox{Cov}(X,Y) &amp;= \sum_{(x,y) \in \Omega} (x - \mu_X) (y - \mu_Y) f(x, y)\notag<span class="sc">\\</span></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>&amp;= (0-1.5)(0-0.5)\cdot \frac{1}{8} + (0-1.5)(1-0.5) \cdot 0 <span class="sc">\\</span></span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a>   &amp;\qquad + (1-1.5)(0-0.5)\cdot \frac{2}{8} + (1-1.5)(1-0.5) \cdot \frac{1}{8} \notag<span class="sc">\\</span></span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>    &amp;\qquad+ (2-1.5)(0-0.5) \cdot \frac{1}{8} + (2-1.5)(1-0.5) \cdot \frac{2}{8} <span class="sc">\\</span></span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a>   &amp;\qquad+ (3-1.5)(0-0.5) \cdot 0 +  (3-1.5)(1-0.5)\cdot\frac{1}{8} \notag<span class="sc">\\</span></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>   &amp;= \frac{1}{4}. \notag</span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a> \end{align}</span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a>Lo stesso risultato può essere trovato usando l'@eq-cov_vc_alt. Iniziamo a calcolare il valore atteso del prodotto $XY$:</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(XY) = 0 \cdot\frac{4}{8} + 1 \cdot\frac{1}{8} + 2 \cdot\frac{2}{8} + 3 \cdot\frac{1}{8} = 1.0.</span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a>Dunque, la covarianza tra $X$ e $Y$ diventa</span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a>\mbox{Cov}(X,Y) &amp;= \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y)\notag<span class="sc">\\</span></span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a> &amp;= 1 -  1.5\cdot 0.5 \notag<span class="sc">\\</span></span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a> &amp;= 0.25.\notag</span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a><span class="fu">## Correlazione</span></span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a>La covarianza dipende dall'unità di misura delle due variabili e quindi non consente di stabilire l'intensità della relazione. Una misura standardizzata della relazione che intercorre fra due variabili è invece rappresentata dalla correlazione. La correlazione si ottiene dividendo la covarianza per le deviazioni standard delle due variabili aleatorie.</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a>::: {#def-cor-rv-def}</span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a>Il coefficiente di correlazione tra $X$ ed $Y$ è il numero definito da</span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a>\rho(X,Y) =\frac{\mbox{Cov}(X,Y)}{\sqrt{\mathbb{V}(X)\mathbb{V}(Y)}}.</span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cor-rv-def}</span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a>Si può anche scrivere $\rho_{X,Y}$ al posto di $\rho(X,Y)$.</span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a>Il coefficiente di correlazione $\rho_{xy}$ è un numero puro, cioè non dipende dall'unità di misura delle variabili, e assume valori compresi tra -1 e +1.</span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a><span class="fu">## Proprietà</span></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>La covarianza tra una variabile aleatoria $X$ e una costante $c$ è nulla: $\mbox{Cov}(c,X) = 0;$</span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la covarianza è simmetrica: $\mbox{Cov}(X,Y) = \mbox{Cov}(Y,X);$</span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>vale $-1 \leq \rho(X,Y) \leq 1;$</span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la correlazione non dipende dall'unità di misura: $\rho(aX, bY) = \rho(X,Y), \quad \forall a, b &gt; 0;$</span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>se $Y = a + bX$ è una funzione lineare di $X$ con costanti $a$ e $b$, allora $\rho(X,Y) = \pm 1$, a seconda del segno di $b$;</span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>la covarianza tra $X$ e $Y$, ciascuna moltiplicata per una costante, è uguale al prodotto delle costanti per la covarianza tra $X$ e $Y$: $\mbox{Cov}(aX,bY) = ab \;\mbox{Cov}(X,Y)$;</span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>vale $\mathbb{V}(X \pm Y) = \mathbb{V}(X) + \mathbb{V}(Y) \pm 2 \cdot \mbox{Cov}(X,Y)$;</span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>vale $\mbox{Cov}(X + Y, Z) = \mbox{Cov}(X,Z) + \mbox{Cov}(Y,Z);$</span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>per una sequenza di variabili aleatorie $X_1, \dots, X_n$, si ha $$\mathbb{V}\left( \sum_{i=1}^n X_i\right) = \sum_{i=1}^n \mathbb{V}(X_i) + 2\sum_{i,j: i&lt;j}cov(X_i, X_j);$$</span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>vale $\mbox{Cov}\left(\sum_{i=1}^n a_i X_i, \sum_{j=1}^m b_jY_j\right) = \sum_{i=1}^n \sum_{j=1}^m a_j b_j\mbox{Cov}(X_j, Y_j);$</span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>se $X_1, X_2, \dots, X_n$ sono indipendenti, allora $$\mbox{Cov}\left(\sum_{i=1}^n a_i X_i, \sum_{j=1}^n b_jX_j\right) = \sum_{i=1}^n a_i b_i \mathbb{V}(X_i).$$</span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a><span class="fu">### Incorrelazione</span></span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a>::: {#def-incorrelation-def}</span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a>Si dice che $X$ ed $Y$ sono incorrelate, o linermente indipendenti, se la loro covarianza è nulla,</span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a>\sigma_{XY} = \mathbb{E} \big<span class="co">[</span><span class="ot">(X - \mu_X) (y-\mu_u) \big</span><span class="co">]</span> = 0,</span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a>$$ {#eq-incorrelation-def}</span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a>che si può anche scrivere come</span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a>\rho_{XY} = 0, \quad \mathbb{E}(XY) = \mathbb{E}(X) \mathbb{E}(Y).</span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a>Si introduce così un secondo tipo di indipendenza, più debole, dopo quello di indipendenza stocastica. Viceversa, però, se $\mbox{Cov}(X, Y) = 0$, non è detto che $X$ ed $Y$ siano indipendenti.</span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a>::: {#exr-incorrelation-1}</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a>Siano $X$ e $Y$ due variabili aleatorie discrete avente una distribuzione di massa di probabilità congiunta pari a</span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a>f_{XY}(x,y) = \frac{1}{4} \quad (x,y) \in <span class="sc">\{</span>(0,0), (1,1), (1, -1), (2,0) <span class="sc">\}</span></span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a>e zero altrimenti. Le due variabili aleatorie $X$ e $Y$ sono mutuamente indipendenti?</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a>::: solution</span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a>La distribuzione marginale della $X$ è</span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a>X = 0, \quad  P_X = 1/4, <span class="sc">\\</span></span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a>X = 1, \quad P_X = 2/4, <span class="sc">\\</span></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a>X = 2, \quad P_X = 1/4.</span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(X) = 0 \frac{1}{4} + 1 \frac{2}{4} + 2 \frac{1}{4} = 1.</span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(X^2) = 0^2 \frac{1}{4} + 1^2 \frac{2}{4} + 2^2 \frac{1}{4} = \frac{3}{2}.</span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a>\mathbb{V}(X) = \frac{3}{2} - 1^2 = \frac{1}{2}.</span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a>La distribuzione marginale della $Y$ è</span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a>Y = -1, \quad  P_Y = 1/4, <span class="sc">\\</span></span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a>Y = 0, \quad P_Y = 2/4, <span class="sc">\\</span></span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a>Y = 1, \quad P_Y = 1/4.</span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(Y) = 0 \frac{2}{4} + 1 \frac{1}{4} + (-1) \frac{1}{4} = 0.</span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(Y^2) = 0^2 \frac{2}{4} + 1^2 \frac{1}{4} + (-1)^2 \frac{1}{4} = \frac{1}{2}.</span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a>\mathbb{V}(X) = \frac{1}{2} - 0^2 = \frac{1}{2}.</span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>Calcoliamo ora la covarianza tra $X$ e $Y$:</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(XY) = \sum_x\sum_y xy f_{XY} (x,y) =</span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>(0\cdot 0)\frac{1}{4} +</span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a>(1\cdot 1)\frac{1}{4} +</span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a>(1\cdot -1)\frac{1}{4} +</span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a>(2\cdot 0)\frac{1}{4} = 0.</span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a>\mbox{Cov}(X,Y) = \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y) = 0 - 1\cdot0 = 0.</span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a>Quindi le due variabili aleatorie hanno covarianza pari a zero. Tuttavia, esse non sono indipendenti, in quanto non è vero che</span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a>f_{XY} (x,y) = f_X(x) f_Y(y)</span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a>per tutti gli $x$ e $y$.</span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a>In conclusione, anche se la condizione di indipendenza implica una covarianza nulla, l'esempio precedente mostra come l'inverso non sia necessariamente vero: la covarianza può essere zero anche se due variabili casuali non sono indipendenti.</span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusioni {.unnumbered}</span></span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a>La densità di probabilità congiunta bivariata tiene simultaneamente conto del comportamento di due variabili casuali $X$ e $Y$ e di come esse si influenzano. Se $X$ e $Y$ sono legate linearmente, allora il coefficiente di correlazione</span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a><span class="in">\rho = \frac{\mbox{Cov}(X, Y)}{\sigma_X \sigma_Y}\notag</span></span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a>fornisce l'indice maggiormente utilizzato per descrivere l'intensità e il segno dell'associazione lineare. Nel caso di un'associazione lineare perfetta, $Y = a + bX$, avremo $\rho = 1$ con $b$ positivo ed $\rho = -1$ con $b$ negativo. Se il coefficiente di correlazione è pari a 0 le variabili si dicono incorrelate. Condizione sufficiente (ma non necessaria) affinché $\rho = 0$ è che le due variabili siano tra loro indipendenti.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>