<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Data Science per psicologi - 19&nbsp; L’influenza della distribuzione a priori</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./036_posterior_sim.html" rel="next">
<link href="./029_conjugate_families.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/data_science/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Benvenuti</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">Prefazione</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./basics.html" class="sidebar-item-text sidebar-link">Parte 1: Nozioni di base</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_key_notions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Concetti chiave</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_measurement.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_freq_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_loc_scale.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_penguins.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Manipolazione e visualizzazione dei dati in <span class="math inline">\(\mathsf{R}\)</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./prob.html" class="sidebar-item-text sidebar-link">Parte 2: Il calcolo delle probabilità</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_prob_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">La logica dell’incerto</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_conditional_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Probabilità condizionata: significato, teoremi, eventi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_bayes_theorem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./018_expval_var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Indici di posizione, di varianza e di associazione di variabili casuali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./019_joint_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./020_density_func.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La densità di probabilità</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./distr.html" class="sidebar-item-text sidebar-link">Parte 3: Distribuzioni di v.c. discrete e continue</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./022_discr_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./023_cont_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./024_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">La funzione di verosimiglianza</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./bayes_inference.html" class="sidebar-item-text sidebar-link">Parte 4: Inferenza bayesiana</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./025_intro_bayes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Credibilità, modelli e parametri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./026_subj_prop.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./029_conjugate_families.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./030_balance_prior_post.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./036_posterior_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Approssimazione della distribuzione a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./040_beta_binomial_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Il modello beta-binomiale in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./041_mcmc_diagnostics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./045_summarize_posterior.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./046_bayesian_prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./050_normal_normal_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./regression.html" class="sidebar-item-text sidebar-link">Parte 5: Regressione lineare</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./051_reglin1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./052_reglin2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Regressione lineare bivariata</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./053_reglin3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Modello di regressione in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./054_reglin4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Inferenza sul modello lineare</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./055_reglin5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./056_pred_check.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Predictive checks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./060_anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Confronto tra le medie di tre o più gruppi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./070_mod_hier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modello gerarchico</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./071_mod_hier_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Modello gerarchico: simulazioni</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./entropy.html" class="sidebar-item-text sidebar-link">Parte 6: Entropia</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./090_entropy.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Entropia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./091_kl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./092_info_criterion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Criterio di informazione e convalida incrociata</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./frequentist_inference.html" class="sidebar-item-text sidebar-link">Parte 7: Inferenza frequentista</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./220_intro_frequentist.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Legge dei grandi numeri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./221_conf_interv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Intervallo fiduciale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./225_distr_camp_mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Distribuzione campionaria</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./226_test_ipotesi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Significatività statistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./227_ttest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza sulle medie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./228_limiti_stat_frequentista.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./999_refs.html" class="sidebar-item-text sidebar-link">Riferimenti bibliografici</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">Appendici</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a01_math_symbols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a02_number_sets.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a03_set_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Insiemi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a04_summation_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Simbolo di somma (sommatorie)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a05_calculus_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a10_markov_chains.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Le catene di Markov</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a15_stan_lang.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Programmare in Stan</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul>
<li><a href="#il-test-di-benchdel" id="toc-il-test-di-benchdel" class="nav-link active" data-scroll-target="#il-test-di-benchdel"><span class="toc-section-number">19.1</span>  Il test di Benchdel</a></li>
  <li><a href="#stessi-dati-diverse-distribuzioni-a-priori" id="toc-stessi-dati-diverse-distribuzioni-a-priori" class="nav-link" data-scroll-target="#stessi-dati-diverse-distribuzioni-a-priori"><span class="toc-section-number">19.2</span>  Stessi dati, diverse distribuzioni a priori</a></li>
  <li><a href="#dati-diversi-stessa-distribuzione-a-priori" id="toc-dati-diversi-stessa-distribuzione-a-priori" class="nav-link" data-scroll-target="#dati-diversi-stessa-distribuzione-a-priori"><span class="toc-section-number">19.3</span>  Dati diversi, stessa distribuzione a priori</a></li>
  <li><a href="#dati-diversi-diverse-distribuzioni-a-priori" id="toc-dati-diversi-diverse-distribuzioni-a-priori" class="nav-link" data-scroll-target="#dati-diversi-diverse-distribuzioni-a-priori"><span class="toc-section-number">19.4</span>  Dati diversi, diverse distribuzioni a priori</a></li>
  <li><a href="#collegare-le-intuizioni-alla-teoria" id="toc-collegare-le-intuizioni-alla-teoria" class="nav-link" data-scroll-target="#collegare-le-intuizioni-alla-teoria"><span class="toc-section-number">19.5</span>  Collegare le intuizioni alla teoria</a></li>
  <li><a href="#commenti-e-considerazioni-finali" id="toc-commenti-e-considerazioni-finali" class="nav-link" data-scroll-target="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-prior-influence" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Codice</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><p>La notazione <span class="math inline">\(p(\theta \mid y) \propto p(\theta) \ p(y \mid \theta)\)</span> rende particolarmente chiaro che la distribuzione a posteriori è un “miscuglio” della distribuzione a priori e della verosimiglianza. Prima di preoccuparci di come calcolare la distribuzione a posteriori in casi diversi dalle famiglie coniugate, cerchiamo di capire meglio cosa significa “mescolare” la distribuzione a priori e la verosimiglianza. Considereremo qui un esempio discusso da <span class="citation" data-cites="Johnson2022bayesrules">Johnson et al. (<a href="999_refs.html#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span>.</p>
<section id="il-test-di-benchdel" class="level2" data-number="19.1"><h2 data-number="19.1" class="anchored" data-anchor-id="il-test-di-benchdel">
<span class="header-section-number">19.1</span> Il test di Benchdel</h2>
<p>Nel fumetto di Alison Bechdel <em>The Rule</em>, un personaggio afferma di guardare un film solo se soddisfa le seguenti tre regole <span class="citation" data-cites="Bechdel1986dykes">(<a href="999_refs.html#ref-Bechdel1986dykes" role="doc-biblioref">Bechdel, 1986</a>)</span>: almeno due caratteri nel film devono essere donne; queste due donne si parlano; parlano di qualcosa altro oltre a parlare di qualche uomo.</p>
<p>Questi criteri costituiscono il <em>test di Bechdel</em> per la rappresentazione delle donne nei film. <span class="citation" data-cites="Johnson2022bayesrules">Johnson et al. (<a href="999_refs.html#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span> pongono la seguente domanda “Quale percentuale dei film che avete visto supera il test di Bechdel?”.</p>
<p>Sia <span class="math inline">\(\pi \in [0, 1]\)</span> una variabile casuale che indica la proporzione sconosciuta di film che superano il test di Bechdel. Tre amiche — la femminista, l’ignara e l’ottimista — hanno opionioni diverse su <span class="math inline">\(\pi\)</span>. Riflettendo sui film che ha visto, la femminista capisce che nella maggioranza dei film mancano personaggi femminili forti. L’ignara non ricorda bene i film che ha visto, quindi non sa quanti film superano il test di Bechdel. Infine, l’ottimista pensa che, in generale, le donne siano ben rappresentate all’interno dei film: secondo lei quasi tutti i film superano il test di Bechdel. Le tre amiche hanno dunque tre modelli a priori diversi di <span class="math inline">\(\pi\)</span>.</p>
<p>Abbiamo visto in precedenza come sia possibile usare la distribuzione Beta per rappresentare le credenze a priori. Ponendo la gran parte della massa della probabilità a priori su valori <span class="math inline">\(\pi &lt; 0.5\)</span>, la distribuzione a priori <span class="math inline">\(\text{Beta}(5, 11)\)</span> riflette il punto di vista femminista secondo il quale la maggioranza dei film non supera il test di Bechdel. Al contrario, la <span class="math inline">\(\text{Beta}(14,1)\)</span> pone la gran parte della massa della distribuzione a priori su valori <span class="math inline">\(\pi\)</span> prossimi a 1, e corrisponde quindi alle credenze a priori dell’amica ottimista. Infine, una <span class="math inline">\(\text{Beta}(1 ,1)\)</span> o <span class="math inline">\(\mbox{Unif}(0, 1)\)</span>, assegna lo stesso livello di plausibilità a tutti i valori <span class="math inline">\(\pi \in [0, 1]\)</span>, e corrisponde all’incertezza a priori dell’ignara.</p>
<p>Nell’esempio di <span class="citation" data-cites="Johnson2022bayesrules">Johnson et al. (<a href="999_refs.html#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span>, le tre amiche decidono di rivedere un campione di <span class="math inline">\(n\)</span> film e di registrare <span class="math inline">\(y\)</span>, ovvero il numero di film che superano il test di Bechdel. Se <span class="math inline">\(y\)</span> corrisponde al numero di “successi” in un numero fisso di <span class="math inline">\(n\)</span> prove Bernoulliane i.i.d., allora la dipendenza di <span class="math inline">\(y\)</span> da <span class="math inline">\(\pi\)</span> viene specificata da un modello binomiale. Quindi, per ciascuna delle tre amiche è possibile scrivere un modello beta-binomiale</p>
<span class="math display">\[\begin{align}
Y \mid \pi &amp; \sim \mbox{Bin}(n, \pi)  \notag\\
\pi &amp; \sim \mbox{Beta}(\alpha, \beta) \notag
\end{align}\]</span>
<p>che utilizza diversi parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> per la distribuzione a priori e che conduce a tre diverse distribuzioni a posteriori per il parametro sconosciuto <span class="math inline">\(\pi\)</span>:</p>
<span class="math display">\[\begin{equation}
\pi \mid (Y = y) \sim \mbox{Beta}(\alpha + y, \beta + n - y).
\end{equation}\]</span>
<p><span class="citation" data-cites="Johnson2022bayesrules">Johnson et al. (<a href="999_refs.html#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span> si chiedono come le credenze a priori delle tre amiche influenzano le credenze a posteriori a cui esse giungono dopo avere osservato i dati. Si chiedono inoltre in che modo la dimensione del campione moduli l’influenza della distribuzione a priori sulla distribuzione a posteriori.</p>
<p>Per rispondere a queste domande, <span class="citation" data-cites="Johnson2022bayesrules">Johnson et al. (<a href="999_refs.html#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span> consideriamo tre diversi scenari:</p>
<ul>
<li>gli stessi dati osservati, ma distribuzioni a priori diverse;</li>
<li>dati diversi, ma la stessa distribuzione a priori;</li>
<li>dati diversi e distribuzioni a priori diverse.</li>
</ul></section><section id="stessi-dati-diverse-distribuzioni-a-priori" class="level2" data-number="19.2"><h2 data-number="19.2" class="anchored" data-anchor-id="stessi-dati-diverse-distribuzioni-a-priori">
<span class="header-section-number">19.2</span> Stessi dati, diverse distribuzioni a priori</h2>
<p>Iniziamo con lo scenario che descrive il caso in cui abbiamo gli stessi dati ma diverse distribuzioni a priori. Supponiamo che le tre amiche decidano di guardare insieme 20 film selezionati a caso.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">bechdel</span>, package <span class="op">=</span> <span class="st">"bayesrules"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">84735</span><span class="op">)</span></span>
<span><span class="va">bechdel_20</span> <span class="op">&lt;-</span> <span class="va">bechdel</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">sample_n</span><span class="op">(</span><span class="fl">20</span><span class="op">)</span></span>
<span><span class="va">bechdel_20</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 3 × 3</span></span>
<span><span class="co">#&gt;    year title      binary</span></span>
<span><span class="co">#&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt; </span></span>
<span><span class="co">#&gt; 1  2005 King Kong  FAIL  </span></span>
<span><span class="co">#&gt; 2  1983 Flashdance PASS  </span></span>
<span><span class="co">#&gt; 3  2013 The Purge  FAIL</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Di questi 20 film, solo il 45% (<span class="math inline">\(y\)</span> = 9) passa il test di Bechdel.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">bechdel_20</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">janitor</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/janitor/man/tabyl.html">tabyl</a></span><span class="op">(</span><span class="va">binary</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">janitor</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/janitor/man/adorn_totals.html">adorn_totals</a></span><span class="op">(</span><span class="st">"row"</span><span class="op">)</span></span>
<span><span class="co">#&gt;  binary  n percent</span></span>
<span><span class="co">#&gt;    FAIL 11    0.55</span></span>
<span><span class="co">#&gt;    PASS  9    0.45</span></span>
<span><span class="co">#&gt;   Total 20    1.00</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Esaminiamo le tre distribuzioni a posteriori. Per la femminista usiamo una distribuzione a priori <span class="math inline">\(\text{Beta}(5, 11)\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">5</span>, beta <span class="op">=</span> <span class="fl">11</span>, y <span class="op">=</span> <span class="fl">9</span>, n <span class="op">=</span> <span class="fl">20</span></span>
<span>  <span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="030_balance_prior_post_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/summarize_beta_binomial.html">summarize_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">5</span>, beta <span class="op">=</span> <span class="fl">11</span>, y <span class="op">=</span> <span class="fl">9</span>, n <span class="op">=</span> <span class="fl">20</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;       model alpha beta      mean      mode        var         sd</span></span>
<span><span class="co">#&gt; 1     prior     5   11 0.3125000 0.2857143 0.01263787 0.11241827</span></span>
<span><span class="co">#&gt; 2 posterior    14   22 0.3888889 0.3823529 0.00642309 0.08014418</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per l’ottimista usiamo una distribuzione a priori <span class="math inline">\(\text{Beta}(14, 1)\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">14</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">9</span>, n <span class="op">=</span> <span class="fl">20</span></span>
<span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="030_balance_prior_post_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/summarize_beta_binomial.html">summarize_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">14</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">9</span>, n <span class="op">=</span> <span class="fl">20</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;       model alpha beta      mean      mode         var         sd</span></span>
<span><span class="co">#&gt; 1     prior    14    1 0.9333333 1.0000000 0.003888889 0.06236096</span></span>
<span><span class="co">#&gt; 2 posterior    23   12 0.6571429 0.6666667 0.006258503 0.07911070</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Infine, per l’ignara usiamo una distribuzione a priori <span class="math inline">\(\text{Beta}(1, 1)\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">1</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">9</span>, n <span class="op">=</span> <span class="fl">20</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="030_balance_prior_post_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/summarize_beta_binomial.html">summarize_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">1</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">9</span>, n <span class="op">=</span> <span class="fl">20</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;       model alpha beta      mean mode        var        sd</span></span>
<span><span class="co">#&gt; 1     prior     1    1 0.5000000  NaN 0.08333333 0.2886751</span></span>
<span><span class="co">#&gt; 2 posterior    10   12 0.4545455 0.45 0.01077973 0.1038255</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per calcolare la distribuzione a posteriori, ho usato le funzioni del pacchetto <code>bayesrules</code>. Ma per lo schema beta-binomiale è facile trovare i parametri della distribuzione a posteriori. Per esempio, nel caso dell’amica femminista, la distribuzione a posteriori è una Beta di parametri</p>
<p><span class="math display">\[
\alpha_{post} = \alpha_{prior} + y = 5+9 = 14
\]</span></p>
<p>e</p>
<p><span class="math display">\[
\beta_{post} = \beta_{prior} + n - y = 11 + 20 - 9 = 22.
\]</span></p>
<p>L’aggiornamento bayesiano indica che le tre amiche otterranno valori molto diversi per la media (o la moda) a posteriori del parametro <span class="math inline">\(\pi\)</span>. Dunque, anche dopo avere visto 20 film, le tre amiche non si trovano d’accordo su quale sia la proporzione di film che passano il test di Bechdel.</p>
<p>Questo non dovrebbe sorprenderci. L’amica ottimista aveva opinioni molto forti sul valore di <span class="math inline">\(\pi\)</span> e i <em>pochi</em> nuovi dati che le sono stati forniti non sono riusciti a convincerla a cambiare idea: pensa ancora che i valori <span class="math inline">\(\pi &gt; 0.5\)</span> siano i più credibili. Lo stesso si può dire, all’estremo opposto, dell’amica femminista: anche lei continua a pensare che i valori <span class="math inline">\(\pi &lt; 0.5\)</span> siano i più credibili. Infine, l’ignara non aveva nessuna opinione a priori su <span class="math inline">\(\pi\)</span> e, anche dopo avere visto 20 film, continua a pensare che il valore <span class="math inline">\(\pi\)</span> più credibile sia quello intermedio, nell’intorno di 0.5.</p>
<p>In conclusione, quando i dati sono deboli (ovvero, quando il campione è piccolo), l’aggiornamento bayesiano altera solo in piccola misura le distribuzioni a priori.</p>
</section><section id="dati-diversi-stessa-distribuzione-a-priori" class="level2" data-number="19.3"><h2 data-number="19.3" class="anchored" data-anchor-id="dati-diversi-stessa-distribuzione-a-priori">
<span class="header-section-number">19.3</span> Dati diversi, stessa distribuzione a priori</h2>
<p>Supponiamo ora che l’amica ottimista abbia tre amiche, Maria, Anna e Sara, tutte ottimiste come lei. L’ottimista chiede a Maria, Anna e Sara di fare loro stesse l’esperimento descritto in precedenza. Maria guarda 13 film; di questi 6 passano il test di Bechdel. Anna guarda 63 film; di questi 29 passano il test di Bechdel. Sara guarda 99 film; di questi 46 passano il test di Bechdel.</p>
<p>Supponiamo che Maria, Anna e Sara condividano la stessa credenza a priori su <span class="math inline">\(\pi\)</span>: ovvero, Beta(14, 1). In tali circostanze e, alla luce dei dati osservati, cosa possiamo dire delle tre distribuzioni a posteriori?</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">14</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">6</span>, n <span class="op">=</span> <span class="fl">13</span></span>
<span>  <span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">14</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">29</span>, n <span class="op">=</span> <span class="fl">63</span></span>
<span>  <span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p3</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">14</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">46</span>, n <span class="op">=</span> <span class="fl">99</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p1</span> <span class="op">+</span> <span class="va">p2</span> <span class="op">+</span> <span class="va">p3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-bechdel-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="030_balance_prior_post_files/figure-html/fig-bechdel-2-1.png" class="img-fluid figure-img" style="width:95.0%"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;19.1: Aggiornamento bayesiano per le credenze di Maria (sinistra, 16 film), Anna (centro, 63 film) e Sara (destra, 99 film).</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>In conclusione, dalla <a href="#fig-bechdel-2">Figura&nbsp;<span>19.1</span></a> notiamo due cose. Primo, all’aumentare delle informazioni disponibili (ovvero, al crescere dell’ampiezza del campione), la distribuzione a posteriori si allontana sempre di più dalla distribuzione a priori e si avvicina sempre di più alla verosimiglianza. Secondo, all’aumentare dell’ampiezza del campione la varianza della distribuzione a posteriori diminuisce sempre di più — ovvero, diminuisce l’incertezza su quelli che sono i valori <span class="math inline">\(\pi\)</span> più credibili.</p>
</section><section id="dati-diversi-diverse-distribuzioni-a-priori" class="level2" data-number="19.4"><h2 data-number="19.4" class="anchored" data-anchor-id="dati-diversi-diverse-distribuzioni-a-priori">
<span class="header-section-number">19.4</span> Dati diversi, diverse distribuzioni a priori</h2>
<p>La <a href="#fig-bechdel-3">Figura&nbsp;<span>19.2</span></a> illustra le distribuzioni a posteriori che si ottengono incrociando tre diversi set di dati (<span class="math inline">\(y\)</span> = 6, <span class="math inline">\(n\)</span> = 13;, <span class="math inline">\(y\)</span> = 29, <span class="math inline">\(n\)</span> = 63; <span class="math inline">\(y\)</span> = 66, <span class="math inline">\(n\)</span> = 99) con tre diverse distribuzioni a priori, <span class="math inline">\(\mbox{Beta}(14, 1)\)</span>, <span class="math inline">\(\mbox{Beta}(5, 11)\)</span> e <span class="math inline">\(\mbox{Beta}(1, 1)\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">14</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">6</span>, n <span class="op">=</span> <span class="fl">13</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">14</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">29</span>, n <span class="op">=</span> <span class="fl">63</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p3</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">14</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">46</span>, n <span class="op">=</span> <span class="fl">99</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p4</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">5</span>, beta <span class="op">=</span> <span class="fl">11</span>, y <span class="op">=</span> <span class="fl">6</span>, n <span class="op">=</span> <span class="fl">13</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p5</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">5</span>, beta <span class="op">=</span> <span class="fl">11</span>, y <span class="op">=</span> <span class="fl">29</span>, n <span class="op">=</span> <span class="fl">63</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p6</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">5</span>, beta <span class="op">=</span> <span class="fl">11</span>, y <span class="op">=</span> <span class="fl">46</span>, n <span class="op">=</span> <span class="fl">99</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p7</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">1</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">6</span>, n <span class="op">=</span> <span class="fl">13</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p8</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">1</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">29</span>, n <span class="op">=</span> <span class="fl">63</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="va">p9</span> <span class="op">&lt;-</span> <span class="fu">bayesrules</span><span class="fu">:::</span><span class="fu"><a href="https://bayes-rules.github.io/bayesrules/docs/reference/plot_beta_binomial.html">plot_beta_binomial</a></span><span class="op">(</span></span>
<span>  alpha <span class="op">=</span> <span class="fl">1</span>, beta <span class="op">=</span> <span class="fl">1</span>, y <span class="op">=</span> <span class="fl">46</span>, n <span class="op">=</span> <span class="fl">99</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> </span>
<span><span class="op">(</span><span class="va">p1</span> <span class="op">+</span> <span class="va">p2</span> <span class="op">+</span> <span class="va">p3</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">p4</span> <span class="op">+</span> <span class="va">p5</span> <span class="op">+</span> <span class="va">p6</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">p7</span> <span class="op">+</span> <span class="va">p8</span> <span class="op">+</span> <span class="va">p9</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-bechdel-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="030_balance_prior_post_files/figure-html/fig-bechdel-3-1.png" class="img-fluid figure-img" style="width:95.0%"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;19.2: Sulle colonne (a partire da sinistra) i dati utilizzati sono, rispettivamente, (y = 6, n = 13), (y = 29, n = 63) e (y = 66, n = 99). Sulle righe (a partire dall’alto), le distribuzioni a priori usate sono: Beta(14, 1), Beta(5, 11) e Beta(1, 1).</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>In conclusione, la <a href="#fig-bechdel-3">Figura&nbsp;<span>19.2</span></a> ci consente di concludere quanto segue: se il campione è grande, una distribuzione a priori debolmente informativa ha uno scarso effetto sulla distribuzione a posteriori; se il campione è piccolo, invece, anche una distribuzione a priori debolmente informativa ha un grande effetto sulla distribuzione a posteriori.</p>
</section><section id="collegare-le-intuizioni-alla-teoria" class="level2" data-number="19.5"><h2 data-number="19.5" class="anchored" data-anchor-id="collegare-le-intuizioni-alla-teoria">
<span class="header-section-number">19.5</span> Collegare le intuizioni alla teoria</h2>
<p>Il compromesso che abbiamo osservato nell’esempio precedente, ovvero l’equilibrio che si ottiene tra la distribuzione a priori e le evidenze fornite dai dati, è molto vicino alle nostre intuizioni. Ma è anche il frutto di una necessità matematica. È infatti possibile riscrivere l’<a href="029_conjugate_families.html#eq-ev-post-beta-bin-1">Equazione&nbsp;<span>18.1</span></a> nel modo seguente</p>
<p><span id="eq-ev-post-beta-bin"><span class="math display">\[
\begin{align}
\mathbb{E}_{\text{post}} &amp;[\text{Beta}(\alpha + y, \beta + n - y)] = \frac{\alpha + y}{\alpha + \beta +n}\notag\\
&amp;= \frac{a+b}{a+b+n} \cdot \frac{a}{a+b} + \frac{n}{a+b+n} \cdot \frac{y}{n}.
\end{align}
\tag{19.1}\]</span></span></p>
<p>L’<a href="#eq-ev-post-beta-bin">Equazione&nbsp;<span>19.1</span></a> indica che il valore atteso a posteriori è una media pesata fra il valore atteso a priori <span class="math inline">\(\left( \frac{\alpha}{\alpha+\beta}\right)\)</span> e la proporzione osservata di successi <span class="math inline">\(\left(\frac{y}{n}\right)\)</span>. I pesi sono <span class="math inline">\(\left( \frac{\alpha+\beta}{\alpha+\beta+n}\right)\)</span> e <span class="math inline">\(\left( \frac{n}{\alpha+\beta+n}\right)\)</span>. Quindi, quando <span class="math inline">\(n\)</span> è grande rispetto ad <span class="math inline">\(\alpha + \beta\)</span>, contano molto i dati osservati e contano poco le credenze a priori. Viceversa, quando <span class="math inline">\(n\)</span> è piccolo rispetto a <span class="math inline">\(\alpha + \beta\)</span>, i dati contano poco rispetto alla credenza a priori.</p>
<p>Queste osservazioni ci fanno capire come scegliere i parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>: se vogliamo assumere una totale ignoranza rispetto al fenomeno in esame, la scelta coerente è <span class="math inline">\(\alpha = \beta = 1\)</span> (ogni valore di <span class="math inline">\(\theta\)</span> è ugualmente credibile); se invece abbiamo delle forti credenze a priori, allora possiamo scegliere <span class="math inline">\(\alpha\)</span> così che sia uguale al valore atteso a priori, mentre <span class="math inline">\(\alpha + \beta\)</span> esprime l’importanza che diamo all’informazione a priori: maggiore è il valore di <span class="math inline">\(\alpha + \beta\)</span>, tanti più dati serviranno per allontanare la distribuzione a posteriori dalla distribuzione a priori. Infine, se <span class="math inline">\(n\)</span> è grande, la distribuzione a posteriori avrà una scarsa influenza sulla distribuzione a priori, a meno di scelte estreme.</p>
</section><section id="commenti-e-considerazioni-finali" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="commenti-e-considerazioni-finali">Commenti e considerazioni finali</h2>
<p>La conclusione che possiamo trarre dall’esempio discusso da <span class="citation" data-cites="Johnson2022bayesrules">Johnson et al. (<a href="999_refs.html#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span> è molto chiara: l’aggiornamento bayesiano può essere paragonato ai processi di ragionamento del senso comune. Quando le nuove evidenze (i dati) sono deboli, non c’è ragione di cambiare idea (le nostre credenze “a posteriori” sono molto simili a ciò che pensavamo prima di avere osservato i dati). Quando le nuove evidenze sono irrefutabili, invece, è necessario modificare le nostre credenze sulla base di ciò che ci dicono i dati, quali che siano le nostre credenze pregresse — non farlo significherebbe vivere in un mondo di fantasia e avere scarse possibilità di sopravvivere nel mondo empirico. L’aggiornamento bayesiano, dunque, non fa altro che esprimere in maniera quantitativa e precisa ciò che ci dicono le nostre intuizioni.</p>
<p>Alla luce di quanto detto sopra, è sorprendente che l’approccio frequentista neghi questa logica. I test frequentisti non tengono conto delle conoscenze pregresse. Dunque, se un test frequentista, calcolato su un piccolo campione (ovvero, quando i dati sono molto deboli), suggerisce che dovremmo farci un’opinione di un certo tipo sul fenomeno in esame, l’indicazione è quella di prendere seriamente in considerazione il risultato del test (ovvero di modificare le nostre credenze) <em>quali che siano le evidenze precedenti</em> – le quali, in generale, potrebbero mostrare che il risultato del test non ha alcun senso. Un tale modo di pensare viene preso sul serio da coloro che, nella comunità scientifica, seguono l’approccio frequentista. Dato che in questo Capitolo abbiamo parlato di fumetti, concluderei dicendo che il significato della presente discussione è catturata nella maniera più chiara possibile in questa famosa <a href="https://xkcd.com/1132/">striscia</a>.</p>
<!-- Se devo sintetizzare la relazione tra distribuzione a priori e distribuzione a posteriori mi viene in mente il seguente "take-home message": se le evidenze fornite dai dati sono convincenti, le credenze iniziali (la distribuzione a priori) sono irrilevanti; se invece i dati forniscono evidenze deboli, la nostra credenza a posteriori (dopo avere visto i dati) è fortemente influenzata dalla nostra credenza iniziale (non è necessario cambiare idea se le nuove evidenze non ci convincono). Presentato in questo modo, il teorema di Bayes non è altro che la formalizzazione del buonsenso. -->


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography" style="display: none">
<div id="ref-Bechdel1986dykes" class="csl-entry" role="doc-biblioentry">
Bechdel, A. (1986). <em>Dykes to watch out for</em>. Firebrand Books.
</div>
<div id="ref-Johnson2022bayesrules" class="csl-entry" role="doc-biblioentry">
Johnson, A. A., Ott, M., &amp; Dogucu, M. (2022). <em><span class="nocase">Bayes Rules! An Introduction to Bayesian Modeling with R</span></em>. CRC Press.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./029_conjugate_families.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./036_posterior_sim.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Approssimazione della distribuzione a posteriori</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb11" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># L'influenza della distribuzione a priori {#sec-prior-influence}</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include = FALSE}</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>La notazione $p(\theta \mid y) \propto p(\theta) \ p(y \mid \theta)$ rende particolarmente chiaro che la distribuzione a posteriori è un "miscuglio" della distribuzione a priori e della verosimiglianza. Prima di preoccuparci di come calcolare la distribuzione a posteriori in casi diversi dalle famiglie coniugate, cerchiamo di capire meglio cosa significa "mescolare" la distribuzione a priori e la verosimiglianza. Considereremo qui un esempio discusso da @Johnson2022bayesrules.</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="fu">## Il test di Benchdel</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>Nel fumetto di Alison Bechdel *The Rule*, un personaggio afferma di guardare un film solo se soddisfa le seguenti tre regole <span class="co">[</span><span class="ot">@Bechdel1986dykes</span><span class="co">]</span>: almeno due caratteri nel film devono essere donne; queste due donne si parlano; parlano di qualcosa altro oltre a parlare di qualche uomo.</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>Questi criteri costituiscono il *test di Bechdel* per la rappresentazione delle donne nei film. @Johnson2022bayesrules pongono la seguente domanda "Quale percentuale dei film che avete visto supera il test di Bechdel?".</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>Sia $\pi \in <span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>$ una variabile casuale che indica la proporzione sconosciuta di film che superano il test di Bechdel. Tre amiche --- la femminista, l'ignara e l'ottimista --- hanno opionioni diverse su $\pi$. Riflettendo sui film che ha visto, la femminista capisce che nella maggioranza dei film mancano personaggi femminili forti. L'ignara non ricorda bene i film che ha visto, quindi non sa quanti film superano il test di Bechdel. Infine, l'ottimista pensa che, in generale, le donne siano ben rappresentate all'interno dei film: secondo lei quasi tutti i film superano il test di Bechdel. Le tre amiche hanno dunque tre modelli a priori diversi di $\pi$.</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>Abbiamo visto in precedenza come sia possibile usare la distribuzione Beta per rappresentare le credenze a priori. Ponendo la gran parte della massa della probabilità a priori su valori $\pi &lt; 0.5$, la distribuzione a priori $\text{Beta}(5, 11)$ riflette il punto di vista femminista secondo il quale la maggioranza dei film non supera il test di Bechdel. Al contrario, la $\text{Beta}(14,1)$ pone la gran parte della massa della distribuzione a priori su valori $\pi$ prossimi a 1, e corrisponde quindi alle credenze a priori dell'amica ottimista. Infine, una $\text{Beta}(1 ,1)$ o $\mbox{Unif}(0, 1)$, assegna lo stesso livello di plausibilità a tutti i valori $\pi \in <span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>$, e corrisponde all'incertezza a priori dell'ignara.</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>Nell'esempio di @Johnson2022bayesrules, le tre amiche decidono di rivedere un campione di $n$ film e di registrare $y$, ovvero il numero di film che superano il test di Bechdel. Se $y$ corrisponde al numero di "successi" in un numero fisso di $n$ prove Bernoulliane i.i.d., allora la dipendenza di $y$ da $\pi$ viene specificata da un modello binomiale. Quindi, per ciascuna delle tre amiche è possibile scrivere un modello beta-binomiale</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{align}</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="in">Y \mid \pi &amp; \sim \mbox{Bin}(n, \pi)  \notag\\</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="in">\pi &amp; \sim \mbox{Beta}(\alpha, \beta) \notag</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="in">\end{align}</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>che utilizza diversi parametri $\alpha$ e $\beta$ per la distribuzione a priori e che conduce a tre diverse distribuzioni a posteriori per il parametro sconosciuto $\pi$:</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a><span class="in">\pi \mid (Y = y) \sim \mbox{Beta}(\alpha + y, \beta + n - y).</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>@Johnson2022bayesrules si chiedono come le credenze a priori delle tre amiche influenzano le credenze a posteriori a cui esse giungono dopo avere osservato i dati. Si chiedono inoltre in che modo la dimensione del campione moduli l'influenza della distribuzione a priori sulla distribuzione a posteriori.</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>Per rispondere a queste domande, @Johnson2022bayesrules consideriamo tre diversi scenari:</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>gli stessi dati osservati, ma distribuzioni a priori diverse;</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>dati diversi, ma la stessa distribuzione a priori;</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>dati diversi e distribuzioni a priori diverse.</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a><span class="fu">## Stessi dati, diverse distribuzioni a priori</span></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>Iniziamo con lo scenario che descrive il caso in cui abbiamo gli stessi dati ma diverse distribuzioni a priori. Supponiamo che le tre amiche decidano di guardare insieme 20 film selezionati a caso.</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(bechdel, <span class="at">package =</span> <span class="st">"bayesrules"</span>)</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">84735</span>)</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>bechdel_20 <span class="ot">&lt;-</span> bechdel <span class="sc">%&gt;%</span> </span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="dv">20</span>)</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>bechdel_20 <span class="sc">%&gt;%</span> </span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">3</span>)</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>\noindent Di questi 20 film, solo il 45% ($y$ = 9) passa il test di Bechdel.</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a>bechdel_20 <span class="sc">%&gt;%</span> </span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">tabyl</span>(binary) <span class="sc">%&gt;%</span> </span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">adorn_totals</span>(<span class="st">"row"</span>)</span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a>Esaminiamo le tre distribuzioni a posteriori. Per la femminista usiamo una distribuzione a priori $\text{Beta}(5, 11)$.</span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">5</span>, <span class="at">beta =</span> <span class="dv">11</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">summarize_beta_binomial</span>(</span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">5</span>, <span class="at">beta =</span> <span class="dv">11</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a>Per l'ottimista usiamo una distribuzione a priori $\text{Beta}(14, 1)$.</span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-90"><a href="#cb11-90" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-91"><a href="#cb11-91" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb11-92"><a href="#cb11-92" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb11-93"><a href="#cb11-93" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-94"><a href="#cb11-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-97"><a href="#cb11-97" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-98"><a href="#cb11-98" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">summarize_beta_binomial</span>(</span>
<span id="cb11-99"><a href="#cb11-99" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb11-100"><a href="#cb11-100" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-101"><a href="#cb11-101" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-102"><a href="#cb11-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-103"><a href="#cb11-103" aria-hidden="true" tabindex="-1"></a>Infine, per l'ignara usiamo una distribuzione a priori $\text{Beta}(1, 1)$.</span>
<span id="cb11-104"><a href="#cb11-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-107"><a href="#cb11-107" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-108"><a href="#cb11-108" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-109"><a href="#cb11-109" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb11-110"><a href="#cb11-110" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-111"><a href="#cb11-111" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-112"><a href="#cb11-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-115"><a href="#cb11-115" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb11-116"><a href="#cb11-116" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">summarize_beta_binomial</span>(</span>
<span id="cb11-117"><a href="#cb11-117" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb11-118"><a href="#cb11-118" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-119"><a href="#cb11-119" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-120"><a href="#cb11-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-121"><a href="#cb11-121" aria-hidden="true" tabindex="-1"></a>Per calcolare la distribuzione a posteriori, ho usato le funzioni del pacchetto <span class="in">`bayesrules`</span>. Ma per lo schema beta-binomiale è facile trovare i parametri della distribuzione a posteriori. Per esempio, nel caso dell'amica femminista, la distribuzione a posteriori è una Beta di parametri</span>
<span id="cb11-122"><a href="#cb11-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-123"><a href="#cb11-123" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-124"><a href="#cb11-124" aria-hidden="true" tabindex="-1"></a>\alpha_{post} = \alpha_{prior} + y = 5+9 = 14</span>
<span id="cb11-125"><a href="#cb11-125" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-126"><a href="#cb11-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-127"><a href="#cb11-127" aria-hidden="true" tabindex="-1"></a>e</span>
<span id="cb11-128"><a href="#cb11-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-129"><a href="#cb11-129" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-130"><a href="#cb11-130" aria-hidden="true" tabindex="-1"></a>\beta_{post} = \beta_{prior} + n - y = 11 + 20 - 9 = 22.</span>
<span id="cb11-131"><a href="#cb11-131" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-132"><a href="#cb11-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-133"><a href="#cb11-133" aria-hidden="true" tabindex="-1"></a>L'aggiornamento bayesiano indica che le tre amiche otterranno valori molto diversi per la media (o la moda) a posteriori del parametro $\pi$. Dunque, anche dopo avere visto 20 film, le tre amiche non si trovano d'accordo su quale sia la proporzione di film che passano il test di Bechdel.</span>
<span id="cb11-134"><a href="#cb11-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-135"><a href="#cb11-135" aria-hidden="true" tabindex="-1"></a>Questo non dovrebbe sorprenderci. L'amica ottimista aveva opinioni molto forti sul valore di $\pi$ e i *pochi* nuovi dati che le sono stati forniti non sono riusciti a convincerla a cambiare idea: pensa ancora che i valori $\pi &gt; 0.5$ siano i più credibili. Lo stesso si può dire, all'estremo opposto, dell'amica femminista: anche lei continua a pensare che i valori $\pi &lt; 0.5$ siano i più credibili. Infine, l'ignara non aveva nessuna opinione a priori su $\pi$ e, anche dopo avere visto 20 film, continua a pensare che il valore $\pi$ più credibile sia quello intermedio, nell'intorno di 0.5.</span>
<span id="cb11-136"><a href="#cb11-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-137"><a href="#cb11-137" aria-hidden="true" tabindex="-1"></a>In conclusione, quando i dati sono deboli (ovvero, quando il campione è piccolo), l'aggiornamento bayesiano altera solo in piccola misura le distribuzioni a priori.</span>
<span id="cb11-138"><a href="#cb11-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-139"><a href="#cb11-139" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dati diversi, stessa distribuzione a priori</span></span>
<span id="cb11-140"><a href="#cb11-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-141"><a href="#cb11-141" aria-hidden="true" tabindex="-1"></a>Supponiamo ora che l'amica ottimista abbia tre amiche, Maria, Anna e Sara, tutte ottimiste come lei. L'ottimista chiede a Maria, Anna e Sara di fare loro stesse l'esperimento descritto in precedenza. Maria guarda 13 film; di questi 6 passano il test di Bechdel. Anna guarda 63 film; di questi 29 passano il test di Bechdel. Sara guarda 99 film; di questi 46 passano il test di Bechdel.</span>
<span id="cb11-142"><a href="#cb11-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-143"><a href="#cb11-143" aria-hidden="true" tabindex="-1"></a>Supponiamo che Maria, Anna e Sara condividano la stessa credenza a priori su $\pi$: ovvero, Beta(14, 1). In tali circostanze e, alla luce dei dati osservati, cosa possiamo dire delle tre distribuzioni a posteriori?</span>
<span id="cb11-144"><a href="#cb11-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-145"><a href="#cb11-145" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-bechdel-2, fig.height = 2.5, out.width = "95%", fig.cap = "Aggiornamento bayesiano per le credenze di Maria (sinistra, 16 film), Anna (centro, 63 film) e Sara (destra, 99 film)."}</span></span>
<span id="cb11-146"><a href="#cb11-146" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-147"><a href="#cb11-147" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">6</span>, <span class="at">n =</span> <span class="dv">13</span></span>
<span id="cb11-148"><a href="#cb11-148" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span> </span>
<span id="cb11-149"><a href="#cb11-149" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-150"><a href="#cb11-150" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-151"><a href="#cb11-151" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">29</span>, <span class="at">n =</span> <span class="dv">63</span></span>
<span id="cb11-152"><a href="#cb11-152" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span> </span>
<span id="cb11-153"><a href="#cb11-153" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-154"><a href="#cb11-154" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-155"><a href="#cb11-155" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">46</span>, <span class="at">n =</span> <span class="dv">99</span></span>
<span id="cb11-156"><a href="#cb11-156" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-157"><a href="#cb11-157" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-158"><a href="#cb11-158" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">+</span> p2 <span class="sc">+</span> p3</span>
<span id="cb11-159"><a href="#cb11-159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-160"><a href="#cb11-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-161"><a href="#cb11-161" aria-hidden="true" tabindex="-1"></a>In conclusione, dalla @fig-bechdel-2 notiamo due cose. Primo, all'aumentare delle informazioni disponibili (ovvero, al crescere dell'ampiezza del campione), la distribuzione a posteriori si allontana sempre di più dalla distribuzione a priori e si avvicina sempre di più alla verosimiglianza. Secondo, all'aumentare dell'ampiezza del campione la varianza della distribuzione a posteriori diminuisce sempre di più --- ovvero, diminuisce l'incertezza su quelli che sono i valori $\pi$ più credibili.</span>
<span id="cb11-162"><a href="#cb11-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-163"><a href="#cb11-163" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dati diversi, diverse distribuzioni a priori</span></span>
<span id="cb11-164"><a href="#cb11-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-165"><a href="#cb11-165" aria-hidden="true" tabindex="-1"></a>La @fig-bechdel-3 illustra le distribuzioni a posteriori che si ottengono incrociando tre diversi set di dati ($y$ = 6, $n$ = 13;, $y$ = 29, $n$ = 63; $y$ = 66, $n$ = 99) con tre diverse distribuzioni a priori, $\mbox{Beta}(14, 1)$, $\mbox{Beta}(5, 11)$ e $\mbox{Beta}(1, 1)$.</span>
<span id="cb11-166"><a href="#cb11-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-167"><a href="#cb11-167" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-bechdel-3, fig.height = 6, out.width = "95%", fig.cap = "Sulle colonne (a partire da sinistra) i dati utilizzati sono, rispettivamente, (y = 6, n = 13), (y = 29, n = 63) e (y = 66, n = 99). Sulle righe (a partire dall'alto), le distribuzioni a priori usate sono: Beta(14, 1), Beta(5, 11) e Beta(1, 1)."}</span></span>
<span id="cb11-168"><a href="#cb11-168" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-169"><a href="#cb11-169" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">6</span>, <span class="at">n =</span> <span class="dv">13</span></span>
<span id="cb11-170"><a href="#cb11-170" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-171"><a href="#cb11-171" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-172"><a href="#cb11-172" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-173"><a href="#cb11-173" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">29</span>, <span class="at">n =</span> <span class="dv">63</span></span>
<span id="cb11-174"><a href="#cb11-174" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-175"><a href="#cb11-175" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-176"><a href="#cb11-176" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-177"><a href="#cb11-177" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">46</span>, <span class="at">n =</span> <span class="dv">99</span></span>
<span id="cb11-178"><a href="#cb11-178" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-179"><a href="#cb11-179" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-180"><a href="#cb11-180" aria-hidden="true" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-181"><a href="#cb11-181" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">5</span>, <span class="at">beta =</span> <span class="dv">11</span>, <span class="at">y =</span> <span class="dv">6</span>, <span class="at">n =</span> <span class="dv">13</span></span>
<span id="cb11-182"><a href="#cb11-182" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-183"><a href="#cb11-183" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-184"><a href="#cb11-184" aria-hidden="true" tabindex="-1"></a>p5 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-185"><a href="#cb11-185" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">5</span>, <span class="at">beta =</span> <span class="dv">11</span>, <span class="at">y =</span> <span class="dv">29</span>, <span class="at">n =</span> <span class="dv">63</span></span>
<span id="cb11-186"><a href="#cb11-186" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-187"><a href="#cb11-187" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-188"><a href="#cb11-188" aria-hidden="true" tabindex="-1"></a>p6 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-189"><a href="#cb11-189" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">5</span>, <span class="at">beta =</span> <span class="dv">11</span>, <span class="at">y =</span> <span class="dv">46</span>, <span class="at">n =</span> <span class="dv">99</span></span>
<span id="cb11-190"><a href="#cb11-190" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-191"><a href="#cb11-191" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-192"><a href="#cb11-192" aria-hidden="true" tabindex="-1"></a>p7 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-193"><a href="#cb11-193" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">6</span>, <span class="at">n =</span> <span class="dv">13</span></span>
<span id="cb11-194"><a href="#cb11-194" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-195"><a href="#cb11-195" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-196"><a href="#cb11-196" aria-hidden="true" tabindex="-1"></a>p8 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-197"><a href="#cb11-197" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">29</span>, <span class="at">n =</span> <span class="dv">63</span></span>
<span id="cb11-198"><a href="#cb11-198" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-199"><a href="#cb11-199" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-200"><a href="#cb11-200" aria-hidden="true" tabindex="-1"></a>p9 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb11-201"><a href="#cb11-201" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">46</span>, <span class="at">n =</span> <span class="dv">99</span></span>
<span id="cb11-202"><a href="#cb11-202" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-203"><a href="#cb11-203" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>) </span>
<span id="cb11-204"><a href="#cb11-204" aria-hidden="true" tabindex="-1"></a>(p1 <span class="sc">+</span> p2 <span class="sc">+</span> p3) <span class="sc">/</span> (p4 <span class="sc">+</span> p5 <span class="sc">+</span> p6) <span class="sc">/</span> (p7 <span class="sc">+</span> p8 <span class="sc">+</span> p9)</span>
<span id="cb11-205"><a href="#cb11-205" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb11-206"><a href="#cb11-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-207"><a href="#cb11-207" aria-hidden="true" tabindex="-1"></a>In conclusione, la @fig-bechdel-3 ci consente di concludere quanto segue: se il campione è grande, una distribuzione a priori debolmente informativa ha uno scarso effetto sulla distribuzione a posteriori; se il campione è piccolo, invece, anche una distribuzione a priori debolmente informativa ha un grande effetto sulla distribuzione a posteriori.</span>
<span id="cb11-208"><a href="#cb11-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-209"><a href="#cb11-209" aria-hidden="true" tabindex="-1"></a><span class="fu">## Collegare le intuizioni alla teoria</span></span>
<span id="cb11-210"><a href="#cb11-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-211"><a href="#cb11-211" aria-hidden="true" tabindex="-1"></a>Il compromesso che abbiamo osservato nell'esempio precedente, ovvero l'equilibrio che si ottiene tra la distribuzione a priori e le evidenze fornite dai dati, è molto vicino alle nostre intuizioni. Ma è anche il frutto di una necessità matematica. È infatti possibile riscrivere l'@eq-ev-post-beta-bin-1 nel modo seguente</span>
<span id="cb11-212"><a href="#cb11-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-213"><a href="#cb11-213" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb11-214"><a href="#cb11-214" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb11-215"><a href="#cb11-215" aria-hidden="true" tabindex="-1"></a>\mathbb{E}_{\text{post}} &amp;<span class="co">[</span><span class="ot">\text{Beta}(\alpha + y, \beta + n - y)</span><span class="co">]</span> = \frac{\alpha + y}{\alpha + \beta +n}\notag<span class="sc">\\</span> </span>
<span id="cb11-216"><a href="#cb11-216" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{a+b}{a+b+n} \cdot \frac{a}{a+b} + \frac{n}{a+b+n} \cdot \frac{y}{n}.</span>
<span id="cb11-217"><a href="#cb11-217" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb11-218"><a href="#cb11-218" aria-hidden="true" tabindex="-1"></a>$$ {#eq-ev-post-beta-bin}</span>
<span id="cb11-219"><a href="#cb11-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-220"><a href="#cb11-220" aria-hidden="true" tabindex="-1"></a>L'@eq-ev-post-beta-bin indica che il valore atteso a posteriori è una media pesata fra il valore atteso a priori $\left( \frac{\alpha}{\alpha+\beta}\right)$ e la proporzione osservata di successi $\left(\frac{y}{n}\right)$. I pesi sono $\left( \frac{\alpha+\beta}{\alpha+\beta+n}\right)$ e $\left( \frac{n}{\alpha+\beta+n}\right)$. Quindi, quando $n$ è grande rispetto ad $\alpha + \beta$, contano molto i dati osservati e contano poco le credenze a priori. Viceversa, quando $n$ è piccolo rispetto a $\alpha + \beta$, i dati contano poco rispetto alla credenza a priori.</span>
<span id="cb11-221"><a href="#cb11-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-222"><a href="#cb11-222" aria-hidden="true" tabindex="-1"></a>Queste osservazioni ci fanno capire come scegliere i parametri $\alpha$ e $\beta$: se vogliamo assumere una totale ignoranza rispetto al fenomeno in esame, la scelta coerente è $\alpha = \beta = 1$ (ogni valore di $\theta$ è ugualmente credibile); se invece abbiamo delle forti credenze a priori, allora possiamo scegliere $\alpha$ così che sia uguale al valore atteso a priori, mentre $\alpha + \beta$ esprime l'importanza che diamo all'informazione a priori: maggiore è il valore di $\alpha + \beta$, tanti più dati serviranno per allontanare la distribuzione a posteriori dalla distribuzione a priori. Infine, se $n$ è grande, la distribuzione a posteriori avrà una scarsa influenza sulla distribuzione a priori, a meno di scelte estreme.</span>
<span id="cb11-223"><a href="#cb11-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-224"><a href="#cb11-224" aria-hidden="true" tabindex="-1"></a><span class="fu">## Commenti e considerazioni finali {.unnumbered}</span></span>
<span id="cb11-225"><a href="#cb11-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-226"><a href="#cb11-226" aria-hidden="true" tabindex="-1"></a>La conclusione che possiamo trarre dall'esempio discusso da @Johnson2022bayesrules è molto chiara: l'aggiornamento bayesiano può essere paragonato ai processi di ragionamento del senso comune. Quando le nuove evidenze (i dati) sono deboli, non c'è ragione di cambiare idea (le nostre credenze "a posteriori" sono molto simili a ciò che pensavamo prima di avere osservato i dati). Quando le nuove evidenze sono irrefutabili, invece, è necessario modificare le nostre credenze sulla base di ciò che ci dicono i dati, quali che siano le nostre credenze pregresse --- non farlo significherebbe vivere in un mondo di fantasia e avere scarse possibilità di sopravvivere nel mondo empirico. L'aggiornamento bayesiano, dunque, non fa altro che esprimere in maniera quantitativa e precisa ciò che ci dicono le nostre intuizioni.</span>
<span id="cb11-227"><a href="#cb11-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-228"><a href="#cb11-228" aria-hidden="true" tabindex="-1"></a>Alla luce di quanto detto sopra, è sorprendente che l'approccio frequentista neghi questa logica. I test frequentisti non tengono conto delle conoscenze pregresse. Dunque, se un test frequentista, calcolato su un piccolo campione (ovvero, quando i dati sono molto deboli), suggerisce che dovremmo farci un'opinione di un certo tipo sul fenomeno in esame, l'indicazione è quella di prendere seriamente in considerazione il risultato del test (ovvero di modificare le nostre credenze) *quali che siano le evidenze precedenti* -- le quali, in generale, potrebbero mostrare che il risultato del test non ha alcun senso. Un tale modo di pensare viene preso sul serio da coloro che, nella comunità scientifica, seguono l'approccio frequentista. Dato che in questo Capitolo abbiamo parlato di fumetti, concluderei dicendo che il significato della presente discussione è catturata nella maniera più chiara possibile in questa famosa <span class="co">[</span><span class="ot">striscia</span><span class="co">](https://xkcd.com/1132/)</span>.</span>
<span id="cb11-229"><a href="#cb11-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-230"><a href="#cb11-230" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Se devo sintetizzare la relazione tra distribuzione a priori e distribuzione a posteriori mi viene in mente il seguente "take-home message": se le evidenze fornite dai dati sono convincenti, le credenze iniziali (la distribuzione a priori) sono irrilevanti; se invece i dati forniscono evidenze deboli, la nostra credenza a posteriori (dopo avere visto i dati) è fortemente influenzata dalla nostra credenza iniziale (non è necessario cambiare idea se le nuove evidenze non ci convincono). Presentato in questo modo, il teorema di Bayes non è altro che la formalizzazione del buonsenso. --&gt;</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>