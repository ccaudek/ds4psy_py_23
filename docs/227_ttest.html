<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Data Science per psicologi - 42&nbsp; Inferenza sulle medie</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./228_limiti_stat_frequentista.html" rel="next">
<link href="./226_test_ipotesi.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza sulle medie</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/data_science/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Benvenuti</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">Prefazione</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./basics.html" class="sidebar-item-text sidebar-link">Parte 1: Nozioni di base</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_key_notions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Concetti chiave</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_measurement.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_freq_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_loc_scale.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_penguins.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Manipolazione e visualizzazione dei dati in <span class="math inline">\(\mathsf{R}\)</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./prob.html" class="sidebar-item-text sidebar-link">Parte 2: Il calcolo delle probabilità</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_prob_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">La logica dell’incerto</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_conditional_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Probabilità condizionata: significato, teoremi, eventi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_bayes_theorem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./018_expval_var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Indici di posizione, di varianza e di associazione di variabili casuali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./019_joint_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./020_density_func.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La densità di probabilità</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./distr.html" class="sidebar-item-text sidebar-link">Parte 3: Distribuzioni di v.c. discrete e continue</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./022_discr_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./023_cont_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./024_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">La funzione di verosimiglianza</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./bayes_inference.html" class="sidebar-item-text sidebar-link">Parte 4: Inferenza bayesiana</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./025_intro_bayes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Credibilità, modelli e parametri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./026_subj_prop.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./029_conjugate_families.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./030_balance_prior_post.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./036_posterior_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Approssimazione della distribuzione a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./040_beta_binomial_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Il modello beta-binomiale in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./041_mcmc_diagnostics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./045_summarize_posterior.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./046_bayesian_prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./050_normal_normal_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./regression.html" class="sidebar-item-text sidebar-link">Parte 5: Regressione lineare</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./051_reglin1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./052_reglin2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Regressione lineare bivariata</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./053_reglin3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Modello di regressione in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./054_reglin4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Inferenza sul modello lineare</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./055_reglin5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./056_pred_check.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Predictive checks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./060_anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Confronto tra le medie di tre o più gruppi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./070_mod_hier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modello gerarchico</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./071_mod_hier_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Modello gerarchico: simulazioni</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./entropy.html" class="sidebar-item-text sidebar-link">Parte 6: Entropia</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./090_entropy.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Entropia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./091_kl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./092_info_criterion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Criterio di informazione e convalida incrociata</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./frequentist_inference.html" class="sidebar-item-text sidebar-link">Parte 7: Inferenza frequentista</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./220_intro_frequentist.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Legge dei grandi numeri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./221_conf_interv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Intervallo fiduciale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./225_distr_camp_mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Distribuzione campionaria</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./226_test_ipotesi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Significatività statistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./227_ttest.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza sulle medie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./228_limiti_stat_frequentista.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./999_refs.html" class="sidebar-item-text sidebar-link">Riferimenti bibliografici</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">Appendici</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a01_math_symbols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a02_number_sets.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a03_set_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Insiemi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a04_summation_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Simbolo di somma (sommatorie)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a05_calculus_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a10_markov_chains.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Le catene di Markov</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a15_stan_lang.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Programmare in Stan</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul>
<li>
<a href="#modello-normale-varianza-nota" id="toc-modello-normale-varianza-nota" class="nav-link active" data-scroll-target="#modello-normale-varianza-nota"><span class="toc-section-number">42.1</span>  Modello Normale: varianza nota</a>
  <ul class="collapse">
<li><a href="#un-test-bilaterale" id="toc-un-test-bilaterale" class="nav-link" data-scroll-target="#un-test-bilaterale"><span class="toc-section-number">42.1.1</span>  Un test bilaterale</a></li>
  <li><a href="#la-statistica-test" id="toc-la-statistica-test" class="nav-link" data-scroll-target="#la-statistica-test"><span class="toc-section-number">42.1.2</span>  La statistica test</a></li>
  <li><a href="#la-distribuzione-campionaria-della-statistica-test" id="toc-la-distribuzione-campionaria-della-statistica-test" class="nav-link" data-scroll-target="#la-distribuzione-campionaria-della-statistica-test"><span class="toc-section-number">42.1.3</span>  La distribuzione campionaria della statistica test</a></li>
  <li><a href="#la-decisione" id="toc-la-decisione" class="nav-link" data-scroll-target="#la-decisione"><span class="toc-section-number">42.1.4</span>  La decisione</a></li>
  <li><a href="#la-statistica-test-z" id="toc-la-statistica-test-z" class="nav-link" data-scroll-target="#la-statistica-test-z"><span class="toc-section-number">42.1.5</span>  La statistica test Z</a></li>
  <li><a href="#i-valori-critici" id="toc-i-valori-critici" class="nav-link" data-scroll-target="#i-valori-critici"><span class="toc-section-number">42.1.6</span>  I valori critici</a></li>
  <li><a href="#il-valore-p" id="toc-il-valore-p" class="nav-link" data-scroll-target="#il-valore-p"><span class="toc-section-number">42.1.7</span>  Il valore-p</a></li>
  <li><a href="#il-test-unilaterale" id="toc-il-test-unilaterale" class="nav-link" data-scroll-target="#il-test-unilaterale"><span class="toc-section-number">42.1.8</span>  Il test unilaterale</a></li>
  </ul>
</li>
  <li>
<a href="#test-direzionali-e-non-direzionali" id="toc-test-direzionali-e-non-direzionali" class="nav-link" data-scroll-target="#test-direzionali-e-non-direzionali"><span class="toc-section-number">42.2</span>  Test direzionali e non direzionali</a>
  <ul class="collapse">
<li><a href="#test-bidirezionale" id="toc-test-bidirezionale" class="nav-link" data-scroll-target="#test-bidirezionale"><span class="toc-section-number">42.2.1</span>  Test bidirezionale</a></li>
  <li><a href="#test-unidirezionale-superiore" id="toc-test-unidirezionale-superiore" class="nav-link" data-scroll-target="#test-unidirezionale-superiore"><span class="toc-section-number">42.2.2</span>  Test unidirezionale superiore</a></li>
  <li><a href="#test-unidirezionale-inferiore" id="toc-test-unidirezionale-inferiore" class="nav-link" data-scroll-target="#test-unidirezionale-inferiore"><span class="toc-section-number">42.2.3</span>  Test unidirezionale inferiore</a></li>
  <li><a href="#eseguire-il-test-z-con-r" id="toc-eseguire-il-test-z-con-r" class="nav-link" data-scroll-target="#eseguire-il-test-z-con-r"><span class="toc-section-number">42.2.4</span>  Eseguire il test Z con R</a></li>
  <li><a href="#assunzioni-del-test-z" id="toc-assunzioni-del-test-z" class="nav-link" data-scroll-target="#assunzioni-del-test-z"><span class="toc-section-number">42.2.5</span>  Assunzioni del test Z</a></li>
  </ul>
</li>
  <li>
<a href="#modello-normale-varianza-sconosciuta" id="toc-modello-normale-varianza-sconosciuta" class="nav-link" data-scroll-target="#modello-normale-varianza-sconosciuta"><span class="toc-section-number">42.3</span>  Modello Normale: varianza sconosciuta</a>
  <ul class="collapse">
<li><a href="#effetto-stroop" id="toc-effetto-stroop" class="nav-link" data-scroll-target="#effetto-stroop"><span class="toc-section-number">42.3.1</span>  Effetto Stroop</a></li>
  <li><a href="#test-t-di-student-con-r" id="toc-test-t-di-student-con-r" class="nav-link" data-scroll-target="#test-t-di-student-con-r"><span class="toc-section-number">42.3.2</span>  Test T di Student con R</a></li>
  </ul>
</li>
  <li>
<a href="#test-unidirezionale" id="toc-test-unidirezionale" class="nav-link" data-scroll-target="#test-unidirezionale"><span class="toc-section-number">42.4</span>  Test unidirezionale</a>
  <ul class="collapse">
<li><a href="#assunzioni" id="toc-assunzioni" class="nav-link" data-scroll-target="#assunzioni"><span class="toc-section-number">42.4.1</span>  Assunzioni</a></li>
  <li><a href="#popolazione-non-normale" id="toc-popolazione-non-normale" class="nav-link" data-scroll-target="#popolazione-non-normale"><span class="toc-section-number">42.4.2</span>  Popolazione non Normale</a></li>
  </ul>
</li>
  <li>
<a href="#due-gruppi-indipendenti" id="toc-due-gruppi-indipendenti" class="nav-link" data-scroll-target="#due-gruppi-indipendenti"><span class="toc-section-number">42.5</span>  Due gruppi indipendenti</a>
  <ul class="collapse">
<li><a href="#test-bidirezionale-1" id="toc-test-bidirezionale-1" class="nav-link" data-scroll-target="#test-bidirezionale-1"><span class="toc-section-number">42.5.1</span>  Test bidirezionale</a></li>
  <li><a href="#la-durata-della-gravidanza" id="toc-la-durata-della-gravidanza" class="nav-link" data-scroll-target="#la-durata-della-gravidanza"><span class="toc-section-number">42.5.2</span>  La durata della gravidanza</a></li>
  <li><a href="#test-unidirezionale-1" id="toc-test-unidirezionale-1" class="nav-link" data-scroll-target="#test-unidirezionale-1"><span class="toc-section-number">42.5.3</span>  Test unidirezionale</a></li>
  <li><a href="#assunzioni-1" id="toc-assunzioni-1" class="nav-link" data-scroll-target="#assunzioni-1"><span class="toc-section-number">42.5.4</span>  Assunzioni</a></li>
  <li><a href="#test-di-welch" id="toc-test-di-welch" class="nav-link" data-scroll-target="#test-di-welch"><span class="toc-section-number">42.5.5</span>  Test di Welch</a></li>
  <li><a href="#assunzioni-del-test-di-welch" id="toc-assunzioni-del-test-di-welch" class="nav-link" data-scroll-target="#assunzioni-del-test-di-welch"><span class="toc-section-number">42.5.6</span>  Assunzioni del test di Welch</a></li>
  </ul>
</li>
  <li>
<a href="#test-t-per-dati-appaiati" id="toc-test-t-per-dati-appaiati" class="nav-link" data-scroll-target="#test-t-per-dati-appaiati"><span class="toc-section-number">42.6</span>  Test T per dati appaiati</a>
  <ul class="collapse">
<li><a href="#proporzione-di-maschi-e-femmine" id="toc-proporzione-di-maschi-e-femmine" class="nav-link" data-scroll-target="#proporzione-di-maschi-e-femmine"><span class="toc-section-number">42.6.1</span>  Proporzione di maschi e femmine</a></li>
  </ul>
</li>
  <li><a href="#commenti-e-considerazioni-finali" id="toc-commenti-e-considerazioni-finali" class="nav-link" data-scroll-target="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-mean-comp" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza sulle medie</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Codice</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><p>Molto spesso in psicologia ci troviamo in una situazione in cui la variabile dipendente è a livello di scala ad intervalli o superiore e ciò che ci interessa è stabilire se il valore medio della variabile dipendente sia più grande in un gruppo o in un altro. Ad esempio, uno psicologo potrebbe voler sapere se i livelli di ansia sono più alti tra i genitori o tra i non genitori, o se la capacità della memoria di lavoro si riduce quando si ascolta musica, rispetto alla condizione in cui non si ascolta musica. In queste situazioni, la variabile dipendente è continua a livello di scala ad intervalli o a rapporti e il nostro predittore è una variabile binaria. In altre parole, ciò che vogliamo fare in situazioni di questo tipo è confrontare le medie dei due gruppi.</p>
<p>La risposta tradizionale al problema del confronto tra due medie è quella di usare il test statistico che va sotto il nome di <span class="math inline">\(t\)</span> di Student, di cui esistono diverse varianti a seconda del tipo di domanda a cui si vuole rispondere. In questo capitolo presenteremo le diverse varianti del test <span class="math inline">\(t\)</span> di Student: il test <span class="math inline">\(t\)</span> a campione unico, il test <span class="math inline">\(t\)</span> per campioni indipendenti e il test <span class="math inline">\(t\)</span> per il confronto tra le medie di due campioni appaiati.</p>
<section id="modello-normale-varianza-nota" class="level2" data-number="42.1"><h2 data-number="42.1" class="anchored" data-anchor-id="modello-normale-varianza-nota">
<span class="header-section-number">42.1</span> Modello Normale: varianza nota</h2>
<p>In questa sezione inizieremo ad esaminare il test <span class="math inline">\(z\)</span>, il quale ci fornisce una versione semplificata del test <span class="math inline">\(t\)</span> di Student, che probabilmente è in assoluto il test statistico più usato (più di una volta a sproposito) dall’approccio frequentista. Lo scopo di questa discussione è quello di presentare la logica che sta alla base della procedura di test di ipotesi frequentista. Il test <span class="math inline">\(z\)</span> chiarisce questa logica esaminando il caso più semplice – un caso che, per motivi che saranno chiariti in seguito, non trova molte applicazioni pratiche. Lo presentiamo qui perché rende trasparente la motivazione frequentista della procedura di test di ipotesi. Gli altri test frequentisti, quelli che si usano nelle applicazioni concrete, sono semplicemente degli sviluppi dell’idea sulla quale si basa il test <span class="math inline">\(z\)</span>. Per cui, se si capisce il test <span class="math inline">\(z\)</span>, si capiscono tutti i test frequentisti.</p>
<p>Il test <span class="math inline">\(z\)</span> applica la procedura di test di ipotesi statistiche che è stata presentata nel capitolo precedente e si pone il problema di verificare un’ipotesi a proposito della media della popolazione utilizzando la media campionaria quale statistica test. In precedenza abbiamo discusso un teorema della teoria della probabilità il quale afferma che la media <span class="math inline">\(\bar{X}_n\)</span> di <span class="math inline">\(n\)</span> variabili aleatorie i.i.d., ciascuna distribuita come <span class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span>, segue una distribuzione normale con parametri <span class="math inline">\(\mu_{\bar{X}_n} = \mu\)</span> e <span class="math inline">\(\sigma^2_{\,\bar{X}_n} = \sigma^2 / n\)</span>. Questo significa che, conoscendo i parametri (media e deviazione standard) della popolazione di origine, è possibile specificare completamente la distribuzione campionaria di <span class="math inline">\(\bar{X}_n\)</span>.</p>
<p>Ovviamente il valore dei parametri è ignoto, ma è qui che interviene la procedura di test di ipotesi. In base all’approccio NHST, la distribuzione campionaria della statistica test viene costruita <em>assumendo come vera</em> l’ipotesi nulla. Il test <span class="math inline">\(z\)</span> – e lo stesso approccio viene seguito per tutti gli altri test di stampo frequentista – determina la distribuzione campionaria della statistica test (per esempio, la media del campione quale stimatore della media della popolazione) ipotizzando che il campione osservato provenga da una popolazione in cui l’ipotesi nulla è vera. La domanda di come determinare i valori dei parametri incogniti della popolazione trova quindi una facile risposta: il valore di tali parametri è fornito da <span class="math inline">\(H_0\)</span>!</p>
<section id="un-test-bilaterale" class="level3" data-number="42.1.1"><h3 data-number="42.1.1" class="anchored" data-anchor-id="un-test-bilaterale">
<span class="header-section-number">42.1.1</span> Un test bilaterale</h3>
<p>Per vedere come come si esegue il test <span class="math inline">\(z\)</span>, consideriamo il seguente esempio. I valori antropometrici medi della popolazione italiana adulta sono stati descritti, per esempio, da un’indagine nazionale condotta da Briziarelli et al.&nbsp;(1994). Ci concentriamo qui sull’altezza media delle donne adulte, la quale risulta essere pari a 162.5 cm tra 18 e 24 anni, con una deviazione standard di 12 cm. Sappiamo anche che la variabile “altezza” segue la distribuzione normale. Per qualche ragione, sospettiamo che, a Firenze, l’altezza media sia diversa da quella a livello nazionale e, per gli scopi di questo esempio, crediamo che possa essere o maggiore o minore di quella italiana.</p>
</section><section id="la-statistica-test" class="level3" data-number="42.1.2"><h3 data-number="42.1.2" class="anchored" data-anchor-id="la-statistica-test">
<span class="header-section-number">42.1.2</span> La statistica test</h3>
<p>Per sottoporre a verifica la nostra ipotesi della ricerca, misuriamo l’altezza di 20 donne fiorentine scelte a caso. Supponiamo di avere ottenuto i seguenti risultati:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">173.53</span>, <span class="fl">175.01</span>, <span class="fl">165.19</span>, <span class="fl">161.06</span>, <span class="fl">173.77</span>, <span class="fl">144.68</span>, <span class="fl">174.06</span>, <span class="fl">163.19</span>, <span class="fl">163.09</span>, <span class="fl">155.47</span>, <span class="fl">165.11</span>, <span class="fl">188.31</span>, <span class="fl">170.95</span>, <span class="fl">172.74</span>, <span class="fl">157.49</span>, <span class="fl">176.30</span>, <span class="fl">155.86</span>, <span class="fl">162.52</span>, <span class="fl">179.95</span>, <span class="fl">170.08</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcoliamo la media del campione:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 167.418</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La media campionaria è un po’ più grande della media della popolazione <span class="math inline">\(\mu = 162.5\)</span> e questo suggerisce che, in effetti, le donne fiorentine potrebbero avere un altezza superiore alla media nazionale. Tuttavia, un campione di ampiezza <span class="math inline">\(n = 20\)</span> è molto piccolo, per cui la diffrenza tra il risultato osservato e il valore atteso (<span class="math inline">\(\mu = 162.5\)</span>) potrebbe essere soltano il prodotto del caso. Per verificare l’ipotesi, che l’altezza delle donne fiorentine sia diversa da quella delle altre donne italiane decidiamo di usare <span class="math inline">\(\bar{X}_{n}\)</span> quale statistica test, ovvero quale stima di <span class="math inline">\(\mu\)</span>.</p>
<p>Per valutare la nostra ipotesi iniziamo ad elencare ciò che sappiamo. Chiamiamo <span class="math inline">\(X\)</span> l’altezza delle donne fiorentine. In primo luogo, sappiamo che la media campionaria è <span class="math inline">\(\bar{X}_{n} = 167.418\)</span>. Se siamo disposti ad assumere che la distribuzione dell’altezza delle donne fiorentine ha la stessa deviazione standard dell’altezza delle altre donne della popolazione italiana, allora possiamo dire che la deviazione standard dell’altezza delle donne fiorentine è <span class="math inline">\(\sigma = 12\)</span>. Inoltre, sappiamo che i valori dell’altezza delle donne fiorentine sono distribuiti in maniera normale dato che, in generale, i valori dell’altezza seguono la legge della distribuzione normale.</p>
<p>Ora elenchiamo ciò che non sappiamo, ma che vorremmo sapere. La nostra ipotesi riguarda il valore incognito <span class="math inline">\(\mu\)</span>, ovvero la media dell’altezza della popolazione delle donne fiorentine – infatti, abbiamo misurato l’altezza di 20 donne fiorentine, non di tutte le donne fiorentine! La nostra ipotesi è <span class="math inline">\(X \sim \mathcal{N}(\mu \neq 162.5, \sigma = 12)\)</span>, con <span class="math inline">\(\mu\)</span> sconosciuto. Dato che, nella procedura NHST, l’ipotesi del ricercatore definisce “l’ipotesi alternativa” <span class="math inline">\(H_1\)</span>, possiamo scrivere:</p>
<p><span class="math display">\[
H_1: X \sim \mathcal{N}(\mu \neq 162.5, \sigma = 12).
\]</span></p>
<p>Una volta definita l’ipotesi alternativa risulta specificata anche l’ipotesi nulla, in quanto essa è l’ipotesi opposta e complementare a <span class="math inline">\(H_1\)</span>. Dunque possiamo scrivere:</p>
<p><span class="math display">\[
H_0: X \sim \mathcal{N}(\mu = 162.5, \sigma = 12).
\]</span></p>
<p>Le ipotesi nulla e alternativa riguardano i parametri della popolazione. In questo particolare esempio, il paraemtro <span class="math inline">\(\mu\)</span> (la media dell’altezza delle donne fiorentine) è incognito ma <span class="math inline">\(\sigma\)</span> è noto (in quanto abbiamo assunto che l’altezza delle donne fiorentine e l’altezza delle donne italiane sono due Normali con la stessa deviazione standard ma con medie diverse). Per stimare <span class="math inline">\(\mu\)</span> dobbiamo usare una qualche statistica test, e la statistica ovvia a questo riguardo è semplicemente la media del campione <span class="math inline">\(\bar{X}\)</span>. Decidiamo dunque di usare <span class="math inline">\(\bar{X}\)</span> quale statistica test. Quello che dobbiamo ancora stabilire sono le caratteristiche della distribuzione campionaria di <span class="math inline">\(\bar{X}\)</span> nel caso di campioni di ampiezza <span class="math inline">\(n=20\)</span>.</p>
</section><section id="la-distribuzione-campionaria-della-statistica-test" class="level3" data-number="42.1.3"><h3 data-number="42.1.3" class="anchored" data-anchor-id="la-distribuzione-campionaria-della-statistica-test">
<span class="header-section-number">42.1.3</span> La distribuzione campionaria della statistica test</h3>
<p>In base all’approccio NHST, la distribuzione campionaria della statistica test viene determinata assumendo come vera l’ipotesi nulla. Nel caso del nostro esempio, l’ipotesi nulla afferma che <span class="math inline">\(X \sim \mathcal{N}(\mu = 162.5, \sigma = 12)\)</span>. Sotto <span class="math inline">\(H_0\)</span>, dunque, la distribuzione campionaria della media di campioni di ampiezza <span class="math inline">\(n=20\)</span> è:</p>
<p><span class="math display">\[
\bar{X} \sim \mathcal{N}\left(\mu_{\bar{X}} = \mu = 162.5, \sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{12}{\sqrt{20}}\right).
\]</span></p>
<p>Si noti che è l’ipotesi nulla a specificare la media <span class="math inline">\(\mu\)</span> e la deviazione standard <span class="math inline">\(\sigma\)</span> della popolazione da cui vengono estatti i campioni che formano la distribuzione campionaria di <span class="math inline">\(\bar{X}\)</span>. Per questa ragione diciamo che la distribuzione campionaria della statistica test, <span class="math inline">\(f(\bar{X} \mid H_0)\)</span>, è stata generata assumendo vera l’ipotesi nulla.</p>
</section><section id="la-decisione" class="level3" data-number="42.1.4"><h3 data-number="42.1.4" class="anchored" data-anchor-id="la-decisione">
<span class="header-section-number">42.1.4</span> La decisione</h3>
<p>Nel problema che stiamo discutendo l’ipotesi alternativa <span class="math inline">\(H_1\)</span> è bilaterale. Ovvero, possiamo rigettare <span class="math inline">\(H_0\)</span> se troviamo che l’altezza media delle donne fiorentine è molto diverso dal valore postulato da <span class="math inline">\(H_0\)</span>, ovvero <span class="math inline">\(\mu_{\bar{X}} = \mu = 162.5\)</span>. Rifiuteremo <span class="math inline">\(H_0\)</span> se la statistica test <span class="math inline">\(\bar{X}\)</span> si dimostra essere di molto maggiore dell’altezza ipotizzata da <span class="math inline">\(H_0\)</span>, oppure di molto minore dell’altezza ipotizzata da <span class="math inline">\(H_0\)</span>.</p>
<p>In altre parole, per valutare <span class="math inline">\(H_0\)</span> dobbiamo determinare se la statistica test cade o meno nella regione di rifiuto. È necessario dunque identificare la regione di rifiuto di <span class="math inline">\(H_0\)</span>. Per fare questo dobbiamo prima scegliere <span class="math inline">\(\alpha\)</span>. Seguendo la consuetudine usata in psicologia, poniamo <span class="math inline">\(\alpha = 0.05\)</span>. Dato che il test è bidirezinale, rigettiamo <span class="math inline">\(H_0\)</span> se la statistica test corrisponde ad un valore estremo che cade o nella coda di destra di <span class="math inline">\(f(\bar{X} \mid H_0)\)</span> <em>oppure</em> nella coda di sinistra di <span class="math inline">\(f(\bar{X} \mid H_0)\)</span>. La regione di rifiuto di <span class="math inline">\(H_0\)</span> sarà dunque divisa in due parti: metà sarà collocata nella coda di sinistra di <span class="math inline">\(f(\bar{X} \mid H_0)\)</span> e metà nella coda di destra di <span class="math inline">\(f(\bar{X} \mid H_0)\)</span>. Quali sono i valori critici che delimitano le due regioni di rifiuto di <span class="math inline">\(H_0\)</span>? Per trovarli, dobbiamo calcolare i quantili di ordine 0.025 e 0.975 della distribuzione normale di media 162.5 e deviazione standard <span class="math inline">\(\frac{12}{\sqrt{20}}\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">162.5</span>, <span class="fl">12</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 157.2409</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.975</span>, <span class="fl">162.5</span>, <span class="fl">12</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 167.7591</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Le due regioni di rifiuto di <span class="math inline">\(H_0\)</span> sono dunque <span class="math inline">\([-\infty, 157.24]\)</span> e <span class="math inline">\([167.76, +\infty]\)</span>, come indicato nella <a href="#fig-regrifiutoaltezzabil">Figura&nbsp;<span>42.1</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">55</span>, <span class="fl">145</span><span class="op">)</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">162.5</span>, sd <span class="op">=</span> <span class="fl">12</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">stat_function</span><span class="op">(</span></span>
<span>    fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">162.5</span>, sd <span class="op">=</span> <span class="fl">12</span><span class="op">)</span>,</span>
<span>    geom <span class="op">=</span> <span class="st">"area"</span>,</span>
<span>    fill <span class="op">=</span> <span class="st">"steelblue"</span>,</span>
<span>    xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">162.5</span>, <span class="fl">12</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">stat_function</span><span class="op">(</span></span>
<span>    fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">162.5</span>, sd <span class="op">=</span> <span class="fl">12</span><span class="op">)</span>,</span>
<span>    geom <span class="op">=</span> <span class="st">"area"</span>,</span>
<span>    fill <span class="op">=</span> <span class="st">"steelblue"</span>,</span>
<span>    xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.975</span>, <span class="fl">162.5</span>, <span class="fl">12</span><span class="op">)</span>, <span class="fl">200</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">162.5</span><span class="op">-</span><span class="fl">3</span><span class="op">*</span><span class="fl">12</span>, <span class="fl">162.5</span><span class="op">+</span><span class="fl">3</span><span class="op">*</span><span class="fl">12</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Altezza (cm)"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Densità"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-regrifiutoaltezzabil" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="227_ttest_files/figure-html/fig-regrifiutoaltezzabil-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;42.1: Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l’ipotesi nulla <span class="math inline">\(X \sim \mathcal{N}(\mu = 162.5, \sigma = 12)\)</span>. Le aree ombreggiate indicano le regioni di rifiuto di <span class="math inline">\(H_0\)</span> per un test bilaterale posto <span class="math inline">\(\alpha\)</span> = 0.05.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Il valore osservato della statistica test, ovvero <span class="math inline">\(\bar{X} = 167.418\)</span>, non cade nella regione di rifiuto di <span class="math inline">\(H_0\)</span>. Pertanto, sulla base delle informazioni disponibili, non possiamo rigettare <span class="math inline">\(H_0\)</span>. E questo conclude la descrizione della logica del test <span class="math inline">\(z\)</span>.</p>
</section><section id="la-statistica-test-z" class="level3" data-number="42.1.5"><h3 data-number="42.1.5" class="anchored" data-anchor-id="la-statistica-test-z">
<span class="header-section-number">42.1.5</span> La statistica test Z</h3>
<p>Solitamente, per giungere alla conclusione descritta sopra si procede in modo diverso, ovvero applicando una semplice formula. In tale formula non facciamo altro che standardizzare la media campionaria all’interno della distribuzione campionaria costruita assumendo come vera <span class="math inline">\(H_0\)</span>. In pratica, per eseguire tale standardizzazione sottraiamo dalla media campionaria la media della distribuzione ipotizzata da <span class="math inline">\(H_0\)</span> e dividiamo per la deviazione standard ipotizzata da <span class="math inline">\(H_0\)</span>:</p>
<span class="math display">\[\begin{equation}
Z = \frac{\bar{X}_n - \mu_{\bar{X}}}{\sigma_{\bar{X}}} = \frac{\bar{X}_n - \mu_{\bar{X}}}{\frac{\sigma}{\sqrt{n}}},
(\#eq:testz)
\end{equation}\]</span>
<p>ovvero</p>
<p><span class="math display">\[
Z = \frac{167.418 - 162.5}{\frac{12}{\sqrt{20}}} = 1.8328.
\]</span> Il valore che abbiamo ottenuto corrisponde alla cosiddetta statistica test <span class="math inline">\(Z\)</span>. Il test <span class="math inline">\(z\)</span> si chiama così proprio perché è basato sulla statistica test <span class="math inline">\(Z\)</span>, e ovviamente <span class="math inline">\(Z\)</span> ha questo nome perché è una variabile aleatoria normale standard di media 0 e varianza 1.</p>
</section><section id="i-valori-critici" class="level3" data-number="42.1.6"><h3 data-number="42.1.6" class="anchored" data-anchor-id="i-valori-critici">
<span class="header-section-number">42.1.6</span> I valori critici</h3>
<p>Quali sono i valori di una normale standard che lasciano in ciascuna delle due code il 2.5% dell’area sottesa alla funzione di densità <span class="math inline">\(f(\bar{X}_{20} \mid H_0)\)</span>? Usando R troviamo</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -1.959964</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.975</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.959964</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Risultano così specificate le due regioni di rifiuto <span class="math inline">\([-\infty, -1.96]\)</span> e <span class="math inline">\([1.96, +\infty]\)</span> illustrate nella <a href="#fig-regrifiutoaltezzabil2">Figura&nbsp;<span>42.2</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">stat_function</span><span class="op">(</span></span>
<span>    fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>    geom <span class="op">=</span> <span class="st">"area"</span>,</span>
<span>    fill <span class="op">=</span> <span class="st">"steelblue"</span>,</span>
<span>    xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">10</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">stat_function</span><span class="op">(</span></span>
<span>    fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>    geom <span class="op">=</span> <span class="st">"area"</span>,</span>
<span>    fill <span class="op">=</span> <span class="st">"steelblue"</span>,</span>
<span>    xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.975</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Altezza (in unità di deviazione standard)"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Densità"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-regrifiutoaltezzabil2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="227_ttest_files/figure-html/fig-regrifiutoaltezzabil2-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;42.2: Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l’ipotesi nulla <span class="math inline">\(X \sim \mathcal{N}(\mu = 0, \sigma = 1)\)</span>. Le aree ombreggiate indicano le regioni di rifiuto di <span class="math inline">\(H_0\)</span> per un test bilaterale posto <span class="math inline">\(\alpha\)</span> = 0.05.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Non è una sorpresa che, facendo i calcoli in questo secondo modo, giungiamo alla stessa conclusione che avevamo trovato in precedenza: la statistica test non cade nella regione di rifiuto di <span class="math inline">\(H_0\)</span> e dunque non possiamo rifiutare l’ipotesi che i dati campionari provengano dalla popolazione specificata da <span class="math inline">\(H_0\)</span>, ovvero <span class="math inline">\(\mathcal{N}(\mu = 162.5, \sigma = 12)\)</span>.</p>
</section><section id="il-valore-p" class="level3" data-number="42.1.7"><h3 data-number="42.1.7" class="anchored" data-anchor-id="il-valore-p">
<span class="header-section-number">42.1.7</span> Il valore-p</h3>
<p>Introduciamo ora un altro concetto centrale dell’inferenza frequentista: quello del valore-<span class="math inline">\(p\)</span>. Il valore-<span class="math inline">\(p\)</span> viene usato per il test dell’ipotesi nulla in base alla regola seguente: se il valore-<span class="math inline">\(p\)</span> è minore di <span class="math inline">\(\alpha\)</span>, allora rigettiamo <span class="math inline">\(H_0\)</span>. Ottenere un valore-<span class="math inline">\(p\)</span> minore di <span class="math inline">\(\alpha\)</span>, infatti, significa osservare una media campionaria molto distante dal valore ipotizzato dall’ipotesi nulla.</p>
<p>Nelle parole di Neyman,</p>
<blockquote class="blockquote">
<p>il valore-<span class="math inline">\(p\)</span> è la probabilità di osservare un valore della statistica test uguale o più estremo di quello osservato qualora sia vera <span class="math inline">\(H_0\)</span>.</p>
</blockquote>
<p>Detto in un altro modo: se il mondo avesse le caratteristiche specificate da <span class="math inline">\(H_0\)</span>, il valore-<span class="math inline">\(p\)</span> descriverebbe la probabilità di osservare un campione che una media uguale a quella del campione osservato, o una media ancora più lontana da quella specificata da <span class="math inline">\(H_0\)</span>. Si noti il carattere ipotetico di questa affermazione: “se il mondo avesse le caratteristiche specificate da <span class="math inline">\(H_0\)</span>”.</p>
<p>Per trovare il valore-<span class="math inline">\(p\)</span>, iniziamo a calcolare l’area sottesa alla funzione di densità <span class="math inline">\(f(\bar{X}_{20} \mid H_0)\)</span> nell’intervallo <span class="math inline">\([162.5, \infty]\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">1.8328</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.03341616</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Questo però non è il valore-<span class="math inline">\(p\)</span> per un test bidirezionale. Infatti, in un test bidirezionale noi rigettiamo <span class="math inline">\(H_0\)</span> sia quando troviamo valori estremi nella coda di destra di <span class="math inline">\(f(\bar{X} \mid H_0)\)</span> sia quando troviamo valori estremi nella coda di <em>sinistra</em> di <span class="math inline">\(f(\bar{X}_{20} \mid H_0)\)</span>. Dunque, dobbiamo calcolare il valore-<span class="math inline">\(p\)</span> utilizzando il <em>valore assoluto</em> della statistica test, ovvero sommando le aree sottese a <span class="math inline">\(f(\bar{X}_{20} \mid H_0)\)</span> negli intervalli <span class="math inline">\([-\infty, \mathcal{G}_n]\)</span> e <span class="math inline">\([\mathcal{G}_n, +\infty]\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">1.8328</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1.8328</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.06683232</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Dato che il valore-<span class="math inline">\(p\)</span> trovato nel test è maggiore di <span class="math inline">\(\alpha = 0.05\)</span>, non rigettiamo l’ipotesi nulla. Ovviamente, giungiamo alla stessa conclusione sia confrontando la statistica test <span class="math inline">\(\mathcal{G}_n\)</span> con il valore critico, sia confrontando il valore-<span class="math inline">\(p\)</span> con <span class="math inline">\(\alpha\)</span>.</p>
</section><section id="il-test-unilaterale" class="level3" data-number="42.1.8"><h3 data-number="42.1.8" class="anchored" data-anchor-id="il-test-unilaterale">
<span class="header-section-number">42.1.8</span> Il test unilaterale</h3>
<p>Proseguiamo la discussione considerando ora il caso di un test monodirezionale. Un tale test risulta appropriato quando l’ipotesi alternativa ha la forma</p>
<p><span class="math display">\[
H_1: X \sim \mathcal{N}(\mu &gt; 162.5, \sigma = 12),
\]</span></p>
<p>per cui, di conseguenza, <span class="math inline">\(H_0\)</span> è:</p>
<p><span class="math display">\[
H_0: X \sim \mathcal{N}(\mu \leq 162.5, \sigma = 12).
\]</span></p>
<p>Come specificata sopra, l’ipotesi alternativa corrisponde all’ipotesi della ricerca secondo la quale le donne fiorentine, in media, sono più alte delle donne italiane.</p>
<p>Anche nel caso di un test unilaterale, è necessario usare la statistica test <span class="math inline">\(Z\)</span> = 162.5. Ciò che è diverso rispetto al caso di un test bilaterale è dove viene collocata la regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span> di <span class="math inline">\(H_0\)</span>. Se l’ipotesi della ricerca è che le donne fiorentine, in media, sono più alte delle donne italiane, è chiaro che evidenze contrarie all’ipotesi nulla vengono fornite quando la media campionaria assume valori molto <em>superiori</em> al valore del parametro specificato da <span class="math inline">\(H_0\)</span>, la quale afferma che l’altezza media delle donne fiorentine è uguale a quella delle donne italiane, o addirittura inferiore. Nel caso del test unidirezionale specificato sopra, quindi, la regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span> sarà collocata sulla sola coda destra della densità <span class="math inline">\(f(\bar{X}_{n} \mid H_0)\)</span> – si veda la <a href="#fig-regrifiutoaltezzabil3">Figura&nbsp;<span>42.3</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">stat_function</span><span class="op">(</span></span>
<span>    fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>    geom <span class="op">=</span> <span class="st">"area"</span>,</span>
<span>    fill <span class="op">=</span> <span class="st">"steelblue"</span>,</span>
<span>    xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.95</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Altezza (in unità di deviazione standard)"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Densità"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-regrifiutoaltezzabil3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="227_ttest_files/figure-html/fig-regrifiutoaltezzabil3-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Figura&nbsp;42.3: Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l’ipotesi nulla <span class="math inline">\(X \sim \mathcal{N}(\mu = 0, \sigma = 1)\)</span>. L’area ombreggiata indica la regione di rifiuto di <span class="math inline">\(H_0\)</span> per un test unilaterale destro posto <span class="math inline">\(\alpha\)</span> = 0.05.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>In generale, in un test unidirezionale il valore-<span class="math inline">\(p\)</span> corrisponde all’area sottesa alla funzione di densità <span class="math inline">\(f(\mathcal{G}_{n} \mid H_0)\)</span> nell’intervallo <span class="math inline">\([\mathcal{G}_n, +\infty]\)</span>, se l’ipotesi nulla ha la forma <span class="math inline">\(H_0: \mu \leq \mu_0\)</span>, oppure nell’intervallo <span class="math inline">\([-\infty, \mathcal{G}_n]\)</span>, se l’ipotesi nulla ha la forma <span class="math inline">\(H_0: \mu \geq \mu_0\)</span>. A differenza del caso bidirezionale, dunque, tutta la regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span> è collocata su una sola coda della distribuzione campionaria della statistica test <span class="math inline">\(f(\bar{X}_{n} \mid H_0)\)</span>.</p>
<p>Nel caso dell’esempio che stiamo discutendo, <span class="math inline">\(Z = 1.8328\)</span> e, dunque, cade nella regione di rifiuto di <span class="math inline">\(H_0\)</span> per un test unilaterale superiore. Possiamo dunque rigettare <span class="math inline">\(H_0\)</span> e concludere che il campione esaminato fornisce evidenza che le donne fiorentine tendono ad essere più alte della media nazionale.</p>
<p>Ma perché possiamo rifiutare <span class="math inline">\(H_0\)</span> nel caso di un test unidirezionale ma non possiamo farlo quando usiamo un test bidirezionale? Perché il test di ipotesi risulta più conservativo quando il test è bidirezionale. Questo ha senso. L’ipotesi della ricerca è molto vaga: dice semplicemente che succederà qualcosa di diverso dal caso di non interesse, ma non sa dire cosa. Di conseguenza, l’ipotesi nulla può essere rigettata solo quando osserviamo un risultato campionario veramente estremo. D’altra parte, invece, bastano evidenze “più deboli” per rigettare <span class="math inline">\(H_0\)</span> quando sappiamo dove guardare, quando possiamo fare delle predizioni su quello che succederà. La procedura di test di ipotesi, quindi, ci incoraggia ad essere precisi, ad avere la capacità di fare delle predizioni direzionali, piuttosto di chiederci semplicemente se è possibile osservare qualcosa, qualunque cosa, di diverso dall’evento di non interesse specificato da <span class="math inline">\(H_0\)</span>.</p>
</section></section><section id="test-direzionali-e-non-direzionali" class="level2" data-number="42.2"><h2 data-number="42.2" class="anchored" data-anchor-id="test-direzionali-e-non-direzionali">
<span class="header-section-number">42.2</span> Test direzionali e non direzionali</h2>
<p>Riassumendo, un test d’ipotesi può essere bidirezionale, unidirezionale superiore e unidirezionale inferiore.</p>
<section id="test-bidirezionale" class="level3" data-number="42.2.1"><h3 data-number="42.2.1" class="anchored" data-anchor-id="test-bidirezionale">
<span class="header-section-number">42.2.1</span> Test bidirezionale</h3>
<p>Per un’ipotesi nulla <span class="math display">\[H_0: \mu = \mu_0\]</span> nel caso di un test bidirezionale la regione di non rifiuto <span class="math inline">\(\mathcal{A}\)</span> di <span class="math inline">\(H_0\)</span> è</p>
<p><span class="math display">\[
\mathcal{A}: \quad \mu_0 - \frac{\sigma}{\sqrt{n}}z_{1-\alpha/2} \leq \mu_n \leq \mu_0 + \frac{\sigma}{\sqrt{n}}z_{1-\alpha/2},
\]</span></p>
<p>dove <span class="math inline">\(\mu_n\)</span> è la realizzazione della statistica test, ovvero la media campionaria, <span class="math inline">\(n\)</span> è l’ampiezza del campione e <span class="math inline">\(z_{1-\alpha/2}\)</span> è il quantile di ordine <span class="math inline">\(1-\alpha/2\)</span> per la variabile standardizzata</p>
<p><span class="math display">\[
Z_n = \frac{\mu_n - \mu_0}{\sigma/\sqrt{n}}.\notag
\]</span></p>
</section><section id="test-unidirezionale-superiore" class="level3" data-number="42.2.2"><h3 data-number="42.2.2" class="anchored" data-anchor-id="test-unidirezionale-superiore">
<span class="header-section-number">42.2.2</span> Test unidirezionale superiore</h3>
<p>La regione di non rifiuto di <span class="math inline">\(H_0: \mu \leq \mu_0\)</span>, con <span class="math inline">\(H_1: \mu &gt; \mu_0\)</span>, è l’intervallo aperto a sinistra:</p>
<p><span class="math display">\[
\mathcal{A}: \quad -\infty &lt; \mu_n \leq \mu_0 + \frac{\sigma}{\sqrt{n}}z_{1-\alpha},
\]</span></p>
<p>dove <span class="math inline">\(z_{1-\alpha}\)</span> è il quantile di ordine <span class="math inline">\(1-\alpha\)</span> della normale standard.</p>
</section><section id="test-unidirezionale-inferiore" class="level3" data-number="42.2.3"><h3 data-number="42.2.3" class="anchored" data-anchor-id="test-unidirezionale-inferiore">
<span class="header-section-number">42.2.3</span> Test unidirezionale inferiore</h3>
<p>La regione di non rifiuto di <span class="math inline">\(H_0: \mu \geq \mu_0\)</span>, con <span class="math inline">\(H_1: \mu &lt; \mu_0\)</span>, è l’intervallo aperto a destra:</p>
<p><span class="math display">\[
\mathcal{A}: \quad \mu_0 - \frac{\sigma}{\sqrt{n}}z_{1-\alpha} \leq \mu_n &lt; +\infty,
\]</span> dove <span class="math inline">\(z_{1-\alpha}\)</span> è il quantile di ordine <span class="math inline">\(1-\alpha\)</span> della normale standard.</p>
</section><section id="eseguire-il-test-z-con-r" class="level3" data-number="42.2.4"><h3 data-number="42.2.4" class="anchored" data-anchor-id="eseguire-il-test-z-con-r">
<span class="header-section-number">42.2.4</span> Eseguire il test Z con R</h3>
<p>Come abbiamo detto in precedenza, nella pratica concreta dell’analisi dei dati il test <span class="math inline">\(Z\)</span> non viene quasi mai usato. Il suo uso è talmente raro che in R non c’è neppure una funzione che lo implementa. Vediamo comunque come svolgere i calcoli con R. Se i dati siano contenuti nel vettore <code>x</code>, non dobbiamo fare altro che calcolare il valore standardizzato della media campionaria assumendo come vera l’ipotesi nulla:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mu_0</span> <span class="op">&lt;-</span> <span class="fl">162.5</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">12</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="va">mu_0</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">sigma</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">z</span></span>
<span><span class="co">#&gt; [1] 1.83283</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Dato che il valore-<span class="math inline">\(p\)</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="va">z</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.0334139</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>è minore di <span class="math inline">\(\alpha = 0.05\)</span>, rifiutiamo <span class="math inline">\(H_0\)</span>. Riportiamo il risultato nel modo seguente.</p>
<blockquote class="blockquote">
<p>Avendo osservato una media campionaria pari a 167.418 cm in un campione casuale di ampiezza <span class="math inline">\(n=20\)</span>, assumendo che la deviazione standard della popolazione sia uguale a 12 cm, possiamo concludere che le donne fiorentine tendono ad avere un’altezza maggiore della media nazionale (<span class="math inline">\(z = 1.8328\)</span>, <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(p = 0.0334\)</span>, test unidirezionale).</p>
</blockquote>
</section><section id="assunzioni-del-test-z" class="level3" data-number="42.2.5"><h3 data-number="42.2.5" class="anchored" data-anchor-id="assunzioni-del-test-z">
<span class="header-section-number">42.2.5</span> Assunzioni del test Z</h3>
<p>Tutti i test statistici fanno delle assunzioni a proposito delle caratteristiche della popolazione da cui sono stati tratti i dati. Alcuni test fanno delle assunzioni ragionevoli, mentre altri test no. Il test <span class="math inline">\(z\)</span> che abbiamo appena descritto è basato sulle seguenti ipotesi:</p>
<ol type="1">
<li><p><em>Normalità</em>. Il test <span class="math inline">\(z\)</span> presuppone che la vera distribuzione della popolazione sia normale. Tale ipotesi è spesso soddisfatta e può essere verificata.</p></li>
<li><p><em>Indipendenza</em>. La seconda ipotesi del test è che le osservazioni campionarie non sono correlate tra loro, né associate tra loro in qualunque modo. Tale assunzione è difficile da valutare con metodi statistici: deve invece essere garantita dal disegno sperimentale che viene utilizzato per raccogliere i dati. Un caso ovvio nel quale tale assunzione viene falsificata è quando i dati riguardano osservazioni compiute sugli stessi soggetti in condizioni diverse o in tempi diversi. È chiaro in questo caso che ci sarà una correlazione tra le osservazioni. Per esempio, se misuriamo i tempi di reazione, è ovvio che, se un soggetto tende ad essere più veloce della media nella condizione <span class="math inline">\(A\)</span>, tenderà anche ad essere più veloce della media nella condizione <span class="math inline">\(B\)</span>. Lo stesso si può dire per un soggetto che tende ad essere più lento della media. Pertanto, sapere se un soggetto è più veloce della media nella condizione <span class="math inline">\(A\)</span> ci consente di fare delle predizioni sul suo comportamento nella condizione <span class="math inline">\(B\)</span> – ovvero, i dati sono correlati e l’assunzione di indipendenza viene violata. L’assunzione di indipendenza, invece, non viene violata quando nelle condizioni <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> dell’esempio abbiamo i dati di soggetti diversi. Conoscendo come si sono comportanti i soggetti nella condizione <span class="math inline">\(A\)</span> non ci consente di fare alcuna predizione su come si comporteranno altri soggetti nella condizione <span class="math inline">\(B\)</span> – ovvero, i dati sono indipendenti.</p></li>
<li><p><em>Deviazione standard nota</em>. La terza ipotesi del test <span class="math inline">\(z\)</span> è che la deviazione standard della popolazione sia nota al ricercatore. Questa assunzione è irragionevole: ciò non si verifica in nessuna applicazione concreta dell’analisi dei dati. In altre parole, questa ipotesi è sempre falsa.</p></li>
</ol>
<p>Dato che è sempre del tutto fuori luogo assumere che <span class="math inline">\(\sigma\)</span> sia nota, poniamoci il problema di cosa fare quando non vogliamo assumere qualcosa che è certamente falso. Questo ci conduce al cosiddetto test <span class="math inline">\(t\)</span> di Student.</p>
</section></section><section id="modello-normale-varianza-sconosciuta" class="level2" data-number="42.3"><h2 data-number="42.3" class="anchored" data-anchor-id="modello-normale-varianza-sconosciuta">
<span class="header-section-number">42.3</span> Modello Normale: varianza sconosciuta</h2>
<p>Se la varianza <span class="math inline">\(\sigma^2\)</span> della popolazione normale non è nota essa deve essere stimata con la statistica campionaria corretta <span class="math inline">\(s_n^2\)</span>. Il test di ipotesi si esegue valutando se il valore empirico della statistica <span class="math display">\[T_n = \frac{(\bar{X}_n -\mu_0)\sqrt{n}}{\hat{s}_n}\]</span> appartiene alla regione di accettazione di <span class="math inline">\(H_0\)</span> oppure alla regione di rifiuto dell’ipotesi nulla.</p>
<p>Se il test è bidirezionale, la regione di non rifiuto di <span class="math inline">\(H_0\)</span> è fornita dal seguente intervallo:</p>
<p><span class="math display">\[
\mathcal{A}: \quad \mu_0 - \frac{s_n}{\sqrt{n}}t_{1-\alpha/2} \leq \mu_n \leq \mu_0 + \frac{s_n}{\sqrt{n}}t_{1-\alpha/2},
\]</span></p>
<p>dove <span class="math inline">\(s_n\)</span> è il valore empirico della stima di <span class="math inline">\(\sigma\)</span> e <span class="math inline">\(t_{1-\alpha/2}\)</span> è il quantile di ordine <span class="math inline">\(1-\alpha/2\)</span> della distribuzione <span class="math inline">\(t\)</span>-Student con <span class="math inline">\(n-1\)</span> gradi di libertà. In modo analogo, si ricavano le regioni di non rifiuto per un test unidirezionale superiore:</p>
<p><span class="math display">\[
\mathcal{A}: \quad -\infty &lt; \mu_n \leq \mu_0 + \frac{s_n}{\sqrt{n}}t_{1-\alpha},
\]</span> oppure unidirezionale inferiore:</p>
<p><span class="math display">\[
\mathcal{A}: \quad \mu_0 - \frac{s_n}{\sqrt{n}}t_{1-\alpha} \leq \mu_n &lt; +\infty.
\]</span></p>
<p>Se il valore empirico della statistica <span class="math inline">\(T_n\)</span> ricavato dal campione ricade in una delle regioni sopra definite l’ipotesi nulla non può essere rifiutata.</p>
<p>Quanto descritto sopra mostra che, quando ci basiamo su una <em>stima</em> della deviazione standard della popolazione, dobbiamo fare degli aggiustamenti alla procedura che abbiamo adottato in precedenza. Questi aggiustamenti furono introdotti nel 1908 da William Sealy Gosset, che all’epoca lavorava come chimico per il birrificio della Guinness. Dal momento che Guinness non vedeva di buon occhio il fatto che suoi dipendenti pubblicassero delle analisi statistiche di ciò che ritenevano essere un segreto commerciale, Gosset pubblicò il lavoro sotto lo pseudonimo “A Student”, da cui il nome “test <em>t</em> di Student”. Gosset capì che la stima di <span class="math inline">\(\sigma\)</span> introduce un ulteriore elemento di incertezza nella procedura di test di ipotesi. Di conseguenza, si rese conto che non è più possibile usare <span class="math inline">\(\mathcal{N}(0, 1)\)</span> quale funzione di densità che descrive <span class="math inline">\(f(\bar{X}_n \mid H_0)\)</span>, ma è invece necessario utilizzare una diversa funzione di densità che è, appunto, la <span class="math inline">\(t\)</span> di Student.</p>
<p>In precedenza abbiamo visto che ci sono infinite distribuzioni <span class="math inline">\(t\)</span> di Student, ciascuna definita da un diverso numero di gradi di libertà. Abbiamo anche visto che la distribuzione <span class="math inline">\(t\)</span>-Student tende alla normale standard per <span class="math inline">\(n \rightarrow \infty\)</span>, per cui quando <span class="math inline">\(n\)</span> è sufficientemente grande (<span class="math inline">\(n &gt; 30\)</span>), facendo un’approssimazione, i quantili <span class="math inline">\(t_{1-\alpha/2}\)</span> e <span class="math inline">\(t_{1-\alpha}\)</span> possono essere sostituiti dai corrispondenti quantili <span class="math inline">\(z_{1-\alpha/2}\)</span> e <span class="math inline">\(z_{1-\alpha}\)</span> della normale standard.</p>
<section id="effetto-stroop" class="level3" data-number="42.3.1"><h3 data-number="42.3.1" class="anchored" data-anchor-id="effetto-stroop">
<span class="header-section-number">42.3.1</span> Effetto Stroop</h3>
<p>Per fare un esempio concreto, supponiamo che ad un campione di 59 studenti di psicologia sia stato chiesto di completare una variante del compito Stroop che utilizza come stimoli facce espressive e le parole “felice” o “triste” <span class="citation" data-cites="caudek2014individual">(<a href="999_refs.html#ref-caudek2014individual" role="doc-biblioref">Caudek, 2014</a>)</span>. In ogni prova dell’esperimento, i soggetti devono classificare l’immagine di un volto (sorridente o triste) nelle due categorie “volto felice” o “volto triste”, ignorando la parola sovrapposta all’immagine. La parola irrilevante per il compito poteva essere compatibile con l’espressione del volto (es., volto felice e parola “felice”: condizione congruente) o incompatibile con essa (es., volto felice e parola “triste”: condizione incongruente). L’effetto Stroop consiste nel ritardo di elaborazione dell’espressione del volto che si riflette in un rallentamento dei tempi di reazione e nell’aumento degli errori nella condizione incongruente rispetto a quella congruente.</p>
<p>Per ciascun partecipante, su un totale di 180 prove, è stato calcolato l’effetto Stroop, ovvero la differenza tra la media dei tempi di reazione nella condizione incongruente e nella condizione congruente. Valori positivi significano che i tempi di reazione medi nella condizione incongruente sono maggiori di quelli nella condizione congruente.</p>
<p>Per i <span class="math inline">\(59\)</span> soggetti dell’esperimento eseguito da <span class="citation" data-cites="caudek2014individual">Caudek (<a href="999_refs.html#ref-caudek2014individual" role="doc-biblioref">2014</a>)</span>, l’effetto Stroop è riportato qui sotto</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">110</span>, <span class="fl">196</span>, <span class="op">-</span><span class="fl">58</span>, <span class="op">-</span><span class="fl">54</span>, <span class="op">-</span><span class="fl">162</span>, <span class="fl">11</span>, <span class="fl">6</span>, <span class="op">-</span><span class="fl">25</span>, <span class="fl">27</span>, <span class="fl">81</span>, <span class="op">-</span><span class="fl">40</span>, <span class="op">-</span><span class="fl">91</span>, <span class="op">-</span><span class="fl">40</span>, <span class="fl">39</span>, <span class="fl">23</span>, <span class="op">-</span><span class="fl">32</span>, <span class="fl">157</span>,  <span class="fl">72</span>, <span class="fl">89</span>, <span class="fl">9</span>, <span class="fl">60</span>, <span class="fl">239</span>, <span class="fl">139</span>, <span class="fl">8</span>, <span class="op">-</span><span class="fl">65</span>, <span class="fl">11</span>, <span class="fl">18</span>, <span class="fl">51</span>, <span class="fl">53</span>, <span class="fl">74</span>, <span class="fl">105</span>, <span class="fl">245</span>, <span class="op">-</span><span class="fl">16</span>, <span class="op">-</span><span class="fl">69</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">11</span>, <span class="fl">65</span>, <span class="op">-</span><span class="fl">10</span>, <span class="fl">118</span>, <span class="op">-</span><span class="fl">62</span>, <span class="fl">48</span>, <span class="op">-</span><span class="fl">78</span>, <span class="fl">96</span>, <span class="op">-</span><span class="fl">122</span>, <span class="fl">7</span>, <span class="fl">83</span>, <span class="op">-</span><span class="fl">60</span>, <span class="fl">57</span>, <span class="fl">111</span>, <span class="op">-</span><span class="fl">11</span>, <span class="fl">34</span>, <span class="fl">27</span>, <span class="fl">84</span>, <span class="fl">240</span>, <span class="op">-</span><span class="fl">67</span>, <span class="fl">111</span>, <span class="fl">92</span>, <span class="op">-</span><span class="fl">93</span>, <span class="fl">13</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>e vale, in media</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 27.52542</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>con una deviazione standard pari a</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 88.2878</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>L’ipotesi nulla è che la prestazione non subisca un effetto di interferenza da parte della parola irrilevante, ovvero che la media dell’effetto Stroop sia 0, <span class="math inline">\(H_0: \mu = 0\)</span>. In base all’ipotesi alternativa, invece, la media dell’effetto Stroop è diversa da 0, <span class="math inline">\(H_1: \mu \neq 0\)</span>.</p>
<p>Poniamoci il problema di svolgere il test <span class="math inline">\(t\)</span> di Student per questi dati.</p>
<p>Per calcolare il valore <span class="math inline">\(T\)</span> del test <span class="math inline">\(t\)</span> di Student dobbiamo standardizzare la media campionaria, ovvero dobbiamo specificare la posizione della statistica test all’interno della sua distribuzione avendo assunto come vera l’ipotesi nulla, ovvero avendo assunto che la media della popolazione sia <span class="math inline">\(0\)</span>. La statistica test dunque si ottiene dividendo la media campionaria per una stima dell’errore standard della media:</p>
<p><span class="math display">\[
T = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}} = \frac{27.52542 - 0}{\frac{88.2878}{\sqrt{59}}} = 2.394745.
\]</span></p>
<p>In R il calcolo si svolge nel modo seguente:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="cn">T</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="cn">T</span></span>
<span><span class="co">#&gt; [1] 2.394745</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si noti che, nel test <span class="math inline">\(z\)</span> l’errore standard era dato da <span class="math inline">\(\sigma/\sqrt{n}\)</span>; nel test <span class="math inline">\(t\)</span> di Student, invece, non conoscendo <span class="math inline">\(\sigma\)</span>, otteniamo una stima dell’errore standard mediante il rapporto <span class="math inline">\(\hat{\sigma}/\sqrt{n} = s_n/\sqrt{n}\)</span>, dove <span class="math inline">\(s_n\)</span> è la stima corretta della deviazione standard della popolazione.</p>
<p>Nel caso presente, per trovare il valore-<span class="math inline">\(p\)</span> è necessario calcolare l’area sottesa alla densità <span class="math inline">\(t_{59-1}\)</span> negli intervalli <span class="math inline">\([-\infty, -T]\)</span> e <span class="math inline">\([T, \infty]\)</span>, ovvero nel caso di valori della statistica <span class="math inline">\(T\)</span> maggiori in valore assoluto al valore osservato. Usando R otteniamo</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fl">2</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="cn">T</span>, <span class="fl">59</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="co">#&gt; [1] 0.01988317</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Posto <span class="math inline">\(\alpha = 0.05\)</span>, i limiti della regione di rifiuto nel caso di un test bidirezionale sono dati dai quantili della distribuzione <span class="math inline">\(t\)</span> di Student con <span class="math inline">\(n-1\)</span> gradi di libertà a cui è associata una probabilità pari a 0.025 in ciascuna coda. Mediante</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.975</span><span class="op">)</span>, <span class="fl">59</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -2.001717  2.001717</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>si trovano i valori critici di <span class="math inline">\(-2.00\)</span> e <span class="math inline">\(2.00\)</span>. Tutti i valori della statistica <span class="math inline">\(T\)</span> minori di <span class="math inline">\(-2.00\)</span> o maggiori di <span class="math inline">\(2.00\)</span> portano dunque al rifiuto di <span class="math inline">\(H_0\)</span>.</p>
<p>Come abbiamo visto in precedenza, ci sono due modi equivalenti per svolgere il test dell’ipotesi: confrontare il valore-<span class="math inline">\(p\)</span> con <span class="math inline">\(\alpha\)</span> o stabilire se il valore osservato della statistica <span class="math inline">\(T\)</span> cade nella regione di rifiuto di <span class="math inline">\(H_0\)</span>. Nel caso presente, il valore-<span class="math inline">\(p\)</span> è minore di <span class="math inline">\(\alpha\)</span> (<span class="math inline">\(0.0199 &lt; 0.05\)</span>) e dunque rifiutiamo <span class="math inline">\(H_0\)</span>. Oppure possiamo confrontare il valore della statistica test con i limiti della regione di rifiuto dell’ipotesi nulla. La statistica <span class="math inline">\(T = 2.39\)</span> ha un valore superiore del valore critico che delimita la regione di rifiuto nella coda di destra della distribuzione di <span class="math inline">\(T\)</span>: 2.39 &gt; 2.00. Dato che il valore <span class="math inline">\(T\)</span> osservato cade nella regione di rifiuto concludiamo rifiutando <span class="math inline">\(H_0\)</span>.</p>
<p>Calcoliamo anche l’intervallo di confidenza al 95%:</p>
<p><span class="math display">\[
\bar{X}_n \pm t^*\frac{s_n}{\sqrt{n}} = 27.52542 \pm \frac{88.2878}{\sqrt{59}} = [4.52, 50.53],
\]</span></p>
<p>laddove <span class="math inline">\(t^*\)</span> è il quantile della <span class="math inline">\(t\)</span> di Student con <span class="math inline">\(n-1 = 59-1\)</span> gradi di libertà di ordine <span class="math inline">\(1 - \alpha/2\)</span>, ovvero</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">0.975</span>, <span class="fl">58</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 2.001717</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Possiamo riportare i risultati nel modo seguente.</p>
<blockquote class="blockquote">
<p>L’esperimento ci fornisce evidenze di un effetto di interferenza pari a 27.5 ms, <span class="math inline">\(t_{59} = 2.39\)</span>, <span class="math inline">\(p = 0.0199\)</span>, CI<span class="math inline">\(_{95}\)</span> = [4.52, 50.53].</p>
</blockquote>
<p>laddove la notazione <span class="math inline">\(t_{59}\)</span> indica il fatto che abbiamo eseguito un test <span class="math inline">\(t\)</span> di Student con 59 gradi di libertà.</p>
</section><section id="test-t-di-student-con-r" class="level3" data-number="42.3.2"><h3 data-number="42.3.2" class="anchored" data-anchor-id="test-t-di-student-con-r">
<span class="header-section-number">42.3.2</span> Test T di Student con R</h3>
<p>La procedura del test <span class="math inline">\(t\)</span> di Student è quasi identica a quella del test <span class="math inline">\(z\)</span>, a parte il fatto che abbiamo usato la stima della deviazione standard della popolazione al posto di <span class="math inline">\(\sigma\)</span> e poi abbiamo valutato la nostra ipotesi usando la distribuzione <span class="math inline">\(t\)</span> con <span class="math inline">\(n-1\)</span> gradi di libertà al posto di <span class="math inline">\(\mathcal{N}(0, 1)\)</span>. Dato che è sempre possibile fare degli errori quando svolgiamo dei calcoli tediosi, controlliamo se i risultati ottenuti sono corretti. Dopo avere inserito i dati nel vettore <code>x</code>, confrontiamo i risultati che abbiamo svolto a mano nell’esercizio sull’effetto Stroop con quelli forniti dalla funzione <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> di :</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  One Sample t-test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  x</span></span>
<span><span class="co">#&gt; t = 2.3947, df = 58, p-value = 0.01988</span></span>
<span><span class="co">#&gt; alternative hypothesis: true mean is not equal to 0</span></span>
<span><span class="co">#&gt; 95 percent confidence interval:</span></span>
<span><span class="co">#&gt;   4.517497 50.533351</span></span>
<span><span class="co">#&gt; sample estimates:</span></span>
<span><span class="co">#&gt; mean of x </span></span>
<span><span class="co">#&gt;  27.52542</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I risultati sono identici a quelli che abbiamo trovato svolgendo i calcoli “a mano”.</p>
</section></section><section id="test-unidirezionale" class="level2" data-number="42.4"><h2 data-number="42.4" class="anchored" data-anchor-id="test-unidirezionale">
<span class="header-section-number">42.4</span> Test unidirezionale</h2>
<p>In realtà, si parla di effetto Stroop solo quando i tempi di reazione sono maggiori, in media, nella condizione incongruente rispetto a quella congruente. Nel caso presente, dunque, è sensato porre tutta la regione di rifiuto nella coda di destra della distribuzione della statistica <span class="math inline">\(T\)</span>. Per calcolare il valore-<span class="math inline">\(p\)</span> di un test unidirezionale superiore è sufficiente calcolare l’area sottesa alla funzione di densità nell’intervallo <span class="math inline">\([T, +\infty]\)</span>. Posto <span class="math inline">\(\alpha = 0.05\)</span>, il valore critico della regione di rifiuto, nel caso di un test unidirezionale superiore, è dato dal quantile della distribuzione <span class="math inline">\(t\)</span> di Student con <span class="math inline">\(n-1\)</span> gradi di libertà a cui è associata una probabilità pari a 0.05 nella coda di destra. Utilizzando <code>qt(0.95, 59 - 1)</code> tale valore risulta essere pari a <span class="math inline">\(1.67\)</span>. Tutti i valori della statistica <span class="math inline">\(T\)</span> maggiori di 1.67 portano al rifiuto di <span class="math inline">\(H_0\)</span>. È ovvio che, se abbiamo trovato un risultato statisticamente significativo con un test bilaterale la stessa conclusione sarà ottenuta, a maggior ragione, con un test unilaterale se la statistica test cade nella coda appropriata della distribuzione campionaria (ovvero, nel caso presente, nella coda di destra). In conclusione, il test dell’ipotesi nulla fornisce evidenze coerenti con l’idea che i tempi di reazione dei soggetti di questo esperimento tendano ad essere più lenti, in media, nella nella condizione incongruente rispetto a quella congruente.</p>
<section id="assunzioni" class="level3" data-number="42.4.1"><h3 data-number="42.4.1" class="anchored" data-anchor-id="assunzioni">
<span class="header-section-number">42.4.1</span> Assunzioni</h3>
<p>Dato che il test <span class="math inline">\(t\)</span> di Student per un campione non è altro che il test <span class="math inline">\(z\)</span> nel caso in cui <span class="math inline">\(\sigma\)</span> non viene considerata come nota, non dovrebbe sorprenderci che le assunzioni del test <span class="math inline">\(t\)</span> di Student siano molto simili a quelle del test <span class="math inline">\(z\)</span>.</p>
<ol type="1">
<li><p><em>Normalità.</em> Assumiamo che la distribuzione della popolazione sia normale.</p></li>
<li><p><em>Indipendenza.</em> Dobbiamo assumere che le osservazioni nel nostro campione siano generate indipendentemente le une dalle altre.</p></li>
</ol>
<p>Queste due assunzioni sembrano sensate. Di conseguenza, il test <span class="math inline">\(t\)</span> di Student per un campione viene ampiamente usato nella pratica corrente per svolgere il confronto tra una media campionaria e la media ipotizzata di una popolazione.</p>
</section><section id="popolazione-non-normale" class="level3" data-number="42.4.2"><h3 data-number="42.4.2" class="anchored" data-anchor-id="popolazione-non-normale">
<span class="header-section-number">42.4.2</span> Popolazione non Normale</h3>
<p>Abbiamo visto in precedenza che la distribuzione campionaria della media, al crescere di <span class="math inline">\(n\)</span>, è ben approssimata dalla legge normale <span class="math inline">\(\mathcal{N}(\mu, \sigma^2/n)\)</span>, <em>indipendentemente dalla forma della distribuzione della popolazione</em>. Di conseguenza, se <span class="math inline">\(n\)</span> è sufficientemente grande (<span class="math inline">\(n &gt; 30\)</span>) e se <span class="math inline">\(H_0\)</span> è vera, la distribuzione delle medie campionarie si può approssimare con una legge normale avente media <span class="math inline">\(\mu_0\)</span> e varianza <span class="math inline">\(\sigma^2/n\)</span>, se <span class="math inline">\(\sigma^2\)</span> è nota, oppure <span class="math inline">\(\hat{s}_n^2/n\)</span>, se <span class="math inline">\(\sigma^2\)</span> sconosciuta. Pertanto, nel caso di grandi campioni, le regioni di accettazione dell’ipotesi nulla sono ancora quelle descritte nel presente capitolo, indipendentemente dalla forma della distribuzione della popolazione di origine. Nel caso di piccoli campioni tratti da una popolazione non normale, invece, non è possibile, in generale, procedere al test sul valore medio mediante la procedura qui descritta.</p>
</section></section><section id="due-gruppi-indipendenti" class="level2" data-number="42.5"><h2 data-number="42.5" class="anchored" data-anchor-id="due-gruppi-indipendenti">
<span class="header-section-number">42.5</span> Due gruppi indipendenti</h2>
<p>Anche se il <span class="math inline">\(t\)</span> di Student per un singolo campione viene spesso usato, non corrisponde al caso più comune di uso del test <span class="math inline">\(t\)</span> di Student. Una situazione molto più comune è quella nella quale vengono confrontati due gruppi di osservazioni indipendenti. In psicologia, questo corrisponde al caso di due gruppi diversi di partecipanti, un gruppo per ciascuna condizione sperimentale. Per ogni partecipante allo studio viene misurata una variabile di interesse e la domanda della ricerca è se i due gruppi provengano o meno da due popolazioni aventi la stessa media. In tale situazione viene applicato il test <span class="math inline">\(t\)</span> per campioni indipendenti.</p>
<section id="test-bidirezionale-1" class="level3" data-number="42.5.1"><h3 data-number="42.5.1" class="anchored" data-anchor-id="test-bidirezionale-1">
<span class="header-section-number">42.5.1</span> Test bidirezionale</h3>
<p>Supponiamo che due popolazioni abbiano distribuzioni normali, con la stessa varianza e con medie incognite. Le due popolazioni sono dunque distribuite come due variabili aleatorie indipendenti</p>
<p><span class="math display">\[
X \sim \mathcal{N}(\mu_1, \sigma^2), \quad Y \sim \mathcal{N}(\mu_2, \sigma^2).
\]</span></p>
<p>Ci chiediamo se ci sono differenze fra le medie di queste due popolazioni e procediamo con il test della seguente ipotesi nulla:</p>
<p><span class="math display">\[
H_0: \mu_1 - \mu_2 = 0\quad \text{(non ci sono differenze fra le medie)}.
\]</span></p>
<p>L’ipotesi alternativa bidirezionale è</p>
<p><span class="math display">\[
H_1: \mu_1  - \mu_2 \neq 0.
\]</span></p>
<p>Avendo osservato i dati di due campioni indipendenti estratti dalle due popolazioni, possiamo calcolare la statistica</p>
<p><span class="math display">\[
T_n = \frac{(\bar{X} - \bar{Y}) - (\mu_1-\mu_2)}{\sqrt{s_p^2 \big(\frac{1}{n_1} + \frac{1}{n_2}\big) }} \notag
\]</span></p>
<p>che si distribuisce come una variabile aleatoria <span class="math inline">\(t\)</span>-Student con <span class="math inline">\(\nu = n_1 + n_2 - 2\)</span> gradi di libertà, dove una stima combinata della varianza, <span class="math inline">\(s^2_p\)</span>, si trova come indicato all’interno della radice quadrata al denominatore della formula precedente. Se l’ipotesi nulla è vera, dunque, la statistica</p>
<p><span class="math display">\[
T_n = \frac{\bar{X} - \bar{Y}}{\sqrt{s_p^2 \big(\frac{1}{n_1} + \frac{1}{n_2}\big) }} \notag
\]</span></p>
<p>si distribuirà come una variabile aleatoria <span class="math inline">\(t\)</span>-Student con <span class="math inline">\(\nu = n_1 + n_2 - 2\)</span> gradi di libertà.</p>
<p>Fissato il livello <span class="math inline">\(\alpha\)</span>, la regione di non rifiuto dell’ipotesi nulla è data da:</p>
<p><span class="math display">\[
\mathcal{A}: \quad -t^{\ast} \cdot s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}} &lt; (\bar{X} - \bar{Y}) &lt; +t^{\ast} \cdot s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}},\notag
\]</span></p>
<p>dove <span class="math inline">\(t^{\ast} = t_{\nu, 1-\alpha/2}\)</span> è il quantile di ordine <span class="math inline">\((1-\alpha/2)\)</span> della distribuzione <span class="math inline">\(t\)</span>-Student con <span class="math inline">\(\nu = n_1 + n_2 - 2\)</span> gradi di libertà.</p>
</section><section id="la-durata-della-gravidanza" class="level3" data-number="42.5.2"><h3 data-number="42.5.2" class="anchored" data-anchor-id="la-durata-della-gravidanza">
<span class="header-section-number">42.5.2</span> La durata della gravidanza</h3>
<p>Per fare un esempio, consideriamo uno studio svolto su 1408 donne ospedalizzate (1) per un ricovero ordinario o (2) per un ricovero d’urgenza relativo al parto. La durata della gravidanza (chiamiamola <span class="math inline">\(x\)</span>) è misurata in settimane complete dall’inizio dell’ultimo periodo mestruale. I dati sono riassunti nel modo seguente.</p>
<ul>
<li><p>Ricovero ordinario: 775 osservazioni con <span class="math inline">\(\bar{x}_o = 39.08\)</span> e <span class="math inline">\(\sigma^2 = 7.77\)</span>.</p></li>
<li><p>Ricovero d’urgenza: 633 osservazioni con <span class="math inline">\(\bar{x}_u = 39.60\)</span> e <span class="math inline">\(\sigma^2 = 4.95\)</span>.</p></li>
</ul>
<p>Ci chiediamo se ci sono evidenze sufficienti per concludere che la durata della gravidanza sia diversa nel caso di un ricovero ordinario o nel caso di un ricovero d’urgenza.</p>
<p>Se possiamo assumere che i dati provengano da due distribuzioni normali aventi uguale varianza, il test <span class="math inline">\(t\)</span> di Student si svolge nel modo seguente. Una stima combinata della varianza è data da</p>
<p><span class="math display">\[
s^2_p = \frac{774 \cdot 7.77 + 632 \cdot 4.95}{1406} \Big(\frac{1}{775} \frac{1}{633}\Big) = 0.0187.
\]</span></p>
<p>La statistica test è</p>
<p><span class="math display">\[
T = \frac{\bar{x}_o - \bar{x}_u}{s_p} = -3.8064.
\]</span></p>
<p>Abbiamo <span class="math inline">\(1,406\)</span> gradi di libertà. Usando R per calcolare il valore-<span class="math inline">\(p\)</span> di un test bilaterale otteniamo</p>
<p><span class="math display">\[
p = P(|T| &gt; |t|) = \texttt{2 * pt(-3.8064, 1406) = 0.00015}.
\]</span></p>
<p>Con <span class="math inline">\(\alpha = 0.05\)</span> possiamo dunque rigettare l’ipotesi nulla di eguaglianza della durata delle gravidanze per i due gruppi di donne.</p>
</section><section id="test-unidirezionale-1" class="level3" data-number="42.5.3"><h3 data-number="42.5.3" class="anchored" data-anchor-id="test-unidirezionale-1">
<span class="header-section-number">42.5.3</span> Test unidirezionale</h3>
<p>Se invece siamo interessati a sapere se la media della prima popolazione è maggiore di quella della seconda popolazione, per esempio, le ipotesi statistiche diventano: <span class="math display">\[\begin{aligned}
H_0: \mu_1 \leq \mu_2, \quad H_1: \mu_1 &gt; \mu_2. \notag\end{aligned}\]</span></p>
<p>Come in precedenza, la statistica test</p>
<p><span class="math display">\[T_n = \frac{\bar{X} - \bar{Y}}{\sqrt{s_p^2 \big(\frac{1}{n_1} + \frac{1}{n_2}\big) }} \notag\]</span></p>
<p>si distribuisce come una variabile aleatorie <span class="math inline">\(t\)</span>-Student con <span class="math inline">\(\nu = n_1 + n_2 - 2\)</span> gradi di libertà. In questo caso, però, fissato il livello <span class="math inline">\(\alpha\)</span>, la regione di accettazione del test è data da:</p>
<p><span class="math display">\[\mathcal{A}: \quad -\infty &lt; (\bar{X} - \bar{Y}) &lt; +t^{\ast} \cdot s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}},\notag\]</span></p>
<p>dove <span class="math inline">\(t^{\ast} = t_{\nu, 1 - \alpha}\)</span> è il quantile di ordine <span class="math inline">\((1 - \alpha)\)</span> della distribuzione <span class="math inline">\(t\)</span>-Student con <span class="math inline">\(\nu = n_1 + n_2 - 2\)</span> gradi di libertà.</p>
</section><section id="assunzioni-1" class="level3" data-number="42.5.4"><h3 data-number="42.5.4" class="anchored" data-anchor-id="assunzioni-1">
<span class="header-section-number">42.5.4</span> Assunzioni</h3>
<p>Il test <span class="math inline">\(t\)</span> per campioni indipendenti si basa sulle seguenti ipotesi.</p>
<ol type="1">
<li><p><em>Normalità.</em> Come nel caso del test <span class="math inline">\(t\)</span> per un singolo campione, anche il test <span class="math inline">\(t\)</span> per campioni indipendenti presume che i dati siano normalmente distribuiti. Specificamente, assumiamo che entrambe le popolazioni da cui sono tratti i due gruppi siano normalmente distribuite. Vedremo in seguito come sia possibile verificare tale assunzione.</p></li>
<li><p><em>Indipendenza.</em> Ancora una volta, si presume che le osservazioni siano campionate indipendentemente. Nel contesto del test <span class="math inline">\(t\)</span> per campioni indipendenti questa assunzione significa due cose diverse. In primo luogo, assumiamo che le osservazioni all’interno di ciascun campione siano indipendenti l’una dall’altra (esattamente come ne caso di un test <span class="math inline">\(t\)</span> per un singolo campione). In secondo luogo, assumiamo anche che non ci siano dipendenze tra i due campioni. Se, ad esempio, scopriamo di avere accidentalmente incluso alcuni partecipanti in entrambe le condizioni sperimentali dello studio (ad esempio, permettendo alla stessa persona di iscriversi a due condizioni diverse), allora questo introduce delle dipendenze le osservazioni dei due campioni e l’ipotesi di indipendenza viene violata.</p></li>
<li><p><em>Omogeneità della varianza</em> (detta anche “omoscedasticità”). La terza ipotesi è che le due popolazioni abbiano la stessa la deviazione standard. È possibile verificare questa ipotesi usando il test di Levene. Tuttavia, c’è un rimedio più semplice per la violazione di questa assunzione, di cui parleremo nella prossima sezione.</p></li>
</ol></section><section id="test-di-welch" class="level3" data-number="42.5.5"><h3 data-number="42.5.5" class="anchored" data-anchor-id="test-di-welch">
<span class="header-section-number">42.5.5</span> Test di Welch</h3>
<p>Il problema più grande relativo all’uso del test <span class="math inline">\(t\)</span> di Student per campioni indipendenti ha a che fare con la terza ipotesi elencata nella sezione precedente: l’ipotesi che entrambe le popolazioni abbiano la stessa deviazione standard. Questo accade raramente nella vita reale: se due popolazioni non hanno la stessa media, perché dovrebbero avere la stessa deviazione standard? Non c’è davvero alcuna ragione per aspettarsi che questa ipotesi sia vera. Per superare tale difficoltà, Welch (1947) sviluppò una seconda forma del test <span class="math inline">\(t\)</span> di Student per campioni indipendenti la quale non richiede l’omogeneità della varianza.</p>
<p>Il test di Welch è molto simile al test <span class="math inline">\(t\)</span> di Student per campioni indipendenti. La statistica test è identica a quella calcolata in precedenza</p>
<p><span id="eq-twelch"><span class="math display">\[
T_n = \frac{\bar{X} - \bar{Y}}{\hat{\sigma}_{\bar{X} - \bar{Y}}}
\tag{42.1}\]</span></span></p>
<p>ovvero, è data dal rapporto tra la differenza tra le medie campionarie e l’errore standard di tale differenza. Ciò che distingue il test di Welch dalla procedura descritta in precedenza è il modo di calcolare l’errore standard della differenza tra due medie. Nel test di Welch, l’errore standard viene stimato nel modo seguente:</p>
<p><span class="math display">\[
\hat{\sigma}_{\bar{X} - \bar{Y}} = \sqrt{\frac{\hat{\sigma}_1^2}{n_1} + \frac{\hat{\sigma}_2^2}{n_2}}.
\]</span></p>
<p>La statistica test viene poi valutata utilizzando una correzione dei gradi di liberà fornita dall’equazione di Welch–Satterthwaite:</p>
<p><span class="math display">\[
gdl = \frac{
(\hat{\sigma}_1^2/n_1 + \hat{\sigma}_2^2/n_2)^2
}{
(\hat{\sigma}_1^2/n_1)^2/(n_1-1) + (\hat{\sigma}_2^2/n_2)^2/(n_2-1)
}.
\]</span></p>
<p>Vediamo ora in un caso concreto come applicare il test di Welch.</p>
<p>Consideriamo il seguente estratto dell’articolo di Mehr et al.&nbsp;(2014):</p>
<blockquote class="blockquote">
<p>The infants’ degree of song exposure was comparable across the two experiments: The estimated total number of song performances was similar in Experiment 1 (<span class="math inline">\(M\)</span> = 76.3, <span class="math inline">\(SD\)</span> = 56.2) and Experiment 2 (<span class="math inline">\(M\)</span> = 81.8, <span class="math inline">\(SD\)</span> = 50.5), <span class="math inline">\(t_{61.3}\)</span> = 0.41, <span class="math inline">\(p\)</span> = .68 (Satterthwaite’s <span class="math inline">\(t\)</span> test) …</p>
</blockquote>
<p>Senza entrare nei dettegli dello studio, poniamoci l’obiettivo di replicare l’analisi statistica descritta dagli autori. I dati del primo esperimento sono:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">35.0</span>, <span class="fl">239.0</span>, <span class="fl">102.0</span>, <span class="fl">27.0</span>, <span class="fl">60.0</span>, <span class="fl">126.0</span>, <span class="fl">134.6667</span>, <span class="fl">63.77777</span>, <span class="fl">44.0</span>, <span class="fl">55.0</span>, <span class="fl">88.0</span>, <span class="fl">53.66666</span>, <span class="fl">59.5</span>, <span class="fl">94.0</span>, <span class="fl">54.0</span>, <span class="fl">26.0</span>, <span class="fl">44.0</span>, <span class="fl">23.0</span>, <span class="fl">38.0</span>, <span class="fl">31.0</span>, <span class="fl">78.4</span>, <span class="fl">135.0</span>, <span class="fl">26.0</span>, <span class="fl">120.9091</span>, <span class="fl">13.0</span>, <span class="fl">245.0</span>, <span class="fl">66.5</span>, <span class="fl">63.0</span>, <span class="fl">57.16667</span>, <span class="fl">29.71428</span>, <span class="fl">70.0</span>, <span class="fl">140.0</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>e i dati del secondo experimento sono:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">43.16666</span>, <span class="fl">63.0</span>, <span class="fl">35.0</span>, <span class="fl">100.8</span>, <span class="fl">69.0</span>, <span class="fl">66.0</span>, <span class="fl">105.0</span>, <span class="fl">270.6667</span>, <span class="fl">62.0</span>, <span class="fl">80.0</span>, <span class="fl">128.0</span>, <span class="fl">104.0</span>, <span class="fl">49.0</span>, <span class="fl">80.0</span>, <span class="fl">51.0</span>, <span class="fl">114.3333</span>, <span class="fl">168.0</span>, <span class="fl">105.0</span>, <span class="fl">37.0</span>, <span class="fl">38.0</span>,  <span class="fl">45.0</span>, <span class="fl">48.0</span>,  <span class="fl">84.0</span>, <span class="fl">99.0</span>,  <span class="fl">38.5</span>, <span class="fl">74.57143</span>, <span class="fl">49.0</span>, <span class="fl">28.0</span>, <span class="fl">64.0</span>, <span class="fl">86.8</span>, <span class="fl">49.0</span>, <span class="fl">182.0</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Dobbiamo eseguire un test <span class="math inline">\(t\)</span> di Student per campioni indipendenti con il metodo di Welch.</p>
<p>In questo caso, <span class="math inline">\(n_1=n_2 = 32\)</span>. Abbiamo inoltre che <span class="math inline">\(\bar{X} = 76.32191\)</span> e <span class="math inline">\(\bar{Y} = 81.77619\)</span>, con <span class="math inline">\(s_1^2 = 3163.961\)</span> e <span class="math inline">\(s_2^2 = 2554.029\)</span>. L’errore standard stimato mediante la procedura di Welch è pari a 13.36739 per cui, utilizzando l’equazione del test di Welch otteniamo la statistica <span class="math inline">\(T = -0.4080286\)</span>. I gradi di libertà per il test di Welch sono pari a 61.30249 il che ci conduce ad un valore-<span class="math inline">\(p\)</span> pari a</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.4080286</span>, <span class="fl">61.30249</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.6846743</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Questi risultati riproducono perfettamente ciò che è stato riportato da Mehr et al.&nbsp;(2014). I calcoli si possono svolgere utilizzando la funzione <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> di R:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Welch Two Sample t-test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  x1 and x2</span></span>
<span><span class="co">#&gt; t = -0.40803, df = 61.302, p-value = 0.6847</span></span>
<span><span class="co">#&gt; alternative hypothesis: true difference in means is not equal to 0</span></span>
<span><span class="co">#&gt; 95 percent confidence interval:</span></span>
<span><span class="co">#&gt;  -32.18136  21.27281</span></span>
<span><span class="co">#&gt; sample estimates:</span></span>
<span><span class="co">#&gt; mean of x mean of y </span></span>
<span><span class="co">#&gt;  76.32191  81.77619</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si noti che R utilizza di default il test di Welch quando sottopone a verifica l’ipotesi nulla dell’eguaglianza di due medie.</p>
<p>L’intervallo di confidenza al 95% è dato da</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">se</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">x2</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fl">61.302</span></span>
<span><span class="va">ci</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">0.975</span>, <span class="va">df</span><span class="op">)</span> <span class="op">*</span> <span class="va">se</span> </span>
<span><span class="va">ci</span></span>
<span><span class="co">#&gt; [1] -32.18137  21.27281</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>il che riproduce il risultato trovato dalla funzione <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code>.</p>
<p>Il messaggio che si può ricavare dalla discussione sul test di Welch è che esso dovrebbe sempre essere eseguito al posto del “tradizionale” test <span class="math inline">\(t\)</span> di Student (infatti, questa è l’impostazione di default in ). Questo perché il test di Welch si comporta meglio del test <span class="math inline">\(t\)</span> di Student se le dimensioni e le varianze dei campioni non sono uguali tra i gruppi e dà lo stesso risultato del test <span class="math inline">\(t\)</span> di Student quando le dimensioni e le varianze del campione sono uguali. Un approccio che viene raccomandato nei testi di statistica è di verificare con il test di Levene l’ipotesi che le varianze siano uguali tra i gruppi, ma molti ricercatori ritengono che sia preferibile utilizzare sempre il test di Welch, indipendentemente dai risultati del test di Levene. Infatti, il test di Levene ha spesso una bassa potenza – ovvero non è in grado di respingere l’ipotesi nulla che le varianze siano uguali anche quando esse sono effettivamente diverse – il che rende problematico assumere che le varianze siano uguali anche se il risultato del test di Levene è nullo.</p>
</section><section id="assunzioni-del-test-di-welch" class="level3" data-number="42.5.6"><h3 data-number="42.5.6" class="anchored" data-anchor-id="assunzioni-del-test-di-welch">
<span class="header-section-number">42.5.6</span> Assunzioni del test di Welch</h3>
<p>Le assunzioni alla base del test di Welch sono simili a quelle del test <span class="math inline">\(t\)</span> di Student per campioni indipendenti, ad eccezione del fatto che il test di Welch non presuppone l’omogeneità della varianza. Rimangono dunque solo l’assunzione di normalità e l’assunzione di indipendenza.</p>
</section></section><section id="test-t-per-dati-appaiati" class="level2" data-number="42.6"><h2 data-number="42.6" class="anchored" data-anchor-id="test-t-per-dati-appaiati">
<span class="header-section-number">42.6</span> Test T per dati appaiati</h2>
<p>Se consideriamo il test <span class="math inline">\(t\)</span> di Student per campioni indipendenti o il test di Welch è evidente che tali test possono essere usati in situazioni in cui i due campioni sono, appunto, indipendenti l’uno dall’altro. Una tale situazione si presenta, ad esempio, quando i partecipanti ad un esperimento vengono assegnati casualmente a una di due condizioni sperimentali. Ma ci possono anche essere disegni sperimentali con caratteristiche diverse. In particolare, in un disegno a misure ripetute ciascun partecipante viene valutato (rispetto alla stessa variabile dipendente) in tutte le condizioni sperimentali e, in tali circostanze, i due campioni non sono indipendenti. Ad esempio, potremmo essere interessati a sapere se ascoltare musica riduce la capacità della memoria di lavoro delle persone. A tal fine, potremmo misurare la capacità della memoria di lavoro di ciascun soggetto in due condizioni: con la musica e senza musica. In un disegno sperimentale di questo tipo ciascun partecipante fa parte di ciascuno dei due gruppi che vengono esaminati. Non possiamo dunque usare l’approccio descritto in precedenza e dobbiamo procedere in un modo diverso, ovvero mediante l’uso del test <span class="math inline">\(t\)</span> per dati appaiati</p>
<p>Nel test <span class="math inline">\(t\)</span> per dati appaiati disponiamo di una coppia ordinata di osservazioni per ciascuna u.s. (per esempio, l’osservazione effettuata ad un pre-test e ad un post-test, oppure nelle condizioni con la musica e senza musica dell’esempio precedente) e diventa così possibile calcolare una misura della variazione <span class="math inline">\(D\)</span> della variabile di interesse rispetto alle due osservazioni. Avendo un insieme <span class="math inline">\(D_1, \dots, D_n\)</span> di variazioni, possiamo calcolarne la media <span class="math inline">\(\bar{D}\)</span> e la deviazione standard <span class="math inline">\(s_D\)</span>:</p>
<p><span class="math display">\[
\bar{D} = \frac{1}{n} \sum_{i = 1}^n D_i, \quad s_D = \sqrt{\frac{1}{n-1}\sum_{i=1}^n (D_i - \bar{D})^2}.
\]</span></p>
<p>L’errore standard per la media delle differenze è dato da</p>
<p><span class="math display">\[
s_{\bar{D}} = \frac{s_D}{\sqrt{n}}.
\]</span></p>
<p>Se <span class="math inline">\(\delta\)</span> è la variazione media della popolazione, allora la statistica</p>
<p><span class="math display">\[
T_n = \frac{\bar{D} - \delta}{s_{\bar{D}}}
\]</span></p>
<p>si distribuisce come una v.a. <span class="math inline">\(t\)</span>-Student con <span class="math inline">\(\nu = n - 1\)</span> gradi di libertà, sotto l’ipotesi che il campione (di variazioni) provenga da una popolazione distribuita in maniera normale. Per il test dell’ipotesi nulla <span class="math inline">\(H_0: \delta = 0\)</span>, si calcola il valore <span class="math inline">\(T_n = \bar{D}/s_{\bar{D}}\)</span> e si procede con il confronto con il valore critico per <span class="math inline">\(\nu = n - 1\)</span> gradi di libertà, dove <span class="math inline">\(n\)</span> è il numero di coppie di osservazioni. Come per tutti i test <span class="math inline">\(t\)</span>, la statistica <span class="math inline">\(T_n\)</span> tende a distribuirsi come una <span class="math inline">\(t\)</span>-Student, indipendentemente dalla forma della distribuzione della popolazione di origine, se <span class="math inline">\(n\)</span> è sufficientemente grande.</p>
<section id="proporzione-di-maschi-e-femmine" class="level3" data-number="42.6.1"><h3 data-number="42.6.1" class="anchored" data-anchor-id="proporzione-di-maschi-e-femmine">
<span class="header-section-number">42.6.1</span> Proporzione di maschi e femmine</h3>
<p>Per fare un esempio, consideriamo i dati forniti dal censimento indiano relativi rapporto numerico tra i due sessi nel 2001 e nel 2011 in 35 stati dell’India (i dati grezzi sono forniti sulla pagina Moodle di Psicometria).</p>
<p>Al momento della nascita, la percentuale di bambini di sesso maschile varia nelle diverse zone del mondo, ma in media nascono 101 maschi ogni 100 femmine <span class="citation" data-cites="orzack2015human">(<a href="999_refs.html#ref-orzack2015human" role="doc-biblioref">Orzack et al., 2015</a>)</span>. Nonostante il fatto che le donne, in generale, vivano più a lungo degli uomini, ci sono due paesi nel mondo che hanno al loro interno un grande squilibrio nel rapporto tra i sessi: la Cina ha quasi 50 milioni di uomini in più rispetto alle donne e l’India 43 milioni. Lo squilibrio di Cina e India è dovuto alle pratiche ampiamente documentate degli aborti selettivi sulla base del genere (a causa anche della disponibilità di tecniche di diagnosi prenatale a prezzi accessibili) e all’infanticidio delle neonate <span class="citation" data-cites="miller2001female">(<a href="999_refs.html#ref-miller2001female" role="doc-biblioref">Miller, 2001</a>)</span>.</p>
<p>Nell’insieme di dati considerato, ogni osservazione corrisponde ad uno stato dell’India. La variabile considerata (<code>child_sex_ratio</code>) è il numero medio di bambine femmine per ogni 1000 bambini maschi – ciò consente di escludere la maggiore longevità delle donne (l’età dei bambini non è specificata). Nel 2001, risultano esserci in media <span class="math inline">\(934\)</span> bambine rispetto a 1000 bambini maschi e nel 2011 risultano <span class="math inline">\(926\)</span> bambine, in media, per ogni 1000 bambini maschi. Per ciascuno stato, sottraiamo il numero medio di bambine calcolate rispetto a 1000 bambini nel 2011 da quello del 2001. Le <span class="math inline">\(35\)</span> differenze così trovate hanno una media pari a <span class="math inline">\(-7.66\)</span> con una deviazione standard di <span class="math inline">\(22.92\)</span>. La statistica test diventa</p>
<p><span class="math display">\[
T = \frac{-7.66 - 0}{22.92/\sqrt{35}} = -1.976.
\]</span></p>
<p>Per un test bilaterale, il valore-<span class="math inline">\(p\)</span> è l’area sottesa alla funzione di densità <span class="math inline">\(t\)</span> con 34 gradi di libertà negli intervalli <span class="math inline">\([-\infty, T]\)</span> e <span class="math inline">\([T, +\infty]\)</span> e risulta essere uguale a <span class="math inline">\(0.056\)</span>. Essendo il valore-<span class="math inline">\(p\)</span> maggiore di <span class="math inline">\(\alpha = 0.05\)</span>, non possiamo rigettare l’ipotesi nulla <span class="math inline">\(H_0: \delta = 0\)</span> che la media della popolazione di differenze sia zero (ovvero che nell’arco temporale considerato non vi siano differenze nel rapporto numerico tra i sessi). In conclusione, non ci sono evidenze che nel decennio 2001-2011 la situazione sia migliorata. Addirittura, la differenza media è negativa, il che suggerisce il contrario.</p>
</section></section><section id="commenti-e-considerazioni-finali" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="commenti-e-considerazioni-finali">Commenti e considerazioni finali</h2>
<p>Il test <span class="math inline">\(t\)</span> di Student nelle sue varianti rappresenta senza dubbio lo strumento statistico di stampo frequentista più ampiamente usato nel mondo della ricerca. Abbiamo visto che è basato su assunzioni ragionevoli, in molte applicazioni pratiche, e quindi potremmo concludere che sia uno strumento utile. Tuttavia, le cose non sono così semplici – non lo sono mai. In questo capitolo abbiamo visto come il test <span class="math inline">\(t\)</span> di Student viene calcolato, come si giunge ad una decisione sulla base della statistica test e del livello di significatività, eccetera. Tali considerazioni, però, sono considerazioni di tipo statistico, ovvero non riguardano le pratiche del mondo reale, ma descrivono solo le proprietà di alcuni teoremi che fanno parte della teoria della probabilità. Il test <span class="math inline">\(t\)</span> di Student, però, non è solo una procedura astratta, che va valutata per la sua eleganza concettuale, ma è invece una procedura che viene usata nella pratica concreta dell’attività di ricerca per rispondere a domande che hanno una grande rilevanza pratica. Per esempio: la psicoterapia è in grado di ridurre lo stato di ansia e depressione? Oppure: l’idrossiclorochina contrasta in maniera efficace il Covid-19?</p>
<p>Qualcuno, ingenuamente, potrebbe pensare che il mondo della ricerca sia una torre d’avorio all’interno della quale l’attività dei ricercatori è motivata, in primo luogo, e quasi soltanto, dal desiderio di fare avanzare le nostre conoscenze. Non è così. La sociologia della scienza ci fornisce un’immagina ben diversa di come stanno le cose. Le motivazioni dei ricercatori sono ben più prosaiche: l’avanzamento in carriera, il potere, il prestigio, il denaro; tutto ciò descrive molto meglio le motivazioni dei ricercatori del “desiderio di fare avanzare le nostre conoscenze”. Ma cosa c’entra il test <span class="math inline">\(t\)</span> di Student in tutto questo? È facile capire che, se lo stipendio dei ricercatori dipende dalle loro pubblicazioni, e se si possono pubblicare solo i risultati statisticamente significativi, allora i ricercatori faranno tutto quello che è in loro potere per ottenere risultati statisticamente significativi. Qui non faccio riferimento al problema della frode nel mondo scientifico, ma al fatto che è <em>inevitabile</em> che, dopo una lunga e onerosa fase di progettazione dello studio e di raccolta dati, i ricercatori eseguano il test <span class="math inline">\(t\)</span> di Student <em>più di una volta</em>, per confrontare tra loro più di due condizioni e per valutare se <em>da qualche parte</em> nei loro dati emerge un risultato statisticamente significativo. Nella pratica corrente, però, la consuetudine è quella di <em>non riportare</em> il fatto che il test sia stato eseguito più volte, quando esso non produce un risultato statisticamente significativo dove avrebbe dovuto, in base alle ipotesi iniziali dei ricercatori. Ma, se questo è quello che fanno i ricercatori nel mondo reale, dobbiamo chiederci: cosa succede in tali circostanze alla probabilità di errore di I tipo? Non occorre essere degli statistici per renderci conto che, così facendo, la probabilità di errore di I tipo non può rimanere al livello nominale <span class="math inline">\(\alpha\)</span>: nella pratica concreta, dunque, la probabilità di falsi positivi è ben più alta della famosa soglia del 5%.</p>
<p>Per concludere, ricordiamoci che la giustificazione ultima dell’approccio NHST (di cui il test <span class="math inline">\(t\)</span> di Student è la procedura più nota) è proprio quella di mantenere sotto controllo la probabilità di errore di I tipo. Ma, alla luce di quanto abbiamo detto sopra, e considerando soprattutto le le considerazioni svolte da <span class="citation" data-cites="gelman2014beyond">Gelman &amp; Carlin (<a href="999_refs.html#ref-gelman2014beyond" role="doc-biblioref">2014</a>)</span> che esamineremo nel prossimo capitolo, la domanda (retorica) che dovrebbe venirci in mente è: l’approccio frequentista riesce a mantenere la sua promessa?</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography" style="display: none">
<div id="ref-caudek2014individual" class="csl-entry" role="doc-biblioentry">
Caudek, C. (2014). Individual differences in cognitive control on self-referenced and other-referenced memory. <em>Consciousness and Cognition</em>, <em>30</em>, 169–183.
</div>
<div id="ref-gelman2014beyond" class="csl-entry" role="doc-biblioentry">
Gelman, A., &amp; Carlin, J. (2014). Beyond power calculations: Assessing type <span>S</span> (sign) and type <span>M</span> (magnitude) errors. <em>Perspectives on Psychological Science</em>, <em>9</em>(6), 641–651.
</div>
<div id="ref-miller2001female" class="csl-entry" role="doc-biblioentry">
Miller, B. D. (2001). Female-selective abortion in <span>A</span>sia: Patterns, policies, and debates. <em>American Anthropologist</em>, <em>103</em>(4), 1083–1095.
</div>
<div id="ref-orzack2015human" class="csl-entry" role="doc-biblioentry">
Orzack, S. H., Stubblefield, J. W., Akmaev, V. R., Colls, P., Munné, S., Scholl, T., Steinsaltz, D., &amp; Zuckerman, J. E. (2015). The human sex ratio from conception to birth. <em>Proceedings of the National Academy of Sciences</em>, <em>112</em>(16), E2102–E2111.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./226_test_ipotesi.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Significatività statistica</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./228_limiti_stat_frequentista.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb25" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Inferenza sulle medie {#sec-mean-comp}</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include = FALSE}</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>Molto spesso in psicologia ci troviamo in una situazione in cui la variabile dipendente è a livello di scala ad intervalli o superiore e ciò che ci interessa è stabilire se il valore medio della variabile dipendente sia più grande in un gruppo o in un altro. Ad esempio, uno psicologo potrebbe voler sapere se i livelli di ansia sono più alti tra i genitori o tra i non genitori, o se la capacità della memoria di lavoro si riduce quando si ascolta musica, rispetto alla condizione in cui non si ascolta musica. In queste situazioni, la variabile dipendente è continua a livello di scala ad intervalli o a rapporti e il nostro predittore è una variabile binaria. In altre parole, ciò che vogliamo fare in situazioni di questo tipo è confrontare le medie dei due gruppi.</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>La risposta tradizionale al problema del confronto tra due medie è quella di usare il test statistico che va sotto il nome di $t$ di Student, di cui esistono diverse varianti a seconda del tipo di domanda a cui si vuole rispondere. In questo capitolo presenteremo le diverse varianti del test $t$ di Student: il test $t$ a campione unico, il test $t$ per campioni indipendenti e il test $t$ per il confronto tra le medie di due campioni appaiati.</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modello Normale: varianza nota</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>In questa sezione inizieremo ad esaminare il test $z$, il quale ci fornisce una versione semplificata del test $t$ di Student, che probabilmente è in assoluto il test statistico più usato (più di una volta a sproposito) dall'approccio frequentista. Lo scopo di questa discussione è quello di presentare la logica che sta alla base della procedura di test di ipotesi frequentista. Il test $z$ chiarisce questa logica esaminando il caso più semplice -- un caso che, per motivi che saranno chiariti in seguito, non trova molte applicazioni pratiche. Lo presentiamo qui perché rende trasparente la motivazione frequentista della procedura di test di ipotesi. Gli altri test frequentisti, quelli che si usano nelle applicazioni concrete, sono semplicemente degli sviluppi dell'idea sulla quale si basa il test $z$. Per cui, se si capisce il test $z$, si capiscono tutti i test frequentisti.</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>Il test $z$ applica la procedura di test di ipotesi statistiche che è stata presentata nel capitolo precedente e si pone il problema di verificare un'ipotesi a proposito della media della popolazione utilizzando la media campionaria quale statistica test. In precedenza abbiamo discusso un teorema della teoria della probabilità il quale afferma che la media $\bar{X}_n$ di $n$ variabili aleatorie i.i.d., ciascuna distribuita come $\mathcal{N}(\mu, \sigma^2)$, segue una distribuzione normale con parametri $\mu_{\bar{X}_n} = \mu$ e $\sigma^2_{\,\bar{X}_n} = \sigma^2 / n$. Questo significa che, conoscendo i parametri (media e deviazione standard) della popolazione di origine, è possibile specificare completamente la distribuzione campionaria di $\bar{X}_n$.</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>Ovviamente il valore dei parametri è ignoto, ma è qui che interviene la procedura di test di ipotesi. In base all'approccio NHST, la distribuzione campionaria della statistica test viene costruita *assumendo come vera* l'ipotesi nulla. Il test $z$ -- e lo stesso approccio viene seguito per tutti gli altri test di stampo frequentista -- determina la distribuzione campionaria della statistica test (per esempio, la media del campione quale stimatore della media della popolazione) ipotizzando che il campione osservato provenga da una popolazione in cui l'ipotesi nulla è vera. La domanda di come determinare i valori dei parametri incogniti della popolazione trova quindi una facile risposta: il valore di tali parametri è fornito da $H_0$!</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="fu">### Un test bilaterale</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>Per vedere come come si esegue il test $z$, consideriamo il seguente esempio. I valori antropometrici medi della popolazione italiana adulta sono stati descritti, per esempio, da un'indagine nazionale condotta da Briziarelli et al. (1994). Ci concentriamo qui sull'altezza media delle donne adulte, la quale risulta essere pari a 162.5 cm tra 18 e 24 anni, con una deviazione standard di 12 cm. Sappiamo anche che la variabile "altezza" segue la distribuzione normale. Per qualche ragione, sospettiamo che, a Firenze, l'altezza media sia diversa da quella a livello nazionale e, per gli scopi di questo esempio, crediamo che possa essere o maggiore o minore di quella italiana.</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="fu">### La statistica test</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>Per sottoporre a verifica la nostra ipotesi della ricerca, misuriamo l'altezza di 20 donne fiorentine scelte a caso. Supponiamo di avere ottenuto i seguenti risultati:</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">173.53</span>, <span class="fl">175.01</span>, <span class="fl">165.19</span>, <span class="fl">161.06</span>, <span class="fl">173.77</span>, <span class="fl">144.68</span>, <span class="fl">174.06</span>, <span class="fl">163.19</span>, <span class="fl">163.09</span>, <span class="fl">155.47</span>, <span class="fl">165.11</span>, <span class="fl">188.31</span>, <span class="fl">170.95</span>, <span class="fl">172.74</span>, <span class="fl">157.49</span>, <span class="fl">176.30</span>, <span class="fl">155.86</span>, <span class="fl">162.52</span>, <span class="fl">179.95</span>, <span class="fl">170.08</span>)</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>Calcoliamo la media del campione:</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>La media campionaria è un po' più grande della media della popolazione $\mu = 162.5$ e questo suggerisce che, in effetti, le donne fiorentine potrebbero avere un altezza superiore alla media nazionale. Tuttavia, un campione di ampiezza $n = 20$ è molto piccolo, per cui la diffrenza tra il risultato osservato e il valore atteso ($\mu = 162.5$) potrebbe essere soltano il prodotto del caso. Per verificare l'ipotesi, che l'altezza delle donne fiorentine sia diversa da quella delle altre donne italiane decidiamo di usare $\bar{X}_{n}$ quale statistica test, ovvero quale stima di $\mu$.</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>Per valutare la nostra ipotesi iniziamo ad elencare ciò che sappiamo. Chiamiamo $X$ l'altezza delle donne fiorentine. In primo luogo, sappiamo che la media campionaria è $\bar{X}_{n} = 167.418$. Se siamo disposti ad assumere che la distribuzione dell'altezza delle donne fiorentine ha la stessa deviazione standard dell'altezza delle altre donne della popolazione italiana, allora possiamo dire che la deviazione standard dell'altezza delle donne fiorentine è $\sigma = 12$. Inoltre, sappiamo che i valori dell'altezza delle donne fiorentine sono distribuiti in maniera normale dato che, in generale, i valori dell'altezza seguono la legge della distribuzione normale.</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>Ora elenchiamo ciò che non sappiamo, ma che vorremmo sapere. La nostra ipotesi riguarda il valore incognito $\mu$, ovvero la media dell'altezza della popolazione delle donne fiorentine -- infatti, abbiamo misurato l'altezza di 20 donne fiorentine, non di tutte le donne fiorentine! La nostra ipotesi è $X \sim \mathcal{N}(\mu \neq 162.5, \sigma = 12)$, con $\mu$ sconosciuto. Dato che, nella procedura NHST, l'ipotesi del ricercatore definisce "l'ipotesi alternativa" $H_1$, possiamo scrivere:</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>H_1: X \sim \mathcal{N}(\mu \neq 162.5, \sigma = 12).</span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>Una volta definita l'ipotesi alternativa risulta specificata anche l'ipotesi nulla, in quanto essa è l'ipotesi opposta e complementare a $H_1$. Dunque possiamo scrivere:</span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>H_0: X \sim \mathcal{N}(\mu = 162.5, \sigma = 12).</span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a>Le ipotesi nulla e alternativa riguardano i parametri della popolazione. In questo particolare esempio, il paraemtro $\mu$ (la media dell'altezza delle donne fiorentine) è incognito ma $\sigma$ è noto (in quanto abbiamo assunto che l'altezza delle donne fiorentine e l'altezza delle donne italiane sono due Normali con la stessa deviazione standard ma con medie diverse). Per stimare $\mu$ dobbiamo usare una qualche statistica test, e la statistica ovvia a questo riguardo è semplicemente la media del campione $\bar{X}$. Decidiamo dunque di usare $\bar{X}$ quale statistica test. Quello che dobbiamo ancora stabilire sono le caratteristiche della distribuzione campionaria di $\bar{X}$ nel caso di campioni di ampiezza $n=20$.</span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a><span class="fu">### La distribuzione campionaria della statistica test</span></span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a>In base all'approccio NHST, la distribuzione campionaria della statistica test viene determinata assumendo come vera l'ipotesi nulla. Nel caso del nostro esempio, l'ipotesi nulla afferma che $X \sim \mathcal{N}(\mu = 162.5, \sigma = 12)$. Sotto $H_0$, dunque, la distribuzione campionaria della media di campioni di ampiezza $n=20$ è:</span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a>\bar{X} \sim \mathcal{N}\left(\mu_{\bar{X}} = \mu = 162.5, \sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{12}{\sqrt{20}}\right).</span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a>Si noti che è l'ipotesi nulla a specificare la media $\mu$ e la deviazione standard $\sigma$ della popolazione da cui vengono estatti i campioni che formano la distribuzione campionaria di $\bar{X}$. Per questa ragione diciamo che la distribuzione campionaria della statistica test, $f(\bar{X} \mid H_0)$, è stata generata assumendo vera l'ipotesi nulla.</span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a><span class="fu">### La decisione</span></span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a>Nel problema che stiamo discutendo l'ipotesi alternativa $H_1$ è bilaterale. Ovvero, possiamo rigettare $H_0$ se troviamo che l'altezza media delle donne fiorentine è molto diverso dal valore postulato da $H_0$, ovvero $\mu_{\bar{X}} = \mu = 162.5$. Rifiuteremo $H_0$ se la statistica test $\bar{X}$ si dimostra essere di molto maggiore dell'altezza ipotizzata da $H_0$, oppure di molto minore dell'altezza ipotizzata da $H_0$.</span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a>In altre parole, per valutare $H_0$ dobbiamo determinare se la statistica test cade o meno nella regione di rifiuto. È necessario dunque identificare la regione di rifiuto di $H_0$. Per fare questo dobbiamo prima scegliere $\alpha$. Seguendo la consuetudine usata in psicologia, poniamo $\alpha = 0.05$. Dato che il test è bidirezinale, rigettiamo $H_0$ se la statistica test corrisponde ad un valore estremo che cade o nella coda di destra di $f(\bar{X} \mid H_0)$ *oppure* nella coda di sinistra di $f(\bar{X} \mid H_0)$. La regione di rifiuto di $H_0$ sarà dunque divisa in due parti: metà sarà collocata nella coda di sinistra di $f(\bar{X} \mid H_0)$ e metà nella coda di destra di $f(\bar{X} \mid H_0)$. Quali sono i valori critici che delimitano le due regioni di rifiuto di $H_0$? Per trovarli, dobbiamo calcolare i quantili di ordine 0.025 e 0.975 della distribuzione normale di media 162.5 e deviazione standard $\frac{12}{\sqrt{20}}$:</span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.025</span>, <span class="fl">162.5</span>, <span class="dv">12</span><span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">20</span>))</span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.975</span>, <span class="fl">162.5</span>, <span class="dv">12</span><span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">20</span>))</span>
<span id="cb25-80"><a href="#cb25-80" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-81"><a href="#cb25-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-82"><a href="#cb25-82" aria-hidden="true" tabindex="-1"></a>Le due regioni di rifiuto di $H_0$ sono dunque $<span class="co">[</span><span class="ot">-\infty, 157.24</span><span class="co">]</span>$ e $<span class="co">[</span><span class="ot">167.76, +\infty</span><span class="co">]</span>$, come indicato nella @fig-regrifiutoaltezzabil.</span>
<span id="cb25-83"><a href="#cb25-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-84"><a href="#cb25-84" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-regrifiutoaltezzabil, fig.cap="Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l'ipotesi nulla $X \\sim \\mathcal{N}(\\mu = 162.5, \\sigma = 12)$. Le aree ombreggiate indicano le regioni di rifiuto di $H_0$ per un test bilaterale posto $\\alpha$ = 0.05."}</span></span>
<span id="cb25-85"><a href="#cb25-85" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">55</span>, <span class="dv">145</span>)), <span class="fu">aes</span>(x)) <span class="sc">+</span> </span>
<span id="cb25-86"><a href="#cb25-86" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="fl">162.5</span>, <span class="at">sd =</span> <span class="dv">12</span>)) <span class="sc">+</span></span>
<span id="cb25-87"><a href="#cb25-87" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb25-88"><a href="#cb25-88" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="fl">162.5</span>, <span class="at">sd =</span> <span class="dv">12</span>),</span>
<span id="cb25-89"><a href="#cb25-89" aria-hidden="true" tabindex="-1"></a>    <span class="at">geom =</span> <span class="st">"area"</span>,</span>
<span id="cb25-90"><a href="#cb25-90" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"steelblue"</span>,</span>
<span id="cb25-91"><a href="#cb25-91" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">qnorm</span>(<span class="fl">0.025</span>, <span class="fl">162.5</span>, <span class="dv">12</span>))</span>
<span id="cb25-92"><a href="#cb25-92" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb25-93"><a href="#cb25-93" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb25-94"><a href="#cb25-94" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="fl">162.5</span>, <span class="at">sd =</span> <span class="dv">12</span>),</span>
<span id="cb25-95"><a href="#cb25-95" aria-hidden="true" tabindex="-1"></a>    <span class="at">geom =</span> <span class="st">"area"</span>,</span>
<span id="cb25-96"><a href="#cb25-96" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"steelblue"</span>,</span>
<span id="cb25-97"><a href="#cb25-97" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim =</span> <span class="fu">c</span>(<span class="fu">qnorm</span>(<span class="fl">0.975</span>, <span class="fl">162.5</span>, <span class="dv">12</span>), <span class="dv">200</span>)</span>
<span id="cb25-98"><a href="#cb25-98" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb25-99"><a href="#cb25-99" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="fl">162.5</span><span class="dv">-3</span><span class="sc">*</span><span class="dv">12</span>, <span class="fl">162.5</span><span class="sc">+</span><span class="dv">3</span><span class="sc">*</span><span class="dv">12</span>)) <span class="sc">+</span></span>
<span id="cb25-100"><a href="#cb25-100" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb25-101"><a href="#cb25-101" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Altezza (cm)"</span>,</span>
<span id="cb25-102"><a href="#cb25-102" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Densità"</span></span>
<span id="cb25-103"><a href="#cb25-103" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-104"><a href="#cb25-104" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-105"><a href="#cb25-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-106"><a href="#cb25-106" aria-hidden="true" tabindex="-1"></a>Il valore osservato della statistica test, ovvero $\bar{X} = 167.418$, non cade nella regione di rifiuto di $H_0$. Pertanto, sulla base delle informazioni disponibili, non possiamo rigettare $H_0$. E questo conclude la descrizione della logica del test $z$.</span>
<span id="cb25-107"><a href="#cb25-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-108"><a href="#cb25-108" aria-hidden="true" tabindex="-1"></a><span class="fu">### La statistica test Z</span></span>
<span id="cb25-109"><a href="#cb25-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-110"><a href="#cb25-110" aria-hidden="true" tabindex="-1"></a>Solitamente, per giungere alla conclusione descritta sopra si procede in modo diverso, ovvero applicando una semplice formula. In tale formula non facciamo altro che standardizzare la media campionaria all'interno della distribuzione campionaria costruita assumendo come vera $H_0$. In pratica, per eseguire tale standardizzazione sottraiamo dalla media campionaria la media della distribuzione ipotizzata da $H_0$ e dividiamo per la deviazione standard ipotizzata da $H_0$:</span>
<span id="cb25-111"><a href="#cb25-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-112"><a href="#cb25-112" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb25-113"><a href="#cb25-113" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb25-114"><a href="#cb25-114" aria-hidden="true" tabindex="-1"></a><span class="in">Z = \frac{\bar{X}_n - \mu_{\bar{X}}}{\sigma_{\bar{X}}} = \frac{\bar{X}_n - \mu_{\bar{X}}}{\frac{\sigma}{\sqrt{n}}}, </span></span>
<span id="cb25-115"><a href="#cb25-115" aria-hidden="true" tabindex="-1"></a><span class="in">(\#eq:testz)</span></span>
<span id="cb25-116"><a href="#cb25-116" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb25-117"><a href="#cb25-117" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-118"><a href="#cb25-118" aria-hidden="true" tabindex="-1"></a>ovvero</span>
<span id="cb25-119"><a href="#cb25-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-120"><a href="#cb25-120" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-121"><a href="#cb25-121" aria-hidden="true" tabindex="-1"></a>Z = \frac{167.418 - 162.5}{\frac{12}{\sqrt{20}}} = 1.8328.</span>
<span id="cb25-122"><a href="#cb25-122" aria-hidden="true" tabindex="-1"></a>$$ Il valore che abbiamo ottenuto corrisponde alla cosiddetta statistica test $Z$. Il test $z$ si chiama così proprio perché è basato sulla statistica test $Z$, e ovviamente $Z$ ha questo nome perché è una variabile aleatoria normale standard di media 0 e varianza 1.</span>
<span id="cb25-123"><a href="#cb25-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-124"><a href="#cb25-124" aria-hidden="true" tabindex="-1"></a><span class="fu">### I valori critici</span></span>
<span id="cb25-125"><a href="#cb25-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-126"><a href="#cb25-126" aria-hidden="true" tabindex="-1"></a>Quali sono i valori di una normale standard che lasciano in ciascuna delle due code il 2.5% dell'area sottesa alla funzione di densità $f(\bar{X}_{20} \mid H_0)$? Usando R troviamo</span>
<span id="cb25-127"><a href="#cb25-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-130"><a href="#cb25-130" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-131"><a href="#cb25-131" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.025</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb25-132"><a href="#cb25-132" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.975</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb25-133"><a href="#cb25-133" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-134"><a href="#cb25-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-135"><a href="#cb25-135" aria-hidden="true" tabindex="-1"></a>Risultano così specificate le due regioni di rifiuto $<span class="co">[</span><span class="ot">-\infty, -1.96</span><span class="co">]</span>$ e $<span class="co">[</span><span class="ot">1.96, +\infty</span><span class="co">]</span>$ illustrate nella @fig-regrifiutoaltezzabil2.</span>
<span id="cb25-136"><a href="#cb25-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-137"><a href="#cb25-137" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-regrifiutoaltezzabil2, fig.cap="Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l'ipotesi nulla $X \\sim \\mathcal{N}(\\mu = 0, \\sigma = 1)$. Le aree ombreggiate indicano le regioni di rifiuto di $H_0$ per un test bilaterale posto $\\alpha$ = 0.05."}</span></span>
<span id="cb25-138"><a href="#cb25-138" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)), <span class="fu">aes</span>(x)) <span class="sc">+</span> </span>
<span id="cb25-139"><a href="#cb25-139" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb25-140"><a href="#cb25-140" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb25-141"><a href="#cb25-141" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb25-142"><a href="#cb25-142" aria-hidden="true" tabindex="-1"></a>    <span class="at">geom =</span> <span class="st">"area"</span>,</span>
<span id="cb25-143"><a href="#cb25-143" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"steelblue"</span>,</span>
<span id="cb25-144"><a href="#cb25-144" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="fu">qnorm</span>(<span class="fl">0.025</span>, <span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb25-145"><a href="#cb25-145" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb25-146"><a href="#cb25-146" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb25-147"><a href="#cb25-147" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb25-148"><a href="#cb25-148" aria-hidden="true" tabindex="-1"></a>    <span class="at">geom =</span> <span class="st">"area"</span>,</span>
<span id="cb25-149"><a href="#cb25-149" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"steelblue"</span>,</span>
<span id="cb25-150"><a href="#cb25-150" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim =</span> <span class="fu">c</span>(<span class="fu">qnorm</span>(<span class="fl">0.975</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">10</span>)</span>
<span id="cb25-151"><a href="#cb25-151" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb25-152"><a href="#cb25-152" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb25-153"><a href="#cb25-153" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb25-154"><a href="#cb25-154" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Altezza (in unità di deviazione standard)"</span>,</span>
<span id="cb25-155"><a href="#cb25-155" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Densità"</span></span>
<span id="cb25-156"><a href="#cb25-156" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-157"><a href="#cb25-157" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-158"><a href="#cb25-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-159"><a href="#cb25-159" aria-hidden="true" tabindex="-1"></a>Non è una sorpresa che, facendo i calcoli in questo secondo modo, giungiamo alla stessa conclusione che avevamo trovato in precedenza: la statistica test non cade nella regione di rifiuto di $H_0$ e dunque non possiamo rifiutare l'ipotesi che i dati campionari provengano dalla popolazione specificata da $H_0$, ovvero $\mathcal{N}(\mu = 162.5, \sigma = 12)$.</span>
<span id="cb25-160"><a href="#cb25-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-161"><a href="#cb25-161" aria-hidden="true" tabindex="-1"></a><span class="fu">### Il valore-p</span></span>
<span id="cb25-162"><a href="#cb25-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-163"><a href="#cb25-163" aria-hidden="true" tabindex="-1"></a>Introduciamo ora un altro concetto centrale dell'inferenza frequentista: quello del valore-$p$. Il valore-$p$ viene usato per il test dell'ipotesi nulla in base alla regola seguente: se il valore-$p$ è minore di $\alpha$, allora rigettiamo $H_0$. Ottenere un valore-$p$ minore di $\alpha$, infatti, significa osservare una media campionaria molto distante dal valore ipotizzato dall'ipotesi nulla.</span>
<span id="cb25-164"><a href="#cb25-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-165"><a href="#cb25-165" aria-hidden="true" tabindex="-1"></a>Nelle parole di Neyman,</span>
<span id="cb25-166"><a href="#cb25-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-167"><a href="#cb25-167" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; il valore-$p$ è la probabilità di osservare un valore della statistica test uguale o più estremo di quello osservato qualora sia vera $H_0$.</span></span>
<span id="cb25-168"><a href="#cb25-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-169"><a href="#cb25-169" aria-hidden="true" tabindex="-1"></a>Detto in un altro modo: se il mondo avesse le caratteristiche specificate da $H_0$, il valore-$p$ descriverebbe la probabilità di osservare un campione che una media uguale a quella del campione osservato, o una media ancora più lontana da quella specificata da $H_0$. Si noti il carattere ipotetico di questa affermazione: "se il mondo avesse le caratteristiche specificate da $H_0$".</span>
<span id="cb25-170"><a href="#cb25-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-171"><a href="#cb25-171" aria-hidden="true" tabindex="-1"></a>Per trovare il valore-$p$, iniziamo a calcolare l'area sottesa alla funzione di densità $f(\bar{X}_{20} \mid H_0)$ nell'intervallo $<span class="co">[</span><span class="ot">162.5, \infty</span><span class="co">]</span>$:</span>
<span id="cb25-172"><a href="#cb25-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-175"><a href="#cb25-175" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-176"><a href="#cb25-176" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">1.8328</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb25-177"><a href="#cb25-177" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-178"><a href="#cb25-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-179"><a href="#cb25-179" aria-hidden="true" tabindex="-1"></a>Questo però non è il valore-$p$ per un test bidirezionale. Infatti, in un test bidirezionale noi rigettiamo $H_0$ sia quando troviamo valori estremi nella coda di destra di $f(\bar{X} \mid H_0)$ sia quando troviamo valori estremi nella coda di *sinistra* di $f(\bar{X}_{20} \mid H_0)$. Dunque, dobbiamo calcolare il valore-$p$ utilizzando il *valore assoluto* della statistica test, ovvero sommando le aree sottese a $f(\bar{X}_{20} \mid H_0)$ negli intervalli $[-\infty, \mathcal{G}_n]$ e $[\mathcal{G}_n, +\infty]$:</span>
<span id="cb25-180"><a href="#cb25-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-183"><a href="#cb25-183" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-184"><a href="#cb25-184" aria-hidden="true" tabindex="-1"></a>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">1.8328</span>, <span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">+</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.8328</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb25-185"><a href="#cb25-185" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-186"><a href="#cb25-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-187"><a href="#cb25-187" aria-hidden="true" tabindex="-1"></a>Dato che il valore-$p$ trovato nel test è maggiore di $\alpha = 0.05$, non rigettiamo l'ipotesi nulla. Ovviamente, giungiamo alla stessa conclusione sia confrontando la statistica test $\mathcal{G}_n$ con il valore critico, sia confrontando il valore-$p$ con $\alpha$.</span>
<span id="cb25-188"><a href="#cb25-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-189"><a href="#cb25-189" aria-hidden="true" tabindex="-1"></a><span class="fu">### Il test unilaterale</span></span>
<span id="cb25-190"><a href="#cb25-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-191"><a href="#cb25-191" aria-hidden="true" tabindex="-1"></a>Proseguiamo la discussione considerando ora il caso di un test monodirezionale. Un tale test risulta appropriato quando l'ipotesi alternativa ha la forma</span>
<span id="cb25-192"><a href="#cb25-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-193"><a href="#cb25-193" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-194"><a href="#cb25-194" aria-hidden="true" tabindex="-1"></a>H_1: X \sim \mathcal{N}(\mu &gt; 162.5, \sigma = 12),</span>
<span id="cb25-195"><a href="#cb25-195" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-196"><a href="#cb25-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-197"><a href="#cb25-197" aria-hidden="true" tabindex="-1"></a>per cui, di conseguenza, $H_0$ è:</span>
<span id="cb25-198"><a href="#cb25-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-199"><a href="#cb25-199" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-200"><a href="#cb25-200" aria-hidden="true" tabindex="-1"></a>H_0: X \sim \mathcal{N}(\mu \leq 162.5, \sigma = 12).</span>
<span id="cb25-201"><a href="#cb25-201" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-202"><a href="#cb25-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-203"><a href="#cb25-203" aria-hidden="true" tabindex="-1"></a>Come specificata sopra, l'ipotesi alternativa corrisponde all'ipotesi della ricerca secondo la quale le donne fiorentine, in media, sono più alte delle donne italiane.</span>
<span id="cb25-204"><a href="#cb25-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-205"><a href="#cb25-205" aria-hidden="true" tabindex="-1"></a>Anche nel caso di un test unilaterale, è necessario usare la statistica test $Z$ = 162.5. Ciò che è diverso rispetto al caso di un test bilaterale è dove viene collocata la regione di rifiuto $\mathcal{R}$ di $H_0$. Se l'ipotesi della ricerca è che le donne fiorentine, in media, sono più alte delle donne italiane, è chiaro che evidenze contrarie all'ipotesi nulla vengono fornite quando la media campionaria assume valori molto *superiori* al valore del parametro specificato da $H_0$, la quale afferma che l'altezza media delle donne fiorentine è uguale a quella delle donne italiane, o addirittura inferiore. Nel caso del test unidirezionale specificato sopra, quindi, la regione di rifiuto $\mathcal{R}$ sarà collocata sulla sola coda destra della densità $f(\bar{X}_{n} \mid H_0)$ -- si veda la @fig-regrifiutoaltezzabil3.</span>
<span id="cb25-206"><a href="#cb25-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-207"><a href="#cb25-207" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-regrifiutoaltezzabil3, fig.cap="Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l'ipotesi nulla $X \\sim \\mathcal{N}(\\mu = 0, \\sigma = 1)$. L'area ombreggiata indica la regione di rifiuto di $H_0$ per un test unilaterale destro posto $\\alpha$ = 0.05."}</span></span>
<span id="cb25-208"><a href="#cb25-208" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)), <span class="fu">aes</span>(x)) <span class="sc">+</span> </span>
<span id="cb25-209"><a href="#cb25-209" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb25-210"><a href="#cb25-210" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb25-211"><a href="#cb25-211" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>),</span>
<span id="cb25-212"><a href="#cb25-212" aria-hidden="true" tabindex="-1"></a>    <span class="at">geom =</span> <span class="st">"area"</span>,</span>
<span id="cb25-213"><a href="#cb25-213" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"steelblue"</span>,</span>
<span id="cb25-214"><a href="#cb25-214" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim =</span> <span class="fu">c</span>(<span class="fu">qnorm</span>(<span class="fl">0.95</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">10</span>)</span>
<span id="cb25-215"><a href="#cb25-215" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb25-216"><a href="#cb25-216" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb25-217"><a href="#cb25-217" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb25-218"><a href="#cb25-218" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Altezza (in unità di deviazione standard)"</span>,</span>
<span id="cb25-219"><a href="#cb25-219" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Densità"</span></span>
<span id="cb25-220"><a href="#cb25-220" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb25-221"><a href="#cb25-221" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-222"><a href="#cb25-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-223"><a href="#cb25-223" aria-hidden="true" tabindex="-1"></a>In generale, in un test unidirezionale il valore-$p$ corrisponde all'area sottesa alla funzione di densità $f(\mathcal{G}_{n} \mid H_0)$ nell'intervallo $[\mathcal{G}_n, +\infty]$, se l'ipotesi nulla ha la forma $H_0: \mu \leq \mu_0$, oppure nell'intervallo $[-\infty, \mathcal{G}_n]$, se l'ipotesi nulla ha la forma $H_0: \mu \geq \mu_0$. A differenza del caso bidirezionale, dunque, tutta la regione di rifiuto $\mathcal{R}$ è collocata su una sola coda della distribuzione campionaria della statistica test $f(\bar{X}_{n} \mid H_0)$.</span>
<span id="cb25-224"><a href="#cb25-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-225"><a href="#cb25-225" aria-hidden="true" tabindex="-1"></a>Nel caso dell'esempio che stiamo discutendo, $Z = 1.8328$ e, dunque, cade nella regione di rifiuto di $H_0$ per un test unilaterale superiore. Possiamo dunque rigettare $H_0$ e concludere che il campione esaminato fornisce evidenza che le donne fiorentine tendono ad essere più alte della media nazionale.</span>
<span id="cb25-226"><a href="#cb25-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-227"><a href="#cb25-227" aria-hidden="true" tabindex="-1"></a>Ma perché possiamo rifiutare $H_0$ nel caso di un test unidirezionale ma non possiamo farlo quando usiamo un test bidirezionale? Perché il test di ipotesi risulta più conservativo quando il test è bidirezionale. Questo ha senso. L'ipotesi della ricerca è molto vaga: dice semplicemente che succederà qualcosa di diverso dal caso di non interesse, ma non sa dire cosa. Di conseguenza, l'ipotesi nulla può essere rigettata solo quando osserviamo un risultato campionario veramente estremo. D'altra parte, invece, bastano evidenze "più deboli" per rigettare $H_0$ quando sappiamo dove guardare, quando possiamo fare delle predizioni su quello che succederà. La procedura di test di ipotesi, quindi, ci incoraggia ad essere precisi, ad avere la capacità di fare delle predizioni direzionali, piuttosto di chiederci semplicemente se è possibile osservare qualcosa, qualunque cosa, di diverso dall'evento di non interesse specificato da $H_0$.</span>
<span id="cb25-228"><a href="#cb25-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-229"><a href="#cb25-229" aria-hidden="true" tabindex="-1"></a><span class="fu">## Test direzionali e non direzionali</span></span>
<span id="cb25-230"><a href="#cb25-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-231"><a href="#cb25-231" aria-hidden="true" tabindex="-1"></a>Riassumendo, un test d'ipotesi può essere bidirezionale, unidirezionale superiore e unidirezionale inferiore.</span>
<span id="cb25-232"><a href="#cb25-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-233"><a href="#cb25-233" aria-hidden="true" tabindex="-1"></a><span class="fu">### Test bidirezionale</span></span>
<span id="cb25-234"><a href="#cb25-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-235"><a href="#cb25-235" aria-hidden="true" tabindex="-1"></a>Per un'ipotesi nulla $$H_0: \mu = \mu_0$$ nel caso di un test bidirezionale la regione di non rifiuto $\mathcal{A}$ di $H_0$ è</span>
<span id="cb25-236"><a href="#cb25-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-237"><a href="#cb25-237" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-238"><a href="#cb25-238" aria-hidden="true" tabindex="-1"></a>\mathcal{A}: \quad \mu_0 - \frac{\sigma}{\sqrt{n}}z_{1-\alpha/2} \leq \mu_n \leq \mu_0 + \frac{\sigma}{\sqrt{n}}z_{1-\alpha/2},</span>
<span id="cb25-239"><a href="#cb25-239" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-240"><a href="#cb25-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-241"><a href="#cb25-241" aria-hidden="true" tabindex="-1"></a>dove $\mu_n$ è la realizzazione della statistica test, ovvero la media campionaria, $n$ è l'ampiezza del campione e $z_{1-\alpha/2}$ è il quantile di ordine $1-\alpha/2$ per la variabile standardizzata</span>
<span id="cb25-242"><a href="#cb25-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-243"><a href="#cb25-243" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-244"><a href="#cb25-244" aria-hidden="true" tabindex="-1"></a>Z_n = \frac{\mu_n - \mu_0}{\sigma/\sqrt{n}}.\notag</span>
<span id="cb25-245"><a href="#cb25-245" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-246"><a href="#cb25-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-247"><a href="#cb25-247" aria-hidden="true" tabindex="-1"></a><span class="fu">### Test unidirezionale superiore</span></span>
<span id="cb25-248"><a href="#cb25-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-249"><a href="#cb25-249" aria-hidden="true" tabindex="-1"></a>La regione di non rifiuto di $H_0: \mu \leq \mu_0$, con $H_1: \mu &gt; \mu_0$, è l'intervallo aperto a sinistra:</span>
<span id="cb25-250"><a href="#cb25-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-251"><a href="#cb25-251" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-252"><a href="#cb25-252" aria-hidden="true" tabindex="-1"></a>\mathcal{A}: \quad -\infty &lt; \mu_n \leq \mu_0 + \frac{\sigma}{\sqrt{n}}z_{1-\alpha},</span>
<span id="cb25-253"><a href="#cb25-253" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-254"><a href="#cb25-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-255"><a href="#cb25-255" aria-hidden="true" tabindex="-1"></a>dove $z_{1-\alpha}$ è il quantile di ordine $1-\alpha$ della normale standard.</span>
<span id="cb25-256"><a href="#cb25-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-257"><a href="#cb25-257" aria-hidden="true" tabindex="-1"></a><span class="fu">### Test unidirezionale inferiore</span></span>
<span id="cb25-258"><a href="#cb25-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-259"><a href="#cb25-259" aria-hidden="true" tabindex="-1"></a>La regione di non rifiuto di $H_0: \mu \geq \mu_0$, con $H_1: \mu &lt; \mu_0$, è l'intervallo aperto a destra:</span>
<span id="cb25-260"><a href="#cb25-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-261"><a href="#cb25-261" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-262"><a href="#cb25-262" aria-hidden="true" tabindex="-1"></a>\mathcal{A}: \quad \mu_0 - \frac{\sigma}{\sqrt{n}}z_{1-\alpha} \leq \mu_n &lt; +\infty,</span>
<span id="cb25-263"><a href="#cb25-263" aria-hidden="true" tabindex="-1"></a>$$ dove $z_{1-\alpha}$ è il quantile di ordine $1-\alpha$ della normale standard.</span>
<span id="cb25-264"><a href="#cb25-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-265"><a href="#cb25-265" aria-hidden="true" tabindex="-1"></a><span class="fu">### Eseguire il test Z con R</span></span>
<span id="cb25-266"><a href="#cb25-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-267"><a href="#cb25-267" aria-hidden="true" tabindex="-1"></a>Come abbiamo detto in precedenza, nella pratica concreta dell'analisi dei dati il test $Z$ non viene quasi mai usato. Il suo uso è talmente raro che in R non c'è neppure una funzione che lo implementa. Vediamo comunque come svolgere i calcoli con R. Se i dati siano contenuti nel vettore <span class="in">`x`</span>, non dobbiamo fare altro che calcolare il valore standardizzato della media campionaria assumendo come vera l'ipotesi nulla:</span>
<span id="cb25-268"><a href="#cb25-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-271"><a href="#cb25-271" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-272"><a href="#cb25-272" aria-hidden="true" tabindex="-1"></a>mu_0 <span class="ot">&lt;-</span> <span class="fl">162.5</span></span>
<span id="cb25-273"><a href="#cb25-273" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">12</span></span>
<span id="cb25-274"><a href="#cb25-274" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb25-275"><a href="#cb25-275" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> (<span class="fu">mean</span>(x) <span class="sc">-</span> mu_0) <span class="sc">/</span> (sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n))</span>
<span id="cb25-276"><a href="#cb25-276" aria-hidden="true" tabindex="-1"></a>z</span>
<span id="cb25-277"><a href="#cb25-277" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-278"><a href="#cb25-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-279"><a href="#cb25-279" aria-hidden="true" tabindex="-1"></a>Dato che il valore-$p$</span>
<span id="cb25-280"><a href="#cb25-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-283"><a href="#cb25-283" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-284"><a href="#cb25-284" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(z, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb25-285"><a href="#cb25-285" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-286"><a href="#cb25-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-287"><a href="#cb25-287" aria-hidden="true" tabindex="-1"></a>è minore di $\alpha = 0.05$, rifiutiamo $H_0$. Riportiamo il risultato nel modo seguente.</span>
<span id="cb25-288"><a href="#cb25-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-289"><a href="#cb25-289" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Avendo osservato una media campionaria pari a 167.418 cm in un campione casuale di ampiezza $n=20$, assumendo che la deviazione standard della popolazione sia uguale a 12 cm, possiamo concludere che le donne fiorentine tendono ad avere un'altezza maggiore della media nazionale ($z = 1.8328$, $n = 20$, $p = 0.0334$, test unidirezionale).</span></span>
<span id="cb25-290"><a href="#cb25-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-291"><a href="#cb25-291" aria-hidden="true" tabindex="-1"></a><span class="fu">### Assunzioni del test Z</span></span>
<span id="cb25-292"><a href="#cb25-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-293"><a href="#cb25-293" aria-hidden="true" tabindex="-1"></a>Tutti i test statistici fanno delle assunzioni a proposito delle caratteristiche della popolazione da cui sono stati tratti i dati. Alcuni test fanno delle assunzioni ragionevoli, mentre altri test no. Il test $z$ che abbiamo appena descritto è basato sulle seguenti ipotesi:</span>
<span id="cb25-294"><a href="#cb25-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-295"><a href="#cb25-295" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>*Normalità*. Il test $z$ presuppone che la vera distribuzione della popolazione sia normale. Tale ipotesi è spesso soddisfatta e può essere verificata.</span>
<span id="cb25-296"><a href="#cb25-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-297"><a href="#cb25-297" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>*Indipendenza*. La seconda ipotesi del test è che le osservazioni campionarie non sono correlate tra loro, né associate tra loro in qualunque modo. Tale assunzione è difficile da valutare con metodi statistici: deve invece essere garantita dal disegno sperimentale che viene utilizzato per raccogliere i dati. Un caso ovvio nel quale tale assunzione viene falsificata è quando i dati riguardano osservazioni compiute sugli stessi soggetti in condizioni diverse o in tempi diversi. È chiaro in questo caso che ci sarà una correlazione tra le osservazioni. Per esempio, se misuriamo i tempi di reazione, è ovvio che, se un soggetto tende ad essere più veloce della media nella condizione $A$, tenderà anche ad essere più veloce della media nella condizione $B$. Lo stesso si può dire per un soggetto che tende ad essere più lento della media. Pertanto, sapere se un soggetto è più veloce della media nella condizione $A$ ci consente di fare delle predizioni sul suo comportamento nella condizione $B$ -- ovvero, i dati sono correlati e l'assunzione di indipendenza viene violata. L'assunzione di indipendenza, invece, non viene violata quando nelle condizioni $A$ e $B$ dell'esempio abbiamo i dati di soggetti diversi. Conoscendo come si sono comportanti i soggetti nella condizione $A$ non ci consente di fare alcuna predizione su come si comporteranno altri soggetti nella condizione $B$ -- ovvero, i dati sono indipendenti.</span>
<span id="cb25-298"><a href="#cb25-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-299"><a href="#cb25-299" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>*Deviazione standard nota*. La terza ipotesi del test $z$ è che la deviazione standard della popolazione sia nota al ricercatore. Questa assunzione è irragionevole: ciò non si verifica in nessuna applicazione concreta dell'analisi dei dati. In altre parole, questa ipotesi è sempre falsa.</span>
<span id="cb25-300"><a href="#cb25-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-301"><a href="#cb25-301" aria-hidden="true" tabindex="-1"></a>Dato che è sempre del tutto fuori luogo assumere che $\sigma$ sia nota, poniamoci il problema di cosa fare quando non vogliamo assumere qualcosa che è certamente falso. Questo ci conduce al cosiddetto test $t$ di Student.</span>
<span id="cb25-302"><a href="#cb25-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-303"><a href="#cb25-303" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modello Normale: varianza sconosciuta</span></span>
<span id="cb25-304"><a href="#cb25-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-305"><a href="#cb25-305" aria-hidden="true" tabindex="-1"></a>Se la varianza $\sigma^2$ della popolazione normale non è nota essa deve essere stimata con la statistica campionaria corretta $s_n^2$. Il test di ipotesi si esegue valutando se il valore empirico della statistica $$T_n = \frac{(\bar{X}_n -\mu_0)\sqrt{n}}{\hat{s}_n}$$ appartiene alla regione di accettazione di $H_0$ oppure alla regione di rifiuto dell'ipotesi nulla.</span>
<span id="cb25-306"><a href="#cb25-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-307"><a href="#cb25-307" aria-hidden="true" tabindex="-1"></a>Se il test è bidirezionale, la regione di non rifiuto di $H_0$ è fornita dal seguente intervallo:</span>
<span id="cb25-308"><a href="#cb25-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-309"><a href="#cb25-309" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-310"><a href="#cb25-310" aria-hidden="true" tabindex="-1"></a>\mathcal{A}: \quad \mu_0 - \frac{s_n}{\sqrt{n}}t_{1-\alpha/2} \leq \mu_n \leq \mu_0 + \frac{s_n}{\sqrt{n}}t_{1-\alpha/2},</span>
<span id="cb25-311"><a href="#cb25-311" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-312"><a href="#cb25-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-313"><a href="#cb25-313" aria-hidden="true" tabindex="-1"></a>dove $s_n$ è il valore empirico della stima di $\sigma$ e $t_{1-\alpha/2}$ è il quantile di ordine $1-\alpha/2$ della distribuzione $t$-Student con $n-1$ gradi di libertà. In modo analogo, si ricavano le regioni di non rifiuto per un test unidirezionale superiore:</span>
<span id="cb25-314"><a href="#cb25-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-315"><a href="#cb25-315" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-316"><a href="#cb25-316" aria-hidden="true" tabindex="-1"></a>\mathcal{A}: \quad -\infty &lt; \mu_n \leq \mu_0 + \frac{s_n}{\sqrt{n}}t_{1-\alpha},</span>
<span id="cb25-317"><a href="#cb25-317" aria-hidden="true" tabindex="-1"></a>$$ oppure unidirezionale inferiore:</span>
<span id="cb25-318"><a href="#cb25-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-319"><a href="#cb25-319" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-320"><a href="#cb25-320" aria-hidden="true" tabindex="-1"></a>\mathcal{A}: \quad \mu_0 - \frac{s_n}{\sqrt{n}}t_{1-\alpha} \leq \mu_n &lt; +\infty.</span>
<span id="cb25-321"><a href="#cb25-321" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-322"><a href="#cb25-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-323"><a href="#cb25-323" aria-hidden="true" tabindex="-1"></a>Se il valore empirico della statistica $T_n$ ricavato dal campione ricade in una delle regioni sopra definite l'ipotesi nulla non può essere rifiutata.</span>
<span id="cb25-324"><a href="#cb25-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-325"><a href="#cb25-325" aria-hidden="true" tabindex="-1"></a>Quanto descritto sopra mostra che, quando ci basiamo su una *stima* della deviazione standard della popolazione, dobbiamo fare degli aggiustamenti alla procedura che abbiamo adottato in precedenza. Questi aggiustamenti furono introdotti nel 1908 da William Sealy Gosset, che all'epoca lavorava come chimico per il birrificio della Guinness. Dal momento che Guinness non vedeva di buon occhio il fatto che suoi dipendenti pubblicassero delle analisi statistiche di ciò che ritenevano essere un segreto commerciale, Gosset pubblicò il lavoro sotto lo pseudonimo "A Student", da cui il nome "test *t* di Student". Gosset capì che la stima di $\sigma$ introduce un ulteriore elemento di incertezza nella procedura di test di ipotesi. Di conseguenza, si rese conto che non è più possibile usare $\mathcal{N}(0, 1)$ quale funzione di densità che descrive $f(\bar{X}_n \mid H_0)$, ma è invece necessario utilizzare una diversa funzione di densità che è, appunto, la $t$ di Student.</span>
<span id="cb25-326"><a href="#cb25-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-327"><a href="#cb25-327" aria-hidden="true" tabindex="-1"></a>In precedenza abbiamo visto che ci sono infinite distribuzioni $t$ di Student, ciascuna definita da un diverso numero di gradi di libertà. Abbiamo anche visto che la distribuzione $t$-Student tende alla normale standard per $n \rightarrow \infty$, per cui quando $n$ è sufficientemente grande ($n &gt; 30$), facendo un'approssimazione, i quantili $t_{1-\alpha/2}$ e $t_{1-\alpha}$ possono essere sostituiti dai corrispondenti quantili $z_{1-\alpha/2}$ e $z_{1-\alpha}$ della normale standard.</span>
<span id="cb25-328"><a href="#cb25-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-329"><a href="#cb25-329" aria-hidden="true" tabindex="-1"></a><span class="fu">### Effetto Stroop</span></span>
<span id="cb25-330"><a href="#cb25-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-331"><a href="#cb25-331" aria-hidden="true" tabindex="-1"></a>Per fare un esempio concreto, supponiamo che ad un campione di 59 studenti di psicologia sia stato chiesto di completare una variante del compito Stroop che utilizza come stimoli facce espressive e le parole "felice" o "triste" <span class="co">[</span><span class="ot">@caudek2014individual</span><span class="co">]</span>. In ogni prova dell'esperimento, i soggetti devono classificare l'immagine di un volto (sorridente o triste) nelle due categorie "volto felice" o "volto triste", ignorando la parola sovrapposta all'immagine. La parola irrilevante per il compito poteva essere compatibile con l'espressione del volto (es., volto felice e parola "felice": condizione congruente) o incompatibile con essa (es., volto felice e parola "triste": condizione incongruente). L'effetto Stroop consiste nel ritardo di elaborazione dell'espressione del volto che si riflette in un rallentamento dei tempi di reazione e nell'aumento degli errori nella condizione incongruente rispetto a quella congruente.</span>
<span id="cb25-332"><a href="#cb25-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-333"><a href="#cb25-333" aria-hidden="true" tabindex="-1"></a>Per ciascun partecipante, su un totale di 180 prove, è stato calcolato l'effetto Stroop, ovvero la differenza tra la media dei tempi di reazione nella condizione incongruente e nella condizione congruente. Valori positivi significano che i tempi di reazione medi nella condizione incongruente sono maggiori di quelli nella condizione congruente.</span>
<span id="cb25-334"><a href="#cb25-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-335"><a href="#cb25-335" aria-hidden="true" tabindex="-1"></a>Per i $59$ soggetti dell'esperimento eseguito da @caudek2014individual, l'effetto Stroop è riportato qui sotto</span>
<span id="cb25-336"><a href="#cb25-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-339"><a href="#cb25-339" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-340"><a href="#cb25-340" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">110</span>, <span class="dv">196</span>, <span class="sc">-</span><span class="dv">58</span>, <span class="sc">-</span><span class="dv">54</span>, <span class="sc">-</span><span class="dv">162</span>, <span class="dv">11</span>, <span class="dv">6</span>, <span class="sc">-</span><span class="dv">25</span>, <span class="dv">27</span>, <span class="dv">81</span>, <span class="sc">-</span><span class="dv">40</span>, <span class="sc">-</span><span class="dv">91</span>, <span class="sc">-</span><span class="dv">40</span>, <span class="dv">39</span>, <span class="dv">23</span>, <span class="sc">-</span><span class="dv">32</span>, <span class="dv">157</span>,  <span class="dv">72</span>, <span class="dv">89</span>, <span class="dv">9</span>, <span class="dv">60</span>, <span class="dv">239</span>, <span class="dv">139</span>, <span class="dv">8</span>, <span class="sc">-</span><span class="dv">65</span>, <span class="dv">11</span>, <span class="dv">18</span>, <span class="dv">51</span>, <span class="dv">53</span>, <span class="dv">74</span>, <span class="dv">105</span>, <span class="dv">245</span>, <span class="sc">-</span><span class="dv">16</span>, <span class="sc">-</span><span class="dv">69</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">11</span>, <span class="dv">65</span>, <span class="sc">-</span><span class="dv">10</span>, <span class="dv">118</span>, <span class="sc">-</span><span class="dv">62</span>, <span class="dv">48</span>, <span class="sc">-</span><span class="dv">78</span>, <span class="dv">96</span>, <span class="sc">-</span><span class="dv">122</span>, <span class="dv">7</span>, <span class="dv">83</span>, <span class="sc">-</span><span class="dv">60</span>, <span class="dv">57</span>, <span class="dv">111</span>, <span class="sc">-</span><span class="dv">11</span>, <span class="dv">34</span>, <span class="dv">27</span>, <span class="dv">84</span>, <span class="dv">240</span>, <span class="sc">-</span><span class="dv">67</span>, <span class="dv">111</span>, <span class="dv">92</span>, <span class="sc">-</span><span class="dv">93</span>, <span class="dv">13</span>)</span>
<span id="cb25-341"><a href="#cb25-341" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-342"><a href="#cb25-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-343"><a href="#cb25-343" aria-hidden="true" tabindex="-1"></a>e vale, in media</span>
<span id="cb25-344"><a href="#cb25-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-347"><a href="#cb25-347" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-348"><a href="#cb25-348" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span>
<span id="cb25-349"><a href="#cb25-349" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-350"><a href="#cb25-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-351"><a href="#cb25-351" aria-hidden="true" tabindex="-1"></a>con una deviazione standard pari a</span>
<span id="cb25-352"><a href="#cb25-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-355"><a href="#cb25-355" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-356"><a href="#cb25-356" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(x)</span>
<span id="cb25-357"><a href="#cb25-357" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-358"><a href="#cb25-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-359"><a href="#cb25-359" aria-hidden="true" tabindex="-1"></a>L'ipotesi nulla è che la prestazione non subisca un effetto di interferenza da parte della parola irrilevante, ovvero che la media dell'effetto Stroop sia 0, $H_0: \mu = 0$. In base all'ipotesi alternativa, invece, la media dell'effetto Stroop è diversa da 0, $H_1: \mu \neq 0$.</span>
<span id="cb25-360"><a href="#cb25-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-361"><a href="#cb25-361" aria-hidden="true" tabindex="-1"></a>Poniamoci il problema di svolgere il test $t$ di Student per questi dati.</span>
<span id="cb25-362"><a href="#cb25-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-363"><a href="#cb25-363" aria-hidden="true" tabindex="-1"></a>Per calcolare il valore $T$ del test $t$ di Student dobbiamo standardizzare la media campionaria, ovvero dobbiamo specificare la posizione della statistica test all'interno della sua distribuzione avendo assunto come vera l'ipotesi nulla, ovvero avendo assunto che la media della popolazione sia $0$. La statistica test dunque si ottiene dividendo la media campionaria per una stima dell'errore standard della media:</span>
<span id="cb25-364"><a href="#cb25-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-365"><a href="#cb25-365" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-366"><a href="#cb25-366" aria-hidden="true" tabindex="-1"></a>T = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}} = \frac{27.52542 - 0}{\frac{88.2878}{\sqrt{59}}} = 2.394745.</span>
<span id="cb25-367"><a href="#cb25-367" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-368"><a href="#cb25-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-369"><a href="#cb25-369" aria-hidden="true" tabindex="-1"></a>In R il calcolo si svolge nel modo seguente:</span>
<span id="cb25-370"><a href="#cb25-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-373"><a href="#cb25-373" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-374"><a href="#cb25-374" aria-hidden="true" tabindex="-1"></a>T <span class="ot">&lt;-</span> (<span class="fu">mean</span>(x)) <span class="sc">/</span> (<span class="fu">sd</span>(x) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">length</span>(x)))</span>
<span id="cb25-375"><a href="#cb25-375" aria-hidden="true" tabindex="-1"></a>T</span>
<span id="cb25-376"><a href="#cb25-376" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-377"><a href="#cb25-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-378"><a href="#cb25-378" aria-hidden="true" tabindex="-1"></a>Si noti che, nel test $z$ l'errore standard era dato da $\sigma/\sqrt{n}$; nel test $t$ di Student, invece, non conoscendo $\sigma$, otteniamo una stima dell'errore standard mediante il rapporto $\hat{\sigma}/\sqrt{n} = s_n/\sqrt{n}$, dove $s_n$ è la stima corretta della deviazione standard della popolazione.</span>
<span id="cb25-379"><a href="#cb25-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-380"><a href="#cb25-380" aria-hidden="true" tabindex="-1"></a>Nel caso presente, per trovare il valore-$p$ è necessario calcolare l'area sottesa alla densità $t_{59-1}$ negli intervalli $<span class="co">[</span><span class="ot">-\infty, -T</span><span class="co">]</span>$ e $<span class="co">[</span><span class="ot">T, \infty</span><span class="co">]</span>$, ovvero nel caso di valori della statistica $T$ maggiori in valore assoluto al valore osservato. Usando R otteniamo</span>
<span id="cb25-381"><a href="#cb25-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-384"><a href="#cb25-384" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-385"><a href="#cb25-385" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pt</span>(T, <span class="dv">59</span> <span class="sc">-</span> <span class="dv">1</span>)) </span>
<span id="cb25-386"><a href="#cb25-386" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-387"><a href="#cb25-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-388"><a href="#cb25-388" aria-hidden="true" tabindex="-1"></a>Posto $\alpha = 0.05$, i limiti della regione di rifiuto nel caso di un test bidirezionale sono dati dai quantili della distribuzione $t$ di Student con $n-1$ gradi di libertà a cui è associata una probabilità pari a 0.025 in ciascuna coda. Mediante</span>
<span id="cb25-389"><a href="#cb25-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-392"><a href="#cb25-392" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-393"><a href="#cb25-393" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="dv">59</span> <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb25-394"><a href="#cb25-394" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-395"><a href="#cb25-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-396"><a href="#cb25-396" aria-hidden="true" tabindex="-1"></a>si trovano i valori critici di $-2.00$ e $2.00$. Tutti i valori della statistica $T$ minori di $-2.00$ o maggiori di $2.00$ portano dunque al rifiuto di $H_0$.</span>
<span id="cb25-397"><a href="#cb25-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-398"><a href="#cb25-398" aria-hidden="true" tabindex="-1"></a>Come abbiamo visto in precedenza, ci sono due modi equivalenti per svolgere il test dell'ipotesi: confrontare il valore-$p$ con $\alpha$ o stabilire se il valore osservato della statistica $T$ cade nella regione di rifiuto di $H_0$. Nel caso presente, il valore-$p$ è minore di $\alpha$ ($0.0199 &lt; 0.05$) e dunque rifiutiamo $H_0$. Oppure possiamo confrontare il valore della statistica test con i limiti della regione di rifiuto dell'ipotesi nulla. La statistica $T = 2.39$ ha un valore superiore del valore critico che delimita la regione di rifiuto nella coda di destra della distribuzione di $T$: 2.39 <span class="sc">\&gt;</span> 2.00. Dato che il valore $T$ osservato cade nella regione di rifiuto concludiamo rifiutando $H_0$.</span>
<span id="cb25-399"><a href="#cb25-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-400"><a href="#cb25-400" aria-hidden="true" tabindex="-1"></a>Calcoliamo anche l'intervallo di confidenza al 95%:</span>
<span id="cb25-401"><a href="#cb25-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-402"><a href="#cb25-402" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-403"><a href="#cb25-403" aria-hidden="true" tabindex="-1"></a>\bar{X}_n \pm t^*\frac{s_n}{\sqrt{n}} = 27.52542 \pm \frac{88.2878}{\sqrt{59}} = <span class="co">[</span><span class="ot">4.52, 50.53</span><span class="co">]</span>,</span>
<span id="cb25-404"><a href="#cb25-404" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-405"><a href="#cb25-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-406"><a href="#cb25-406" aria-hidden="true" tabindex="-1"></a>laddove $t^*$ è il quantile della $t$ di Student con $n-1 = 59-1$ gradi di libertà di ordine $1 - \alpha/2$, ovvero</span>
<span id="cb25-407"><a href="#cb25-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-410"><a href="#cb25-410" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-411"><a href="#cb25-411" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="dv">58</span>)</span>
<span id="cb25-412"><a href="#cb25-412" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-413"><a href="#cb25-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-414"><a href="#cb25-414" aria-hidden="true" tabindex="-1"></a>Possiamo riportare i risultati nel modo seguente.</span>
<span id="cb25-415"><a href="#cb25-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-416"><a href="#cb25-416" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; L'esperimento ci fornisce evidenze di un effetto di interferenza pari a 27.5 ms, $t_{59} = 2.39$, $p = 0.0199$, CI$_{95}$ = </span><span class="sc">\[</span><span class="at">4.52, 50.53</span><span class="sc">\]</span><span class="at">.</span></span>
<span id="cb25-417"><a href="#cb25-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-418"><a href="#cb25-418" aria-hidden="true" tabindex="-1"></a>laddove la notazione $t_{59}$ indica il fatto che abbiamo eseguito un test $t$ di Student con 59 gradi di libertà.</span>
<span id="cb25-419"><a href="#cb25-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-420"><a href="#cb25-420" aria-hidden="true" tabindex="-1"></a><span class="fu">### Test T di Student con R</span></span>
<span id="cb25-421"><a href="#cb25-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-422"><a href="#cb25-422" aria-hidden="true" tabindex="-1"></a>La procedura del test $t$ di Student è quasi identica a quella del test $z$, a parte il fatto che abbiamo usato la stima della deviazione standard della popolazione al posto di $\sigma$ e poi abbiamo valutato la nostra ipotesi usando la distribuzione $t$ con $n-1$ gradi di libertà al posto di $\mathcal{N}(0, 1)$. Dato che è sempre possibile fare degli errori quando svolgiamo dei calcoli tediosi, controlliamo se i risultati ottenuti sono corretti. Dopo avere inserito i dati nel vettore <span class="in">`x`</span>, confrontiamo i risultati che abbiamo svolto a mano nell'esercizio sull'effetto Stroop con quelli forniti dalla funzione <span class="in">`t.test()`</span> di :</span>
<span id="cb25-423"><a href="#cb25-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-426"><a href="#cb25-426" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-427"><a href="#cb25-427" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(x)</span>
<span id="cb25-428"><a href="#cb25-428" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-429"><a href="#cb25-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-430"><a href="#cb25-430" aria-hidden="true" tabindex="-1"></a>I risultati sono identici a quelli che abbiamo trovato svolgendo i calcoli "a mano".</span>
<span id="cb25-431"><a href="#cb25-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-432"><a href="#cb25-432" aria-hidden="true" tabindex="-1"></a><span class="fu">## Test unidirezionale</span></span>
<span id="cb25-433"><a href="#cb25-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-434"><a href="#cb25-434" aria-hidden="true" tabindex="-1"></a>In realtà, si parla di effetto Stroop solo quando i tempi di reazione sono maggiori, in media, nella condizione incongruente rispetto a quella congruente. Nel caso presente, dunque, è sensato porre tutta la regione di rifiuto nella coda di destra della distribuzione della statistica $T$. Per calcolare il valore-$p$ di un test unidirezionale superiore è sufficiente calcolare l'area sottesa alla funzione di densità nell'intervallo $<span class="co">[</span><span class="ot">T, +\infty</span><span class="co">]</span>$. Posto $\alpha = 0.05$, il valore critico della regione di rifiuto, nel caso di un test unidirezionale superiore, è dato dal quantile della distribuzione $t$ di Student con $n-1$ gradi di libertà a cui è associata una probabilità pari a 0.05 nella coda di destra. Utilizzando <span class="in">`qt(0.95, 59 - 1)`</span> tale valore risulta essere pari a $1.67$. Tutti i valori della statistica $T$ maggiori di 1.67 portano al rifiuto di $H_0$. È ovvio che, se abbiamo trovato un risultato statisticamente significativo con un test bilaterale la stessa conclusione sarà ottenuta, a maggior ragione, con un test unilaterale se la statistica test cade nella coda appropriata della distribuzione campionaria (ovvero, nel caso presente, nella coda di destra). In conclusione, il test dell'ipotesi nulla fornisce evidenze coerenti con l'idea che i tempi di reazione dei soggetti di questo esperimento tendano ad essere più lenti, in media, nella nella condizione incongruente rispetto a quella congruente.</span>
<span id="cb25-435"><a href="#cb25-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-436"><a href="#cb25-436" aria-hidden="true" tabindex="-1"></a><span class="fu">### Assunzioni</span></span>
<span id="cb25-437"><a href="#cb25-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-438"><a href="#cb25-438" aria-hidden="true" tabindex="-1"></a>Dato che il test $t$ di Student per un campione non è altro che il test $z$ nel caso in cui $\sigma$ non viene considerata come nota, non dovrebbe sorprenderci che le assunzioni del test $t$ di Student siano molto simili a quelle del test $z$.</span>
<span id="cb25-439"><a href="#cb25-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-440"><a href="#cb25-440" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>*Normalità.* Assumiamo che la distribuzione della popolazione sia normale.</span>
<span id="cb25-441"><a href="#cb25-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-442"><a href="#cb25-442" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>*Indipendenza.* Dobbiamo assumere che le osservazioni nel nostro campione siano generate indipendentemente le une dalle altre.</span>
<span id="cb25-443"><a href="#cb25-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-444"><a href="#cb25-444" aria-hidden="true" tabindex="-1"></a>Queste due assunzioni sembrano sensate. Di conseguenza, il test $t$ di Student per un campione viene ampiamente usato nella pratica corrente per svolgere il confronto tra una media campionaria e la media ipotizzata di una popolazione.</span>
<span id="cb25-445"><a href="#cb25-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-446"><a href="#cb25-446" aria-hidden="true" tabindex="-1"></a><span class="fu">### Popolazione non Normale</span></span>
<span id="cb25-447"><a href="#cb25-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-448"><a href="#cb25-448" aria-hidden="true" tabindex="-1"></a>Abbiamo visto in precedenza che la distribuzione campionaria della media, al crescere di $n$, è ben approssimata dalla legge normale $\mathcal{N}(\mu, \sigma^2/n)$, *indipendentemente dalla forma della distribuzione della popolazione*. Di conseguenza, se $n$ è sufficientemente grande ($n &gt; 30$) e se $H_0$ è vera, la distribuzione delle medie campionarie si può approssimare con una legge normale avente media $\mu_0$ e varianza $\sigma^2/n$, se $\sigma^2$ è nota, oppure $\hat{s}_n^2/n$, se $\sigma^2$ sconosciuta. Pertanto, nel caso di grandi campioni, le regioni di accettazione dell'ipotesi nulla sono ancora quelle descritte nel presente capitolo, indipendentemente dalla forma della distribuzione della popolazione di origine. Nel caso di piccoli campioni tratti da una popolazione non normale, invece, non è possibile, in generale, procedere al test sul valore medio mediante la procedura qui descritta.</span>
<span id="cb25-449"><a href="#cb25-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-450"><a href="#cb25-450" aria-hidden="true" tabindex="-1"></a><span class="fu">## Due gruppi indipendenti</span></span>
<span id="cb25-451"><a href="#cb25-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-452"><a href="#cb25-452" aria-hidden="true" tabindex="-1"></a>Anche se il $t$ di Student per un singolo campione viene spesso usato, non corrisponde al caso più comune di uso del test $t$ di Student. Una situazione molto più comune è quella nella quale vengono confrontati due gruppi di osservazioni indipendenti. In psicologia, questo corrisponde al caso di due gruppi diversi di partecipanti, un gruppo per ciascuna condizione sperimentale. Per ogni partecipante allo studio viene misurata una variabile di interesse e la domanda della ricerca è se i due gruppi provengano o meno da due popolazioni aventi la stessa media. In tale situazione viene applicato il test $t$ per campioni indipendenti.</span>
<span id="cb25-453"><a href="#cb25-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-454"><a href="#cb25-454" aria-hidden="true" tabindex="-1"></a><span class="fu">### Test bidirezionale</span></span>
<span id="cb25-455"><a href="#cb25-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-456"><a href="#cb25-456" aria-hidden="true" tabindex="-1"></a>Supponiamo che due popolazioni abbiano distribuzioni normali, con la stessa varianza e con medie incognite. Le due popolazioni sono dunque distribuite come due variabili aleatorie indipendenti</span>
<span id="cb25-457"><a href="#cb25-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-458"><a href="#cb25-458" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-459"><a href="#cb25-459" aria-hidden="true" tabindex="-1"></a>X \sim \mathcal{N}(\mu_1, \sigma^2), \quad Y \sim \mathcal{N}(\mu_2, \sigma^2).</span>
<span id="cb25-460"><a href="#cb25-460" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-461"><a href="#cb25-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-462"><a href="#cb25-462" aria-hidden="true" tabindex="-1"></a>Ci chiediamo se ci sono differenze fra le medie di queste due popolazioni e procediamo con il test della seguente ipotesi nulla:</span>
<span id="cb25-463"><a href="#cb25-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-464"><a href="#cb25-464" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-465"><a href="#cb25-465" aria-hidden="true" tabindex="-1"></a>H_0: \mu_1 - \mu_2 = 0\quad \text{(non ci sono differenze fra le medie)}.</span>
<span id="cb25-466"><a href="#cb25-466" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-467"><a href="#cb25-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-468"><a href="#cb25-468" aria-hidden="true" tabindex="-1"></a>L'ipotesi alternativa bidirezionale è</span>
<span id="cb25-469"><a href="#cb25-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-470"><a href="#cb25-470" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-471"><a href="#cb25-471" aria-hidden="true" tabindex="-1"></a>H_1: \mu_1  - \mu_2 \neq 0.</span>
<span id="cb25-472"><a href="#cb25-472" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-473"><a href="#cb25-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-474"><a href="#cb25-474" aria-hidden="true" tabindex="-1"></a>Avendo osservato i dati di due campioni indipendenti estratti dalle due popolazioni, possiamo calcolare la statistica</span>
<span id="cb25-475"><a href="#cb25-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-476"><a href="#cb25-476" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-477"><a href="#cb25-477" aria-hidden="true" tabindex="-1"></a>T_n = \frac{(\bar{X} - \bar{Y}) - (\mu_1-\mu_2)}{\sqrt{s_p^2 \big(\frac{1}{n_1} + \frac{1}{n_2}\big) }} \notag</span>
<span id="cb25-478"><a href="#cb25-478" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-479"><a href="#cb25-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-480"><a href="#cb25-480" aria-hidden="true" tabindex="-1"></a>che si distribuisce come una variabile aleatoria $t$-Student con $\nu = n_1 + n_2 - 2$ gradi di libertà, dove una stima combinata della varianza, $s^2_p$, si trova come indicato all'interno della radice quadrata al denominatore della formula precedente. Se l'ipotesi nulla è vera, dunque, la statistica</span>
<span id="cb25-481"><a href="#cb25-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-482"><a href="#cb25-482" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-483"><a href="#cb25-483" aria-hidden="true" tabindex="-1"></a>T_n = \frac{\bar{X} - \bar{Y}}{\sqrt{s_p^2 \big(\frac{1}{n_1} + \frac{1}{n_2}\big) }} \notag</span>
<span id="cb25-484"><a href="#cb25-484" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-485"><a href="#cb25-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-486"><a href="#cb25-486" aria-hidden="true" tabindex="-1"></a>si distribuirà come una variabile aleatoria $t$-Student con $\nu = n_1 + n_2 - 2$ gradi di libertà.</span>
<span id="cb25-487"><a href="#cb25-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-488"><a href="#cb25-488" aria-hidden="true" tabindex="-1"></a>Fissato il livello $\alpha$, la regione di non rifiuto dell'ipotesi nulla è data da:</span>
<span id="cb25-489"><a href="#cb25-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-490"><a href="#cb25-490" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-491"><a href="#cb25-491" aria-hidden="true" tabindex="-1"></a>\mathcal{A}: \quad -t^{\ast} \cdot s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}} &lt; (\bar{X} - \bar{Y}) &lt; +t^{\ast} \cdot s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}},\notag</span>
<span id="cb25-492"><a href="#cb25-492" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-493"><a href="#cb25-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-494"><a href="#cb25-494" aria-hidden="true" tabindex="-1"></a>dove $t^{\ast} = t_{\nu, 1-\alpha/2}$ è il quantile di ordine $(1-\alpha/2)$ della distribuzione $t$-Student con $\nu = n_1 + n_2 - 2$ gradi di libertà.</span>
<span id="cb25-495"><a href="#cb25-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-496"><a href="#cb25-496" aria-hidden="true" tabindex="-1"></a><span class="fu">### La durata della gravidanza</span></span>
<span id="cb25-497"><a href="#cb25-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-498"><a href="#cb25-498" aria-hidden="true" tabindex="-1"></a>Per fare un esempio, consideriamo uno studio svolto su 1408 donne ospedalizzate (1) per un ricovero ordinario o (2) per un ricovero d'urgenza relativo al parto. La durata della gravidanza (chiamiamola $x$) è misurata in settimane complete dall'inizio dell'ultimo periodo mestruale. I dati sono riassunti nel modo seguente.</span>
<span id="cb25-499"><a href="#cb25-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-500"><a href="#cb25-500" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Ricovero ordinario: 775 osservazioni con $\bar{x}_o = 39.08$ e $\sigma^2 = 7.77$.</span>
<span id="cb25-501"><a href="#cb25-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-502"><a href="#cb25-502" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Ricovero d'urgenza: 633 osservazioni con $\bar{x}_u = 39.60$ e $\sigma^2 = 4.95$.</span>
<span id="cb25-503"><a href="#cb25-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-504"><a href="#cb25-504" aria-hidden="true" tabindex="-1"></a>Ci chiediamo se ci sono evidenze sufficienti per concludere che la durata della gravidanza sia diversa nel caso di un ricovero ordinario o nel caso di un ricovero d'urgenza.</span>
<span id="cb25-505"><a href="#cb25-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-506"><a href="#cb25-506" aria-hidden="true" tabindex="-1"></a>Se possiamo assumere che i dati provengano da due distribuzioni normali aventi uguale varianza, il test $t$ di Student si svolge nel modo seguente. Una stima combinata della varianza è data da</span>
<span id="cb25-507"><a href="#cb25-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-508"><a href="#cb25-508" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-509"><a href="#cb25-509" aria-hidden="true" tabindex="-1"></a>s^2_p = \frac{774 \cdot 7.77 + 632 \cdot 4.95}{1406} \Big(\frac{1}{775} \frac{1}{633}\Big) = 0.0187.</span>
<span id="cb25-510"><a href="#cb25-510" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-511"><a href="#cb25-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-512"><a href="#cb25-512" aria-hidden="true" tabindex="-1"></a>La statistica test è</span>
<span id="cb25-513"><a href="#cb25-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-514"><a href="#cb25-514" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-515"><a href="#cb25-515" aria-hidden="true" tabindex="-1"></a>T = \frac{\bar{x}_o - \bar{x}_u}{s_p} = -3.8064.</span>
<span id="cb25-516"><a href="#cb25-516" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-517"><a href="#cb25-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-518"><a href="#cb25-518" aria-hidden="true" tabindex="-1"></a>Abbiamo $1,406$ gradi di libertà. Usando R per calcolare il valore-$p$ di un test bilaterale otteniamo</span>
<span id="cb25-519"><a href="#cb25-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-520"><a href="#cb25-520" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-521"><a href="#cb25-521" aria-hidden="true" tabindex="-1"></a>p = P(|T| &gt; |t|) = \texttt{2 * pt(-3.8064, 1406) = 0.00015}.</span>
<span id="cb25-522"><a href="#cb25-522" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-523"><a href="#cb25-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-524"><a href="#cb25-524" aria-hidden="true" tabindex="-1"></a>Con $\alpha = 0.05$ possiamo dunque rigettare l'ipotesi nulla di eguaglianza della durata delle gravidanze per i due gruppi di donne.</span>
<span id="cb25-525"><a href="#cb25-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-526"><a href="#cb25-526" aria-hidden="true" tabindex="-1"></a><span class="fu">### Test unidirezionale</span></span>
<span id="cb25-527"><a href="#cb25-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-528"><a href="#cb25-528" aria-hidden="true" tabindex="-1"></a>Se invece siamo interessati a sapere se la media della prima popolazione è maggiore di quella della seconda popolazione, per esempio, le ipotesi statistiche diventano: $$\begin{aligned}</span>
<span id="cb25-529"><a href="#cb25-529" aria-hidden="true" tabindex="-1"></a>H_0: \mu_1 \leq \mu_2, \quad H_1: \mu_1 &gt; \mu_2. \notag\end{aligned}$$</span>
<span id="cb25-530"><a href="#cb25-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-531"><a href="#cb25-531" aria-hidden="true" tabindex="-1"></a>Come in precedenza, la statistica test</span>
<span id="cb25-532"><a href="#cb25-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-533"><a href="#cb25-533" aria-hidden="true" tabindex="-1"></a>$$T_n = \frac{\bar{X} - \bar{Y}}{\sqrt{s_p^2 \big(\frac{1}{n_1} + \frac{1}{n_2}\big) }} \notag$$</span>
<span id="cb25-534"><a href="#cb25-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-535"><a href="#cb25-535" aria-hidden="true" tabindex="-1"></a>si distribuisce come una variabile aleatorie $t$-Student con $\nu = n_1 + n_2 - 2$ gradi di libertà. In questo caso, però, fissato il livello $\alpha$, la regione di accettazione del test è data da:</span>
<span id="cb25-536"><a href="#cb25-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-537"><a href="#cb25-537" aria-hidden="true" tabindex="-1"></a>$$\mathcal{A}: \quad -\infty &lt; (\bar{X} - \bar{Y}) &lt; +t^{\ast} \cdot s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}},\notag$$</span>
<span id="cb25-538"><a href="#cb25-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-539"><a href="#cb25-539" aria-hidden="true" tabindex="-1"></a>dove $t^{\ast} = t_{\nu, 1 - \alpha}$ è il quantile di ordine $(1 - \alpha)$ della distribuzione $t$-Student con $\nu = n_1 + n_2 - 2$ gradi di libertà.</span>
<span id="cb25-540"><a href="#cb25-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-541"><a href="#cb25-541" aria-hidden="true" tabindex="-1"></a><span class="fu">### Assunzioni</span></span>
<span id="cb25-542"><a href="#cb25-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-543"><a href="#cb25-543" aria-hidden="true" tabindex="-1"></a>Il test $t$ per campioni indipendenti si basa sulle seguenti ipotesi.</span>
<span id="cb25-544"><a href="#cb25-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-545"><a href="#cb25-545" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>*Normalità.* Come nel caso del test $t$ per un singolo campione, anche il test $t$ per campioni indipendenti presume che i dati siano normalmente distribuiti. Specificamente, assumiamo che entrambe le popolazioni da cui sono tratti i due gruppi siano normalmente distribuite. Vedremo in seguito come sia possibile verificare tale assunzione.</span>
<span id="cb25-546"><a href="#cb25-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-547"><a href="#cb25-547" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>*Indipendenza.* Ancora una volta, si presume che le osservazioni siano campionate indipendentemente. Nel contesto del test $t$ per campioni indipendenti questa assunzione significa due cose diverse. In primo luogo, assumiamo che le osservazioni all'interno di ciascun campione siano indipendenti l'una dall'altra (esattamente come ne caso di un test $t$ per un singolo campione). In secondo luogo, assumiamo anche che non ci siano dipendenze tra i due campioni. Se, ad esempio, scopriamo di avere accidentalmente incluso alcuni partecipanti in entrambe le condizioni sperimentali dello studio (ad esempio, permettendo alla stessa persona di iscriversi a due condizioni diverse), allora questo introduce delle dipendenze le osservazioni dei due campioni e l'ipotesi di indipendenza viene violata.</span>
<span id="cb25-548"><a href="#cb25-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-549"><a href="#cb25-549" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>*Omogeneità della varianza* (detta anche "omoscedasticità"). La terza ipotesi è che le due popolazioni abbiano la stessa la deviazione standard. È possibile verificare questa ipotesi usando il test di Levene. Tuttavia, c'è un rimedio più semplice per la violazione di questa assunzione, di cui parleremo nella prossima sezione.</span>
<span id="cb25-550"><a href="#cb25-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-551"><a href="#cb25-551" aria-hidden="true" tabindex="-1"></a><span class="fu">### Test di Welch</span></span>
<span id="cb25-552"><a href="#cb25-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-553"><a href="#cb25-553" aria-hidden="true" tabindex="-1"></a>Il problema più grande relativo all'uso del test $t$ di Student per campioni indipendenti ha a che fare con la terza ipotesi elencata nella sezione precedente: l'ipotesi che entrambe le popolazioni abbiano la stessa deviazione standard. Questo accade raramente nella vita reale: se due popolazioni non hanno la stessa media, perché dovrebbero avere la stessa deviazione standard? Non c'è davvero alcuna ragione per aspettarsi che questa ipotesi sia vera. Per superare tale difficoltà, Welch (1947) sviluppò una seconda forma del test $t$ di Student per campioni indipendenti la quale non richiede l'omogeneità della varianza.</span>
<span id="cb25-554"><a href="#cb25-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-555"><a href="#cb25-555" aria-hidden="true" tabindex="-1"></a>Il test di Welch è molto simile al test $t$ di Student per campioni indipendenti. La statistica test è identica a quella calcolata in precedenza</span>
<span id="cb25-556"><a href="#cb25-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-557"><a href="#cb25-557" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-558"><a href="#cb25-558" aria-hidden="true" tabindex="-1"></a>T_n = \frac{\bar{X} - \bar{Y}}{\hat{\sigma}_{\bar{X} - \bar{Y}}}</span>
<span id="cb25-559"><a href="#cb25-559" aria-hidden="true" tabindex="-1"></a>$$ {#eq-twelch}</span>
<span id="cb25-560"><a href="#cb25-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-561"><a href="#cb25-561" aria-hidden="true" tabindex="-1"></a>ovvero, è data dal rapporto tra la differenza tra le medie campionarie e l'errore standard di tale differenza. Ciò che distingue il test di Welch dalla procedura descritta in precedenza è il modo di calcolare l'errore standard della differenza tra due medie. Nel test di Welch, l'errore standard viene stimato nel modo seguente:</span>
<span id="cb25-562"><a href="#cb25-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-563"><a href="#cb25-563" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-564"><a href="#cb25-564" aria-hidden="true" tabindex="-1"></a>\hat{\sigma}_{\bar{X} - \bar{Y}} = \sqrt{\frac{\hat{\sigma}_1^2}{n_1} + \frac{\hat{\sigma}_2^2}{n_2}}.</span>
<span id="cb25-565"><a href="#cb25-565" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-566"><a href="#cb25-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-567"><a href="#cb25-567" aria-hidden="true" tabindex="-1"></a>La statistica test viene poi valutata utilizzando una correzione dei gradi di liberà fornita dall'equazione di Welch--Satterthwaite:</span>
<span id="cb25-568"><a href="#cb25-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-569"><a href="#cb25-569" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-570"><a href="#cb25-570" aria-hidden="true" tabindex="-1"></a>gdl = \frac{</span>
<span id="cb25-571"><a href="#cb25-571" aria-hidden="true" tabindex="-1"></a>(\hat{\sigma}_1^2/n_1 + \hat{\sigma}_2^2/n_2)^2</span>
<span id="cb25-572"><a href="#cb25-572" aria-hidden="true" tabindex="-1"></a>}{</span>
<span id="cb25-573"><a href="#cb25-573" aria-hidden="true" tabindex="-1"></a>(\hat{\sigma}_1^2/n_1)^2/(n_1-1) + (\hat{\sigma}_2^2/n_2)^2/(n_2-1)</span>
<span id="cb25-574"><a href="#cb25-574" aria-hidden="true" tabindex="-1"></a>}.</span>
<span id="cb25-575"><a href="#cb25-575" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-576"><a href="#cb25-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-577"><a href="#cb25-577" aria-hidden="true" tabindex="-1"></a>Vediamo ora in un caso concreto come applicare il test di Welch.</span>
<span id="cb25-578"><a href="#cb25-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-579"><a href="#cb25-579" aria-hidden="true" tabindex="-1"></a>Consideriamo il seguente estratto dell'articolo di Mehr et al. (2014):</span>
<span id="cb25-580"><a href="#cb25-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-581"><a href="#cb25-581" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The infants' degree of song exposure was comparable across the two experiments: The estimated total number of song performances was similar in Experiment 1 ($M$ = 76.3, $SD$ = 56.2) and Experiment 2 ($M$ = 81.8, $SD$ = 50.5), $t_{61.3}$ = 0.41, $p$ = .68 (Satterthwaite's $t$ test) ...</span></span>
<span id="cb25-582"><a href="#cb25-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-583"><a href="#cb25-583" aria-hidden="true" tabindex="-1"></a>Senza entrare nei dettegli dello studio, poniamoci l'obiettivo di replicare l'analisi statistica descritta dagli autori. I dati del primo esperimento sono:</span>
<span id="cb25-584"><a href="#cb25-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-587"><a href="#cb25-587" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-588"><a href="#cb25-588" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">35.0</span>, <span class="fl">239.0</span>, <span class="fl">102.0</span>, <span class="fl">27.0</span>, <span class="fl">60.0</span>, <span class="fl">126.0</span>, <span class="fl">134.6667</span>, <span class="fl">63.77777</span>, <span class="fl">44.0</span>, <span class="fl">55.0</span>, <span class="fl">88.0</span>, <span class="fl">53.66666</span>, <span class="fl">59.5</span>, <span class="fl">94.0</span>, <span class="fl">54.0</span>, <span class="fl">26.0</span>, <span class="fl">44.0</span>, <span class="fl">23.0</span>, <span class="fl">38.0</span>, <span class="fl">31.0</span>, <span class="fl">78.4</span>, <span class="fl">135.0</span>, <span class="fl">26.0</span>, <span class="fl">120.9091</span>, <span class="fl">13.0</span>, <span class="fl">245.0</span>, <span class="fl">66.5</span>, <span class="fl">63.0</span>, <span class="fl">57.16667</span>, <span class="fl">29.71428</span>, <span class="fl">70.0</span>, <span class="fl">140.0</span>)</span>
<span id="cb25-589"><a href="#cb25-589" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-590"><a href="#cb25-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-591"><a href="#cb25-591" aria-hidden="true" tabindex="-1"></a>e i dati del secondo experimento sono:</span>
<span id="cb25-592"><a href="#cb25-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-595"><a href="#cb25-595" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-596"><a href="#cb25-596" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">43.16666</span>, <span class="fl">63.0</span>, <span class="fl">35.0</span>, <span class="fl">100.8</span>, <span class="fl">69.0</span>, <span class="fl">66.0</span>, <span class="fl">105.0</span>, <span class="fl">270.6667</span>, <span class="fl">62.0</span>, <span class="fl">80.0</span>, <span class="fl">128.0</span>, <span class="fl">104.0</span>, <span class="fl">49.0</span>, <span class="fl">80.0</span>, <span class="fl">51.0</span>, <span class="fl">114.3333</span>, <span class="fl">168.0</span>, <span class="fl">105.0</span>, <span class="fl">37.0</span>, <span class="fl">38.0</span>,  <span class="fl">45.0</span>, <span class="fl">48.0</span>,  <span class="fl">84.0</span>, <span class="fl">99.0</span>,  <span class="fl">38.5</span>, <span class="fl">74.57143</span>, <span class="fl">49.0</span>, <span class="fl">28.0</span>, <span class="fl">64.0</span>, <span class="fl">86.8</span>, <span class="fl">49.0</span>, <span class="fl">182.0</span>)</span>
<span id="cb25-597"><a href="#cb25-597" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-598"><a href="#cb25-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-599"><a href="#cb25-599" aria-hidden="true" tabindex="-1"></a>Dobbiamo eseguire un test $t$ di Student per campioni indipendenti con il metodo di Welch.</span>
<span id="cb25-600"><a href="#cb25-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-601"><a href="#cb25-601" aria-hidden="true" tabindex="-1"></a>In questo caso, $n_1=n_2 = 32$. Abbiamo inoltre che $\bar{X} = 76.32191$ e $\bar{Y} = 81.77619$, con $s_1^2 = 3163.961$ e $s_2^2 = 2554.029$. L'errore standard stimato mediante la procedura di Welch è pari a 13.36739 per cui, utilizzando l'equazione del test di Welch otteniamo la statistica $T = -0.4080286$. I gradi di libertà per il test di Welch sono pari a 61.30249 il che ci conduce ad un valore-$p$ pari a</span>
<span id="cb25-602"><a href="#cb25-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-605"><a href="#cb25-605" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-606"><a href="#cb25-606" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> <span class="sc">*</span> <span class="fu">pt</span>(<span class="sc">-</span><span class="fl">0.4080286</span>, <span class="fl">61.30249</span>)</span>
<span id="cb25-607"><a href="#cb25-607" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-608"><a href="#cb25-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-609"><a href="#cb25-609" aria-hidden="true" tabindex="-1"></a>Questi risultati riproducono perfettamente ciò che è stato riportato da Mehr et al. (2014). I calcoli si possono svolgere utilizzando la funzione <span class="in">`t.test()`</span> di R:</span>
<span id="cb25-610"><a href="#cb25-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-613"><a href="#cb25-613" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-614"><a href="#cb25-614" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(x1, x2)</span>
<span id="cb25-615"><a href="#cb25-615" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-616"><a href="#cb25-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-617"><a href="#cb25-617" aria-hidden="true" tabindex="-1"></a>Si noti che R utilizza di default il test di Welch quando sottopone a verifica l'ipotesi nulla dell'eguaglianza di due medie.</span>
<span id="cb25-618"><a href="#cb25-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-619"><a href="#cb25-619" aria-hidden="true" tabindex="-1"></a>L'intervallo di confidenza al 95% è dato da</span>
<span id="cb25-620"><a href="#cb25-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-623"><a href="#cb25-623" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb25-624"><a href="#cb25-624" aria-hidden="true" tabindex="-1"></a>se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">var</span>(x1) <span class="sc">/</span> <span class="fu">length</span>(x1) <span class="sc">+</span> <span class="fu">var</span>(x2) <span class="sc">/</span> <span class="fu">length</span>(x2))</span>
<span id="cb25-625"><a href="#cb25-625" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fl">61.302</span></span>
<span id="cb25-626"><a href="#cb25-626" aria-hidden="true" tabindex="-1"></a>ci <span class="ot">&lt;-</span> (<span class="fu">mean</span>(x1) <span class="sc">-</span> <span class="fu">mean</span>(x2)) <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, df) <span class="sc">*</span> se </span>
<span id="cb25-627"><a href="#cb25-627" aria-hidden="true" tabindex="-1"></a>ci</span>
<span id="cb25-628"><a href="#cb25-628" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb25-629"><a href="#cb25-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-630"><a href="#cb25-630" aria-hidden="true" tabindex="-1"></a>il che riproduce il risultato trovato dalla funzione <span class="in">`t.test()`</span>.</span>
<span id="cb25-631"><a href="#cb25-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-632"><a href="#cb25-632" aria-hidden="true" tabindex="-1"></a>Il messaggio che si può ricavare dalla discussione sul test di Welch è che esso dovrebbe sempre essere eseguito al posto del "tradizionale" test $t$ di Student (infatti, questa è l'impostazione di default in ). Questo perché il test di Welch si comporta meglio del test $t$ di Student se le dimensioni e le varianze dei campioni non sono uguali tra i gruppi e dà lo stesso risultato del test $t$ di Student quando le dimensioni e le varianze del campione sono uguali. Un approccio che viene raccomandato nei testi di statistica è di verificare con il test di Levene l'ipotesi che le varianze siano uguali tra i gruppi, ma molti ricercatori ritengono che sia preferibile utilizzare sempre il test di Welch, indipendentemente dai risultati del test di Levene. Infatti, il test di Levene ha spesso una bassa potenza -- ovvero non è in grado di respingere l'ipotesi nulla che le varianze siano uguali anche quando esse sono effettivamente diverse -- il che rende problematico assumere che le varianze siano uguali anche se il risultato del test di Levene è nullo.</span>
<span id="cb25-633"><a href="#cb25-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-634"><a href="#cb25-634" aria-hidden="true" tabindex="-1"></a><span class="fu">### Assunzioni del test di Welch</span></span>
<span id="cb25-635"><a href="#cb25-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-636"><a href="#cb25-636" aria-hidden="true" tabindex="-1"></a>Le assunzioni alla base del test di Welch sono simili a quelle del test $t$ di Student per campioni indipendenti, ad eccezione del fatto che il test di Welch non presuppone l'omogeneità della varianza. Rimangono dunque solo l'assunzione di normalità e l'assunzione di indipendenza.</span>
<span id="cb25-637"><a href="#cb25-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-638"><a href="#cb25-638" aria-hidden="true" tabindex="-1"></a><span class="fu">## Test T per dati appaiati</span></span>
<span id="cb25-639"><a href="#cb25-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-640"><a href="#cb25-640" aria-hidden="true" tabindex="-1"></a>Se consideriamo il test $t$ di Student per campioni indipendenti o il test di Welch è evidente che tali test possono essere usati in situazioni in cui i due campioni sono, appunto, indipendenti l'uno dall'altro. Una tale situazione si presenta, ad esempio, quando i partecipanti ad un esperimento vengono assegnati casualmente a una di due condizioni sperimentali. Ma ci possono anche essere disegni sperimentali con caratteristiche diverse. In particolare, in un disegno a misure ripetute ciascun partecipante viene valutato (rispetto alla stessa variabile dipendente) in tutte le condizioni sperimentali e, in tali circostanze, i due campioni non sono indipendenti. Ad esempio, potremmo essere interessati a sapere se ascoltare musica riduce la capacità della memoria di lavoro delle persone. A tal fine, potremmo misurare la capacità della memoria di lavoro di ciascun soggetto in due condizioni: con la musica e senza musica. In un disegno sperimentale di questo tipo ciascun partecipante fa parte di ciascuno dei due gruppi che vengono esaminati. Non possiamo dunque usare l'approccio descritto in precedenza e dobbiamo procedere in un modo diverso, ovvero mediante l'uso del test $t$ per dati appaiati</span>
<span id="cb25-641"><a href="#cb25-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-642"><a href="#cb25-642" aria-hidden="true" tabindex="-1"></a>Nel test $t$ per dati appaiati disponiamo di una coppia ordinata di osservazioni per ciascuna u.s. (per esempio, l'osservazione effettuata ad un pre-test e ad un post-test, oppure nelle condizioni con la musica e senza musica dell'esempio precedente) e diventa così possibile calcolare una misura della variazione $D$ della variabile di interesse rispetto alle due osservazioni. Avendo un insieme $D_1, \dots, D_n$ di variazioni, possiamo calcolarne la media $\bar{D}$ e la deviazione standard $s_D$:</span>
<span id="cb25-643"><a href="#cb25-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-644"><a href="#cb25-644" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-645"><a href="#cb25-645" aria-hidden="true" tabindex="-1"></a>\bar{D} = \frac{1}{n} \sum_{i = 1}^n D_i, \quad s_D = \sqrt{\frac{1}{n-1}\sum_{i=1}^n (D_i - \bar{D})^2}.</span>
<span id="cb25-646"><a href="#cb25-646" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-647"><a href="#cb25-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-648"><a href="#cb25-648" aria-hidden="true" tabindex="-1"></a>L'errore standard per la media delle differenze è dato da</span>
<span id="cb25-649"><a href="#cb25-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-650"><a href="#cb25-650" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-651"><a href="#cb25-651" aria-hidden="true" tabindex="-1"></a>s_{\bar{D}} = \frac{s_D}{\sqrt{n}}.</span>
<span id="cb25-652"><a href="#cb25-652" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-653"><a href="#cb25-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-654"><a href="#cb25-654" aria-hidden="true" tabindex="-1"></a>Se $\delta$ è la variazione media della popolazione, allora la statistica</span>
<span id="cb25-655"><a href="#cb25-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-656"><a href="#cb25-656" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-657"><a href="#cb25-657" aria-hidden="true" tabindex="-1"></a>T_n = \frac{\bar{D} - \delta}{s_{\bar{D}}}</span>
<span id="cb25-658"><a href="#cb25-658" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-659"><a href="#cb25-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-660"><a href="#cb25-660" aria-hidden="true" tabindex="-1"></a>si distribuisce come una v.a. $t$-Student con $\nu = n - 1$ gradi di libertà, sotto l'ipotesi che il campione (di variazioni) provenga da una popolazione distribuita in maniera normale. Per il test dell'ipotesi nulla $H_0: \delta = 0$, si calcola il valore $T_n = \bar{D}/s_{\bar{D}}$ e si procede con il confronto con il valore critico per $\nu = n - 1$ gradi di libertà, dove $n$ è il numero di coppie di osservazioni. Come per tutti i test $t$, la statistica $T_n$ tende a distribuirsi come una $t$-Student, indipendentemente dalla forma della distribuzione della popolazione di origine, se $n$ è sufficientemente grande.</span>
<span id="cb25-661"><a href="#cb25-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-662"><a href="#cb25-662" aria-hidden="true" tabindex="-1"></a><span class="fu">### Proporzione di maschi e femmine</span></span>
<span id="cb25-663"><a href="#cb25-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-664"><a href="#cb25-664" aria-hidden="true" tabindex="-1"></a>Per fare un esempio, consideriamo i dati forniti dal censimento indiano relativi rapporto numerico tra i due sessi nel 2001 e nel 2011 in 35 stati dell'India (i dati grezzi sono forniti sulla pagina Moodle di Psicometria).</span>
<span id="cb25-665"><a href="#cb25-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-666"><a href="#cb25-666" aria-hidden="true" tabindex="-1"></a>Al momento della nascita, la percentuale di bambini di sesso maschile varia nelle diverse zone del mondo, ma in media nascono 101 maschi ogni 100 femmine <span class="co">[</span><span class="ot">@orzack2015human</span><span class="co">]</span>. Nonostante il fatto che le donne, in generale, vivano più a lungo degli uomini, ci sono due paesi nel mondo che hanno al loro interno un grande squilibrio nel rapporto tra i sessi: la Cina ha quasi 50 milioni di uomini in più rispetto alle donne e l'India 43 milioni. Lo squilibrio di Cina e India è dovuto alle pratiche ampiamente documentate degli aborti selettivi sulla base del genere (a causa anche della disponibilità di tecniche di diagnosi prenatale a prezzi accessibili) e all'infanticidio delle neonate <span class="co">[</span><span class="ot">@miller2001female</span><span class="co">]</span>.</span>
<span id="cb25-667"><a href="#cb25-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-668"><a href="#cb25-668" aria-hidden="true" tabindex="-1"></a>Nell'insieme di dati considerato, ogni osservazione corrisponde ad uno stato dell'India. La variabile considerata (<span class="in">`child_sex_ratio`</span>) è il numero medio di bambine femmine per ogni 1000 bambini maschi -- ciò consente di escludere la maggiore longevità delle donne (l'età dei bambini non è specificata). Nel 2001, risultano esserci in media $934$ bambine rispetto a 1000 bambini maschi e nel 2011 risultano $926$ bambine, in media, per ogni 1000 bambini maschi. Per ciascuno stato, sottraiamo il numero medio di bambine calcolate rispetto a 1000 bambini nel 2011 da quello del 2001. Le $35$ differenze così trovate hanno una media pari a $-7.66$ con una deviazione standard di $22.92$. La statistica test diventa</span>
<span id="cb25-669"><a href="#cb25-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-670"><a href="#cb25-670" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-671"><a href="#cb25-671" aria-hidden="true" tabindex="-1"></a>T = \frac{-7.66 - 0}{22.92/\sqrt{35}} = -1.976.</span>
<span id="cb25-672"><a href="#cb25-672" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb25-673"><a href="#cb25-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-674"><a href="#cb25-674" aria-hidden="true" tabindex="-1"></a>Per un test bilaterale, il valore-$p$ è l'area sottesa alla funzione di densità $t$ con 34 gradi di libertà negli intervalli $<span class="co">[</span><span class="ot">-\infty, T</span><span class="co">]</span>$ e $<span class="co">[</span><span class="ot">T, +\infty</span><span class="co">]</span>$ e risulta essere uguale a $0.056$. Essendo il valore-$p$ maggiore di $\alpha = 0.05$, non possiamo rigettare l'ipotesi nulla $H_0: \delta = 0$ che la media della popolazione di differenze sia zero (ovvero che nell'arco temporale considerato non vi siano differenze nel rapporto numerico tra i sessi). In conclusione, non ci sono evidenze che nel decennio 2001-2011 la situazione sia migliorata. Addirittura, la differenza media è negativa, il che suggerisce il contrario.</span>
<span id="cb25-675"><a href="#cb25-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-676"><a href="#cb25-676" aria-hidden="true" tabindex="-1"></a><span class="fu">## Commenti e considerazioni finali {.unnumbered}</span></span>
<span id="cb25-677"><a href="#cb25-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-678"><a href="#cb25-678" aria-hidden="true" tabindex="-1"></a>Il test $t$ di Student nelle sue varianti rappresenta senza dubbio lo strumento statistico di stampo frequentista più ampiamente usato nel mondo della ricerca. Abbiamo visto che è basato su assunzioni ragionevoli, in molte applicazioni pratiche, e quindi potremmo concludere che sia uno strumento utile. Tuttavia, le cose non sono così semplici -- non lo sono mai. In questo capitolo abbiamo visto come il test $t$ di Student viene calcolato, come si giunge ad una decisione sulla base della statistica test e del livello di significatività, eccetera. Tali considerazioni, però, sono considerazioni di tipo statistico, ovvero non riguardano le pratiche del mondo reale, ma descrivono solo le proprietà di alcuni teoremi che fanno parte della teoria della probabilità. Il test $t$ di Student, però, non è solo una procedura astratta, che va valutata per la sua eleganza concettuale, ma è invece una procedura che viene usata nella pratica concreta dell'attività di ricerca per rispondere a domande che hanno una grande rilevanza pratica. Per esempio: la psicoterapia è in grado di ridurre lo stato di ansia e depressione? Oppure: l'idrossiclorochina contrasta in maniera efficace il Covid-19?</span>
<span id="cb25-679"><a href="#cb25-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-680"><a href="#cb25-680" aria-hidden="true" tabindex="-1"></a>Qualcuno, ingenuamente, potrebbe pensare che il mondo della ricerca sia una torre d'avorio all'interno della quale l'attività dei ricercatori è motivata, in primo luogo, e quasi soltanto, dal desiderio di fare avanzare le nostre conoscenze. Non è così. La sociologia della scienza ci fornisce un'immagina ben diversa di come stanno le cose. Le motivazioni dei ricercatori sono ben più prosaiche: l'avanzamento in carriera, il potere, il prestigio, il denaro; tutto ciò descrive molto meglio le motivazioni dei ricercatori del "desiderio di fare avanzare le nostre conoscenze". Ma cosa c'entra il test $t$ di Student in tutto questo? È facile capire che, se lo stipendio dei ricercatori dipende dalle loro pubblicazioni, e se si possono pubblicare solo i risultati statisticamente significativi, allora i ricercatori faranno tutto quello che è in loro potere per ottenere risultati statisticamente significativi. Qui non faccio riferimento al problema della frode nel mondo scientifico, ma al fatto che è *inevitabile* che, dopo una lunga e onerosa fase di progettazione dello studio e di raccolta dati, i ricercatori eseguano il test $t$ di Student *più di una volta*, per confrontare tra loro più di due condizioni e per valutare se *da qualche parte* nei loro dati emerge un risultato statisticamente significativo. Nella pratica corrente, però, la consuetudine è quella di *non riportare* il fatto che il test sia stato eseguito più volte, quando esso non produce un risultato statisticamente significativo dove avrebbe dovuto, in base alle ipotesi iniziali dei ricercatori. Ma, se questo è quello che fanno i ricercatori nel mondo reale, dobbiamo chiederci: cosa succede in tali circostanze alla probabilità di errore di I tipo? Non occorre essere degli statistici per renderci conto che, così facendo, la probabilità di errore di I tipo non può rimanere al livello nominale $\alpha$: nella pratica concreta, dunque, la probabilità di falsi positivi è ben più alta della famosa soglia del 5%.</span>
<span id="cb25-681"><a href="#cb25-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-682"><a href="#cb25-682" aria-hidden="true" tabindex="-1"></a>Per concludere, ricordiamoci che la giustificazione ultima dell'approccio NHST (di cui il test $t$ di Student è la procedura più nota) è proprio quella di mantenere sotto controllo la probabilità di errore di I tipo. Ma, alla luce di quanto abbiamo detto sopra, e considerando soprattutto le le considerazioni svolte da @gelman2014beyond che esamineremo nel prossimo capitolo, la domanda (retorica) che dovrebbe venirci in mente è: l'approccio frequentista riesce a mantenere la sua promessa?</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>