[
  {
    "objectID": "index.html#benvenuti",
    "href": "index.html#benvenuti",
    "title": "Data Science per psicologi",
    "section": "Benvenuti",
    "text": "Benvenuti\nQuesto è il sito web per “Data Science per psicologi”. Viene qui presentato il materiale delle lezioni dell’insegnamento di Psicometria B000286 (A.A. 2022/2023) rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze. Lo scopo di questo insegnamento è quello di fornire agli studenti un’introduzione all’analisi dei dati psicologici. Le conoscenze/competenze che verranno sviluppate in questo insegnamento sono quelle della Data Science applicata alla psicologia, ovvero, un insieme di conoscenze/competenze che si pongono all’intersezione tra psicologia, statistica e informatica."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Data Science per psicologi",
    "section": "License",
    "text": "License\nThis book was created by Corrado Caudek and is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."
  },
  {
    "objectID": "preface.html#struttura-del-corso",
    "href": "preface.html#struttura-del-corso",
    "title": "Prefazione",
    "section": "Struttura del corso",
    "text": "Struttura del corso\nLa dispensa si compone di sette parti. La parte I copre ciò che viene spesso chiamato statistica descrittiva. La parte II fornisce alcune nozioni di base della teoria delle probabilità. La parte III presenta le variabili casuali continue e le principali distribuzioni di densità. Qui verrà anche introdotta la funzione di verosimiglianza. La parte IV copre i concetti teorici di base dell’analisi bayesiana dei dati. La Parte V introduce i modelli di regressione. La parte VI affronta il problema del confronto tra modelli. La parte VII introduce le idee di base dell’inferenza frequentista e mette a confronto l’approccio frequentista e quello bayesiano.\nLe caratteristiche generali di questo insegnamento sono le seguenti.\n\nIn primo luogo, utilizzeremo un approccio incentrato sui modelli, ovvero rappresenteremo e parleremo esplicitamente dei modelli statistici come di un insieme formalizzato di ipotesi che stanno alla base di una specifica analisi dei dati.\nIn secondo luogo, utilizzeremo un approccio computazionale, ovvero promuoveremo la comprensione delle nozioni matematiche mediante simulazioni al computer.\nIn terzo luogo, adotteremo un approccio duplice, in quanto introdurremo sia l’approccio frequentista all’inferenza statistica che quello bayesiano. Inizieremo con l’approccio bayesiano, perché è quello più intuitivo. Inoltre, la discussione dell’approccio bayesiano aiuta anche a comprendere meglio i concetti di base del paradigma frequentista. Presenteremo poi l’inferenza frequentista e ne metteremo in evidenza i limiti.\n\nQuesta dispensa contiene anche delle appendici con informazioni aggiuntive. Tra le altre cose, le appendici forniscono un ripasso della teoria degli insiemi e della notazione matematica e, soprattutto, introducono \\(\\mathsf{R}\\), il principale linguaggio di programmazione che utilizzeremo."
  },
  {
    "objectID": "preface.html#lanalisi-dei-dati-psicologici",
    "href": "preface.html#lanalisi-dei-dati-psicologici",
    "title": "Prefazione",
    "section": "L’analisi dei dati psicologici",
    "text": "L’analisi dei dati psicologici\nSembra sensato dire qualche parola su una domanda che è importante per gli studenti: perché dobbiamo spendere tanto tempo per studiare le tecniche di analisi dei dati quando in realtà, quello che ci interessa, in psicologia, è tutt’altro? Questa è una bella domanda. Ma c’è una ragione molto semplice che dovrebbe farci capire perché la Data Science sia così importante per la psicologia. Infatti, a ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia gli individui ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, in certi casi, predire. In questo senso, la psicologia è molto diversa dall’ingegneria, per esempio. Le proprietà di un determinato ponte sotto certe condizioni, ad esempio, sono molto simili a quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non può dirsi degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono proprio l’oggetto di studio della psicologia: è dunque chiaro che i problemi che la psicologia si pone sono molto diversi da quelli affrontati, ad esempio, dagli ingegneri. Questa è la ragione per cui abbiamo bisogno della Data Science in psicologia: la Data Science ci consente di descrivere la variazione e il cambiamento. E queste sono le caratteristiche di base dei fenomeni psicologici.\nSono sicuro che, leggendo queste righe, a molti studenti sarà venuta in mente la seguente domanda: perché non chiediamo a qualche esperto di fare il “lavoro sporco” (ovvero le analisi statistiche) per noi, mentre noi (gli psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli “tecnici” della Data Science? La risposta a questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della Data Science. Le tematiche della Data Science non possono essere ignorate né dai ricercatori in psicologia, né da coloro che svolgono la professione di psicologo al di fuori dell’Università. Infatti, anche i professionisti al di fuori dall’università devono essere in graedo di leggere la letteratura psicologica più recente: il continuo aggiornamento delle conoscenze è infatti richiesto dalla deontologia della professione. Ma per potere fare questo è necessario conoscere un bel po’ di Data Science! Basta aprire a caso una rivista specialistica di psicologia per rendersi conto di quanto ciò sia vero: gli articoli che riportano i risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. Ed è ovvio che la comprensione della letteratura psicologica rappresenti un requisito minimo nel bagaglio professionale dello psicologo.\nLe considerazioni precedenti cercano di chiarire il seguente punto: la Data Science non è qualcosa da studiare a malincuore, in un singolo insegnamento universitario, per poi poterla tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano gli strumenti della Data Science in tantissimi ambiti della loro attività professionale: in particolare quando costruiscono, somministrano e interpretano i test psicometrici. È dunque chiaro che la Data Science è un tassello imprescindibile del bagaglio professionale dello psicologo."
  },
  {
    "objectID": "preface.html#come-studiare",
    "href": "preface.html#come-studiare",
    "title": "Prefazione",
    "section": "Come studiare",
    "text": "Come studiare\nIl metodo di studio che consiglio agli studenti è quello di seguire attivamente le lezioni, di assimilare i concetti via via che essi vengono presentati e di verificare in autonomia le procedure presentate a lezione.\nLa prima fase dello studio, che è sicuramente individuale, è quella in cui lo studente deve acquisire le conoscenze teoriche relative ai problemi che saranno presentati all’esame. La seconda fase di studio, che può essere facilitata da scambi con altri e da incontri di gruppo, porta lo studente ad acquisire la capacità di applicare le conoscenze: è necessario sapere usare un software (nel nostro caso \\(\\textsf{R}\\)) per risolvere i problemi che verranno presentati all’esame. Le due fasi non sono però separate: in questa materia è molto utile adottare un approccio di learning by doing.\nPer tutte queste ragioni, incoraggio gli studenti\n\na farmi domande per chiarire ciò che non è stato capito appieno;\na svolgere gli esercizi proposti su Moodle seguendo il calendario indicato; tali problemi rappresentano il livello di difficoltà richiesto per superare l’esame e consentono allo studente di capire se le competenze sviluppate fino a quel punto siano sufficienti rispetto alle richieste dell’esame;\na partecipare attivamente alle chat sui forum che sono stati predisposti."
  },
  {
    "objectID": "basics.html",
    "href": "basics.html",
    "title": "Parte 1: Nozioni di base",
    "section": "",
    "text": "Questa dispensa è strutturata in maniera tale da rispecchiare la suddivisione tra i temi della misurazione, dell’analisi descrittiva e dell’inferenza.\nIn questa prima parte affronteremo i temi della misurazione e delll’analisi descrittiva dei dati. Nel capitolo Capitolo 1 verranno presentati i concetti chiave della Data Science. Nel capitolo Capitolo 2 sarà affrontato il tema della misurazione. Nel capitolo Capitolo 3 verranno introdotti i concetti che vengono utilizzati per descrivere le distribuzioni dei dati. Verranno poi introdotti gli indici di tendenza centrale e di dispersione nel capitolo Capitolo 4. Infine, nel capitolo Capitolo 5 verrà affrontato il problema di descrivere le relazioni tra variabili.\nPrima di affrontare tali temi sarà necessario introdurre il linguaggio di programmazione statistica R (un’introduzione a R è fornita in Appendice)."
  },
  {
    "objectID": "001_key_notions.html#popolazioni-e-campioni",
    "href": "001_key_notions.html#popolazioni-e-campioni",
    "title": "1  Concetti chiave",
    "section": "1.1 Popolazioni e campioni",
    "text": "1.1 Popolazioni e campioni\nPopolazione. L’analisi dei dati inizia con l’individuazione delle unità portatrici di informazioni circa il fenomeno di interesse. Si dice popolazione (o universo) l’insieme \\(\\Omega\\) delle entità capaci di fornire informazioni sul fenomeno oggetto dell’indagine statistica. Possiamo scrivere \\(\\Omega = \\{\\omega_i\\}_{i=1, \\dots, n}= \\{\\omega_1, \\omega_2, \\dots, \\omega_n\\}\\), oppure \\(\\Omega = \\{\\omega_1, \\omega_2, \\dots \\}\\) nel caso di popolazioni finite o infinite, rispettivamente. Gli elementi \\(\\omega_i\\) dell’insieme \\(\\Omega\\) sono detti unità statistiche.\n\n\n\n\n\n\nSe la notazione che uso qui non è chiara, si veda l’appendice per un ripasso delle nozioni di base della teoria degli insiemi.\n\n\n\nL’obiettivo principale della ricerca psicologica, sia nelle ricerche sperimentali che in quelle osservazionali, è quello di studiare i fenomeni psicologici in una data popolazione. È quindi necessario essere molto chiari su quale sia la popolazione di interesse (ovvero, la popolazione a cui si applicano i risultati della ricerca). La popolazione di interesse può essere reale (ad esempio, tutte le persone che si trovavano nella città di Hiroshima al momento del bombardamento atomico e sono sopravvissute per un anno) o ipotetica (ad esempio, tutte le persone depresse che possono essere sottoposte ad un intervento psicologico). Il ricercatore deve sempre essere in grado di determinare se un determinato individuo appartiene o meno alla popolazione in esame.\nUna sotto-popolazione è una popolazione che soddisfa delle proprietà ben definite. Ad esempio, potremmo essere interessati alla sotto-popolazione degli uomini di età inferiore ai 30 anni o alla sotto-popolazione dei pazienti depressi che sono stati sottoposti ad uno specifico intervento psicologico. Molte domande scientifiche si pondono il problema di descrivere le differenze tra sotto-popolazioni – ad esempio, il confronto tra un gruppo sottoposto a psicoterapia e un gruppo di controllo per determinare l’efficacia di un trattamento.\nCampione. Un sottoinsieme della popolazione, ovvero un insieme di elementi \\(\\omega_i\\), viene chiamato campione. Ciascuna unità statistica \\(\\omega_i\\) (abbreviata con u.s.) è portatrice dell’informazione che verrà rilevata mediante un’operazione di misurazione. Un campione è dunque un sottoinsieme di una popolazione utilizzato per conoscere una tale popolazione.\nA differenza di una sotto-popolazione definita in base a criteri chiari, un campione viene generalmente selezionato tramite un procedura casuale. Il campionamento casuale consente al ricercatore di trarre conclusioni sulla popolazione e, soprattutto, di quantificare l’incertezza sui risultati. Il campione usato in un sondaggio è un esempio di campione casuale. Si noti però che molti studi osservazionali non utilizzano dei dati campionati casualmente. Un campione di convenienza può essere costituito, ad esempio, una coorte di studenti selezionati in un unico istituto.\nIndipendentemente da come vengono ottenuti i dati, il ricercatore si deve sempre porre il problema della rappresentatività statistica del campione, ovvero deve chiedersi se il campione è in grado di rispecchiare e di riprodurre senza distorsioni le caratteristiche di interesse della popolazione. Il metodo più semplice che garantisce la rappresentatività è dato dalla casualità della selezione delle unità statistiche del campione. In psicologia, tuttavia, molto spesso i ricercatori non hanno a disposizione gli strumenti (si legga, i fondi) per utilizzare la tecnica del campionamento casuale nelle loro ricerche."
  },
  {
    "objectID": "001_key_notions.html#variabili-e-costanti",
    "href": "001_key_notions.html#variabili-e-costanti",
    "title": "1  Concetti chiave",
    "section": "1.2 Variabili e costanti",
    "text": "1.2 Variabili e costanti\nUna variabile è qualsiasi proprietà o descrittore che può assumere più valori (numerici o categoriali). Si può pensare ad una variabile come la domanda di cui il valore dell’u.s. è la risposta. Ad esempio, “Qual è l’età di questo partecipante?” “19 anni”. Qui, “età” è la variabile e “19” è il suo valore.\nLa probabilità che la variabile \\(X\\) assuma il valore \\(x\\) si scrive \\(P(X = x)\\). Questo è spesso abbreviato in \\(P(x)\\). Si noti che \\(P(X = 19)\\) è interpretato come la probabilità che un individuo selezionato a caso dalla popolazione abbia 19 anni. Possiamo anche esaminare la probabilità congiunta di più valori contemporaneamente; ad esempio, la probabilità di \\(X = x\\) e \\(Y = y\\) è scritta \\(P(X = x, Y = y)\\) o \\(P(x, y)\\). La nozione di “variabile” si contrappone alla nozione di “costante”, ovvero ad una proprietà che rimane invariante per tutte le unità statistiche.\nSi dice modalità ciascuna delle varianti con cui una variabile statistica può presentarsi. Definiamo insieme delle modalità di una variabile statistica l’insieme \\(M\\) di tutte le possibili espressioni con cui la variabile può manifestarsi. Le modalità osservate e facenti parte del campione si chiamano dati.\n\nEsempio 1.1 Supponiamo che il fenomeno studiato sia l’intelligenza. In uno studio, la popolazione potrebbe corrispondere all’insieme di tutti gli italiani adulti. La variabile considerata potrebbe essere il punteggio del test standardizzato WAIS-IV. Le modalità di tale variabile potrebbero essere 112, 92, 121, … Tale variabile è di tipo quantitativo discreto.\n\n\nEsempio 1.2 Supponiamo che il fenomeno studiato sia il compito Stroop. La popolazione potrebbe corrispondere all’insieme dei bambini dai 6 agli 8 anni. La variabile considerata potrebbe essere il reciproco dei tempi di reazione in secondi. Le modalità di tale variabile potrebbero essere 1.93, 2.35, 1.32, 1.49, 1.62, 2.93, … La variabile è di tipo quantitativo continuo.\n\n\nEsempio 1.3 Supponiamo che il fenomeno studiato sia il disturbo di personalità. La popolazione potrebbe corrispondere all’insieme dei detenuti nelle carceri italiane. La variabile considerata potrebbe essere l’assessment del disturbo di personalità tramite interviste cliniche strutturate. Le modalità di tale variabile potrebbero essere i Cluster A, Cluster B, Cluster C descritti dal DSM-V. Tale variabile è di tipo qualitativo.\n\n\n1.2.1 Variabili casuali\nIl termine variabile usato nella statistica è equivalente al termine variabile casuale usato nella teoria delle probabilità. Lo studio dei risultati degli interventi psicologici è lo studio delle variabili casuali che misurano questi risultati. Una variabile casuale cattura una caratteristica specifica degli individui nella popolazione e i suoi valori variano tipicamente tra gli individui. In teoria, ogni variabile casuale può assumere una gamma di possibili valori sebbene, in pratica, osserviamo un valore specifico per ogni individuo. Useremo lettere maiuscole come \\(X\\) e \\(Y\\) per fare riferiremo alle variabili casuali; useremo lettere minuscole come \\(x\\) e \\(y\\) quando faremo riferimento ai valori assunti da una variabile casuale in una specifica circostanza.\n\n\n\n\n\n\nChe differenza c’è tra una variabile casuale e una variabile statistica? La differenza tra questi due concetti può essere descritta dall’incertezza epistemica del ricercatore. Supponiamo, ad esempio, che l’esperimento casuale sia il lancio di un dado e la variabile di interesse \\(X\\) sia l’esito del lancio del dado. Poniamo che in una prova dell’esperimento casuale, ovvero in uno specifico lancio, la variabile \\(X\\) assuma il valore 5. Prima del lancio del dado, la variabile \\(X\\) è una variabile casuale (il ricercatore sa che \\(X\\) può assumere i valore 1, …, 6, ma non conosce lo specifico valore che verrà osservato dopo il lancio); dopo il lancio del dado, avendo osservato \\(X\\) = 5, la variabile \\(X\\) diventa una variabile statistica, ovvero costituisce un dato del campione di osservazioni."
  },
  {
    "objectID": "001_key_notions.html#statistica",
    "href": "001_key_notions.html#statistica",
    "title": "1  Concetti chiave",
    "section": "1.3 Statistica",
    "text": "1.3 Statistica\nUna statistica è una qualsiasi funzione del campione di una variabile casuale.\n\n\n\n\n\n\nEsempi di statistiche sono la media campionaria, la mediana campionaria, la varianza, ecc. Ma, per la definizione precedente, qualunque funzione arbitraria del campione costituisce una statistica: per esempio, il rapporto tra il valore minimo e il logaritmo del valore massimo del campione. Pur essendo insensato, un tale valore è una statistica del campione.\n\n\n\n\n1.3.1 Variabili indipendenti e variabili dipendenti\nUn primo compito fondamentale in qualsiasi analisi dei dati è l’identificazione delle variabili dipendenti (\\(Y\\)) e delle variabili indipendenti (\\(X\\)). Le variabili dipendenti sono anche chiamate variabili di esito o di risposta e le variabili indipendenti sono anche chiamate predittori o covariate. Ad esempio, nell’analisi di regressione, che esamineremo in seguito, la domanda centrale è quella di capire come varia \\(Y\\) al variare di \\(X\\). Più precisamente, la domanda che viene posta è: se viene mutato il valore della variabile indipendente \\(X\\), quale conseguenza ne deriva per la variabile dipendente \\(Y\\)? In parole povere, le variabili indipendenti e dipendenti sono analoghe a “cause” ed “effetti”, laddove le virgolette qui usate sottolineano che questa è solo un’analogia e che la determinazione delle cause può avvenire soltanto mediante l’utilizzo di un appropriato disegno sperimentale e di un’adeguata analisi statistica.\nSe una variabile è una variabile indipendente o dipendente dipende dalla domanda di ricerca. A volte può essere difficile distinguere le variabili dipendenti dalle variabili indipendenti, in particolare quando siamo specificamente interessati ai rapporti di causa/effetto. Ad esempio, supponiamo di indagare l’associazione tra esercizio fisico e insonnia. Vi sono evidenze che l’esercizio fisico (fatto al momento giusto della giornata) può ridurre l’insonnia. Ma l’insonnia può anche ridurre la capacità di una persona di fare esercizio fisico. Non è dunque facile capire quale sia la causa e quale sia l’effetto, ovvero quale sia la variabile dipendente e quale la variabile indipendente. La possibilità di identificare il ruolo delle variabili (dipendente/indipendente) dipende dalla nostra comprensione del fenomeno in esame.\n\nEsempio 1.4 Uno psicologo convoca 120 studenti universitari per un test di memoria. Prima di iniziare l’esperimento, a metà dei soggetti viene detto che si tratta di un compito particolarmente difficile; agli altri soggetti non viene data alcuna indicazione. Lo psicologo misura il punteggio nella prova di memoria di ciascun soggetto. In questo esperimento, la variabile indipendente è l’informazione sulla difficoltà della prova. La variabile indipendente viene manipolata dallo sperimentatore assegnando i soggetti (di solito in maniera causale) alla condizione (modalità) “informazione assegnata” o alla condizione “informazione non data”. La variabile dipendente è ciò che viene misurato nell’esperimento, ovvero il punteggio nella prova di memoria di ciascun soggetto.\n\n\n\n1.3.2 La matrice dei dati\nLe realizzazioni delle variabili esaminate in una rilevazione statistica vengono organizzate in una matrice dei dati. Le colonne della matrice dei dati contengono gli insiemi dei dati individuali di ciascuna variabile statistica considerata. Ogni riga della matrice contiene tutte le informazioni relative alla stessa unità statistica. Una generica matrice dei dati ha l’aspetto seguente:\n\\[\nD_{m,n} =\n\\begin{pmatrix}\n  \\omega_1 & a_{1}   & b_{1}   & \\cdots & x_{1} & y_{1}\\\\\n  \\omega_2 & a_{2}   & b_{2}   & \\cdots & x_{2} & y_{2}\\\\\n  \\vdots   & \\vdots  & \\vdots  & \\ddots & \\vdots & \\vdots  \\\\\n\\omega_n  & a_{n}   & b_{n}   & \\cdots & x_{n} & y_{n}\n\\end{pmatrix}\n\\]\ndove, nel caso presente, la prima colonna contiene il nome delle unità statistiche, la seconda e la terza colonna si riferiscono a due mutabili statistiche (o variabili categoriali; \\(A\\) e \\(B\\)) e ne presentano le modalità osservate nel campione mentre le ultime due colonne si riferiscono a due variabili statistiche (\\(X\\) e \\(Y\\)) e ne presentano le modalità osservate nel campione. Generalmente, tra le unità statistiche \\(\\omega_i\\) non esiste un ordine progressivo; l’indice attribuito alle unità statistiche nella matrice dei dati si riferisce semplicemente alla riga che esse occupano."
  },
  {
    "objectID": "001_key_notions.html#effetto",
    "href": "001_key_notions.html#effetto",
    "title": "1  Concetti chiave",
    "section": "1.4 Effetto",
    "text": "1.4 Effetto\nL’effetto è una qualche misura dei dati. Dipende dal tipo di dati e dal tipo di test statistico che si vuole utilizzare. Ad esempio, se viene lanciata una moneta 100 volte e esce testa 66 volte, l’effetto sarà 66/100. Diventa poi possibile confrontare l’effetto ottenuto con l’effetto nullo che ci si aspetterebbe da una moneta bilanciata (50/100), o con qualsiasi altro effetto che può essere scelto. La dimensione dell’effetto si riferisce alla differenza tra l’effetto misurato nei dati e l’effetto nullo (di solito un valore che ci si aspetta di ottenere in base al caso soltanto)."
  },
  {
    "objectID": "001_key_notions.html#stima-e-inferenza",
    "href": "001_key_notions.html#stima-e-inferenza",
    "title": "1  Concetti chiave",
    "section": "1.5 Stima e inferenza",
    "text": "1.5 Stima e inferenza\nLa stima è il processo mediante il quale il campione viene utilizzato per conoscere le proprietà di interesse della popolazione. Ad esempio, la media campionaria è una stima naturale della media della popolazione e la mediana campionaria è una stima naturale della mediana della popolazione. Quando si discute la stima di una proprietà della popolazione (a volte indicata come parametro della popolazione) o la stima della distribuzione di una variabile casuale (ovvero la probabilità che la variabile assuma qualsiasi valore in un dato intervallo), si fa riferimento all’utilizzo dei dati osservati per conoscere le proprietà di interesse della popolazione. L’inferenza statistica è il processo mediante il quale le stime campionarie vengono utilizzate per rispondere alle domande della ricerca e per valutare specifiche ipotesi relative alla popolazione. Nell’ultima parte di questa dispensa discuteremo le procedure bayesiane dell’inferenza e illustreremo i limiti dell’inferenza frequentista."
  },
  {
    "objectID": "001_key_notions.html#modelli-psicologici",
    "href": "001_key_notions.html#modelli-psicologici",
    "title": "1  Concetti chiave",
    "section": "1.6 Modelli psicologici",
    "text": "1.6 Modelli psicologici\nIl termine modello è onnipresente in statistica e nella data science. Un modello statistico include le ipotesi e le specifiche matematiche relative alla distribuzione della variabile casuale di interesse. Il modello dipende dai dati e dalla domanda di ricerca, ma raramente è unico; nella maggior parte dei casi, esiste più di un modello che potrebbe ragionevolmente usato per affrontare la stessa domanda di ricerca avendo a disposizione i dati osservati. Il problema di cosa costituisca un buon modello è una domanda su cui torneremo ripetutamente in questa dispensa.\nUn modello psicologico di un qualche aspetto del comportamento umano o della mente ha le seguenti proprietà:\n\ndescrive le caratteristiche del comportamento in questione,\nformula predizioni sulle caratteristiche future del comportamento,\nè sostenuto da evidenze empiriche,\ndeve essere falsificabile (ovvero, in linea di principio, deve potere fare delle predizioni su aspetti del fenomeno considerato che non sono ancora noti e che, se venissero indagati, potrebbero portare a rigettare il modello, se si dimostrassero incompatibili con esso).\n\nL’analisi dei dati si pone l’obiettivo di valutare un modello psicologico mediante strumenti statistici."
  },
  {
    "objectID": "005_measurement.html#misurare-la-mente-umana",
    "href": "005_measurement.html#misurare-la-mente-umana",
    "title": "2  La misurazione in psicologia",
    "section": "\n2.1 Misurare la mente umana",
    "text": "2.1 Misurare la mente umana\nIntroduco il problema della misurazione in psicologia parlando dell’intelligenza. In quanto psicologi, siamo abituati a pensare alla misurazione dell’intelligenza, ma anche le persone che non sono psicologi sono ben familiari con la misurazione dell’intelligenza: tra le misurazioni delle caratteristiche psicologiche, infatti, la misurazione dell’intelligenza è forse la più conosciuta.\nI test di intelligenza consistono in una serie di problemi di carattere verbale, numerico o simbolico. Come ci si può aspettare, alcune persone riescono a risolvere correttamente un numero maggiore di problemi di altre. Possiamo contare il numero di risposte corrette e osservare le differenze individuali nei punteggi calcolati. Scopriamo in questo modo che le differenze individuali nell’abilità di risolvere tali problemi risultano sorprendentemente stabili nell’età adulta. Inoltre, diversi test di intelligenza tendono ad essere correlati positivamente: le persone che risolvono un maggior numero di problemi verbali, in media, tenderanno anche a risolvere correttamente un numero più grande di problemi numerici e simbolici. Esiste quindi una notevole coerenza delle differenze osservate tra le persone, sia nel tempo sia considerando diverse procedure di test e valutazione.\nAvendo stabilito che ci sono differenze individuali tra le persone, è possibile esaminare le associazioni tra i punteggi dei test di intelligenza e altre variabili. Possiamo indagare se le persone con punteggi più alti nei test di intelligenza, rispetto a persone che ottengono punteggi più bassi, hanno più successo sul lavoro; se guadagnano di più; se votano in modo diverso; o se hanno un’aspettativa di vita più alta. Possiamo esaminare le differenze nei punteggi dei test di intelligenza in funzione di variabili come il genere, il gruppo etnico-razziale o lo stato socio-economico. Possiamo fare ricerche sull’associazione tra i punteggi dei test di intelligenza e l’efficienza dell’elaborazione neuronale, i tempi di reazione o la quantità di materia grigia all’interno della scatola cranica. Tutte queste ricerche sono state condotte e gli psicologi hanno scoperto una vasta gamma di associazioni tra le misure dell’intelligenza e altre variabili. Alcune di queste associazioni sono grandi e stabili, altre sono piccole e difficili da replicare. In riferimento all’intelligenza, dunque, gli psicologi hanno condotto un enorme numero di ricerche ponendosi domande diverse. In quali condizioni si verificano determinati effetti? Quali variabili mediano o moderano le relazioni tra i punteggi dei test di intelligenza e altre variabili? Queste relazioni si mantengono stabili in diversi gruppi di persone? Le ricerche sull’intelligenza umana sono un campo in continuo sviluppo.\nTuttavia, una domanda sorge spontanea: che cosa misurano esattamente i test di intelligenza? Dopo un secolo di ricerche sui punteggi dei test di intelligenza e, in generale, sui test psicologici, non sappiamo ancora rispondere a questa domanda. Questa considerazione relativa ai test di intelligenza ci conduce dunque alle seguenti domande: che cos’è esattamente un costrutto psicologico (come l’intelligenza, ad esempio)? Come può essere misurato un costrutto psicologico? Queste sono domande a cui è difficile rispondere e a cui è dedicata un’intera area di ricerca, quella della teoria della misurazione psicologica. Non possiamo qui entrare nel merito delle complessità della teoria della misurazione psicologica (questi temi più generali verranno approfonditi nei successivi insegnamenti sulla testistica psicologica). La motivazione delle considerazioni precedenti era solo quella di fare qualche accenno al contesto generale all’interno del quale si colloca il tema di cui ci occuperemo qui, ovvero quello delle scale di misura."
  },
  {
    "objectID": "005_measurement.html#le-scale-di-misura",
    "href": "005_measurement.html#le-scale-di-misura",
    "title": "2  La misurazione in psicologia",
    "section": "\n2.2 Le scale di misura",
    "text": "2.2 Le scale di misura\nIn generale possiamo dire che la teoria della misurazione si occupa dello studio delle relazioni esistenti tra due domini: il “mondo fisico” e il “mondo psicologico”. Secondo la teoria della misurazione, la misurazione è un’attività rappresentativa, cioè è un processo di assegnazione di numeri in modo tale da preservare, all’interno del dominio numerico, le relazioni qualitative che sono state osservate nel mondo empirico. La teoria della misurazione ha lo scopo di specificare le condizioni necessarie per la costruzione di una rappresentazione adeguata delle relazioni empiriche all’interno di un sistema numerico. Da una prospettiva formale, le operazioni descritte dalla teoria della misurazione possono essere concettualizzate in termini di mappatura tra le relazioni esistenti all’interno di due insiemi (quello empirico e quello numerico). Il risultato di questa attività è chiamato “scala di misurazione”.\nUna famosa teoria delle scale di misura è stata proposta da (Stevens, 1946). Stevens ci fa notare che, in linea di principio, le variabili psicologiche sono in grado di rappresentare (preservare) con diversi gradi di accuratezza le relazioni qualitative che sono state osservate nei fenomeni psicologici. Secondo la teoria di Stevens, possiamo distinguere tra quattro scale di misura: le scale nominali (nominal scales), ordinali (ordinal scales), a intervalli (interval scales), di rapporti (ratio scales). Tali scale di misura consentono operazioni aritmetiche diverse, come indicato nella tabella successiva, in quanto ciasuna di esse è in grado di “catturare” soltanto alcune delle proprietà dei fenomeni psicologici che intende misurare.\n\n\n2.2.1 Scala nominale\nIl livello di misurazione più semplice è quello della scala nominale. Questa scala di misurazione corrisponde ad una tassonomia. I simoboli o numeri che costituiscono questa scala non sono altro che i nomi delle categorie che utilizziamo per classificare i fenomeni psicologici. In base alle misure fornite da una scala nominale, l’unica cosa che siamo in grado di dire a proposito di una caratteristica psicologica è se essa è uguale o no ad un’altra caratteristica psicologica.\nLa scala nominale raggruppa dunque i dati in categorie qualitative mutuamente esclusive (cioè nessun dato si può collocare in più di una categoria). Esiste la sola relazione di equivalenza tra le misure delle u.s., cioè nella scala nominale gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti: \\(x_i = x_j\\) oppure \\(x_i \\neq x_j\\).\nL’unica operazione algebrica che possiamo compiere sulle modalità della scala nominale è quella di contare le u.s. che appartengono ad ogni modalità e contare il numero delle modalità (classi di equivalenza). Dunque la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nA partire da una scala nominale è possibile costruire altre scale nominali che sono equivalenti alla prima trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle modalità, ma lasciando però inalterata la suddivisione u.s. nelle medesime classi di equivalenza. Questo significa che prendendo una variabile misurata su scala nominale e cambiando i nomi delle sue categorie otteniamo una nuova variabile esattamente corrispondente alla prima.\n\n2.2.2 Scala ordinale\nLa scala ordinale conserva la proprietà della scala nominale di classificare ciascuna u.s. all’interno di una e una sola categoria, ma alla relazione di equivalenza tra elementi di una stessa classe aggiunge la relazione di ordinamento tra le classi di equivalenza. Essendo basata su una relazione d’ordine, una scala ordinale descrive soltanto l’ordine di rango tra le modalità, ma non ci dà alcuna informazione su quanto una modalità sia più grande di un’altra. Non ci dice, per esempio, se la distanza tra le modalità \\(a\\) e \\(b\\) sia uguale, maggiore o minore della distanza tra le modalità \\(b\\) e \\(c\\).\n\nEsempio 2.1 Un esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore.\n\n\n2.2.3 Scala ad intervalli\nLa scala ad intervalli include le proprietà di quella nominale e di quella ordinale, e in più consente di misurare le distanze tra le coppie di u.s. nei termini di un intervallo costante, chiamato unità di misura, a cui viene attribuito il valore “1”. La posizione dell’origine della scala, cioè il punto zero, è scelta arbitrariamente, nel senso che non indica l’assenza della quantità che si sta misurando. Avendo uno zero arbitrario, questa scala di misura consente valori negativi. Lo zero, infatti, non viene attribuito all’u.s. in cui la proprietà misurata risulta assente.\nLa scala a intervalli equivalenti ci consente di effettuare operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non era possibile eseguire nel caso di misure a livello di scala ordinale o nominale. Il limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Possiamo dire, per esempio, che la distanza tra \\(a\\) e \\(b\\) è la metà della distanza tra \\(c\\) e \\(d\\). Oppure che la distanza tra \\(a\\) e \\(b\\) è uguale alla distanza tra \\(c\\) e \\(d\\). Non possiamo dire, però, che \\(a\\) possiede la proprietà misurata in quantità doppia rispetto \\(b\\). Non possiamo cioè stabilire dei rapporti diretti tra le misure ottenute. Solo per le differenze tra le modalità sono dunque permesse tutte le operazioni aritmetiche: le differenze possono essere tra loro sommate, elevate a potenza oppure divise, determinando così le quantità che stanno alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l’unità di misura è arbitraria, ovvero può essere cambiata attraverso una dilatazione, operazione che consiste nel moltiplicare tutti i valori della scala per una costante positiva. Poiché l’aggiunta di una costante non altera le differenze tra i valori della scala, è anche ammessa la traslazione, operazione che consiste nel sommare una costante a tutti i valori della scala. Essendo la scala invariate rispetto alla traslazione e alla dilatazione, le trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b > 0.\n\\]\nL’aspetto che rimane invariante a seguito di una trasformazione lineare è l’uguaglianza dei rapporti fra intervalli.\nEsempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: 30\\(^\\circ\\)C \\(>\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c’è una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non è il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\nÈ facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n2.2.4 Scala di rapporti\nNella scala a rapporti equivalenti la posizione dello zero non è arbitraria, ma corrisponde all’elemento dotato di intensità nulla rispetto alla proprietà misurata. Una scala a rapporti equivalenti si costruisce associando il numero 0 all’elemento con intensità nulla; viene poi scelta un’unità di misura \\(u\\) e, ad ogni elemento, si assegna un numero \\(a\\) definito come: \\[a = \\frac{d}{u}\\] dove \\(d\\) rappresenta la distanza dall’origine. Alle u.s. vengono dunque assegnati dei numeri tali per cui le differenze e i rapporti tra i numeri riflettono le differenze e i rapporti tra le intensità della proprietà misurata.\nOperazioni aritmetiche sono possibili non solo sulle differenze tra i valori della scala (come per la scala a intervalli equivalenti), ma anche sui valori stessi della scala. L’unica arbitrarietà riguarda l’unità di misura che si utilizza. L’unità di misura può cambiare, ma qualsiasi unità di misura si scelga, lo zero deve sempre indicare l’intensità nulla della proprietà considerata.\nLe trasformazioni ammissibili a questo livello di scala sono dette trasformazioni di similarità: \\[y' = by, \\quad b > 0.\\] A questo livello di scala, a seguito delle trasformazioni ammissibili, rimangono invariati anche i rapporti: \\[\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}.\\]"
  },
  {
    "objectID": "005_measurement.html#gerarchia-dei-livelli-di-scala-di-misura",
    "href": "005_measurement.html#gerarchia-dei-livelli-di-scala-di-misura",
    "title": "2  La misurazione in psicologia",
    "section": "\n2.3 Gerarchia dei livelli di scala di misura",
    "text": "2.3 Gerarchia dei livelli di scala di misura\nStevens (1946) parla di livelli di scala poiché i quattro tipi di scala di misura stanno in una precisa gerarchia: la scala nominale rappresenta il livello più basso della misurazione, la scala a rapporti equivalenti è invece il livello più alto.\n\n\nScale di modalità\nOperazioni aritmetiche\n\n\n\nnominali\nenumerare le classi di equivalenza e/o\n\n\n\nle frequenze per ciascuna classe di equivalenza\n\n\nordinali\nenumerare le classi di equivalenza e/o\n\n\n\nle frequenze per ciascuna classe di equivalenza\n\n\nintervallari\ndifferenze (rapporti tra differenze)\n\n\ndi rapporti\nrapporti diretti tra le misure\n\n\n\nPassando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.\n\nPer ciò che riguarda le trasformazioni ammissibili, più il livello di scala è basso, più le funzioni sono generali (sono minori cioè i vincoli per passare da una rappresentazione numerica ad un’altra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa più restrittiva."
  },
  {
    "objectID": "005_measurement.html#variabili-discrete-o-continue",
    "href": "005_measurement.html#variabili-discrete-o-continue",
    "title": "2  La misurazione in psicologia",
    "section": "\n2.4 Variabili discrete o continue",
    "text": "2.4 Variabili discrete o continue\nLe variabili a livello di intervalli e di rapporti possono essere discrete o continue. Le variabili discrete possono assumere alcuni valori ma non altri. Una volta che l’elenco di valori accettabili è stato specificato, non ci sono casi che cadono tra questi valori. Le variabili discrete di solito assumono valori interi.\nQuando una variabile può assumere qualsiasi valore entro un intervallo specificato, allora si dice che la variabile è continua. In teoria, ciò significa che frazioni e decimali possono essere utilizzati per raggiungere un livello di precisione qualsiasi. In pratica, a un certo punto dobbiamo arrotondare i numeri, rendendo tecnicamente la variabile discreta. In variabili veramente discrete, tuttavia, non è possibile aumentare a piacimento il livello di precisione della misurazione.\n\n\nEsempio 2.2 Il numero di biciclette possedute da una persona è una variabile discreta poiché tale variabile può assumere come modalità solo i numeri interi non negativi. Frazioni di bicicletta non hanno senso."
  },
  {
    "objectID": "005_measurement.html#alcune-misure-sono-migliori-di-altre",
    "href": "005_measurement.html#alcune-misure-sono-migliori-di-altre",
    "title": "2  La misurazione in psicologia",
    "section": "\n2.5 Alcune misure sono migliori di altre",
    "text": "2.5 Alcune misure sono migliori di altre\nIn psicologia, ciò che vogliamo misurare non è una caratteristica fisica, ma invece è un concetto teorico inosservabile, ovvero un costrutto. Un costrutto rappresenta il risultato di una fondata riflessione scientifica, non è per definizione accessibile all’osservazione diretta, ma viene inferito dall’osservazione di opportuni indicatori (Sartori, 2005). Ad esempio, supponiamo che un docente voglia valutare quanto bene uno studente comprenda la distinzione tra le quattro diverse scale di misura che sono state descritte sopra. Il docente potrebbe predisporre un test costituito da un insieme di domande e potrebbe contare a quante domande lo studente risponde correttamente. Questo test, però, può o può non essere una buona misura del costrutto relativo alla conoscenza effettiva delle quattro scale di misura. Per esempio, se il docente scrive le domande del test in modo ambiguo o se usa una linguaggio troppo tecnico che lo studente non conosce, allora i risultati del test potrebbero suggerire che lo studente non conosce la materia in questione anche se in realtà questo non è vero. D’altra parte, se il docente prepara un test a scelta multipla con risposte errate molto ovvie, allora lo studente può ottenere dei buoni risultati al test anche senza essere in grado di comprendere adeguatamente le proprietà delle quattro scale di misura. In generale non è possibile misurare un costrutto senza una certa quantità di errore. Poniamoci dunque il problema di determinare in che modo una misurazione possa dirsi adeguata.\n\n2.5.1 Tipologie di errori\nL’errore è, per definizione, la differenza tra il valore vero e il valore misurato della grandezza in esame. Gli errori sono classificati come sistematici (o determinati) e casuali (o indeterminati). Gli errori casuali sono fluttuazioni, in eccesso o in difetto rispetto al valore reale, delle singole determinazioni e sono dovuti alle molte variabili incontrollabili che influenzano ogni misura psicologica. Gli errori sistematici, invece, influiscono sulla misurazione sempre nello stesso senso e, solitamente, per una stessa quantità (possono essere additivi o proporzionali).\nLe differenze tra le due tipologie di errori, sistematici e casuali, introducono i concetti di accuratezza e di precisione della misura. Una misura viene definita:\n\n\naccurata, quando vi è un accordo tra la misura effettuata ed il valore reale;\n\nprecisa quando, ripetendo più volte la misura, i risultati ottenuti sono concordanti, cioè differiscono in maniera irrilevante tra loro.\n\nLa metafora del tiro a bersaglio illustra la relazione tra precisione e accuratezza.\n\n\n\n\nFigura 2.1: Metafora del tiro al bersaglio.\n\n\n\n\nPer tenere sotto controllo l’incidenza degli errori, sono stati introdotti in psicologia i concetti di attendibilità e validità.\nUno strumento si dice attendibile quando valuta in modo coerente e stabile la stessa variabile: i risultati ottenuti si mantengono costanti dopo ripetute somministrazione ed in assenza di variazioni psicologiche e fisiche dei soggetti sottoposti al test o cambiamenti dell’ambiente in cui ha luogo la somministrazione.\nL’attendibilità di uno strumento, però, non è sufficiente: in primo luogo uno strumento di misura deve essere valido, laddove la validità rappresenta il grado in cui uno strumento misura effettivamente ciò che dovrebbe misurare. In genere, si fa riferimento ad almeno quattro tipi di validità.\n\nLa validità di costrutto riguarda il grado in cui un test misura ciò per cui è stato costruito. Essa si suddivide in: validità convergente e validità divergente. La validità convergente fa riferimento alla concordanza tra uno strumento e un altro che misura lo stesso costrutto. La validità divergente, al contrario, valuta il grado di discriminazione tra strumenti che misurano costrutti differenti. Senza validità di costrutto le altre forme di validità non hanno senso.\nIn base alla validità di contenuto, un test fornisce una misura valida di un attributo psicologico se il dominio dell’attributo è rappresentato in maniera adeguata dagli item del test. Un requisito di base della validità di contenuto è la rilevanza e la rappresentatività del contenuto degli item in riferimento all’attributo che il test intende misurare.\nLa validità di criterio valuta il grado di concordanza tra i risultati dello strumento considerato e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto, o tra i risultati dello strumento considerato e un criterio esterno. Nella validità concorrente, costrutto e criterio vengono misurati contestualmente, consentendo un confronto immediato. Nella validità predittiva, il costrutto viene misurato prima e il criterio in un momento successivo, consentendo la valutazione della capacità dello strumento di predire un evento futuro.\nInfine, la validità di facciata fa riferimento al grado in cui il test appare valido ai soggetti a cui esso è diretto. La validità di facciata è importante in ambiti particolari, quali ad esempio la selezione del personale per una determinata occupazione. In questo caso è ovviamente importante che chi si sottopone al test ritenga che il test vada a misurare quegli aspetti che sono importanti per le mansioni lavorative che dovranno essere svolte, piuttosto che altre cose. In generale, la validità di facciata non è utile, tranne in casi particolari."
  },
  {
    "objectID": "005_measurement.html#commenti-e-considerazioni-finali",
    "href": "005_measurement.html#commenti-e-considerazioni-finali",
    "title": "2  La misurazione in psicologia",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nUna domanda che uno psicologo spesso si pone è: “sulla base delle evidenze osservate, possiamo concludere dicendo che l’intervento psicologico è efficace nel trattamento e nella cura del disturbo?” Le considerazioni svolte in questo capitolo dovrebbero farci capire che, prima di cercare di rispondere a questa domanda con l’analisi statistica dei dati, devono essere affrontati i problemi della validità e dell’attendibilità delle misure (oltre a stabilire l’appropriato livello di scala di misura delle osservazioni). L’attendibilità è un prerequisito della validità. Se gli errori di misurazione sono troppo grandi, i dati sono inutili. Inoltre, uno strumento di misurazione può essere preciso ma non valido. La validità e l’attendibilità delle misurazioni sono dunque entrambe necessarie.\nIn generale, l’attendibilità e la validità delle misure devono essere valutate per capire se i dati raccolti da un ricercatore siano adeguati (1) per fornire una risposta alla domanda della ricerca, e (2) per giungere alla conclusione proposta dal ricercatore alla luce dei risultati dell’analisi statistica che è stata eseguita. È chiaro che le informazioni fornite in questo capitolo si limitano a scalfire la superficie di questi problemi. I concetti qui introdotti, però, devono sempre essere tenuti a mente e costituiscono il fondamento di quanto verrà esposto nei capitoli successivi.\n\n\n\n\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677–680."
  },
  {
    "objectID": "007_freq_distr.html#chapter-descript",
    "href": "007_freq_distr.html#chapter-descript",
    "title": "3  Analisi esplorativa dei dati",
    "section": "\n3.1 Introduzione all’esplorazione dei dati",
    "text": "3.1 Introduzione all’esplorazione dei dati\nLe analisi esplorative dei dati sono indispensabili per condurre in modo corretto una qualsiasi analisi statistica, dal livello base a quello avanzato. Si parla di analisi descrittiva dei dati se l’obiettivo è quello di descrivere le caratteristiche di un campione. Si parla di analisi esplorativa dei dati (Exploratory Data Analysis o EDA) se l’obiettivo è quello di esplorare i dati alla ricerca di nuove informazioni e relazioni tra variabili. Questa distinzione, seppur importante a livello teorico, nella pratica è più fumosa perché spesso entrambe le situazioni si verificano contemporaneamente nella stessa indagine statistica e le metodologie di analisi che si utilizzano sono molto simili. È ovvio che è necessario usare un software sia per il calcolo delle statistiche descrittive che per l’analisi esplorativa dei dati. In questo capitolo dunque le descrizioni dei concetti di base della EDA saranno sempre accompagnate con le istruzioni \\(\\mathsf{R}\\) necessarie per calcolare in pratica le quantità discusse."
  },
  {
    "objectID": "007_freq_distr.html#un-excursus-storico",
    "href": "007_freq_distr.html#un-excursus-storico",
    "title": "3  Analisi esplorativa dei dati",
    "section": "\n3.2 Un excursus storico",
    "text": "3.2 Un excursus storico\nNel 1907 Francis Galton, cugino di Charles Darwin, matematico e statistico autodidatta, geografo, esploratore, teorico della dattiloscopia (ovvero, dell’uso delle impronte digitali a fini identificativi) e dell’eugenetica, scrisse una lettera alla rivista scientifica Nature sulla sua visita alla Fat Stock and Poultry Exhibition di Plymouth. Lì vide alcuni membri del pubblico partecipare ad un gioco il cui scopo era quello di indovinare il peso della carcassa di un grande bue che era appena stato scuoiato. Galton si procurò i 787 dei biglietti che erano stati compilati dal pubblico e considerò il valore medio di 547 kg come la “scelta democratica” dei partecipanti, in quanto “ogni altra stima era stata giudicata troppo alta o troppo bassa dalla maggioranza dei votanti”. Il punto interessante è che il peso corretto di 543 kg si dimostrò essere molto simile alla “scelta democratica” basata sulle stime dei 787 partecipanti. Galton intitolò la sua lettera a Nature Vox Populi (voce del popolo), ma questo processo decisionale è ora meglio conosciuto come la “saggezza delle folle” (wisdom of crowds). Possiamo dire che, nel suo articolo del 1907, Galton effettuò quello che ora chiamiamo un riepilogo dei dati, ovvero calcolò un indice sintetico a partire da un insieme di dati. In questo capitolo esamineremo le tecniche che sono state sviluppate nel secolo successivo per riassumere le grandi masse di dati con cui sempre più spesso ci dobbiamo confrontare. Vedremo come calcolare e interpretare gli indici di posizione e di dispersione, discuteremo le distribuzioni di frequenze e le relazioni tra variabili. Vedremo inoltre quali sono le tecniche di visualizzazione che ci consentono di rappresentare questi sommari dei dati mediante dei grafici."
  },
  {
    "objectID": "007_freq_distr.html#riassumere-i-dati",
    "href": "007_freq_distr.html#riassumere-i-dati",
    "title": "3  Analisi esplorativa dei dati",
    "section": "\n3.3 Riassumere i dati",
    "text": "3.3 Riassumere i dati\nPrima di entrare nei dettagli, iniziamo con una considerazione generale. Quando riassumiamo i dati, è ovvio che, necessariamente, buttiamo via delle informazioni. Potremmo dunque chiederci: è una buona idea procedere in questo modo? Non sarebbe meglio conservare, oltre a ciò che viene trasmesso dagli indici riassuntivi della statistica descrittiva, le informazioni specifiche di ciascun soggetto che partecipa ad un esperimento psicologico? Che dire poi delle informazioni che descrivono come sono stati raccolti i dati, come l’ora del giorno o l’umore del partecipante? Tutte queste informazioni vengono perdute quando riassumiamo i dati. La risposta alla domanda ipotetica che ci siamo posti è che, in generale, non è una buona idea conservare tutti i dettagli di ciò che conosciamo. È molto più utile riassumere le informazioni a disposizione perché una tale semplificazione consente i processi di generalizzazione.\nIn un contesto letterario, l’importanza della generalizzazione è stata sottolineata da Jorge Luis Borges nel suo racconto “Funes o della memoria”. In questo racconto, Borges descrive un individuo che perde la capacità di dimenticare e si concentra sulla relazione tra generalizzazione e pensiero:\n\nPensare è dimenticare una differenza, generalizzare, astrarre. Nel mondo troppo pieno di Funes, c’erano solo dettagli.\n\nCome possiamo ben immaginare, la vita di Funes non è facile. Se facciamo riferimento alla psicologia, possiamo dire che gli psicologi hanno studiato a lungo l’utilità della generalizzazione per il pensiero. Un esempio è fornito dal fenomeno della formazione dei concetti e lo psicologo che viene in mente a questo proposito è sicuramente Eleanor Rosch, la quale ha studiato i principi di base della categorizzazione. Come è stato illustrato dalle ricerche di Eleanor Rosch, i concetti ci forniscono uno strumento potente per organizzare le nostre conoscenze. Siamo in grado di riconoscere facilmente i diversi esemplare di un concetto – per esempio, “gli uccelli” – anche se i singoli esemplari che fanno parte della categoria sono molto diversi tra loro (l’aquila, il gabbiano, il pettirosso). Inoltre, l’uso dei concetti, cioè la generalizzazione, è utile perché ci consente di fare previsioni sulle proprietà dei singoli esemplari che appartengono ad una categoria, anche se non abbiamo mai avuto un’esperienza diretta con essi – per esempio, possiamo fare la predizione che tutti gli uccelli possono volare e mangiare vermi, ma non possono guidare un’automobile o parlare in inglese. Queste previsioni non sono sempre corrette, ma sono molto utili.\nIn un certo senso, potremmo dire che le statistiche descrittive ci fornisco l’analogo dei “prototipi” che, secondo Eleanor Rosch, stanno alla base del processo psicologico di creazione dei concetti. Un prototipo è l’esemplare più rappresentativo di una categoria. Per analogia, una statistica descrittiva come la media, ad esempio, può essere intesa come l’osservazione “tipica”. Conoscere il “valore tipico” di un insieme di dati (quale la media o la mediana) è molto utile per quello che ci dice delle altre osservazioni (che sarebbe troppo oneroso elencare): ciò che il valore tipo di una distribuzione ci dice è che le altre osservazioni “assomigliano” al valore tipico. Quindi, con un unico indice riusciamo a catturare ciò che molteplici osservazioni “hanno in comune”. Ovviamente, questa “somiglianza” ha dei limiti e vedremo anche come descrivere in forma sintetica il concetto complementare, ovvero quello della “differenza” tra le osservazioni.\nLa statistica descrittiva ci fornisce gli strumenti per riassumere, in una forma visiva o numerica, i dati che abbiamo raccolto. Le rappresentazioni grafiche più usate della statistica descrittiva sono gli istogrammi, i diagrammi a dispersione o i box-plot, e gli indici sintetici più comuni sono la media, la mediana, la varianza e la deviazione standard. Questi sono gli strumenti di base della data science."
  },
  {
    "objectID": "007_freq_distr.html#i-dati-grezzi",
    "href": "007_freq_distr.html#i-dati-grezzi",
    "title": "3  Analisi esplorativa dei dati",
    "section": "\n3.4 I dati grezzi",
    "text": "3.4 I dati grezzi\nPer introdurre i principali strumenti della statistica descrittiva considereremo qui i dati raccolti da Zetsche et al. (2019). Questi ricercatori hanno studiato le aspettative negative quale meccanismo chiave nel mantenimento e nella reiterazione della depressione. In questo studio, Zetsche et al. (2019) si sono chiesti se individui depressi maturano delle aspettative accurate sul loro umore futuro, oppure se tali aspettative sono distorte negativamente. In uno degli studi riportati viene esaminato un campione costituito da 30 soggetti con almeno un episodio depressivo maggiore e un campione di 37 controlli sani. Gli autori hanno misurato il livello depressivo con il Beck Depression Inventory (BDI-II). Questi sono i dati che considereremo qui.\n\nEsercizio 3.1 Iniziamo a porci una semplice domanda: vogliamo conoscere il livello di depressione, misurato dalla scala BDI-II, nel campione di soggetti esaminati da Zetsche et al. (2019). La risposta più semplice a tale domanda consiste semplicemente nell’elencare i valori BDI-II del campione.\n\n\nSoluzione. Iniziamo dunque a leggere i dati in \\(\\mathsf{R}\\). Se il file data.mood.csv si trova nella cartella data contenuta nella working directory, allora possiamo usare le istruzioni seguenti.\n\ndf = pd.read_csv('data/data.mood.csv',index_col=0)\n\nStampo il nome delle colonne del DataFrame.\n\nlist(df.columns)\n#> ['vpn_nr', 'esm_id', 'group', 'bildung', 'bdi', 'nr_of_episodes', 'nobs_mood', 'trigger_counter', 'form', 'traurig_re', 'niedergeschlagen_re', 'unsicher_re', 'nervos_re', 'glucklich_re', 'frohlich_re', 'mood_sad.5', 'mood_fearful.5', 'mood_neg.5', 'mood_happy.5', 'cesd_sum', 'rrs_sum', 'rrs_brood', 'rrs_reflect', 'forecast_sad', 'forecast_fear', 'forecast_neg', 'forecast_happy', 'recall_sad', 'recall_fear', 'recall_neg', 'recall_happy', 'diff_neg.fore.5', 'diff_sad.fore.5', 'diff_fear.fore.5', 'diff_happy.fore.5', 'diff_neg.retro.5', 'diff_sad.retro.5', 'diff_fear.retro.5', 'diff_happy.retro.5', 'mood_sad5_tm1', 'mood_neg5_tm1', 'mood_fearful5_tm1', 'mood_happy5_tm1']\n\nSeleziono unicamente le colonne di interesse.\n\ndf = df[['esm_id','group','bdi']]\ndf.head()\n#>    esm_id group   bdi\n#> 1      10   mdd  25.0\n#> 2      10   mdd  25.0\n#> 3      10   mdd  25.0\n#> 4      10   mdd  25.0\n#> 5      10   mdd  25.0\n\nC’è un solo valore BDI-II per ciascun soggetto ma tale valore viene ripetuto tante volte quante volte sono le righe del DataFrame associate ad ogni soggetto (ciascuna riga corrisponde ad una prova diversa su altre variabili).\n\ndf.shape\n#> (1188, 3)\n\nÈ dunque necessario trasformare il DataFrame in modo tale da avere un’unica riga per ciascun soggetto, ovvero un unico valore BDI-II per soggetto.\n\ndf = df.drop_duplicates(keep='first')\ndf.shape\n#> (67, 3)\n\n\ndf.head()\n#>     esm_id group   bdi\n#> 1       10   mdd  25.0\n#> 15       9   mdd  30.0\n#> 30       6   mdd  26.0\n#> 46       7   mdd  35.0\n#> 65      12   mdd  44.0\n\nEsaminiamo i dati.\n\ndf.groupby('group')['bdi'].describe().round(1)\n#>        count  mean  std   min   25%   50%   75%   max\n#> group                                                \n#> ctl     36.0   1.6  2.7   0.0   0.0   1.0   2.0  12.0\n#> mdd     30.0  30.9  6.6  19.0  26.0  30.0  35.0  44.0\n\nPer semplicità, presentiamo i valori BDI-II ordinati dal più piccolo al più grande.\n\nprint(*df['bdi'].sort_values())\n#> 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 5.0 7.0 9.0 12.0 19.0 22.0 22.0 24.0 25.0 25.0 26.0 26.0 26.0 27.0 27.0 28.0 28.0 30.0 30.0 30.0 31.0 31.0 33.0 33.0 34.0 35.0 35.0 35.0 36.0 39.0 41.0 43.0 43.0 44.0 nan\n\n\ndf.shape\n#> (67, 3)\n\nEscludo il dato mancante.\n\ndf = df[pd.notnull(df['bdi'])]\ndf.shape\n#> (66, 3)\n\n\nprint(*df['bdi'].sort_values())\n#> 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 5.0 7.0 9.0 12.0 19.0 22.0 22.0 24.0 25.0 25.0 26.0 26.0 26.0 27.0 27.0 28.0 28.0 30.0 30.0 30.0 31.0 31.0 33.0 33.0 34.0 35.0 35.0 35.0 36.0 39.0 41.0 43.0 43.0 44.0\n\n\nÈ chiaro però che i dati grezzi sono di difficile lettura – e se abbiamo grandi masse di dati (un caso molto comune in psicologia) ogni “lettura” diretta dei dati grezzi è impossibile. Nella sezione successiva vedremo come sia possibile creare una rappresentazione sintetica e, soprattutto, comprensibile dei dati grezzi."
  },
  {
    "objectID": "007_freq_distr.html#distribuzioni-di-frequenze",
    "href": "007_freq_distr.html#distribuzioni-di-frequenze",
    "title": "3  Analisi esplorativa dei dati",
    "section": "\n3.5 Distribuzioni di frequenze",
    "text": "3.5 Distribuzioni di frequenze\nUno dei modi che ci consentono di effettuare una sintesi dei dati è quello di generare una distribuzione di frequenze.\n\nDefinizione 3.1 Una distribuzione di frequenze è un riepilogo del conteggio della frequenza con cui le modalità osservate in un insieme di dati si verificano in un intervallo di valori.\n\nIn altre parole, la distribuzione di frequenze della variabile \\(X\\) corrisponde all’insieme delle frequenze assegnate a ciascun possibile valore di \\(X\\).\n\n\n\n\n\n\nNel paragrafo seguente utilizzerò i seguenti concetti di “partizione” e “disgiunzione” della teoria degli insiemi. Inoltre, userò il concetto matematico di “intervallo.” Un ripasso di tali concetti è fornito nell’Appendice. Si noti, inoltre, l’uso della notazione \\(\\bar{X}\\) per denotare la media della variabile \\(X\\).\n\n\n\nPer creare una distribuzione di frequenze possiamo procedere effettuando una partizione delle modalità della variabile di interesse in \\(m\\) classi (denotate con \\(\\Delta_i\\)) tra loro disgiunte. In tale partizione, la classe \\(i\\)-esima coincide con un intervallo di valori aperto a destra \\([a_i, b_i)\\) o aperto a sinistra \\((a_i, b_i]\\). Ad ogni classe \\(\\Delta_i\\) avente \\(a_i\\) e \\(b_i\\) come limite inferiore e superiore associamo l’ampiezza \\(b_i - a_i\\) (non necessariamente uguale per ogni classe) e il valore centrale \\(\\bar{x}_i\\). La scelta delle classi è arbitraria, ma è buona norma non definire classi con un numero troppo piccolo (\\(< 5\\)) di osservazioni. Poiché ogni elemento dell’insieme \\(\\{x_i\\}_{i=1}^n\\) appartiene ad una ed una sola classe \\(\\Delta_i\\), possiamo calcolare le quantità elencate di seguito.\n\nLa frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\).\n\nProprietà: \\(n_1 + n_2 + \\dots + n_m = n\\).\n\n\nLa frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe.\n\nProprietà: \\(f_1+f_2+\\dots+f_m =1\\).\n\n\nLa frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(i\\)-esima compresa: \\(N_i = \\sum_{i=1}^m n_i.\\)\n\nLa frequenza cumulata relativa \\(F_i\\), ovvero \\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{i=1}^m f_i.\\)\n\n\n\nEsercizio 3.2 Si calcoli la distribuzione di frequenza assoluta e la distribuzione di frequenza relativa per i valori del BDI-II del campione di Zetsche et al. (2019).\n\n\nSoluzione. Per costruire una distribuzione di frequenza è innanzitutto necessario scegliere gli intervalli delle classi. Facendo riferimento ai cut-off usati per l’interpretazione del BDI-II, definiamo i seguenti intervalli aperti a destra:\n\ndepressione minima: \\([0, 13.5)\\),\ndepressione lieve: \\([13.5, 19.5)\\),\ndepressione moderata: \\([19.5, 28.5)\\),\ndepressione severa: \\([28.5, 63)\\).\n\nEsaminando i dati, possiamo notare che 36 soggetti cadono nella prima classe, uno nella seconda classe, e così via. La distribuzione di frequenza della variabile bdi2 è riportata nella tabella seguente. Questa distribuzione di frequenza ci aiuta a capire meglio cosa sta succedendo. Se consideriamo la frequenza relativa, ad esempio, possiamo notare che ci sono due valori maggiormente ricorrenti e tali valori corrispondono alle due classi più estreme. Questo ha senso nel caso presente, in quanto il campione esaminato da Zetsche et al. (2019) includeva due gruppi di soggetti: soggetti sani (con valori BDI-II bassi) e soggetti depressi (con valori BDI-II alti).1 In una distribuzione di frequenza tali valori tipici vanno sotto il nome di mode della distribuzione.\n\n\n\nLim. classi\nFr. ass.\nFr. rel.\nFr. ass. cum.\nFr. rel. cum.\n\n\n\n\\([0, 13.5)\\)\n36\n36/66\n36\n36/66\n\n\n\\([13.5, 19.5)\\)\n1\n1/66\n37\n37/66\n\n\n\\([19.5, 28.5)\\)\n12\n12/66\n49\n49/66\n\n\n\\([28.5, 63)\\)\n17\n17/66\n66\n66/66\n\n\n\n\nPoniamoci ora il problema di costruire la tabella precedente utilizzando Python.\nAggiungo a df una colonna che contiene una variabile categoriale che classifica ciascuna osservazione in una delle quattro classi definite sopra.\n\ndf['bdi_class'] = pd.cut(df['bdi'], [0, 13.5, 19.5, 28.5, 45], include_lowest=True)\nprint(df)\n#>       esm_id group   bdi       bdi_class\n#> 1         10   mdd  25.0    (19.5, 28.5]\n#> 15         9   mdd  30.0    (28.5, 45.0]\n#> 30         6   mdd  26.0    (19.5, 28.5]\n#> 46         7   mdd  35.0    (28.5, 45.0]\n#> 65        12   mdd  44.0    (28.5, 45.0]\n#> ...      ...   ...   ...             ...\n#> 1105      99   ctl   0.0  (-0.001, 13.5]\n#> 1121     100   ctl   2.0  (-0.001, 13.5]\n#> 1133     104   ctl   0.0  (-0.001, 13.5]\n#> 1152     103   ctl   0.0  (-0.001, 13.5]\n#> 1171     102   ctl   1.0  (-0.001, 13.5]\n#> \n#> [66 rows x 4 columns]\n\nVerifico.\n\nmy_tab = pd.crosstab(index=df[\"bdi_class\"], columns=\"count\") \nmy_tab\n#> col_0           count\n#> bdi_class            \n#> (-0.001, 13.5]     36\n#> (13.5, 19.5]        1\n#> (19.5, 28.5]       12\n#> (28.5, 45.0]       17\n\n\n\n3.5.1 Distribuzioni congiunte\nInsiemi di variabili possono anche avere distribuzioni di frequenze, dette distribuzioni congiunte. La distribuzione congiunta di un insieme di variabili \\(V\\) è l’insieme delle frequenze di ogni possibile combinazione di valori delle variabili in \\(V\\). Ad esempio, se \\(V\\) è un insieme di due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali può assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) è \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), \\(f(X = 2, Y = 2) = 0.2\\). Proprio come con le distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1."
  },
  {
    "objectID": "007_freq_distr.html#istogramma",
    "href": "007_freq_distr.html#istogramma",
    "title": "3  Analisi esplorativa dei dati",
    "section": "\n3.6 Istogramma",
    "text": "3.6 Istogramma\nI dati sintetizzati in una distribuzione di frequenze possono essere rappresentati graficamente in un istogramma. Un istogramma si costruisce riportando sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate i valori della funzione costante a tratti\n\\[\n\\varphi_n(x)= \\frac{f_i}{b_i-a_i}, \\quad x\\in \\Delta_i,\\, i=1, \\dots, m\n\\]\nche misura la densità della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\), ovvero il rapporto fra la frequenza relativa \\(f_i\\) e l’ampiezza (\\(b_i - a_i\\)) della classe. In questo modo il rettangolo dell’istogramma associato alla classe \\(\\Delta_i\\) avrà un’area proporzionale alla frequenza relativa \\(f_i\\). Si noti che l’area totale dell’istogramma delle frequenze relative è data della somma delle aree dei singoli rettangoli e quindi vale 1.0.\n\nEsercizio 3.3 Si utilizzi Python per costruire un istogramma per i valori BDI-II riportati da Zetsche et al. (2019).\n\n\nSoluzione. Con i quattro intervalli individuati dai cut-off del BDI-II creo ora una prima versione dell’istogramma – si notino le frequenze assolute sull’asse delle ordinate.\n\nbdi_bins = [0, 13.5, 19.5, 28.5, 44]\nsns.histplot(data = df, x = \"bdi\", stat = \"count\", bins=bdi_bins)\n\n\n\n\n\n\n\nUna versione alternativa dello stesso grafico è la seguente.\n\nax = sns.histplot(df['bdi'], bins=bdi_bins)\n\nfor p in ax.patches:\n  ax.annotate(f'{p.get_height():.0f}\\n', \n  (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='center', color='crimson')\nplt.show()\n\n\n\n\n\n\n\nPoniamo ora, sull’asse x, le densità.\n\nsns.histplot(data = df, x = \"bdi\", stat = \"density\", bins=bdi_bins)\n\n\n\n\n\n\n\nIn generale, però, è molto più comune usare classi aventi tutte la medesima ampiezza.\n\nsns.histplot(data = df, x = \"bdi\", stat = \"density\")\n\n\n\nFigura 3.1: Istogramma per i valori BDI-II riportati da Zetsche et al. (2019).\n\n\n\n\nAnche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale. Questo è il caso dell’istogramma della Figura 3.2.\n\nsns.histplot(data = df, x = \"bdi\", stat = \"density\")\n\n\n\nFigura 3.2: Una rappresentazione più comune per l’istogramma dei valori BDI-II nella quale gli intervalli delle classi hanno ampiezze uguali."
  },
  {
    "objectID": "007_freq_distr.html#kernel-density-plot",
    "href": "007_freq_distr.html#kernel-density-plot",
    "title": "3  Analisi esplorativa dei dati",
    "section": "\n3.7 Kernel density plot",
    "text": "3.7 Kernel density plot\nIl confronto tra la Figura 3.1 e la Figura 3.2 rende chiaro il limite dell’istogramma: il profilo dell’istogramma è arbitrario, in quanto dipende dal numero e dall’ampiezza delle classi. Questo rende difficile l’interpretazione.\nIl problema precedente può essere alleviato utilizzando una rappresentazione alternativa della distribuzione di frequenza, ovvero la stima della densità della frequenza dei dati (detta anche stima kernel di densità). Un modo semplice per pensare a tale rappresentazione, che in inglese va sotto il nome di kernel density plot (cioè i grafici basati sulla stima kernel di densità), è quello di immaginare un grande campione di dati, in modo che diventi possibile definire un enorme numero di classi di equivalenza di ampiezza molto piccola, le quali non risultino vuote. In tali circostanze, la funzione di densità empirica non è altro che il profilo lisciato dell’istogramma. La stessa idea si applica anche quando il campione è piccolo. In tali circostanze, invece di raccogliere le osservazioni in barre come negli istogrammi, lo stimatore di densità kernel colloca una piccola “gobba” (bump), determinata da un fattore \\(K\\) (kernel) e da un parametro \\(h\\) di smussamento detto ampiezza di banda (bandwidth), in corrispondenza di ogni osservazione, quindi somma le gobbe risultanti generando una curva smussata.\nL’interpretazione che possiamo attribuire al kernel density plot è simile a quella che viene assegnata agli istogrammi: l’area sottesa al kernel density plot in un certo intervallo rappresenta la proporzione di casi della distribuzione che hanno valori compresi in quell’intervallo.\n\nEsercizio 3.4 All’istogramma dei valori BDI-II di Zetsche et al. (2019) si sovrapponga un kernel density plot.\n\nsns.displot(data=df, x=\"bdi\", hue=\"group\", stat=\"density\", kde=True);\nplt.xlabel('BDI-II')\n\n\n\nFigura 3.3: Kernel density plot e corrispondente istogramma per i valori BDI-II."
  },
  {
    "objectID": "007_freq_distr.html#forma-di-una-distribuzione",
    "href": "007_freq_distr.html#forma-di-una-distribuzione",
    "title": "3  Analisi esplorativa dei dati",
    "section": "\n3.8 Forma di una distribuzione",
    "text": "3.8 Forma di una distribuzione\nIn generale, la forma di una distribuzione descrive come i dati si distribuiscono intorno ai valori centrali. Distinguiamo tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali o multimodali. Un’illustrazione grafica è fornita nella Figura 3.4. Nel pannello 1 la distribuzione è unimodale con asimmetria negativa; nel pannello 2 la distribuzione è unimodale con asimmetria positiva; nel pannello 3 la distribuzione è simmetrica e unimodale; nel pannello 4 la distribuzione è bimodale.\n\n\n\n\nFigura 3.4: 1: Asimmetria negativa. 2: Asimmetria positiva. 3: Distribuzione unimodale. 4: Distribuzione bimodale.\n\n\n\n\n\nEsercizio 3.5 Il kernel density plot della Figura 3.3 indica che la distribuzione dei valori del BDI-II nel campione di Zetsche et al. (2019) è bimodale. Ciò indica che le osservazioni della distribuzione si addensano in due cluster ben distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l’altro gruppo tende ad avere BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019)."
  },
  {
    "objectID": "007_freq_distr.html#indici-di-posizione",
    "href": "007_freq_distr.html#indici-di-posizione",
    "title": "3  Analisi esplorativa dei dati",
    "section": "\n3.9 Indici di posizione",
    "text": "3.9 Indici di posizione\n\n3.9.1 Quantili\nLa descrizione della distribuzione dei valori BDI-II di Zetsche et al. (2019) può essere facilitata dalla determinazione di alcuni valori caratteristici che sintetizzano le informazioni contenute nella distribuzione di frequenze. Si dicono quantili (o frattili) quei valori caratteristici che hanno le seguenti proprietà. I quartili sono quei valori che ripartiscono i dati \\(x_i\\) in quattro parti ugualmente numerose (pari ciascuna al 25% del totale). Il primo quartile, \\(q_1\\), lascia alla sua sinistra il 25% del campione pensato come una fila ordinata (a destra quindi il 75%). Il secondo quartile \\(q_2\\) lascia a sinistra il 50% del campione (a destra quindi il 50%). Esso viene anche chiamato mediana. Il terzo quartile lascia a sinistrail 75% del campione (a destra quindi il 25%). Secondo lo stesso criterio, si dicono decili i quantili di ordine \\(p\\) multiplo di 0.10 e percentili i quantili di ordine \\(p\\) multiplo di 0.01.\nCome si calcolano i quantili? Consideriamo la definizione di quantile non interpolato di ordine \\(p\\) \\((0 < p < 1)\\). Si procede innanzitutto ordinando i dati in ordine crescente, \\(\\{x_1, x_2, \\dots, x_n\\}\\). Ci sono poi due possibilità. Se il valore \\(np\\) non è intero, sia \\(k\\) l’intero tale che \\(k < np < k + 1\\) – ovvero, la parte intera di \\(np\\). Allora \\(q_p = x_{k+1}.\\) Se \\(np = k\\) con \\(k\\) intero, allora \\(q_p = \\frac{1}{2}(x_{k} + x_{k+1}).\\) Se vogliamo calcolare il primo quartile \\(q_1\\), ad esempio, utilizziamo \\(p = 0.25\\). Dovendo calcolare gli altri quantili basta sostituire a \\(p\\) il valore appropriato.\nGli indici di posizione, tra le altre cose, hanno un ruolo importante, ovvero vengono utilizzati per creare una rappresentazione grafica di una distribuzione di valori che è molto popolare e può essere usata in alternativa ad un istogramma (in realtà vedremo poi come possa essere combinata con un istogramma). Tale rappresentazione va sotto il nome di box-plot.\n\nEsercizio 3.6 Per fare un esempio, consideriamo i nove soggetti del campione clinico di Zetsche et al. (2019) che hanno riportato un unico episodio di depressione maggiore. Per tali soggetti i valori ordinati del BDI-II (per semplicità li chiameremo \\(x\\)) sono i seguenti: 19, 26, 27, 28, 28, 33, 33, 41, 43. Per il calcolo del secondo quartile (non interpolato), ovvero per il calcolo della mediana, dobbiamo considerare la quantità \\(np = 9 \\cdot 0.5 = 4.5\\), non intero. Quindi, \\(q_1 = x_{4 + 1} = 27\\). Per il calcolo del quantile (non interpolato) di ordine \\(p = 2/3\\) dobbiamo considerare la quantità \\(np = 9 \\cdot 2/3 = 6\\), intero. Quindi, \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\n\n\nEsercizio 3.7 Usiamo numpy per trovare la soluzione dell’esercizio precedente.\n\nimport numpy as np\n\nx = [19, 26, 27, 28, 28, 33, 33, 41, 43]\nnp.quantile(x, 2/3)\n#> 33.0"
  },
  {
    "objectID": "007_freq_distr.html#mostrare-i-dati",
    "href": "007_freq_distr.html#mostrare-i-dati",
    "title": "3  Analisi esplorativa dei dati",
    "section": "\n3.10 Mostrare i dati",
    "text": "3.10 Mostrare i dati\n\n3.10.1 Diagramma a scatola\nIl diagramma a scatola (o box plot) è uno strumento grafico utile al fine di ottenere informazioni circa la dispersione e l’eventuale simmetria o asimmetria di una distribuzione. Per costruire un box-plot si rappresenta sul piano cartesiano un rettangolo (cioè la “scatola”) di altezza arbitraria la cui base corrisponde alla dist intanza interquartile (IQR = \\(q_{0.75} - q_{0.25}\\)). La linea interna alla scatola rappresenta la mediana \\(q_{0.5}\\). Si tracciano poi ai lati della scatola due segmenti di retta i cui estremi sono detti “valore adiacente” inferiore e superiore. Il valore adiacente inferiore è il valore più piccolo tra le osservazioni che risulta maggiore o uguale al primo quartile meno la distanza corrispondente a 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più grande tra le osservazioni che risulta minore o uguale a \\(Q_3+1.5\\) IQR. I valori esterni ai valori adiacenti (chiamati valori anomali) vengono rappresentati individualmente nel box plot per meglio evidenziarne la presenza e la posizione.\n\n\n\n\nFigura 3.5: Box-plot: \\(M\\) è la mediana, \\(\\bar{x}\\) è la media aritmetica e IQR è la distanza interquartile (\\(Q_3 - Q_1\\)).\n\n\n\n\n\nEsercizio 3.8 Si utilizzi un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo usandi i dati di Zetsche et al. (2019).\n\nsns.boxplot(x='group', y='bdi', hue=\"group\", data=df)\n\n\n\nFigura 3.6: Un box plot per i valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al. (2019).\n\n\n\n\nUn risultato migliore si può ottienere mostrando anche i dati grezzi.\n\nplt.figure(figsize=(9,4))\nsns.boxplot(y=\"group\", x=\"bdi\", data=df);\nsns.stripplot(y=\"group\", x=\"bdi\", color='black', alpha=0.3, data=df);\nplt.ylabel(\"Group\")\nplt.xlabel(\"BDI-II\")\n\n\n\n\n\n\n\n\n\n3.10.2 Grafico a violino\nI grafici a violino (violin plot) prendono lo spunto dai box-plot ma riportano il profilo di densità dei valori osservati sotto forma di kernel density plot. La forma tipica di questi grafici, quella che dà loro il nome, deriva dal fatto che il kernel density plot dei dati è riportato simmetricamente da entrambi i lati della distribuzione. Ad un violin plot possono essere sovrapposti al bisogno un boxplot o un grafico a punti (dotplot), a testimonianza del fatto che è possibile integrare diverse visualizzazioni dei dati.\n\nplt.figure(figsize=(9,4))\nsns.violinplot(data=df, x=\"bdi\", y=\"group\");\nsns.stripplot(y=\"group\", x=\"bdi\", color='black', alpha=0.3, data=df);\nplt.ylabel(\"Group\")\nplt.xlabel(\"BDI-II\")\n\n\n\nFigura 3.7: Un violin plot per i valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al. (2019). La linea curva simmetrica è l’istogramma lisciato (kernel density plot) che abbiamo descritto in precedenza. In questa rappresentazione del violin plot, al suo interno, è stato collocato un box plot. Per completezza, al violin plot abbiamo anche sovrapposto un grafico a punti (dotplot).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.10.3 L’eccellenza grafica\nNon c’è un unico modo “corretto” per la rappresentazione grafica dei dati. Ciascuno dei grafici che abbiamo discusso in precedenza ha i suoi pregi e i suoi difetti. Un ricercatore che ha molto influenzato il modo in cui viene realizzata la visualizzazione dei dati scientifici è Edward Tufte, soprannominato dal New York Times il “Leonardo da Vinci dei dati.” Secondo Tufte, “l’eccellenza nella grafica consiste nel comunicare idee complesse in modo chiaro, preciso ed efficiente”. Nella visualizzazione delle informazioni, l’“eccellenza grafica” ha l’obiettivo di comunicare al lettore il maggior numero di idee nella maniera più diretta e semplice possibile. Secondo Tufte (2001), le rappresentazioni grafiche dovrebbero:\n\nmostrare i dati;\nindurre l’osservatore a riflettere sulla sostanza piuttosto che sulla progettazione grafica, o qualcos’altro;\nevitare di distorcere quanto i dati stanno comunicando (“integrità grafica”);\npresentare molte informazioni in forma succinta;\nrivelare la coerenza tra le molte dimensioni dei dati;\nincoraggiare l’osservatore a confrontare differenti sottoinsiemi di dati;\nrivelare i dati a diversi livelli di dettaglio, da una visione ampia alla struttura di base;\nservire ad uno scopo preciso (descrizione, esplorazione, o la risposta a qualche domanda);\nessere fortemente integrate con le descrizioni statistiche e verbali dei dati fornite nel testo.\n\nPer l’esempio discusso sopra, la Figura 3.6, la Figura 3.7 mostrano entrambe che la distribuzione dei dati è all’incirca simmetrica nel gruppo clinico mentre nel gruppo di controllo c’è un’asimmetria positiva. Tra le due rappresentazioni grafiche, però, la Figura 3.7 offre la rappresentazione dei grafica dei dati più completa, compatta e comprensibile. Il seguente link fornisce alcune illustrazioni dei principi elencati sopra."
  },
  {
    "objectID": "007_freq_distr.html#commenti-e-considerazioni-finali",
    "href": "007_freq_distr.html#commenti-e-considerazioni-finali",
    "title": "3  Analisi esplorativa dei dati",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nUna distribuzione è una rappresentazione del modo in cui le diverse modalità di una variabile si distribuiscono nelle unità statistiche che compongono il campione o la popolazione oggetto di studio. Il modo più diretto per trasmettere descrivere le proprietà della distribuzione di una variabile discreta è quello di fornire una rappresentazione grafica della distribuzione di frequenza. In seguito vedremo la corrispondente rappresentazione che viene usata nel caso delle variabili continue.\n\n\n\n\n\n\nTufte, E. R. (2001). The visual display of quantitative information. Graphics press Cheshire, CT.\n\n\nZetsche, U., Bürkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688."
  },
  {
    "objectID": "011_loc_scale.html#indici-di-tendenza-centrale",
    "href": "011_loc_scale.html#indici-di-tendenza-centrale",
    "title": "4  Indici di posizione e di scala",
    "section": "\n4.1 Indici di tendenza centrale",
    "text": "4.1 Indici di tendenza centrale\nTra le misure di tendenza centrale, ovvero tra gli indici che ci informano sui valori attorno ai quali sono prevalentemente concentrati i dati di un campione, quella più comunemente usata è la media.\n\n# Pandas for managing datasets\nimport pandas as pd\n# Matplotlib for additional customization\nfrom matplotlib import pyplot as plt\n# Seaborn for plotting and styling\nimport seaborn as sns\nfrom scipy import stats\nimport numpy as np\n\n# Set theme\nsns.set_palette(\"colorblind\")\n\nimport os\n# cwd = os.getcwd()\n# print(cwd)\n\n\n\n\n\n\n\nPer un’introduzione “soft” alla nozione di tendenza centrale di una distribuzione statistica si segua il link.\n\n\n\n\n4.1.1 Media\nTutti conosciamo la media aritmetica di \\(\\{x_1, x_2, \\dots, x_n\\}\\), ovvero il numero reale \\(\\bar{x}\\) definito da\n\\[\n\\begin{equation}\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i.\n\\end{equation}\n\\tag{4.1}\\]\n\n\n\n\n\n\nNella Equazione 4.1 ho usato la notazione delle sommatorie per descrivere una somma di valori. Questa notazione è molto usata in statistica e viene descritta in Appendice.\n\n\n\nLa media gode della seguente importante proprietà: la somma degli scarti tra ciascuna modalità \\(x_i\\) e la media aritmetica \\(\\bar{x}\\) è nulla, cioè\n\\[\n\\begin{equation}\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\end{equation}\n\\tag{4.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nCiò ci consente di pensare alla media come al baricentro della distribuzione.\nUn’altra proprietà della media è la seguente. La somma dei quadrati degli scarti tra ciascuna modalità \\(x_i\\) e una costante arbitraria \\(a\\), cioè\n\\[\n\\begin{equation}\n\\varphi(a) = \\sum_{i=1}^n (x_i - a)^2,\\notag\n\\end{equation}\n\\tag{4.3}\\]\nè minima per \\(a = \\bar{x}\\).\n\n\n\n\n\n\nIl concetto statistico di media ha suscitato molte battute. Per esempio, il fatto che, in media, ciascuno di noi ha un numero di gambe circa pari a 1.9999999. Oppure, il fatto che, in media, ciascuno di noi ha un testicolo. Ma la media ha altri problemi, oltre al fatto di ispirare battute simili alle precedenti. In particolare, dobbiamo notare che la media non è sempre l’indice che meglio rappresenta la tendenza centrale di una distribuzione. In particolare, ciò non accade quando la distribuzione è asimmetrica, o in presenza di valori anomali (outlier) – si veda il pannello di sinistra della ?fig-raincloud. In tali circostanze, la tendenza centrale della distribuzione è meglio rappresentata dalla mediana o dalla media spuntata (si veda più sotto).\n\n\n\n\nEsercizio 4.1 Si calcoli la media dei valori BDI-II separatamente per ciascuno dei due gruppi di soggetti esaminati da Zetsche et al. (2019).\n\n# Leggo i dati, seleziono le colonne appropriate, elimino i duplicati, rimuovo \n# il dato mancante.\ndf = pd.read_csv('data/data.mood.csv',index_col=0)\ndf = df[['esm_id','group','bdi']]\ndf = df.drop_duplicates(keep='first')\ndf = df[pd.notnull(df['bdi'])]\n\n# Trovo le medie dei valori BDI-II dei due gruppi.\ndf.groupby('group')['bdi'].describe().round(1)\n#>        count  mean  std   min   25%   50%   75%   max\n#> group                                                \n#> ctl     36.0   1.6  2.7   0.0   0.0   1.0   2.0  12.0\n#> mdd     30.0  30.9  6.6  19.0  26.0  30.0  35.0  44.0\n\n\n\n4.1.2 Media spuntata\nLa media spuntata \\(\\bar{x}_t\\) (trimmed mean) non è altro che la media dei dati calcolata considerando solo il 90% (o altra percentuale) dei dati centrali. Per calcolare \\(\\bar{x}_t\\) si ordinando i dati secondo una sequenza crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), per poi eliminare il primo 5% e l’ultimo 5% dei dati della serie così ordinata. La media spuntata è data dalla media aritmetica dei dati rimanenti.\n\nEsercizio 4.2 Si calcoli la media spuntata dei valori BDI-II per i due gruppi di soggetti esaminati da Zetsche et al. (2019) escludendo il 10% dei valori più estremi.\nIniziamo ad esaminare la numerosità di ciascun gruppo.\n\ndf.groupby(\"group\").size()\n#> group\n#> ctl    36\n#> mdd    30\n#> dtype: int64\n\nPossiamo selezionare i dati del gruppo mdd nel modo seguente.\n\ndf[df[\"group\"]=='mdd']\n#>      esm_id group   bdi\n#> 1        10   mdd  25.0\n#> 15        9   mdd  30.0\n#> 30        6   mdd  26.0\n#> 46        7   mdd  35.0\n#> 65       12   mdd  44.0\n#> 83       16   mdd  30.0\n#> 100      21   mdd  22.0\n#> 119      18   mdd  33.0\n#> 136      20   mdd  43.0\n#> 151      22   mdd  43.0\n#> 171      23   mdd  24.0\n#> 191      25   mdd  39.0\n#> 211      24   mdd  19.0\n#> 283      31   mdd  25.0\n#> 338      30   mdd  31.0\n#> 358      37   mdd  28.0\n#> 525      48   mdd  30.0\n#> 561      45   mdd  35.0\n#> 646      55   mdd  31.0\n#> 666      50   mdd  26.0\n#> 795      63   mdd  36.0\n#> 811      62   mdd  41.0\n#> 827      65   mdd  26.0\n#> 846      66   mdd  35.0\n#> 864      68   mdd  33.0\n#> 903      78   mdd  28.0\n#> 933      80   mdd  27.0\n#> 953      81   mdd  34.0\n#> 964      85   mdd  22.0\n#> 981      84   mdd  27.0\n\nCalcoliamo ora la media spuntata dei due gruppi.\n\nbdi_mdd = df[df[\"group\"]=='mdd'].bdi\nstats.trim_mean(bdi_mdd, 0.10)\n#> 30.625\nbdi_ctl = df[df[\"group\"]=='ctl'].bdi\nstats.trim_mean(bdi_ctl, 0.10)\n#> 1.0\n\n\n\n4.1.3 Moda e mediana\nIn precedenza abbiamo già incontrato altri due popolari indici di tendenza centrale: la moda (Mo), ovvero il valore centrale della classe con la frequenza massima (può succedere che una distribuzione abbia più mode; in tal caso si dice multimodale e questo operatore perde il suo significato di indice di tendenza centrale) e la mediana \\(\\tilde{x}\\).\n\nEsercizio 4.3 Si calcolino i quantili di ordine 0.25, 0.5 e 0.75 dei valori BDI-II per i due gruppi di soggetti di Zetsche et al. (2019).\n\n#create functions to calculate 0.10 and 0.90 quantiles\ndef q1(x):\n    return x.quantile(0.10)\n\ndef q3(x):\n    return x.quantile(0.90)\n\n#calculate quantiles by group\nvals = {'bdi': [q1, q3]}\ndf.groupby('group').agg(vals)\n#>         bdi      \n#>          q1    q3\n#> group            \n#> ctl     0.0   4.0\n#> mdd    23.8  41.2\n\n\n\n\n\n\n\n\nSi noti che solitamente i software restituiscono un valore interpolato del \\(p\\)-esimo quantile \\(q_p\\) \\((0 < p < 1)\\), il quale viene calcolato mediante specifiche procedure. Il risultato fornito dai software, dunque, non sarà identico a quello trovato utilizzando la definizione non interpolata di quantile che abbiamo presentato in precedenza. Se, per qualche ragione, vogliamo conoscere l’algoritmo usato per la determinazione dei quantili interpolati, dobbiamo leggere la documentazione del software."
  },
  {
    "objectID": "011_loc_scale.html#indici-di-dispersione",
    "href": "011_loc_scale.html#indici-di-dispersione",
    "title": "4  Indici di posizione e di scala",
    "section": "\n4.2 Indici di dispersione",
    "text": "4.2 Indici di dispersione\nLe medie e gli indici di posizione descritti in precedenza forniscono delle sintesi dei dati che mettono in evidenza la tendenza centrale delle osservazioni. Tali indici, tuttavia, non considerano un aspetto importante della distribuzione dei dati, ovvero la variabilità dei valori numerici della variabile statistica. È dunque necessario sintetizzare la distribuzione di una variabile statistica oltre che con le misure di posizione anche tramite l’utilizzo di indicatori che valutino la dispersione delle unità statistice.\n\n\n\n\n\n\nPer un’introduzione “soft” al tema degli indici di dispersione si segua il link.\n\n\n\n\n4.2.1 Indici basati sull’ordinamento dei dati\nÈ possibile calcolare degli indici di variabilità basati sull’ordinamento dei dati. L’indice più ovvio è l’intervallo di variazione, ovvero la distanza tra il valore massimo e il valore minimo di una distribuzione di modalità, mentre in precedenza abbiamo già incontrato la differenza interquartile. Questi due indici, però, hanno il limite di essere calcolati sulla base di due soli valori della distribuzione (\\(x_{\\text{max}}\\) e \\(x_{\\text{min}}\\), oppure \\(x_{0.25}\\) e \\(x_{0.75}\\)). Pertanto non utilizzano tutte le informazioni che sono disponibili. Inoltre, l’intervallo di variazione ha il limite di essere pesantemente influenzato dalla presenza di valori anomali.\n\n4.2.2 Varianza\nDati i limiti delle statistiche precedenti è più comune misurare la variabilità di una variabile statistica come la dispersione dei dati attorno ad un indice di tendenza centrale. Infatti, la misura di variabilità di gran lunga più usata per valutare la variabilità di una variabile statistica è senza dubbio la varianza. La varianza\n\\[\n\\begin{equation}\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{4.4}\\]\nè la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione.\nLa varianza è una misura di dispersione più complessa di quelle esaminate in precedenza. È appropriata solo nel caso di distribuzioni simmetriche e, anch’essa, è fortemente influenzata dai valori anomali. Inoltre, è espressa in un’unità di misura che è il quadrato dell’unità di misura dei dati originari e quindi ad essa non può essere assegnata un’interpretazione intuitiva.\n\nEsercizio 4.4 Si calcoli la varianza dei valori BDI-II per i dati di Zetsche et al. (2019).\nApplicando la formula precedente, per tutto il campione abbiamo\n\nvar_bdi = sum((df.bdi - np.mean(df.bdi))**2) / len(df.bdi)\nround(var_bdi, 4)\n#> 236.2388\n\nPossiamo anche usare le funzioni di numpy.\n\nvar_bdi = np.var(df.bdi)\nround(var_bdi, 4)\n#> 236.2388\n\n\n\n4.2.2.1 Stima della varianza della popolazione\nSi noti il denominatore della formula della varianza. Nell’Equazione 4.4 ho usato \\(n\\) (l’ampiezza campionaria, ovvero il numero di osservazioni del campione). In questo modo ottengo la varianza quale statistica descrittiva del campione. In alternativa, è possibile usare \\(n-1\\) al denominatore:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{4.5}\\]\nIn questo secondo modo si trova la varianza quale stimatore della varianza della popolazione. Si può dimostrare che l’Equazione 4.5 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre invece la Equazione 4.4 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) per la varianza quale statistica descrittiva, \\(s^2\\) per la varianza quale stimatore.\n\nEsercizio 4.5 Per illustrare il punto precedente svolgiamo una simulazione.\n\nimport random\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nEstraggo un campione casuale di 10 osservazioni dalla popolazione del quoziente di intelligenza.\n\nx = np.random.normal(loc = 100, scale = 15, size = 10)\nprint(x)\n#> [ 81.17070624 100.35069264  68.1950899   57.96551529  90.15808424\n#>  125.61104223 110.79690116 113.22592754  92.61442233  96.89704775]\n\nCalcolo la varianza con \\(n\\) al denominatore. Si noti che la “vera” varianza del quoziente di intelligenza è \\(15^2\\) = 225.\n\nnp.var(x)\n#> 384.4493983096239\n\nConsideriamo ora 10 campioni casuali del QI.\n\nloc = 100\nscale = 15\nsize = 4\nniter = 10\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = np.random.normal(loc, scale, size)\n    random_samples.append(one_sample)\n\nIl primo campione è\n\nrandom_samples[0]\n#> array([85.53870397, 91.09826595, 79.48383929, 98.6820146 ])\n\nIl decimo campione è\n\nrandom_samples[9]\n#> array([ 96.9281537 , 101.48833754,  97.02814599,  99.87664806])\n\nStampiamo tutti e 10 i campioni.\n\nrs = np.array(random_samples)\nrs\n#> array([[ 85.53870397,  91.09826595,  79.48383929,  98.6820146 ],\n#>        [119.09265717,  86.67387284,  95.02799371,  56.46242066],\n#>        [103.12802245, 103.13909694, 112.15934503,  95.8227122 ],\n#>        [ 97.59083982,  67.1746377 , 105.20100163, 108.06586713],\n#>        [111.90171046, 102.71742144,  96.36614998, 104.02118416],\n#>        [ 94.93411727, 108.00656212, 111.37636944,  97.44631896],\n#>        [107.73941918, 123.04392679, 111.77922494, 115.09265642],\n#>        [ 95.87590295,  86.82367216,  90.00344021,  97.0524578 ],\n#>        [103.70110958,  82.89416431,  83.35520427,  77.78202689],\n#>        [ 96.9281537 , 101.48833754,  97.02814599,  99.87664806]])\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando \\(n\\) al denominatore. Otteniamo così 10 stime della varianza della popolazione del QI.\n\nx_var = np.var(rs, axis=1) # applichiamo la funzione su ciascuna riga\nprint(x_var)\n#> [ 50.080926   501.4036708   33.5445251  263.69316018  30.52784334\n#>   47.77926698  31.60706991  17.64003824  98.50565593   3.75648187]\n\nRipetiamo ora la simulazione usando un numero di iterazioni maggiore.\n\nloc = 100\nscale = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = np.random.normal(loc, scale, size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, axis=1)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\nsns.histplot(x_var)\n\n\n\n\n\n\n\nLa stima più verosimile della varianza del QI è dato dalla media di questa distribuzione.\n\nnp.mean(x_var)\n#> 170.9802825174357\n\nSi noti che il valore medio della stima della varianza ottenuta con l’Equazione 4.4 è troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipeto ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nrandom.seed(2023)\nloc = 100\nscale = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = np.random.normal(loc, scale, size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=1, axis=1)\n\nnp.mean(x_var)\n#> 223.3573010872812\n\nIn questo secondo caso, il valore atteso della stima della varianza trovata con \\(n-1\\) al denominatore è molto simile al valore corretto di 225.\n\n\n4.2.3 Precisione\nSi definisce precisione l’inverso della varianza:\n\\[\n\\begin{equation}\n\\tau = \\frac{1}{\\sigma^2}.\n\\end{equation}\n\\tag{4.6}\\]\nAlcuni ritengono che la precisione sia più “intuitiva” della varianza perché dice quanto sono concentrati i valori attorno alla media piuttosto che quanto sono dispersi. In altri termini, si potrebbe argomentare che siamo più interessati a quanto sia precisa una misurazione piuttosto che a quanto sia imprecisa. Più sono dispersi i valori attorno alla media (alta varianza), meno sono precisi (poca precisione); minore è la varianza, maggiore è la precisione.\n\n\n\n\n\n\nLa precisione è uno dei due parametri naturali della distribuzione gaussiana. Nei termini della Equazione 4.6, la distribuzione gaussiana (si veda il Capitolo (distr-rv-cont?)) può essere espressa nel modo seguente\n\\[\n{\\displaystyle f(y)=\\sqrt{\\frac{\\tau}{2\\pi}} e^{-{\\frac {1}{2}}\\tau\\left({y-\\mu }\\right)^{2}}},\n\\]\nanziché come\n\\[\n{\\displaystyle f(y)={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {y-\\mu }{\\sigma }}\\right)^{2}}}.\n\\]\n\n\n\n\n4.2.4 Deviazione standard\nDato che l’unità di misura della varianza coincide con il quadrato dell’unità di misura dei dati, la varianza è difficile da interpretare. Questo problema si può risolvere prendendo la radice quadrata della varianza, ottenendo così una misura espressa nell’unità di misura originaria dei dati. Una tale misura si chiama deviazione standard (o scarto quadratico medio, o scarto tipo)1:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}\n\\tag{4.7}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s > 0\\).\nCome nel caso della varianza, anche la deviazione standard \\(s\\) dovrebbe essere usata soltanto quando la media è adeguata per descrivere il centro della distribuzione, ovvero, nel caso di distribuzioni simmetriche. Come nel caso della media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dai dati anomali, ovvero dalla presenza di uno o di pochi dati che sono molto più distanti dalla media rispetto agli altri valori della distribuzione.\n\nEsercizio 4.6 Si calcoli la deviazione standard per i valori BDI-II del campione di Zetsche et al. (2019).\nApplicando l’Equazione 4.7, per tutto il campione abbiamo\n\nnp.std(df.bdi)\n#> 15.370060219395436\n\nPer ciascun gruppo, abbiamo:\n\ndf.groupby('group')['bdi'].std()\n#> group\n#> ctl    2.707427\n#> mdd    6.606858\n#> Name: bdi, dtype: float64\n\n\n\n4.2.4.1 Interpretazione\nAlla deviazione standard può essere assegnata una semplice interpretazione: la deviazione standard è simile (ma non identica) allo scarto semplice medio campionario, ovvero alla media aritmetica dei valori assoluti degli scarti dalla media. La deviazione standard ci dice, dunque, quanto sono distanti, in media, le singole osservazioni dal centro della distribuzione. Un’interpretazione più precisa del significato dello scarto tipo è fornita nel paragrafo successivo.\n\nEsercizio 4.7 Si verifichi l’interpretazione della deviazione standard fornita sopra usando i valori BDI-II del campione di Zetsche et al. (2019).\nPer questi dati la deviazione standard è\n\nnp.std(df.bdi)\n#> 15.370060219395436\n\nLo scarto semplice medio campionario è\n\nnp.mean(np.abs(df.bdi - np.mean(df.bdi)))\n#> 14.539944903581269\n\n\n\n4.2.5 Deviazione mediana assoluta\nUna misura robusta della dispersione statistica di un campione è la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana, ovvero:\n\\[\n{\\displaystyle \\operatorname {MAD} =\\operatorname {median} \\left(\\ \\left|X_{i}-\\operatorname {median} (X)\\right|\\ \\right)}\n\\tag{4.8}\\]\nNel caso di una distribuzione dei dati unimodale simmetrica di forma campanulare (ovvero, normale) si ha che\n\\[\n{\\displaystyle \\text{deviazione standard} \\approx 1.4826\\ \\operatorname {MAD} .\\,}\n\\]\nPertanto, solitamente i software restituiscono il valore MAD moltiplicato per una tale costante.\n\nEsercizio 4.8 I dati di Zetsche et al. (2019) seguono una distribuzione bimodale, per cui il vincolo precedente non si applica. Verifichiamo dunque il principio precedente usando un campione di dati estratto da una popolazione normale.\n\nx = np.random.normal(loc=100, scale=15, size=10000)\n1.4826 * np.median(np.abs(x - np.median(x)))\n#> 14.912293804211595\n\n\n\n4.2.6 Indici di variabilità relativi\nA volte può essere interessante effettuare un confronto fra due misure di variabilità di grandezze incommensurabili, ovvero di caratteri rilevati mediante differenti unità di misura. In questi casi, le misure di variabilità precedentemente descritte si rivelano inadeguate in quanto dipendono dall’unità di misura adottata. Diventa dunque necessario ricorrere a particolari numeri adimensionali detti indici relativi di variabilità. Il più importante di tali indici è il coefficiente di variazione, ovvero il numero puro\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}\n\\tag{4.9}\\]\nottenuto dal rapporto tra la deviazione standard e la media dei dati.\nUn altro indice relativo di variabilità è la differenza interquartile rapportata al primo quartile, oppure al terzo quartile, oppure alla mediana, cioè:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]"
  },
  {
    "objectID": "011_loc_scale.html#commenti-e-considerazioni-finali",
    "href": "011_loc_scale.html#commenti-e-considerazioni-finali",
    "title": "4  Indici di posizione e di scala",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLe statistiche descrittive ci forniscono degli indici sintetici che riassumono i dati, ovvero le nostre misurazioni dell’intera popolazione o di un campione estratto da una popolazione. Le statistiche descrittive comprendono gli indici di tendenza centrale e gli indici di dispersione. Gli indici di tendenza centrale includono la media, la mediana e la moda, mentre gli indici di dispersione includono la deviazione standard, la varianza, la curtosi e l’asimmetria (questi ultimi due indici sono definiti in relazione alla distribuzione Normale e verranno dunque discussi in quel contesto).\n\n\n\n\n\n\nZetsche, U., Bürkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688."
  },
  {
    "objectID": "012_correlation.html",
    "href": "012_correlation.html",
    "title": "5  Le relazioni tra variabili",
    "section": "",
    "text": "6 Associazione statistica\nIn questo capitolo esamineremo il problema di visualizzare e di quantificare una particolare relazione tra due variabili quantitative. Presenteremo prima uno strumento grafico, il diagramma a dispersione, che consente di visualizzare l’associazione tra due variabili quantitative. Considereremo poi la covarianza e la correlazione che consentono di quantificare la forza e la direzione dell’associazione lineare tra due variabili quantitative."
  },
  {
    "objectID": "012_correlation.html#diagramma-a-dispersione",
    "href": "012_correlation.html#diagramma-a-dispersione",
    "title": "5  Le relazioni tra variabili",
    "section": "\n6.1 Diagramma a dispersione",
    "text": "6.1 Diagramma a dispersione\nIl diagramma di dispersione è la rappresentazione grafica delle coppie di punti individuati da due variabili \\(X\\) e \\(Y\\). Per fare un esempio concreto, consideriamo nuovamente la ricerca di Zetsche et al. (2019). Zetsche et al. (2019) hanno misurato il livello di depressione dei soggetti utilizzando due scale psicometriche: il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D). Il BDI-II è uno strumento self-report che valutare la presenza e l’intensità di sintomi depressivi in pazienti adulti e adolescenti di almeno 13 anni di età con diagnosi psichiatrica mentre la CES-D è una scala self-report progettata per misurare i sintomi depressivi che sono stati vissuti nella settimana precedente nella popolazione generale, specialmente quella degli adolescenti/giovani adulti. Usiamo questi dati per costruire un diagramma a dispersione. Poniamo, ad esempio, i valori BDI-II sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate. In tale grafico, fornito dalla Figura 6.1, cascun punto corrisponde ad un individuo del quale conosciamo il livello di depressione misurato dalle due scale psicometriche.\nÈ chiaro che i valori delle scale BDI-II e CES-D non possono essere identici, e questo per due motivi: (1) la presenza degli errori di misurazione e (2) l’unità di misura delle due variabili. L’errore di misurazione corrompe sempre, almeno in parte, qualunque operazione di misurazione. E questo è vero specialmente in psicologia dove l’attendibilità (cioè, la precisione degli strumenti di misurazione è minore che in altre discipline (quali la fisica, ad esempio). Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere uguali è che l’unità di misura delle due scale è arbitraria. Infatti, qual è l’unità di misura della depressione? Chi può dirlo! Ma, al di là delle differenze derivanti dall’errore di misurazione e dalla differente unità di misura, ci aspettiamo che, se le due scale misurano entrambe lo stesso costrutto (la depressione), allora i valori prodotti dalle due scale dovranno essere tra loro linearmente associati. Per capire cosa si intende con “associazione lineare” iniziamo a guardare i dati. Per fare questo utilizziamo un diagramma a dispersione.\n\n# Pandas for managing datasets\nimport pandas as pd\n# Matplotlib for additional customization\nfrom matplotlib import pyplot as plt\n# Seaborn for plotting and styling\nimport seaborn as sns\nfrom scipy import stats\nimport numpy as np\n\n# Set theme\nsns.set_palette(\"colorblind\")\n\nimport os\n# cwd = os.getcwd()\n# print(cwd)\n\n\ndf = pd.read_csv('data/data.mood.csv',index_col=0)\ndf = df[['esm_id','group','bdi', 'cesd_sum']]\ndf = df.drop_duplicates(keep='first')\ndf = df[pd.notnull(df['bdi'])]\n\n\nplt.scatter(df['bdi'], df['cesd_sum'])\nplt.rcParams.update({'figure.figsize':(10,10), 'figure.dpi':100})\nplt.xlabel('BDI-II')\nplt.ylabel('CESD')\nplt.axvline(np.mean(df.bdi), alpha=0.2)\nplt.axhline(np.mean(df.cesd_sum), alpha=0.2)\n\n\n\nFigura 6.1: Associazione tra le variabili BDI-II e CES-D nello studio di Zetsche et al. (2019). In grigio sono rappresentate le osservazioni del gruppo di controllo; in nero quelle dei pazienti.\n\n\n\n\nDalla Figura 6.1 notiamo che i dati mostrano una tendenza a disporsi attorno ad una retta – nel gergo statistico, questo fatto viene espresso dicendo che i punteggi CES-D tendono ad essere linearmente associati ai punteggi BDI-II. È ovvio, tuttavia, che tale relazione lineare è lungi dall’essere perfetta – se fosse perfetta, tutti i punti del diagramma a dispersione si disporrebbero esattamente lungo una retta. Si pone dunque il problema di trovare un indice numerico che descriva di quanto la nube di punti si discosta da una perfetta relazione lineare tra le due variabili, ovvero che descriva la direzione e la forza della relazione lineare tra le due variabili. Ci sono vari indici statistici che possono essere utilizzati a questo scopo."
  },
  {
    "objectID": "012_correlation.html#covarianza",
    "href": "012_correlation.html#covarianza",
    "title": "5  Le relazioni tra variabili",
    "section": "\n6.2 Covarianza",
    "text": "6.2 Covarianza\nIniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa”. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{6.1}\\]\nL’equazione Equazione 4.9 ci fornisce la definizione della covarianza.\n\n6.2.1 Interpretazione\nPer capire il significato dell’Equazione 4.9, supponiamo di dividere il grafico della Figura 6.1 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avrà segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avrà segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa.\nSe il segno della covarianza ci informa sulla direzione della relazione, il valore assoluto della covarianza ci dice invece ben poco. Esso, infatti, dipende dall’unità di misura delle variabili. Nel caso presente questo concetto è difficile da comprendere, dato che le due variabili in esame hanno un’unità di misura arbitraria e sconosciuta. Ma quest’idea diventa chiara se pensiamo alla relazione lineare tra l’altezza e il peso delle persone, ad esempio. La covarianza tra queste due quantità è certamente positiva, ma il valore assoluto della covarianza diventa più grande se l’altezza viene misurata in millimetri e il peso in grammi, e più piccolo se l’altezza viene misurata in metri e il peso in chilogrammi. Dato che il valore assoluto della covarianza dipende dall’unità di misura delle variabili, abbiamo bisogno di un indice di associazione lineare adimensionale. Questo indice è fornito dalla correlazione."
  },
  {
    "objectID": "012_correlation.html#correlazione",
    "href": "012_correlation.html#correlazione",
    "title": "5  Le relazioni tra variabili",
    "section": "\n6.3 Correlazione",
    "text": "6.3 Correlazione\nÈ possibile trasformare la covarianza in modo tale da renderla immune alle trasformazioni dell’unità di misura delle variabili. Questa operazione si dice standardizzazione e corrisponde alla divisione della covarianza per le deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr_{XY} = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{6.2}\\]\nLa quantità che si ottiene in questo modo viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, l’hanno introdotta).\n\n6.3.1 Proprietà\nIl coefficiente di correlazione ha le seguenti proprietà:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\nè un numero puro, cioè non dipende dall’unità di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n6.3.2 Interpretazione\nAll’indice di correlazione possiamo assegnare la seguente interpretazione:\n\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\n\\(-1 < r_{XY} < +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa;\n\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\n\nEsercizio 6.1 Per i dati della Figura 6.1, la covarianza è 207.426. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire quale sia l’intensità della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva."
  },
  {
    "objectID": "012_correlation.html#correlazione-e-causazione",
    "href": "012_correlation.html#correlazione-e-causazione",
    "title": "5  Le relazioni tra variabili",
    "section": "\n6.4 Correlazione e causazione",
    "text": "6.4 Correlazione e causazione\nFacendo riferimento nuovamente alla Figura 6.1, possiamo dire che, in molte applicazioni (ma non nel caso presente!) l’asse \\(x\\) rappresenta una quantità nota come variabile indipendente e l’interesse si concentra sulla sua influenza sulla variabile dipendente tracciata sull’asse \\(y\\). Ciò presuppone che sia nota la direzione in cui l’influenza causale potrebbe risiedere (\\(x \\rightarrow y\\), vs. \\(y \\rightarrow x\\)).\nÈ importante però tenere bene a mente che la correlazione è soltanto un indice descrittivo della relazione lineare tra due variabili e in nessun caso può essere usata per inferire alcunché sulle relazioni causali che legano le variabili. È ben nota l’espressione: “correlazione non significa causazione”."
  },
  {
    "objectID": "012_correlation.html#usi-della-correlazione",
    "href": "012_correlation.html#usi-della-correlazione",
    "title": "5  Le relazioni tra variabili",
    "section": "\n6.5 Usi della correlazione",
    "text": "6.5 Usi della correlazione\nAnche se non può essere usata per studiare le relazioni causali, la correlazione viene usata per molti altri scopi tra i quali, per esempio, quello di misurare la validità concorrente di un test psiologico. Se un test psicologico misura effettivamente ciò che ci si aspetta che misuri (nel caso dell’esempio presente, la depressione), allora dovremo aspettarci che fornisca una correlazione alta con i risultati di altri test che misurano lo stesso costrutto – come nel caso dei dati di (Zetsche et al., 2019). Un’altra proprietà desiderabile di un test psicometrico è la validità divergente: i risultati di test psicometrici che misurano costrutti diversi dovrebbero essere poco associati tra loro. In altre parole, in questo secondo caso dovremmo aspettarci una bassa correlazione."
  },
  {
    "objectID": "012_correlation.html#correlazione-di-spearman",
    "href": "012_correlation.html#correlazione-di-spearman",
    "title": "5  Le relazioni tra variabili",
    "section": "\n6.6 Correlazione di Spearman",
    "text": "6.6 Correlazione di Spearman\nUna misura alternativa della relazione lineare tra due variabili è fornita dal coefficiente di correlazione di Spearman e dipende soltanto dalla relazione d’ordine dei dati, non dagli specifici valori dei dati. Tale misura di associazione è appropriata quando, del fenomeno in esame, gli psicologi sono stati in grado di misurare soltanto le relazioni d’ordine tra le diverse modalità della risposta dei soggetti, non l’intensità della risposta. Le variabili psicologiche che hanno questa proprietà si dicono ordinali.\n\n\n\n\n\n\nSi ricordi che, nel caso di una variabile ordinale, non è possibile sintetizzare le osservazioni mediante le statistiche descrittive che abbiamo descritto in precedenza, quali ad esempio la media e la varianza. È invece possibile riassumere le ossservazioni su una variabile ordinale mediante una distribuzione di frequenze per le varie modalità della risposta. Come abbiamo visto or ora, è anche possibile descrivere la direzione e la forza dell’associazione tra due variabili ordinali mediante la correlazione di Spearman.\n\n\n\n\nEsercizio 6.2 Per due variabili arbitrarie di livello ordinale, si trovi la correlazione di Spearman.\n\nstats.spearmanr([1,2,3,4,5], [5,6,7,8,7])\n#> SpearmanrResult(correlation=0.8207826816681233, pvalue=0.08858700531354381)"
  },
  {
    "objectID": "012_correlation.html#correlazione-nulla",
    "href": "012_correlation.html#correlazione-nulla",
    "title": "5  Le relazioni tra variabili",
    "section": "\n6.7 Correlazione nulla",
    "text": "6.7 Correlazione nulla\nUn ultimo aspetto da mettere in evidenza a proposito della correlazione riguarda il fatto che la correlazione descrive la direzione e l’intensità della relazione lineare tra due variabili. Relazioni non lineari tra le variabili, anche se sono molto forti, non vengono catturate dalla correlazione. È importante rendersi conto che una correlazione pari a zero non significa che non c’è relazione tra le due variabili, ma solo che tra esse non c’è una relazione lineare.\n\nLa Figura 6.2 fornisce tredici esempi di correlazione nulla in presenza di una chiara relazione (non lineare) tra due variabili.\n\ndatasaurus_data = pd.read_csv('data/datasaurus.csv')\ndatasaurus_data\n#>          dataset          x          y\n#> 0           dino  55.384600  97.179500\n#> 1           dino  51.538500  96.025600\n#> 2           dino  46.153800  94.487200\n#> 3           dino  42.820500  91.410300\n#> 4           dino  40.769200  88.333300\n#> ...          ...        ...        ...\n#> 1841  wide_lines  33.674442  26.090490\n#> 1842  wide_lines  75.627255  37.128752\n#> 1843  wide_lines  40.610125  89.136240\n#> 1844  wide_lines  39.114366  96.481751\n#> 1845  wide_lines  34.583829  89.588902\n#> \n#> [1846 rows x 3 columns]\n\n\ndatasaurus_data.groupby('dataset').agg({'x': ['count','mean', 'std'],'y': ['count','mean', 'std']})\n#>                x                           y                      \n#>            count       mean        std count       mean        std\n#> dataset                                                           \n#> away         142  54.266100  16.769825   142  47.834721  26.939743\n#> bullseye     142  54.268730  16.769239   142  47.830823  26.935727\n#> circle       142  54.267320  16.760013   142  47.837717  26.930036\n#> dino         142  54.263273  16.765142   142  47.832253  26.935403\n#> dots         142  54.260303  16.767735   142  47.839829  26.930192\n#> h_lines      142  54.261442  16.765898   142  47.830252  26.939876\n#> high_lines   142  54.268805  16.766704   142  47.835450  26.939998\n#> slant_down   142  54.267849  16.766759   142  47.835896  26.936105\n#> slant_up     142  54.265882  16.768853   142  47.831496  26.938608\n#> star         142  54.267341  16.768959   142  47.839545  26.930275\n#> v_lines      142  54.269927  16.769959   142  47.836988  26.937684\n#> wide_lines   142  54.266916  16.770000   142  47.831602  26.937902\n#> x_shape      142  54.260150  16.769958   142  47.839717  26.930002\n\n\n\n\n\nFigura 6.2: Tredici insiemi di dati (fittizi) per i quali i coefficienti di correlazione di Pearson sono sempre uguali a 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili."
  },
  {
    "objectID": "012_correlation.html#commenti-e-considerazioni-finali",
    "href": "012_correlation.html#commenti-e-considerazioni-finali",
    "title": "5  Le relazioni tra variabili",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa prima fase dell’analisi dei dati riassume i dati mediante gli strumenti della statistica descrittiva. Le tipiche domande che vengono affrontate in questa fase sono: qual è la distribuzione delle variabili di interesse? Quali relazioni rra coppie di variabili si possono osservare nel campione? Ci sono delle osservazioni ‘anomale’, ovvero estremamente discrepanti rispetto alle altre, sia quando si esaminano le statistiche descrittive univariate (ovvero, quelle che riguardano le caratteristiche di una variabile presa singolarmente), sia quando vengono esaminate le statistiche bivariate (ovvero, le statistiche che descrivono l’associazione tra le variabili)? È importante avere ben chiare le idee su questi punti prima di procedere con qualsiasi procedura statistica di tipo inferenziale. Per rispondere alle domande che abbiamo elencato sopra, ed ad altre simili, è molto utile procedere con delle rappresentazioni grafiche dei dati.\n\n\n\n\n\n\nZetsche, U., Bürkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688."
  },
  {
    "objectID": "013_penguins.html#codifica-dei-dati-grezzi",
    "href": "013_penguins.html#codifica-dei-dati-grezzi",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.1 Codifica dei dati grezzi",
    "text": "6.1 Codifica dei dati grezzi\nSi chiamano “dati grezzi” quelli che provengono dal mondo circostanze, i dati raccolti per mezzo di esperimenti, interviste, questionari, ecc. Questi dati (detti dataset) raramente vengono forniti con una struttura logica precisa. Per poterli elaborare mediante software è necessario prima trasformarli in maniera tale che abbiano una struttura logica organizzata. La struttura che solitamente si utilizza è quella tabellare (detta matrice dei dati), ovvero si dispongono i dati in una tabella nella quale ciascuna riga corrisponde ad un’osservazione e ciascuna colonna corrisponde ad una variabile rilevata. In \\(\\mathsf{R}\\) una tale struttura è chiamata data frame o tibble (il tibble è solo un modo diverso di stampare un data frame sulla console)."
  },
  {
    "objectID": "013_penguins.html#trattamento-dei-dati-con-dplyr",
    "href": "013_penguins.html#trattamento-dei-dati-con-dplyr",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.2 Trattamento dei dati con dplyr\n",
    "text": "6.2 Trattamento dei dati con dplyr\n\nUtilizzando i pacchetti del tidyverse (tidyverse è un insieme, o bundle, di pacchetti R), le operazioni di trasformazione dei dati risultano molto semplificate. Per la manipolazione dei dati vengono usati i seguenti pacchetti del tidyverse:\n\ndplyr\n\ntidyr (tibbles, dataframe e tabelle)\n\nstringr (stringhe)\n\nIl pacchetto dplyr (al momento uno dei pacchetti più famosi e utilizzati per la gestione dei dati) offre una serie di funzionalità che consentono di eseguire le operazioni più comuni di manipolazione dei dati in una maniera più semplice rispetto a quanto succeda quando usiamo le funzioni base di R.\nIl pacchetto dplyr include sei funzioni base: filter(), select(), mutate(), arrange(), group_by() e summarise(). Queste sei funzioni costituiscono i verbi del linguaggio di manipolazione dei dati. A questi sei verbi si aggiunge il pipe %>% (oppure |>) che serve a concatenare più operazioni. In particolare, considerando una matrice osservazioni per variabili, select() e mutate() si occupano di organizzare le variabili, filter() e arrange() i casi, e group_by() e summarise() i gruppi.\nPer introdurre le funzionalità di dplyr, utilizzeremo i dati msleep forniti dal pacchetto ggplot2. Tali dati descrivono le ore di sonno medie di 83 specie di mammiferi (Savage et al., 2007). Carichiamo il boundle tidyverse (che contiene ggplot2) e leggiamo nella memoria di lavoro l’oggetto msleep:\n\nlibrary(\"tidyverse\")\ndata(msleep)\ndim(msleep)\n#> [1] 83 11\n\n\n6.2.0.1 Operatore pipe\nPrima di presentare le funzionalità di dplyr, introduciamo l’operatore pipe %>% del pacchetto magrittr – ma ora presente anche in base \\(\\mathsf{R}\\) nella versione |>. L’operatore pipe, %>% o |>, serve a concatenare varie funzioni insieme, in modo da inserire un’operazione dietro l’altra. Una spiegazione intuitiva dell’operatore pipe è stata fornita in un tweet di @andrewheiss. Consideriamo la seguente istruzione in pseudo-codice \\(\\mathsf{R}\\):\n\nleave_house(\n  get_dressed(\n    get_out_of_bed(\n      wake_up(me, time = \"8:00\"), \n      side = \"correct\"), \n    pants = TRUE, \n    shirt = TRUE), \n  car = TRUE, \n  bike = FALSE\n)\n\nIl listato precedente descrive una serie di (pseudo) funzioni concatenate, le quali costituiscono gli argomenti di altre funzioni. Scritto così, il codice è molto difficile da capire. Possiamo però ottenere lo stesso risultato utilizzando l’operatore pipe che facilita enormememnte la leggibilità del codice:\n\nme |> \n  wake_up(time = \"8:00\") |> \n  get_out_of_bed(side = \"correct\") |> \n  get_dressed(pants = TRUE, shirt = TRUE) |> \n  leave_house(car = TRUE, bike = FALSE)\n\nIn questa seconda versione del (pseudo) codice \\(\\mathsf{R}\\) si capisce molto meglio ciò che vogliamo fare. Il tibble me viene passato alla funzione wake_up(). La funzione wake_up() ha come argomento l’ora del giorno: time = \"8:00\". Una volta “svegliati” (wake up) dobbiamo scendere dal letto. Quindi l’output di wake_up() viene passato alla funzione get_out_of_bed() la quale ha come argomento side = \"correct\" perché vogliamo scendere dal letto dalla parte giusta. E così via.\nQuesto pseudo-codice chiarisce il significato dell’operatore pipe. L’operatore |> è “syntactic sugar” per una serie di chiamate di funzioni concatenate, ovvero, detto in altre parole, consente di definire la relazione tra una serie di funzioni nelle quali il risultato (output) di una funzione viene utilizzato come l’input di una funzione successiva."
  },
  {
    "objectID": "013_penguins.html#esaminare-i-dati",
    "href": "013_penguins.html#esaminare-i-dati",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.3 Esaminare i dati",
    "text": "6.3 Esaminare i dati\nIniziamo a trasformare il data frame msleep in un tibble.\n\nmsleep <- tibble(msleep)\n\nI nomi delle colonne del tibble (ovvero, i nomi delle variabili del campione) si ottengono con la funzione names().\n\nnames(msleep)\n#>  [1] \"name\"         \"genus\"        \"vore\"         \"order\"        \"conservation\"\n#>  [6] \"sleep_total\"  \"sleep_rem\"    \"sleep_cycle\"  \"awake\"        \"brainwt\"     \n#> [11] \"bodywt\"\n\nI valori iniziali di ciascuna colonna del tibble possono essere visualizzati usando la funzone glimpse().\n\nglimpse(msleep)\n#> Rows: 83\n#> Columns: 11\n#> $ name         <chr> \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater shor…\n#> $ genus        <chr> \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", \"Bra…\n#> $ vore         <chr> \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"carn…\n#> $ order        <chr> \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", \"Art…\n#> $ conservation <chr> \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"dome…\n#> $ sleep_total  <dbl> 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0, 5…\n#> $ sleep_rem    <dbl> NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.8, …\n#> $ sleep_cycle  <dbl> NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833333, N…\n#> $ awake        <dbl> 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0, 1…\n#> $ brainwt      <dbl> NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000, 0…\n#> $ bodywt       <dbl> 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0.04…\n\nPer le variabili qualitative, possiamo creare una distribuzione di frequenze assolute mediante la funzione table().\n\ntable(msleep$vore)\n#> \n#>   carni   herbi insecti    omni \n#>      19      32       5      20\n\nUsando table() possiamo anche creare una tabella di contingenza.\n\ntable(msleep$vore, msleep$conservation)\n#>          \n#>           cd domesticated en lc nt vu\n#>   carni    1            2  1  5  1  4\n#>   herbi    1            7  2 10  3  3\n#>   insecti  0            0  1  2  0  0\n#>   omni     0            1  0  8  0  0\n\nSi ricordi che, quando si usa table() per creare una tabella di contingenza, i dati mancanti (NA) vengono esclusi."
  },
  {
    "objectID": "013_penguins.html#estrarre-una-singola-colonna-con-pull",
    "href": "013_penguins.html#estrarre-una-singola-colonna-con-pull",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.4 Estrarre una singola colonna con pull()\n",
    "text": "6.4 Estrarre una singola colonna con pull()\n\nEstraiamo da msleep la variabile sleep_total usando il verbo pull():\n\nmsleep |> \n  pull(sleep_total)\n#>  [1] 12.1 17.0 14.4 14.9  4.0 14.4  8.7  7.0 10.1  3.0  5.3  9.4 10.0 12.5 10.3\n#> [16]  8.3  9.1 17.4  5.3 18.0  3.9 19.7  2.9  3.1 10.1 10.9 14.9 12.5  9.8  1.9\n#> [31]  2.7  6.2  6.3  8.0  9.5  3.3 19.4 10.1 14.2 14.3 12.8 12.5 19.9 14.6 11.0\n#> [46]  7.7 14.5  8.4  3.8  9.7 15.8 10.4 13.5  9.4 10.3 11.0 11.5 13.7  3.5  5.6\n#> [61] 11.1 18.1  5.4 13.0  8.7  9.6  8.4 11.3 10.6 16.6 13.8 15.9 12.8  9.1  8.6\n#> [76] 15.8  4.4 15.6  8.9  5.2  6.3 12.5  9.8\n\nIn maniera equivalente, possiamo usare l’operatore $ di base \\(\\mathsf{R}\\):\n\nmsleep$sleep_total\n#>  [1] 12.1 17.0 14.4 14.9  4.0 14.4  8.7  7.0 10.1  3.0  5.3  9.4 10.0 12.5 10.3\n#> [16]  8.3  9.1 17.4  5.3 18.0  3.9 19.7  2.9  3.1 10.1 10.9 14.9 12.5  9.8  1.9\n#> [31]  2.7  6.2  6.3  8.0  9.5  3.3 19.4 10.1 14.2 14.3 12.8 12.5 19.9 14.6 11.0\n#> [46]  7.7 14.5  8.4  3.8  9.7 15.8 10.4 13.5  9.4 10.3 11.0 11.5 13.7  3.5  5.6\n#> [61] 11.1 18.1  5.4 13.0  8.7  9.6  8.4 11.3 10.6 16.6 13.8 15.9 12.8  9.1  8.6\n#> [76] 15.8  4.4 15.6  8.9  5.2  6.3 12.5  9.8\n\nPossiamo ordinare i dati con sort().\n\nmsleep$sleep_total |> \n  sort() \n#>  [1]  1.9  2.7  2.9  3.0  3.1  3.3  3.5  3.8  3.9  4.0  4.4  5.2  5.3  5.3  5.4\n#> [16]  5.6  6.2  6.3  6.3  7.0  7.7  8.0  8.3  8.4  8.4  8.6  8.7  8.7  8.9  9.1\n#> [31]  9.1  9.4  9.4  9.5  9.6  9.7  9.8  9.8 10.0 10.1 10.1 10.1 10.3 10.3 10.4\n#> [46] 10.6 10.9 11.0 11.0 11.1 11.3 11.5 12.1 12.5 12.5 12.5 12.5 12.8 12.8 13.0\n#> [61] 13.5 13.7 13.8 14.2 14.3 14.4 14.4 14.5 14.6 14.9 14.9 15.6 15.8 15.8 15.9\n#> [76] 16.6 17.0 17.4 18.0 18.1 19.4 19.7 19.9\n\nOppure, in ordine decrescente:\n\nmsleep$sleep_total |> \n  sort(decreasing = TRUE) \n#>  [1] 19.9 19.7 19.4 18.1 18.0 17.4 17.0 16.6 15.9 15.8 15.8 15.6 14.9 14.9 14.6\n#> [16] 14.5 14.4 14.4 14.3 14.2 13.8 13.7 13.5 13.0 12.8 12.8 12.5 12.5 12.5 12.5\n#> [31] 12.1 11.5 11.3 11.1 11.0 11.0 10.9 10.6 10.4 10.3 10.3 10.1 10.1 10.1 10.0\n#> [46]  9.8  9.8  9.7  9.6  9.5  9.4  9.4  9.1  9.1  8.9  8.7  8.7  8.6  8.4  8.4\n#> [61]  8.3  8.0  7.7  7.0  6.3  6.3  6.2  5.6  5.4  5.3  5.3  5.2  4.4  4.0  3.9\n#> [76]  3.8  3.5  3.3  3.1  3.0  2.9  2.7  1.9\n\nPossiamo attribuire la colonna estratta dal tibble ad un oggetto nella memoria di lavoro di \\(\\mathsf{R}\\) usando l’operatore di attribuzione <-.\n\nsl_tot <- msleep |> \n  pull(sleep_total)\n\nEssendo sl_tot presente nella emoria di lavoro di \\(\\mathsf{R}\\), possiamo passarlo a qualsiasi altra funzione di \\(\\mathsf{R}\\). Per esempio, possiamo calcolare la media di sl_tot usando la funzione mean()\n\nmean(sl_tot)\n#> [1] 10.43373\n\noppure la deviazione standard usando la funzione sd()\n\nsd(sl_tot)\n#> [1] 4.450357"
  },
  {
    "objectID": "013_penguins.html#selezionare-più-colonne-con-select",
    "href": "013_penguins.html#selezionare-più-colonne-con-select",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.5 Selezionare più colonne con select()\n",
    "text": "6.5 Selezionare più colonne con select()\n\nSe vogliamo selezionare da msleep un insieme di variabili, ad esempio name, vore e sleep_total, possiamo usare il verbo select()\n\ndt <- msleep |> \n  dplyr::select(name, vore, sleep_total)\ndt\n#> # A tibble: 83 × 3\n#>   name                       vore  sleep_total\n#>   <chr>                      <chr>       <dbl>\n#> 1 Cheetah                    carni        12.1\n#> 2 Owl monkey                 omni         17  \n#> 3 Mountain beaver            herbi        14.4\n#> 4 Greater short-tailed shrew omni         14.9\n#> 5 Cow                        herbi         4  \n#> 6 Three-toed sloth           herbi        14.4\n#> 7 Northern fur seal          carni         8.7\n#> 8 Vesper mouse               <NA>          7  \n#> # … with 75 more rows\n\nladdove la sequenza di istruzioni precedenti significa che abbiamo passato msleep alla funzione select() contenuta nel pacchetto dplyr e l’output di select() è stato salvato (usando l’operatore di assegnazione, <-) nell’oggetto dt. Alla funzione select() abbiamo passato gli argomenti name, vore e sleep_total."
  },
  {
    "objectID": "013_penguins.html#selezionare-le-righe-che-soddisfano-una-condizione",
    "href": "013_penguins.html#selezionare-le-righe-che-soddisfano-una-condizione",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.6 Selezionare le righe che soddisfano una condizione",
    "text": "6.6 Selezionare le righe che soddisfano una condizione\nIl verbo filter() consente di selezionare da un tibble un sottoinsieme di righe (osservazioni). Per esempio, possiamo selezionare tutte le osservazioni nella variabile vore contrassegnate come carni (ovvero, tutti i carnivori):\n\ndt %>%\n  dplyr::filter(vore == \"carni\")\n#> # A tibble: 19 × 3\n#>   name                 vore  sleep_total\n#>   <chr>                <chr>       <dbl>\n#> 1 Cheetah              carni        12.1\n#> 2 Northern fur seal    carni         8.7\n#> 3 Dog                  carni        10.1\n#> 4 Long-nosed armadillo carni        17.4\n#> 5 Domestic cat         carni        12.5\n#> 6 Pilot whale          carni         2.7\n#> 7 Gray seal            carni         6.2\n#> 8 Thick-tailed opposum carni        19.4\n#> # … with 11 more rows\n\nPer utilizzare il verbo filter() in modo efficace è neccessario usare gli operatori relazionali\n\\[\\begin{array}{l l}\n\\hline\n\\text{Operazione logica}   & \\text{Operatore}  \\\\\n\\hline\n      \\text{uguale}             &  == \\\\\n      \\text{diverso}            &  !=  \\\\\n      \\text{minore}             &  <  \\\\\n      \\text{maggiore}           &  >  \\\\\n      \\text{minore o uguale}      & <=  \\\\\n      \\text{maggiore o uguale}  & >=  \\\\\n\\hline\n\\end{array}\\]\ne gli operatori logici di \\(\\mathsf{R}\\).\n\\[\\begin{array}{l l}\n\\hline\n\\text{Operazione logica}   & \\text{Operatore}  \\\\\n\\hline\n      \\text{AND}      &  \\&    \\\\\n      \\text{OR }      &  | \\\\\n      \\text{NOT}     &  !   \\\\\n\\hline\n\\end{array}\\]\nPer un approfondimento, si veda il Capitolo Comparisons di R for Data Science."
  },
  {
    "objectID": "013_penguins.html#creare-una-nuova-variabile-con-mutate",
    "href": "013_penguins.html#creare-una-nuova-variabile-con-mutate",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.7 Creare una nuova variabile con mutate()\n",
    "text": "6.7 Creare una nuova variabile con mutate()\n\nTalvolta vogliamo creare una nuova variabile, per esempio, sommando o dividendo due variabili, oppure calcolandone la media. A questo scopo si usa il verbo mutate(). Per esempio, se vogliamo esprimere i valori di sleep_total in minuti, moltiplichiamo per 60:\n\ndt |> \n  mutate(\n    sleep_minutes = sleep_total * 60\n  ) |> \n  dplyr::select(sleep_total, sleep_minutes)\n#> # A tibble: 83 × 2\n#>   sleep_total sleep_minutes\n#>         <dbl>         <dbl>\n#> 1        12.1           726\n#> 2        17            1020\n#> 3        14.4           864\n#> 4        14.9           894\n#> 5         4             240\n#> 6        14.4           864\n#> 7         8.7           522\n#> 8         7             420\n#> # … with 75 more rows"
  },
  {
    "objectID": "013_penguins.html#ordinare-i-dati-con-arrange",
    "href": "013_penguins.html#ordinare-i-dati-con-arrange",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.8 Ordinare i dati con arrange()\n",
    "text": "6.8 Ordinare i dati con arrange()\n\nIl verbo arrange() ordina i dati in base ai valori di una o più variabili. Per esempio, possiamo ordinare la variabile sleep_total dal valore più alto al più basso in questo modo:\n\ndt |> \n  arrange(\n    desc(sleep_total)\n  )\n#> # A tibble: 83 × 3\n#>   name                   vore    sleep_total\n#>   <chr>                  <chr>         <dbl>\n#> 1 Little brown bat       insecti        19.9\n#> 2 Big brown bat          insecti        19.7\n#> 3 Thick-tailed opposum   carni          19.4\n#> 4 Giant armadillo        insecti        18.1\n#> 5 North American Opossum omni           18  \n#> 6 Long-nosed armadillo   carni          17.4\n#> 7 Owl monkey             omni           17  \n#> 8 Arctic ground squirrel herbi          16.6\n#> # … with 75 more rows"
  },
  {
    "objectID": "013_penguins.html#raggruppare-i-dati-con-group_by",
    "href": "013_penguins.html#raggruppare-i-dati-con-group_by",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.9 Raggruppare i dati con group_by()\n",
    "text": "6.9 Raggruppare i dati con group_by()\n\nIl verbo group_by() raggruppa insieme i valori in base a una o più variabili. Lo vedremo in uso in seguito insieme a summarise().\nNota: con dplyr(), le operazioni raggruppate vengono iniziate con la funzione group_by(). È una buona norma utilizzare ungroup() alla fine di una serie di operazioni raggruppate, altrimenti i raggruppamenti verranno mantenuti nelle analisi successiva, il che non è sempre auspicabile."
  },
  {
    "objectID": "013_penguins.html#sommario-dei-dati-con-summarise",
    "href": "013_penguins.html#sommario-dei-dati-con-summarise",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.10 Sommario dei dati con summarise()\n",
    "text": "6.10 Sommario dei dati con summarise()\n\nIl verbo summarise() collassa il dataset in una singola riga dove viene riportato il risultato della statistica richiesta. Per esempio, la media del tempo totale del sonno è\n\ndt |> \n  summarise(\n    m_sleep = mean(sleep_total, na.rm = TRUE)\n  ) \n#> # A tibble: 1 × 1\n#>   m_sleep\n#>     <dbl>\n#> 1    10.4"
  },
  {
    "objectID": "013_penguins.html#operazioni-raggruppate",
    "href": "013_penguins.html#operazioni-raggruppate",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.11 Operazioni raggruppate",
    "text": "6.11 Operazioni raggruppate\nSopra abbiamo visto come i mammiferi considerati dormano, in media, 10.4 ore al giorno. Troviamo ora il sonno medio in funzione di vore:\n\ndt |> \n  group_by(vore) |> \n  summarise(\n    m_sleep = mean(sleep_total, na.rm = TRUE), \n    n = n()\n  )\n#> # A tibble: 5 × 3\n#>   vore    m_sleep     n\n#>   <chr>     <dbl> <int>\n#> 1 carni     10.4     19\n#> 2 herbi      9.51    32\n#> 3 insecti   14.9      5\n#> 4 omni      10.9     20\n#> 5 <NA>      10.2      7\n\nSi noti che, nel caso di 7 osservazioni, il valore di vore non era specificato. Per tali osservazioni, dunque, la classe di appartenenza è NA."
  },
  {
    "objectID": "013_penguins.html#applicare-una-funzione-su-più-colonne-across",
    "href": "013_penguins.html#applicare-una-funzione-su-più-colonne-across",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.12 Applicare una funzione su più colonne: across()\n",
    "text": "6.12 Applicare una funzione su più colonne: across()\n\nÈ spesso utile eseguire la stessa operazione su più colonne, ma copiare e incollare è sia noioso che soggetto a errori:\n\ndf |> \n  group_by(g1, g2) %>%\n  summarise(\n    a = mean(a),\n    b = mean(b),\n    c = mean(c),\n    d = mean(d)\n  )\n\nIn tali circostanze è possibile usare la funzione across() che consente di riscrivere il codice precedente in modo più succinto:\n\ndf |> \n  group_by(g1, g2) %>% \n  summarise(across(a:d, mean))\n\nPer i dati presenti, ad esempio, possiamo avere:\n\nmsleep |> \n  group_by(vore) |> \n  summarise(across(starts_with(\"sleep\"), ~ mean(.x, na.rm = TRUE)))\n#> # A tibble: 5 × 4\n#>   vore    sleep_total sleep_rem sleep_cycle\n#>   <chr>         <dbl>     <dbl>       <dbl>\n#> 1 carni         10.4       2.29       0.373\n#> 2 herbi          9.51      1.37       0.418\n#> 3 insecti       14.9       3.52       0.161\n#> 4 omni          10.9       1.96       0.592\n#> 5 <NA>          10.2       1.88       0.183"
  },
  {
    "objectID": "013_penguins.html#dati-categoriali-in-mathsfr",
    "href": "013_penguins.html#dati-categoriali-in-mathsfr",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.13 Dati categoriali in \\(\\mathsf{R}\\)\n",
    "text": "6.13 Dati categoriali in \\(\\mathsf{R}\\)\n\nConsideriamo una variabile che descrive il genere e include le categorie male, female e non-conforming. In \\(\\mathsf{R}\\), ci sono due modi per memorizzare queste informazioni. Uno è usare la classe character strings e l’altro è usare la classe factor. Non ci addentrimo qui nelle sottigliezze di questa distinzione, motivata in gran parte per le necessità della programmazione con le funzioni di tidyverse. Per gli scopi di questo insegnamento sarà sufficiente codificare le variabili qualitative usando la classe factor. Una volta codificati i dati qualitativi utilizzando la classe factor, si pongono spesso due problemi:\n\nmodificare le etichette dei livelli (ovvero, le modalità) di un fattore,\nriordinare i livelli di un fattore."
  },
  {
    "objectID": "013_penguins.html#modificare-le-etichette-dei-livelli-di-un-fattore",
    "href": "013_penguins.html#modificare-le-etichette-dei-livelli-di-un-fattore",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.14 Modificare le etichette dei livelli di un fattore",
    "text": "6.14 Modificare le etichette dei livelli di un fattore\nEsaminiamo l’esempio seguente.\n\nf_1 <- c(\"old_3\", \"old_4\", \"old_1\", \"old_1\", \"old_2\")\nf_1 <- factor(f_1)\ny <- 1:5\ndf <- tibble(f_1, y)\ndf\n#> # A tibble: 5 × 2\n#>   f_1       y\n#>   <fct> <int>\n#> 1 old_3     1\n#> 2 old_4     2\n#> 3 old_1     3\n#> 4 old_1     4\n#> 5 old_2     5\n\nSupponiamo ora di volere che i livelli del fattore f_1 abbiano le etichette new_1, new_2, ecc. Per ottenere questo risultato usiamo la funzione forcats::fct_recode():\n\ndf <- df |> \n  mutate(f_1 =\n    forcats::fct_recode(\n      f_1, \n      \"poco\" = \"old_1\", \n      \"medio\" = \"old_2\", \n      \"tanto\" = \"old_3\", \n      \"massimo\" = \"old_4\"\n      )\n   )\ndf\n#> # A tibble: 5 × 2\n#>   f_1         y\n#>   <fct>   <int>\n#> 1 tanto       1\n#> 2 massimo     2\n#> 3 poco        3\n#> 4 poco        4\n#> 5 medio       5"
  },
  {
    "objectID": "013_penguins.html#riordinare-i-livelli-di-un-fattore",
    "href": "013_penguins.html#riordinare-i-livelli-di-un-fattore",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.15 Riordinare i livelli di un fattore",
    "text": "6.15 Riordinare i livelli di un fattore\nSpesso i livelli dei fattori hanno un ordinamento naturale. Quindi, gli utenti devono avere un modo per imporre l’ordine desiderato sulla codifica delle loro variabili qualitative. Se per qualche motivo vogliamo ordinare i livelli f_1 in ordine inverso, ad esempio, possiamo procedere nel modo seguente.\n\ndf$f_1 <- factor(df$f_1,\n  levels = c(\n    \"massimo\", \"tanto\", \"medio\", \"poco\" \n  )\n)\nsummary(df$f_1)\n#> massimo   tanto   medio    poco \n#>       1       1       1       2\n\nPer approfondire le problematiche della manipolazione di variabili qualitative in \\(\\mathsf{R}\\), si veda McNamara & Horton (2018)."
  },
  {
    "objectID": "013_penguins.html#creare-grafici-con-ggplot2",
    "href": "013_penguins.html#creare-grafici-con-ggplot2",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.16 Creare grafici con ggplot2()\n",
    "text": "6.16 Creare grafici con ggplot2()\n\nIl pacchetto ggplot2() è un potente strumento per rappresentare graficamente i dati. Le iniziali del nome, gg, si riferiscono alla “Grammar of Graphics”, che è un modo di pensare le figure come una serie di layer stratificati. Originariamente descritta da Wilkinson (2012), la grammatica dei grafici è stata aggiornata e applicata in R da Hadley Wickham, il creatore del pacchetto.\nLa funzione da cui si parte per inizializzare un grafico è ggplot(). La funzione ggplot() richiede due argomenti. Il primo è l’oggetto di tipo data.frame che contiene i dati da visualizzare – in alternativa al primo argomento, un dataframe può essere passato a ggplot() mediante l’operatore pipe. Il secondo è una particolare lista che viene generata dalla funzione aes(), la quale determina l’aspetto (aesthetic) del grafico. La funzione aes() richiede necessariamente di specificare “x” e “y”, ovvero i nomi delle colonne del data.frame che è stato utilizzato quale primo argomento di ggplot() (o che è stato passato da pipe), le quali rappresentano le variabili da porre rispettivamente sugli assi orizzontale e verticale.\nLa definizione della tipologia di grafico e i vari parametri sono poi definiti successivamente, aggiungendo all’oggetto creato da ggplot() tutte le componenti necessarie. Saranno quindi altre funzioni, come geom_bar(), geom_line() o geom_point() a occuparsi di aggiungere al livello di base barre, linee, punti, e così via. Infine, tramite altre funzioni, ad esempio labs(), sarà possibile definire i dettagli più fini.\nGli elementi grafici (bare, punti, segmenti, …) usati da ggplot2 sono chiamati geoms. Mediante queste funzioni è possibile costruire diverse tipologie di grafici:\n\n\ngeom_bar(): crea un layer con delle barre;\n\ngeom_point(): crea un layer con dei punti (diagramma a dispersione);\n\ngeom_line(): crea un layer con una linea retta;\n\ngeom_histogram(): crea un layer con un istogramma;\n\ngeom_boxplot(): crea un layer con un box-plot;\n\ngeom_errorbar(): crea un layer con barre che rappresentano intervalli di confidenza;\n\ngeom_hline() e geom_vline() : crea un layer con una linea orizzontale o verticale definita dall’utente.\n\nUn comando generico ha la seguente forma:\n\nmy_graph <- my_data |> \n  ggplot(aes(x_var, y_var)) +\n  geom_...()\n\nLa prima volta che si usa il pacchetto ggplot2 è necessario installarlo. Per fare questo possiamo installare tidyverse che, oltre a caricare ggplot2, carica anche altre utili funzioni per l’analisi dei dati. Ogni volta che si inizia una sessione R è necessario attivare i pacchetti che si vogliono usare, ma non è necessario istallarli una nuova volta. Se è necessario specificare il pacchetto nel quale è contenuta la funzione che vogliamo utilizzare, usiamo la sintassi package::function(). Per esempio, l’istruzione ggplot2::ggplot() rende esplicito che stiamo usando la funzione ggplot() contenuta nel pacchetto ggplot2."
  },
  {
    "objectID": "013_penguins.html#diagramma-a-dispersione",
    "href": "013_penguins.html#diagramma-a-dispersione",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.17 Diagramma a dispersione",
    "text": "6.17 Diagramma a dispersione\nConsideriamo nuovamenti i dati contenuti nel tibble msleep e poniamoci il problema di rappresentare graficamente la relazione tra il numero medio di ore di sonno giornaliero (sleep_total) e il peso dell’animale (bodywt). Usando le impostazioni di default di ggplot2, con le istruzioni seguenti, otteniamo il grafico fornito dalla figura seguente.\n\ndata(\"msleep\")\np <- msleep |> \n  ggplot(\n    aes(x = bodywt, y = sleep_total)\n  ) +\n  geom_point()\nprint(p)\n\n\n\n\n\n\n\nColoriamo ora in maniera diversa i punti che rappresentano animali carnivori, erbivori, ecc.\n\np <- msleep |> \n  ggplot(\n    aes(x = bodywt, y = sleep_total, col = vore)\n  ) +\n  geom_point()\nprint(p)\n\n\n\n\n\n\n\nÈ chiaro, senza fare alcuna analisi statistica, che la relazione tra le due variabili non è lineare. Trasformando in maniera logaritmica i valori dell’asse \\(x\\) la relazione si linearizza.\n\np <- msleep |> \n  ggplot(\n    aes(x = log(bodywt), y = sleep_total, col = vore)\n  ) +\n  geom_point()\nprint(p)\n\n\n\n\n\n\n\nInfine, aggiustiamo il “tema” del grafico (si noti l’utilizzo di una tavolozza di colori adatta ai daltonici mediante il pacchetto viridis), aggiungiamo le etichette sugli assi e il titolo.\n\nlibrary(\"viridis\")\nmsleep |> \n  ggplot(\n    aes(x = log(bodywt), y = sleep_total, col = vore)\n  ) +\n  geom_point(size = 2, alpha = .8) +\n  labs(\n    x = \"Peso corporeo (log)\",\n    y = \"Ore di sonno\",\n    title = \"Il sonno in 83 specie di mammiferi\",\n    subtitle = \"Un esempio di visualizzazione con ggplot()\",\n    caption = \"Fonte: Savage e West (2007)\"\n  ) +\n  scale_fill_viridis(discrete = TRUE, option = \"viridis\") +\n  theme_minimal() +\n  theme(legend.title = element_blank()) \n\n\n\n\n\n\n\nLa visualizzazione può essere migliorata cambiando le etichette della legenda del grafico. Per fare questo è necessario intervenire sui dati prima di usare ggplot() – per esempio, come abbiamo fatto in precedenza con la funzione forcats::fct_recode()."
  },
  {
    "objectID": "013_penguins.html#istogramma",
    "href": "013_penguins.html#istogramma",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "\n6.18 Istogramma",
    "text": "6.18 Istogramma\nCreiamo ora un istogramma che rappresenta la distribuzione del (logaritmo del) peso medio del cervello delle 83 specie di mammiferi considerate da Savage & West (2007). L’argomento aes(y = ..density..) in geom_histogram() produce le frequenze relative. L’opzione di default (senza questo argomento) porta ggplot() a rappresentare le frequenze assolute.\n\nmsleep |> \n  ggplot(\n    aes(log(brainwt))\n  ) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Peso del cervello (log)\",\n    y = \"Frequenza relativa\"\n  ) +\n  theme(legend.title = element_blank())"
  },
  {
    "objectID": "013_penguins.html#commenti-e-considerazioni-finali",
    "href": "013_penguins.html#commenti-e-considerazioni-finali",
    "title": "6  Manipolazione e visualizzazione dei dati in \\(\\mathsf{R}\\)",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nPer minimizzare gli errori di sintassi (dimenticare una virgola, non chiudere una parentesi, ecc.) – ovvero, gli errori più frequenti quando si scrive il codice in \\(\\mathsf{R}\\) – è necessario utilizzare uno stile di programmazione. Uno stile di programmazione è un insieme di regole per la gestione dell’indentazione dei blocchi di codice, per la creazione dei nomi dei file e delle variabili e per le convenzioni tipografiche che vengono usate. Scrivere il codice in \\(\\mathsf{R}\\) con stile consente di creare listati più leggibili e semplici da modificare, minimizza la possibilità di errore, e consente correzioni e modifiche più rapide. Vi sono molteplici stili di programmazione che possono essere utilizzati dall’utente, anche se è bene attenersi a quelle che sono le convenzioni maggiormente diffuse, allo scopo di favorire la comunicazione. In ogni caso, l’importante è di essere coerenti, ovvero di adottare le stesse convenzioni in tutte le parti del codice che si scrive. Ad esempio, se si sceglie di usare lo stile snake_case per il nome composto di una variabile (es., personality_trait), non è appropriato usare lo stile lower Camel case per un’altra variabile (es., socialStatus). Dato che questo argomento è stato trattato ampiamente in varie sedi, mi limito qui a rimandare ad uno stile di programmazione molto popolare, quello proposto da Hadley Wickham, il creatore di tidyverse. La soluzione più semplice è quella installare stiler, che è uno RStudio Addin, e formattare il codice in maniera automatica utilizzando lo stile proposto da Hadley Wickham. Si possono ottenere informazioni su stiler seguendo questo link.\n\n\n\n\n\n\nMcNamara, A., & Horton, N. J. (2018). Wrangling categorical data in r. The American Statistician, 72(1), 97–104.\n\n\nSavage, V. M., Allen, A. P., Brown, J. H., Gillooly, J. F., Herman, A. B., Woodruff, W. H., & West, G. B. (2007). Scaling of number, size, and metabolic rate of cells with body size in mammals. Proceedings of the National Academy of Sciences, 104(11), 4718–4723.\n\n\nSavage, V. M., & West, G. B. (2007). A quantitative, theoretical framework for understanding mammalian sleep. Proceedings of the National Academy of Sciences, 104(3), 1051–1056.\n\n\nWilkinson, L. (2012). The grammar of graphics. In Handbook of computational statistics (pp. 375–414). Springer."
  },
  {
    "objectID": "prob.html",
    "href": "prob.html",
    "title": "Parte 2: Il calcolo delle probabilità",
    "section": "",
    "text": "In questa seconda parte introdotti i concetti di base della teoria delle probabilità.\nNel capitolo Capitolo 7 verrà presentata la legge dei grandi numeri, il concetto di variabile casuale e la funzione di massa di probabilità."
  },
  {
    "objectID": "015_prob_intro.html#che-cosè-la-probabilità",
    "href": "015_prob_intro.html#che-cosè-la-probabilità",
    "title": "7  La logica dell’incerto",
    "section": "\n7.1 Che cos’è la probabilità?",
    "text": "7.1 Che cos’è la probabilità?\nLa definizione della probabilità è un problema estremamente dibattuto ed aperto. Sono state fornite due possibili soluzioni al problema di definire il concetto di probabilità.\n\nLa natura della probabilità è “ontologica” (ovvero, basata sulla metafisica): la probabilità è una proprietà della della realtà, del mondo, di come sono le cose, indipendentemente dalla nostra esperienza. È una visione che qualcuno chiama “oggettiva”.\nLa natura della probabilità è “epistemica” (ovvero, basata sulla conoscenza): la probabilità si riferisce alla conoscenza che abbiamo del mondo, non al mondo in sé. Di conseguenza è detta, in contrapposizione alla precedente definizione, “soggettiva”.\n\nIn termini epistemici, la probabilità fornisce una misura della nostra incertezza sul verificarsi di un evento, alla luce delle informazioni disponibili. Potremmo dire che c’è una “scala” naturale che ha per estremi il vero (1: evento certo), da una parte, ed il falso (0: evento impossibile), dall’altra. La probabilità è la quantificazione di questa scala: descrive lo stato della nostra incertezza rispetto al contenuto di verità di una proposizione.\nL’incertezza nelle nostre previsioni può sorgere per due ragioni fondamentalmente diverse. La prima è dovuta alla nostra ignoranza relativamente alle cause nascoste sottostanti o dei meccanismi che generano i dati. Questa è, appunto, un’incertezza epistemica. Il secondo tipo di incertezza deriva invece dalla variabilità intrinseca dei fenomeni, che non può essere ridotta anche se raccogliamo più dati. Questa seconda forma di incertezza è talvolta chiamata aleatoria. Come esempio concreto, consideriamo il lancio di una moneta equilibrata. Sappiamo con certezza che la probabilità di testa è \\(P = 0.5\\), quindi non c’è incertezza epistemica, ma non questo non è sufficiente per prevedere con certezza il risultato – in altre parole, l’incertezza aleatoria persiste anche in assenza di incertezza epistemica.\nL’interpretazione bayesiana di probabilità si contrappone all’interpretazione frequentista. Nell’interpretazione frequentista, la probabilità \\(P(E)\\) rappresenta la frequenza relativa a lungo termine di un grande numero di ripetizioni di un esperimento casuale sotto le medesime condizioni. Viene stressata qui l’idea che ciò di cui parliamo è qualcosa che emerge nel momento in cui è possibile ripetere l’esperimento casuale tante volte sotto le medesime condizioni – sono invece esclusi gli eventi unici e irripetibili.\n\n\nL’interpretazione bayesiana della probabilità fa invece ricorso ad una concezione più ampia, non legata al solo evento in sé, ma che include anche il soggetto assegnante la funzione di probabilità. In pratica l’assegnazione di probabilità bayesiana viene effettuata dal decisore, in base alle proprie conoscenze a priori integrate con tutto il generico bagaglio culturale personale. In questo modo, la probabilità non sarà obbligatoriamente la stessa per tutti i soggetti, ma variarierà a seconda delle informazioni a disposizione, dell’esperienza personale e soprattutto del punto di vista proprio di ogni decisore ed è dunque assimilabile al “grado di fiducia” – in inglese degree of belief – di un dato soggetto, in un dato istante e con un dato insieme d’informazioni, circa l’accadere dell’evento \\(E\\).\n\n[N]essuna scienza ci permetterà di dire: il tale fatto accadrà, andrà così e così, perché ciò è conseguenza di tale legge, e tale legge è una verità assoluta, ma tanto meno ci condurrà a concludere scetticamente: la verità assoluta non esiste, e quindi tale fatto può accadere e può non accadere, può andare così e può andare in tutt’altro modo, nulla io ne so. Quel che si potrà dire è questo: io prevedo che il tale fatto avverrà, e avverrà nel tal modo, perché l’esperienza del passato e l’elaborazione scientifica cui il pensiero dell’uomo l’ha sottoposta mi fanno sembrare ragionevole questa previsione” (Finetti, 1931).\n\n\n\n\n\n\n\nLa caratterizzazione ‘epistemica’ della nozione di probabilità può essere chiarita facendo riferimento all’esempio prototipico con il quale la probabilità viene solitamente descritta, ovvero come una frequenza relativa. A questo proposito, McElreath ci chiede di riflettere con maggiore attenzione sul fenomeno costituito da una sequenza di lanci di una moneta, ovvero l’esempio tradizionale con il quale si descrive un evento “aleatorio”. Ingenuamente potremmo pensare che un tale fenomeno sia “casuale”, nel senso che, all’interno della sequenza, non vi è alcuna informazione negli eventi (lanci) passati che sia utile per prevedere gli eventi futuri. Ma non è così. Il lancio di una moneta è un fenomeno deterministico, regolato dalle leggi fisiche. Infatti, sono state create delle macchine che, applicando la stessa forza ogni volta, sono in grado di ripetere lo stesso esito (testa o croce) in ogni prova. Questo significa che la “casualità” della sequenza di lanci non è una proprietà del fenomeno fisico che vorremmo descrivere (i fenomeni fisici sono sempre deterministici in quanto sono regolati dalle leggi della fisica) ma bensì è epistemica, ovvero riguarda lo stato dell’informazione disponibile all’osservatore.\n\n\n\n\n7.1.1 Formalizzazione dell’incertezza\nLa caratterizzazione della probabilità quale rappresentazione dell’incertezza epistemica è stata formalizzata in ambito bayesiano da Ramsey e de Finetti. De Finetti riconduce l’assegnazione di probabilità allo scommettere sul verificarsi di un evento: la probabilità di un evento \\(E\\) è la quota \\(p(E)\\) che un individuo reputa di dover pagare ad un banco per ricevere “1” ovvero “0” verificandosi o non verificandosi \\(E\\).\nIn termini formali, secondo De Finetti, le valutazioni di probabilità degli eventi devono rispondere ai principi di equità e coerenza.\n\nUna scommessa risponde al principio di equità se il ruolo di banco e giocatore sono scambiabili in ogni momento del gioco e sempre alle stesse condizioni.\nUna scommessa risponde al principio di coerenza se non vi sono combinazioni di scommesse che consentano (sia al banco che al giocatore) di realizzare perdite o vincite certe.\n\nL’approccio definettiano dell’impostazione della scommessa si basa dunque sulle assunzioni di razionalità e coerenza del decisore, al quale è fatto esplicito divieto di effettuare scommesse a perdita o guadagno certo. Il decisore, proponendo la scommessa, deve essere disposto a scambiare il posto dello scommettitore con quello del banco.\nIl metodo della scommessa, oltre che una definizione, fornisce un mezzo operativo di assegnazione della probabilità. Sulla base di questa definizione operativa, che si può ritenere ragionevolmente soddisfatta dal comportamento di un qualunque individuo che agisca in modo razionale in condizioni di incertezza, possono essere agevolmente dimostrate tutte le proprietà classiche della probabilità: essa non può assumere valori negativi, né può essere superiore all’unità; se \\(E\\) è un evento certo, la sua probabilità è 1; se invece \\(E\\) è un evento impossibile, la sua probabilità è 0.\nI problemi posti dall’approccio definettiano riguardano l’arbitrarietà dell’assegnazione soggettività di probabilità la quale sembra negare la validità dell’intero costrutto teorico. In risposta a tale critica, i bayesiani sostengono che gli approcci oggettivisti alla probabilità nascondono scelte arbitrarie preliminari e sono basate su assunzioni implausibili. È molto più onesto esplicitare subito tutte le scelte arbitrarie effettuate nel corso dell’analisi in modo da controllarne coerenza e razionalità.\n\n\n\n\n\n\nPer chi desidera approfondire, un’introduzione molto leggibile alle tematiche della definizione della probabilità nella storia della scienza è fornita nel primo capitolo del testo Bernoulli’s fallacy (Clayton, 2021)."
  },
  {
    "objectID": "015_prob_intro.html#variabili-casuali-e-probabilità-di-un-evento",
    "href": "015_prob_intro.html#variabili-casuali-e-probabilità-di-un-evento",
    "title": "7  La logica dell’incerto",
    "section": "\n7.2 Variabili casuali e probabilità di un evento",
    "text": "7.2 Variabili casuali e probabilità di un evento\nEsaminiamo qui di seguito alcuni concetti di base della teoria delle probabilità, la quale può essere intesa come un’estensione della logica.\n\n7.2.1 Eventi e probabilità\nNella teoria delle probabilità il risultato “testa” nel lancio di una moneta è chiamato evento.1 Un evento, denotato da una variabile binaria, corrisponde ad uno stato del mondo che si verifica oppure no. Ad esempio, \\(Y\\) = 1 può denotare l’evento per cui il lancio di una moneta produce il risultato testa. Il funzionale \\(P(Y)\\) denota la probabilità con cui si ritiene che l’evento \\(Y\\) sia vero (o la proporzione di volte che si verifica tale evento osservando a lungo termine delle ripetizioni indipendenti di un esperimento casuale). Ad esempio, per il lancio di una moneta equilibrata, la probabilità dell’evento “il risultato del lancio della moneta è testa” è scritta come \\(P(Y = 1) = 0.5.\\)\nSe la moneta è equilibrata dobbiamo anche avere \\(P(Y = 0) = 0.5\\). I due eventi \\(Y\\) = 1 e \\(Y\\) = 0 sono mutuamente esclusivi nel senso che non possono entrambi verificarsi contemporaneamente: \\(P(Y = 1\\; \\land \\; Y = 0) = 0.\\) Gli eventi \\(Y\\) = 1 e \\(Y\\) = 0 di dicono esaustivi, nel senso che almeno uno di essi deve verificarsi e nessun altro tipo di evento è possibile. Nella notazione probabilistica, \\(P(Y = 1\\; \\lor \\; Y = 0) = 1.\\) Il connettivo logico “o” (\\(\\lor\\)) specifica eventi disgiunti, ovvero eventi che non possono verificarsi contemporaneamente (eventi incompatibili) e per i quali, perciò, la probabilità della loro congiunzione è \\(P(A \\; \\land \\; B) = 0\\). Il connettivo logico “e” (\\(\\land\\)), invece, specifica eventi congiunti, ovvero eventi che possono verificarsi contemporaneamente (eventi compatibili) e per i quali, perciò, la probabilità della loro congiunzione è \\(P(A \\; \\land \\; B) > 0\\). La probabilità del verificarsi di due eventi congiunti \\(A\\) e \\(B\\) si può denotare, in maniera equivalente, con la notazione precedente, oppure con \\(P(A \\cap B)\\), oppure con \\(P(A, B)\\).\nSi richiede che \\(0 \\leq P(A) \\leq 1\\), dove \\(P(A) = 0\\) denota l’evento impossibile e \\(P(A) = 1\\) denota l’evento certo. Scriviamo \\(P(\\lnot A)\\) o \\(P(\\bar{A})\\) per denotare la probabilità che l’evento \\(A\\) non avvenga; questa probabilità è definita come \\(P(\\bar{A}) = 1 − P(A)\\).\n\n7.2.2 Spazio campione e risultati possibili\nAnche se il lancio di una moneta produce sempre uno specifico risultato nel mondo reale, possiamo anche immaginare i possibili risultati alternativi che si sarebbero potuti osservare. Quindi, anche se in uno specifico lancio la moneta dà testa (\\(Y\\) = 1), possiamo immaginare la possibilità che il lancio possa avere prodotto croce (\\(Y\\) = 0). Tale ragionamento controfattuale è la chiave per comprendere la teoria delle probabilità e l’inferenza statistica.\nI risultati possibili che si possono osservare come conseguenza del lancio di una moneta determinano i valori possibili che la variabile casuale può assumere. L’insieme \\(\\Omega\\) di tutti i risultati possibili è chiamato spazio campione (sample space). Lo spazio campione può essere concettualizzato come un’urna contenente una pallina per ogni possibile risultato del lancio della moneta. Su ogni pallina è scritto il valore della variabile casuale. Uno specifico lancio di una moneta – ovvero, l’osservazione di uno specifico valore di una variabile casuale – è chiamato esperimento casuale.\nIl lancio di un dado ci fornisce l’esempio di un altro esperimento casuale. Supponiamo di essere interessati all’evento “il lancio del dado produce un numero dispari”. Un evento seleziona un sottoinsieme dello spazio campione: in questo caso, l’insieme dei risultati \\(\\{1, 3, 5\\}\\). Se esce 3, per esempio, diciamo che si è verificato l’evento “dispari” (ma l’evento “dispari” si sarebbe anche verificato anche se fosse uscito 1 o 5)."
  },
  {
    "objectID": "015_prob_intro.html#distribuzione-di-probabilità",
    "href": "015_prob_intro.html#distribuzione-di-probabilità",
    "title": "7  La logica dell’incerto",
    "section": "\n7.3 Distribuzione di probabilità",
    "text": "7.3 Distribuzione di probabilità\nSia \\(Y\\) il risultato del lancio di moneta equilibrata; non di un generico lancio di una moneta, ma un’istanza specifica del lancio di una specifica moneta in un dato momento. Definita in questo modo, \\(Y\\) è una variabile casuale, ovvero una variabile i cui valori non possono essere previsti con esattezza. Se la moneta è equilibrata, c’è una probabilità del 50% che il lancio della moneta dia come risultato “testa” e una probabilità del 50% che dia come risultato “croce”. Per facilitare la trattazione, le variabili casuali assumono solo valori numerici. Per lo specifico lancio della moneta in questione, diciamo, ad esempio, che la variabile casuale \\(Y\\) assume il valore 1 se esce testa e il valore 0 se esce croce.\nUna variabile casuale può essere discreta o continua. Una variabile casuale discreta può assumere un numero finito di valori \\(x_1, \\dots ,x_n\\), in corrispondenza degli eventi \\(E_i, \\dots, E_n\\) che si verificano con le rispettive probabilità \\(p_1, \\dots, p_n\\). Un esempio è il punteggio totale di un test psicometrico costituito da item su scala Likert. Invece un esempio di una variabile casuale continua è la distanza tra due punti, che può assumere infiniti valori all’interno di un certo intervallo. L’insieme \\(S\\) dei valori che la variabile casuale può assumere è detto spazio dei valori o spazio degli stati.\nLa caratteristica fondamentale di una variabile casuale è data dall’insieme delle probabilità dei suoi valori, detta distribuzione di probabilità. Nel seguito useremo la notazione \\(P(\\cdot)\\) per fare riferimento alle distribuzioni di probabilità delle variabili casuali discrete e \\(p(\\cdot)\\) per fare riferimento alla densità di probabilità delle variabili casuali continue. In questo contesto, l’insieme dei valori che la variabile casuale può assumere è detto supporto della sua distribuzione di probabilità. Il supporto di una variabile casuale può essere finito (come nel caso di una variabile casuale uniforme di supporto \\([a, b]\\)) o infinito (nel caso di una variabile causale gaussiana il cui supporto coincide con la retta reale)."
  },
  {
    "objectID": "015_prob_intro.html#usare-la-simulazione-per-stimare-le-probabilità",
    "href": "015_prob_intro.html#usare-la-simulazione-per-stimare-le-probabilità",
    "title": "7  La logica dell’incerto",
    "section": "\n7.4 Usare la simulazione per stimare le probabilità",
    "text": "7.4 Usare la simulazione per stimare le probabilità\n\nIn questa dispensa verrà adottata l’interpretazione bayesiana delle probabilità. Tuttavia, le regole di base della teoria delle probabilità sono le stesse, indipendentemente dall’interpretazione adottata. Pertanto, negli esempi seguenti, possiamo utilizzare la simulazione per stimare le probabilità degli eventi in un modo diretto, ovvero mediante la generazione di molteplici osservazioni delle variabili casuali derivate dagli eventi di interesse.\nSimuliamo il lancio di una moneta equilibrata.\nDefiniamo una variabile casuale bernoulliana \\(X\\) con \\(\\pi\\) (probabilità di successo) uguale a 0.5.\n\np = 0.5\nX = bernoulli(p)\n\nEsaminiamo 20 realizzazioni di \\(X\\).\n\nx = X.rvs(20)\nprint(x)\n#> [0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 0]\n\nLa stima della probabilità dell’evento \\(P(Y = 1)\\) è data dalla frequenza relativa del numero di volte in cui abbiamo osservato l’evento di interesse (\\(Y = 1\\)).\n\nnp.mean(x)\n#> 0.5\n\nEsaminiamo ora una simulazione nella quale facciamo variare l’ampiezza del campione usato per la stima empirica della probabilità. Nella simulazione vengono generati 10,000 campioni di ampiezza \\(n\\). Di ciascuno di questi campioni casuali viene calcolata la media. Le 10,000 stime empiriche di \\(\\pi\\) vengono poi visualizzate con un istogramma.\n\ndef cointoss(p=0.5, size=10):\n    niter = 10000\n    X = bernoulli(p)\n    random_samples = []\n    for i in range(niter):\n        x = X.rvs(size)\n        random_samples.append(x)\n    \n    rs = np.array(random_samples)\n    p_estimates = np.mean(rs, axis=1)\n    sns.histplot(p_estimates, stat = \"density\");\n    plt.xlim([0, 1])\n    plt.show()\n\nIniziamo con campioni di ampiezza \\(n\\) = 10.\n\ncointoss(size=10)\n\n\n\n\n\n\n\nDato che la moneta è equilibrata, le stime empiriche della probabilità dell’evento \\(P(Y = 1)\\) sono uguali, in media, al valore che ci aspettiamo, ovvero \\(P(Y = 1) = 0.5\\), ma il risultato ottenuto varia di molto da campione a campione. Proviamo ora ad aumentare il numero di lanci in ciascun campione: \\(n\\) = 100.\n\ncointoss(size=100)\n\n\n\n\n\n\n\nIn questo secondo caso, gli errori tendono ad essere più piccoli che nel caso precedente. Usiamo ora 1000 lanci in ciascun campione.\n\ncointoss(size=1000)\n\n\n\n\n\n\n\nOra le stime empiriche che otteniamo in ciascun campione sono tutte molto vicine alla probabilità vera (cioè 0.5, perché la moneta è equilibrata).\nI risultati delle simulazioni precedenti pongono dunque il problema di determinare quale sia il numero di lanci di cui abbiamo bisogno per assicurarci che le stime empiriche di \\(\\pi\\) siano accurate (ovvero, vicine al valore corretto della probabilità teorica)."
  },
  {
    "objectID": "015_prob_intro.html#la-legge-dei-grandi-numeri",
    "href": "015_prob_intro.html#la-legge-dei-grandi-numeri",
    "title": "7  La logica dell’incerto",
    "section": "\n7.5 La legge dei grandi numeri",
    "text": "7.5 La legge dei grandi numeri\nLa visualizzazione mediante grafici contribuisce alla comprensione dei concetti della statistica e della teoria delle probabilità. Un modo per descrivere ciò che accade all’aumentare del numero \\(M\\) di ripetizioni del lancio della moneta consiste nel registrare la stima della probabilità dell’evento \\(P(Y = 1)\\) in funzione del numero di ripetizioni dell’esperimento casuale per ogni \\(m \\in 1:M\\). Possiamo ottenere un grafico dell’andamento della stima di \\(P(Y = 1)\\) in funzione di \\(m\\) nel modo seguente:\n\n\n\n\nFigura 7.1: Stima della probabilità di successo in funzione del numero dei lanci di una moneta.\n\n\n\n\nLa Figura 7.1, quando è espressa su una scala lineare, non rivela chiaramente l’andamento della simulazione. Imponiamo dunque una scala logaritmica sull’asse delle ascisse (\\(x\\)). Su scala logaritmica, i valori tra 1 e 10 vengono tracciati all’incirca con la stessa ampiezza che si osserva tra i valori 50 e 700, eccetera.\n\n\n\n\nFigura 7.2: Stima della probabilità di successo in funzione del numero dei lanci di una moneta.\n\n\n\n\nLa Figura 7.2 fornisce una rappresentazione grafica della legge dei grandi numeri. La legge dei grandi numeri dice che, all’aumentare del numero di ripetizioni dell’esperimento casuale, la media dei risultati ottenuti tende al valore atteso, man mano che vengono eseguite più prove. Nella figura Figura 7.2 vediamo infatti che, all’aumentare del numero M di lanci della moneta, la stima di \\(P(Y = 1)\\) converge al valore 0.5."
  },
  {
    "objectID": "015_prob_intro.html#variabili-casuali-multiple",
    "href": "015_prob_intro.html#variabili-casuali-multiple",
    "title": "7  La logica dell’incerto",
    "section": "\n7.6 Variabili casuali multiple",
    "text": "7.6 Variabili casuali multiple\nLe variabili casuali non esistono isolatamente. Abbiamo iniziato con una sola variabile casuale \\(Y\\) che rappresenta il risultato di un singolo, specifico lancio di una moneta equlibrata. Ma supponiamo ora di lanciare la moneta tre volte. I risultati di ciascuno dei tre lanci possono essere rappresentati da una diversa variabile casuale, ad esempio, \\(Y_1 , Y_2 , Y_3\\). Possiamo assumere che ogni lancio sia indipendente, ovvero che non dipenda dal risultato degli altri lanci. Per ciascuna di queste variabili \\(Y_n\\), con \\(n \\in 1:3\\), abbiamo che \\(P(Y_n =1)=0.5\\) e \\(P(Y_n =0)=0.5\\).\nÈ possibile combinare più variabili casuali usando le operazioni aritmetiche. Se \\(Y_1 , Y_2, Y_3\\) sono variabili casuali che rappresentano tre lanci di una moneta equilibrata (o, in maniera equivalente, un lancio di tre monete equilibrate), possiamo definire la somma di tali variabili casuali come\n\\[\nZ = Y_1 + Y_2 + Y_3.\n\\]\nPossiamo simulare i valori assunti dalla variabile casuale \\(Z\\) simulando i valori di \\(Y_1, Y_2, Y_3\\) per poi sommarli.\n\nsize = 4\nnp.sum(X.rvs(size))\n#> 0\n\nRipetiamo questa simulazione \\(M\\) = 10,000 volte.\n\nsize = 4\nniter = 10000\nrandom_samples = [X.rvs(size) for i in range(niter)]\nrs = np.array(random_samples)\np_estimates = np.mean(rs, axis=1)\n\nlen(p_estimates)\n#> 10000\n\ne calcoliamo poi una stima della probabilità che la variabile casuale \\(Z\\) assuma ciascuno dei possibili valori 0, 1, 2, 3. Nel caso di 4 monete equilibrate, abbiamo:\n\ndf = pd.DataFrame(p_estimates, columns=['p_est'])\nprint(df)\n#>       p_est\n#> 0      0.50\n#> 1      0.50\n#> 2      0.25\n#> 3      0.50\n#> 4      0.50\n#> ...     ...\n#> 9995   1.00\n#> 9996   0.75\n#> 9997   0.25\n#> 9998   0.50\n#> 9999   0.25\n#> \n#> [10000 rows x 1 columns]\n\n\ndf['p_est'].value_counts() / niter\n#> 0.50    0.3752\n#> 0.25    0.2552\n#> 0.75    0.2445\n#> 1.00    0.0660\n#> 0.00    0.0591\n#> Name: p_est, dtype: float64\n\nUna variabile casuale le cui modalità possono essere costituite solo da numeri interi è detta variabile casuale discreta:\n\\[\n\\mathbb{Z} = \\dots, -2, -1, 0, 1, 2, \\dots\n\\]"
  },
  {
    "objectID": "015_prob_intro.html#sec-fun-mass-prob",
    "href": "015_prob_intro.html#sec-fun-mass-prob",
    "title": "7  La logica dell’incerto",
    "section": "\n7.7 Funzione di massa di probabilità",
    "text": "7.7 Funzione di massa di probabilità\nÈ conveniente avere una funzione che associa una probabilità a ciascun possibile valore di una variabile casuale. In generale, ciò è possibile se e solo se la variabile casuale è discreta, così com’è stata definita nel paragrafo precedente. Ad esempio, se consideriamo \\(Z = Y_1 + \\dots + Y_4\\) come, ad esempio, il numero di risultati “testa” in 4 lanci della moneta, allora possiamo definire la seguente funzione:\n\\[\n\\begin{array}{rclll}\np_Z(0) & = & 1/16 & & \\mathrm{TTTT}\n\\\\\np_Z(1) & = & 4/16 & & \\mathrm{HTTT, THTT, TTHT, TTTH}\n\\\\\np_Z(2) & = & 6/16 & & \\mathrm{HHTT, HTHT, HTTH, THHT, THTH, TTTH}\n\\\\\np_Z(3) & = & 4/16 & & \\mathrm{HHHT, HHTH, HTHH, THHH}\n\\\\\np_Z(4) & = & 1/16 & & \\mathrm{HHHH}\n\\end{array}\n\\]\nIl lancio di quattro monete può produrre 16 risultati possibili. Dato che i lanci sono indipendenti, se le monete sono equilibrate ogni possibile risultato è ugualmente probabile. Nella tabella precedente, le sequenze dei risultati possibili del lancio delle 4 monete sono riportate nella colonna più a destra. Le probabilità si ottengono dividendo il numero di sequenze che producono lo stesso numero di eventi testa per il numero dei risultati possibili.\nLe sequenze come \\(\\mathrm{TTTT}\\), \\(\\mathrm{HTTT}\\), ecc. sono chiamate “eventi elementari” (ovvero, corrispondono ad un possibile esito dell’esperimento casuale). L’evento \\(Z = u\\), con \\(u \\in 0 \\dots, 4\\) è un “evento composto”, il quale può essere costituito da più eventi elementari.\nLa funzione \\(p_Z\\) è stata costruita per associare a ciascun valore \\(u\\) della variabile casuale \\(Z\\) la probabilità dell’evento \\(Z = u\\). Convenzionalmente, queste probabilità sono scritte come\n\\[\nP_Z(z) = P(Z = z).\n\\]\nLa parte a destra dell’uguale si può leggere come: “la probabilità che la variabile casuale \\(Z\\) assuma il valore \\(z\\)”. Una funzione definita come sopra è detta funzione di massa di probabilità della variabile casuale \\(Z\\). Ad ogni variabile casuale discreta è associata un’unica funzione di massa di probabilità.\nUna rappresentazione grafica della stima della funzione di massa di probabilità per l’esperimento casuale del lancio di quattro monete equilibrate è fornita nella Figura 7.3.\n\n\n\n\nFigura 7.3: Grafico di \\(M = 100,000\\) simulazioni della funzione di massa di probabilità di una variabile casuale definita come il numero di teste in quattro lanci di una moneta equilibrata.\n\n\n\n\nSe \\(A\\) è un sottoinsieme della variabile casuale \\(Z\\), allora denotiamo con \\(P_{z}(A)\\) la probabilità assegnata ad \\(A\\) dalla distribuzione \\(P_{z}\\). Mediante una distribuzione di probabilità \\(P_{z}\\) è possibile determinare la probabilità di ciascun sottoinsieme \\(A \\subset Z\\) come\n\\[\\begin{equation}\nP_{z}(A) = \\sum_{z \\in A} P_{z}(Z = z).\n\\end{equation}\\]\nUna funzione di massa di probabilità soddisfa le proprietà\n\n\n\\(0 \\leq P(X=x) \\leq 1\\),\n\n\\(\\sum_{x \\in X} P(x) = 1\\).\n\n\nEsercizio 7.1 Per l’esempio discusso nella Sezione 7.7, la probabilità che la variabile casuale \\(Z\\) sia un numero dispari è\n\\[\nP(\\text{Z è un numero dispari}) = P_{z}(Z = 1) + P_{z}(Z = 3) = \\frac{4}{16} + \\frac{4}{16} = \\frac{1}{2}.\n\\]\n\n\n7.7.1 Funzione di ripartizione\nData una variabile casuale discreta \\(X\\) possiamo calcolare la probabilità che \\(X\\) non superi un certo valore \\(x\\), ossia la sua funzione di ripartizione. Poichè \\(X\\) assume valori discreti possiamo cumulare le probabilità mediante una somma:\n\\[\nF(x_k) = P(X \\leq x_k) = \\sum_{x \\leq x_k} P(x).\n\\]\n\nEsercizio 7.2 Per l’esempio discusso nella Sezione 7.7, la funzione di ripartizione della variabile casuale \\(Z\\) è fornita nella tabella seguente.\n\n\n\n\n\n z \n    pz \n    cum_prob \n  \n\n\n 0 \n    0.0625 \n    0.0625 \n  \n\n 1 \n    0.2500 \n    0.3125 \n  \n\n 2 \n    0.3750 \n    0.6875 \n  \n\n 3 \n    0.2500 \n    0.9375 \n  \n\n 4 \n    0.0625 \n    1.0000"
  },
  {
    "objectID": "015_prob_intro.html#commenti-e-considerazioni-finali",
    "href": "015_prob_intro.html#commenti-e-considerazioni-finali",
    "title": "7  La logica dell’incerto",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questo capitolo abbiamo visto come si costruisce lo spazio campione di un esperimento casuale, quali sono le proprietà di base della probabilità e come si assegnano le probabilità agli eventi definiti sopra uno spazio campione discreto. Abbiamo anche introdotto le nozioni di variabile casuale, ovvero di una variabile che assume i suoi valori in maniera casuale. Abbiamo descritto il modo di specificare la probabilità con cui sono una variabile casuale assume i suoi differenti valori, ovvero la funzione di ripartizione \\(F(X) = P(X < x)\\) e la funzione di massa di probabilità.\n\n\n\n\n\n\nClayton, A. (2021). Bernoulli’s fallacy: Statistical illogic and the crisis of modern science. Columbia University Press.\n\n\nFinetti, B. de. (1931). Probabilismo. Logos, 163–219."
  },
  {
    "objectID": "016_conditional_prob.html#sec-bayes-cancer",
    "href": "016_conditional_prob.html#sec-bayes-cancer",
    "title": "8  Probabilità condizionata: significato, teoremi, eventi indipendenti",
    "section": "\n8.1 Probabilità condizionata su altri eventi",
    "text": "8.1 Probabilità condizionata su altri eventi\nL’attribuzione di una probabilità ad un evento è sempre condizionata dalle conoscenze che abbiamo a disposizione. Per un determinato stato di conoscenze, attribuiamo ad un dato evento una certa probabilità di verificarsi; ma se il nostro stato di conoscenze cambia, allora cambierà anche la probabilità che attribuiremo all’evento in questione. Infatti, si può pensare che tutte le probabilità siano probabilità condizionate, anche se l’evento condizionante non è sempre esplicitamente menzionato.\nPer introdurre la probabilità condizionata, Albert & Hu (2019) utilizzando il famoso paradosso delle tre carte.\n\nCi sono tre carte, delle quali la prima (\\(A\\)) è rossa su entrambi i lati, la seconda (\\(B\\)) su un lato è rossa e sull’altro è bianca e la terza (\\(C\\)) è bianca su entrambi i lati. Ponendo su un tavolo una delle tre carte, scelta a caso, ottengo che il lato visibile è di colore rosso. Qual è la probabilità che anche il lato non visibile sia di colore rosso? La risposta intuitiva porta solitamente a rispondere che la probabilità ricercata sia pari al 50%, in quanto solo due carte (la \\(A\\) e la \\(B\\)) possono mostrare il colore rosso e solo una di queste (la \\(A\\)) può mostrare anche sull’altro lato il colore rosso; tuttavia si dimostra che la risposta giusta è 2/3. (da Wikipedia)\n\nAlbert & Hu (2019) propongono di risolvere il problema con una simulazione \\(\\textsf{R}\\): prima di tutto si sceglie una carta a caso, e poi si sceglie un lato della carta. Ci sono tre carte possibili, che chiamiamo “c_rossa”, “c_bianca”, e “c_entrambi”. Per la carta rossa, ci sono due lati rossi; per la carta bianca ci sono due lati bianchi e la carta “entrambi” ha un lato rosso e un lato bianco.\n\nimport pandas as pd\nfrom numpy import random\nimport numpy as np\nimport random\nrandom.seed(2023)\n\n\ndata={\n    'Carta':['c_rossa', 'c_rossa', 'c_bianca', 'c_bianca', 'c_entrambi', 'c_entrambi'],\n    'Lato':[\"rosso\", \"rosso\", \"bianco\", \"bianco\", \"rosso\", \"bianco\"]\n    }\ndf = pd.DataFrame(data, columns=['Carta', 'Lato'])\ndf\n#>         Carta    Lato\n#> 0     c_rossa   rosso\n#> 1     c_rossa   rosso\n#> 2    c_bianca  bianco\n#> 3    c_bianca  bianco\n#> 4  c_entrambi   rosso\n#> 5  c_entrambi  bianco\n\nEstraiamo una carta a caso e classifichiamo il risultato ottenuto in base al tipo di carta e lato osservato. Ripetiamo l’esperimento 1,000 volte:\n\nnrep = 10000\nrs = df.sample(n=nrep, replace=True, random_state=1)\nrs\n#>          Carta    Lato\n#> 5   c_entrambi  bianco\n#> 3     c_bianca  bianco\n#> 4   c_entrambi   rosso\n#> 0      c_rossa   rosso\n#> 1      c_rossa   rosso\n#> ..         ...     ...\n#> 4   c_entrambi   rosso\n#> 3     c_bianca  bianco\n#> 5   c_entrambi  bianco\n#> 0      c_rossa   rosso\n#> 4   c_entrambi   rosso\n#> \n#> [10000 rows x 2 columns]\n\n\ntable = pd.crosstab(rs['Carta'], rs['Lato']) \nprint(table)\n#> Lato        bianco  rosso\n#> Carta                    \n#> c_bianca      3372      0\n#> c_entrambi    1736   1635\n#> c_rossa          0   3257\n\nSe si osserva il colore rosso (seconda colonna nella tabella precedente), questo risultato è dovuto ad una carta \\(A\\) (“rossa”) in 3257 casi e ad una carta \\(B\\) (“entrambi”) in 1635 casi. Quindi, nella simulazione il risultato per cui è stato osservato un colore rosso (3257 + 1635) è associato ad una carta \\(A\\) (“rossa”) in circa 2/3 dei casi – se il lato visibile è di colore rosso, allora c’è una probabilità di 2/3 che anche il lato non visibile sia di colore rosso.\nQuesto esempio dimostra come le nostre intuizioni a proposito della probabilità condizionata non sono sempre corrette. Consideriamo un altro problema più articolato.\n\nEsempio 8.1 Supponiamo che lo screening per la diagnosi precoce del tumore mammario si avvalga di un test che è accurato al 90%, nel senso che classifica correttamente il 90% delle donne colpite dal cancro e il 90% delle donne che non hanno il cancro al seno. Supponiamo che l’1% delle donne sottoposte allo screening abbia effettivamente il cancro al seno (e d’altra parte, il 99% non lo ha). Ci chiediamo: (1) qual è la probabilità che una donna scelta a caso ottenga una mammografia positiva, e (2) se la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?\n\n\nSoluzione. Per risolvere questo problema, supponiamo che il test in questione venga somministrato ad un grande campione di donne, diciamo a 1000 donne. Di queste 1000 donne, 10 (ovvero, l’1%) hanno il cancro al seno. Per queste 10 donne, il test darà un risultato positivo in 9 casi (ovvero, nel 90% dei casi). Per le rimanenti 990 donne che non hanno il cancro al seno, il test darà un risultato positivo in 99 casi (se la probabilità di un vero positivo è del 90%, la probabilità di un falso positivo è del 10%). Questa situazione è rappresentata nella figura Figura 8.1.\nCombinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non ce l’hanno, per un totale di 108 risultati positivi. Dunque, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 11%. Ma delle 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno il cancro al seno. Dunque, la probabilità di essere una donna che ha veramente il cancro al seno, dato un risultato positivo al test (che ha le proprietà descritte sopra), è pari a \\(\\frac{9}{108}\\) = 8%.\n\n\n\n\nFigura 8.1: Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia in un campione di 1,000 donne.\n\n\n\n\n\nNell’esercizio precedente, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, mentre la probabilità dell’evento “avere il cancro al seno, dato che il test ha prodotto un risultato positivo” è una probabilità condizionata.\nIn termini generali, la probabilità condizionata \\(P(A \\mid B)\\) rappresenta la probabilità che si verifichi l’evento \\(A\\) sapendo che si è verificato l’evento \\(B\\). Arriviamo dunque alla seguente definizione.\n\nDefinizione 8.1 Dato un qualsiasi evento \\(A\\), si chiama probabilità condizionata di \\(A\\) dato \\(B\\) il numero\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{con}\\, P(B) > 0,\n\\tag{8.1}\\]\ndove \\(P(A\\cap B)\\) è la probabilità congiunta dei due eventi, ovvero la probabilità che si verifichino entrambi.\n\nConcludiamo con un problema molto semplice per consolidare la nostra comprensione del concetto di probabilità condizionata.\n\nEsempio 8.2 Da un mazzo di 52 carte (13 carte per ciascuno dei 4 semi) ne viene estratta una in modo casuale. Qual è la probabilità che esca una figura di cuori? Sapendo che la carta estratta ha il seme di cuori, qual è la probabilità che il valore numerico della carta sia 7, 8 o 9?\n\n\nSoluzione. Ci sono 13 carte di cuori, dunque la risposta alla prima domanda è 1/4. Questa è una probabilità non condizionata, dunque il suo calcolo non presenta alcuna difficoltà. La seconda probabilità cercata è una probabilità condizionata. Anche in questo secondo caso dobbiamo solo contare, ma, in questo caso, considerando solo un sottoinsieme di carte, ovvero le 13 carte di cuori. In questo modo è facile arrivare al risultato cercato, ovvero 3/13. Applicando la formula Equazione 8.1, con \\(A\\) = 7, 8, o 9 e \\(B\\) = cuori, arriviamo allo stesso risulato:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{3/52}{13/52} = \\frac{3}{13}.\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#la-regola-moltiplicativa",
    "href": "016_conditional_prob.html#la-regola-moltiplicativa",
    "title": "8  Probabilità condizionata: significato, teoremi, eventi indipendenti",
    "section": "\n8.2 La regola moltiplicativa",
    "text": "8.2 La regola moltiplicativa\nDalla definizione di probabilità condizionata (Equazione 8.1) è possibile esprimere la probabilità congiunta tramite le condizionate. La regola moltiplicativa (o legge delle probabilità composte, o regola della catena) afferma che la probabilità che si verifichino due eventi \\(A\\) e \\(B\\) è pari alla probabilità di uno dei due eventi moltiplicato con la probabilità dell’altro evento condizionato al verificarsi del primo:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{8.2}\\]\nLa Equazione 8.2 si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right)\n\\tag{8.3}\\]\nPer esempio, nel caso di quattro eventi abbiamo\n\\[\n\\begin{split}\nP(A_1 \\cap A_2 \\cap A_3 \\cap A_4) = {}& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot \\\\\n& P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\]\n\nEsempio 8.3 Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l’Equazione 8.2, la sua probabilità vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per la Equazione 8.3, vale\n\\[\nP(B_1 \\cap B_2 \\cap B_3)=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2),\n\\]\ndove la probabilità \\(P(B_3 \\mid B_1 \\cap B_2)\\) si calcola supponendo che si sia verificato l’evento condizionante \\(\\{B_1 \\cap B_2\\}\\). Lo spazio campionario per questa probabilità condizionata è costituito da 4 palline bianche e 4 nere, per cui \\(P(B_3 \\mid B_1 \\cap B_2) = 1/2\\) e quindi:\n\\[\nP (B_1 \\cap B_2 \\cap B_3) = \\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8}  = \\frac{1}{6}.\n\\]\nLa probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} = \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#lindipendendenza-stocastica",
    "href": "016_conditional_prob.html#lindipendendenza-stocastica",
    "title": "8  Probabilità condizionata: significato, teoremi, eventi indipendenti",
    "section": "\n8.3 L’indipendendenza stocastica",
    "text": "8.3 L’indipendendenza stocastica\nUn concetto molto importante per le applicazioni statistiche della probabilità è quello dell’indipendenza stocastica. L’Equazione 8.1 consente di esprimere il concetto di indipendenza di un evento da un altro in forma intuitiva: se \\(A\\) e \\(B\\) sono eventi indipendenti, allora il verificarsi di \\(A\\) non influisce sulla probabilità del verificarsi di \\(B\\), ovvero non la condiziona, e il verificarsi di \\(B\\) non influisce sulla probabilità del verificarsi di \\(A\\). Infatti, per l’Equazione 8.1, si ha che, se \\(A\\) e \\(B\\) sono due eventi indipendenti, risulta:\n\\[\nP(A \\mid B) = \\frac{P(A)P(B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A)P(B)}{P(A)} = P(B).\n\\]\nPossiamo dunque dire che due eventi \\(A\\) e \\(B\\) sono indipendenti se\n\\[\n\\begin{split}\nP(A \\mid B) &= P(A), \\\\\nP(B \\mid A) &= P(B).\n\\end{split}\n\\]\n\nEsempio 8.4 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = {esce un 1 o un 2 nel primo lancio} e \\(B\\) = {il punteggio totale è 8}. Gli eventi \\(A\\) e \\(B\\) sono indipendenti?\nRappresentiamo qui sotto lo spazio campione dell’esperimento casuale.\n\n\n\n\nRappresentazione dello spazio campionario dei risultati dell’esperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l’evento \\(B\\): ‘il punteggio totale è 8’.\n\n\n\n\nGli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti. Infatti, le loro probabilità valgono \\(P(A) = 12/36\\) e \\(P(B) = 5/36\\) e la probabilità della loro intersezione è\n\\[\nP(A \\cap B) = 1/36 = 3/108 \\neq P(A)P(B) = 5/108.\n\\]\n\n\nNota. Il concetto di indipendenza è del tutto differente da quello di incompatibilità. Si noti infatti che due eventi A e B incompatibili (per i quali si ha \\(A \\cap B = \\emptyset\\)) sono statisticamente dipendenti, poiché il verificarsi dell’uno esclude il verificarsi dell’altro: \\(P(A \\cap B)=0 \\neq P(A)P(B)\\)."
  },
  {
    "objectID": "016_conditional_prob.html#il-teorema-della-probabilità-totale",
    "href": "016_conditional_prob.html#il-teorema-della-probabilità-totale",
    "title": "8  Probabilità condizionata: significato, teoremi, eventi indipendenti",
    "section": "\n8.4 Il teorema della probabilità totale",
    "text": "8.4 Il teorema della probabilità totale\nDato un insieme finito \\(A_i\\) di eventi, nel calcolo della probabilità dell’unione di tutti gli eventi, se gli eventi considerati non sono a due a due incompatibili, si deve tenere conto delle loro intersezioni. In particolare, la probabilità dell’unione di due eventi \\(A\\) e \\(B\\) è pari alla somma delle singole probabilità \\(P(A)\\) e \\(P(B)\\) diminuita della probabilità della loro intersezione:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\tag{8.4}\\]\nNel caso di tre eventi, si ha\n\\[\n\\begin{split}\nP(A \\cup B \\cup C) &= P(A)+P(B)+P(C)-P(A\\cap B)-P(A\\cap C) - \\\\\n& \\qquad P(B\\cap C) + P(A\\cap B\\cap C).\n\\end{split}\n\\]\nLa formula per il caso di \\(n\\) eventi si ricava per induzione.\nPer il caso di due soli eventi, se \\(A\\) e \\(B\\) sono indipendenti, l’Equazione 8.4 si modifica nella relazione seguente:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A)P(B).\n\\]\nNel caso di due eventi \\(A\\) e \\(B\\) incompatibili, se cioè \\(P(A \\cap B) = \\varnothing\\), si ha che\n\\[\nA\\cap B=\\varnothing \\Rightarrow P(A\\cup B)=P(A)+P(B).\n\\]\nSi può dimostrare per induzione che ciò vale anche per un insieme finito di eventi \\(A_{n}\\) a due a due incompatibili, ovvero che:\n\\[\nA_i\\cap A_j=\\varnothing, i\\neq j \\Rightarrow P\\left(\\bigcup_{i=1}^n A_i\\right)=\\sum_{i=1}^nP(A_i).\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#il-teorema-della-probabilità-assoluta",
    "href": "016_conditional_prob.html#il-teorema-della-probabilità-assoluta",
    "title": "8  Probabilità condizionata: significato, teoremi, eventi indipendenti",
    "section": "\n8.5 Il teorema della probabilità assoluta",
    "text": "8.5 Il teorema della probabilità assoluta\nIl teorema della probabilità assoluta (detto anche teorema delle partizioni) consente di calcolare la probabilità di un evento \\(E\\) di cui sono note le probabilità condizionate rispetto ad altri eventi \\((H_i)_{i\\geq 1}\\), a condizione che essi costituiscano una partizione dell’evento certo \\(\\Omega\\), ovvero\n\n\n\\(\\bigcup_{i=1}^\\infty H_i = \\Omega\\);\n\n\\(H_j \\cap H_j = \\emptyset, i\\neq j\\);\n\n\\(P(H_i) > 0, i = 1, \\dots, \\infty\\).\n\nNel caso di una partizione dello spazio campione in \\(n\\) sottoinsiemi abbiamo\n\\[\nP(E) = \\sum_{i=1}^n P(H_i\\cap E) = \\sum_{i=1}^n P(E \\mid H_i) P(H_i).\n\\]\nConsideriamo, ad esempio, una partizione dell’evento certo in tre sottoinsiemi.\n\n\n\n\nPartizione dell’evento certo \\(\\Omega\\) in tre sottoinsiemi sui quali viene definito l’evento \\(E\\).\n\n\n\n\nIn tali circostanze si ha che\n\\[\nP(E) = P(E \\cap H_1) + P(E \\cap H_2) + P(E \\cap H_3),\n\\tag{8.5}\\]\novvero\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2) + P(E \\mid H_3) P(H_3).\n\\tag{8.6}\\]\nIn base al teorema della probabilità assoluta, dunque, se l’evento \\(E\\) è costituito da tutti gli eventi elementari in \\(E \\cap H_1\\), \\(E \\cap H_2\\) e \\(E \\cap H_3\\), allora la sua probabilità è data dalla somma delle probabilità condizionate \\(P(E \\mid H_i)\\), ciascuna delle quali pesata per la probabilità dell’evento condizionante \\(H_i\\).\n\nEsempio 8.5 Si considerino tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?\n\n\nSoluzione. Sia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che corrisponde alla scelta dell’\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilità assoluta, la probabilità di estrarre una pallina rossa è dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#indipendenza-condizionale",
    "href": "016_conditional_prob.html#indipendenza-condizionale",
    "title": "8  Probabilità condizionata: significato, teoremi, eventi indipendenti",
    "section": "\n8.6 Indipendenza condizionale",
    "text": "8.6 Indipendenza condizionale\nAggiungo qui delle considerazioni sul concetto di indipendenza condizionale a cui si farà riferimento nell’ultima parte della dispensa. L’indipendenza condizionale descrive situazioni in cui un’osservazione è irrilevante o ridondante quando si valuta la certezza di un’ipotesi. L’indipendenza condizionale è solitamente formulata nei termini della probabilità condizionata, come un caso speciale in cui la probabilità dell’ipotesi data un’osservazione non informativa è uguale alla probabilità senza tale osservazione non informativa.\nSe \\(A\\) è l’ipotesi e \\(B\\) e \\(C\\) sono osservazioni, l’indipendenza condizionale può essere espressa come l’uguaglianza:\n\\[\nP(A \\mid B,C)=P(A \\mid C).\n\\]\nDato che \\(P(A \\mid B,C)\\) è uguale a \\(P(A \\mid C)\\), questa uguaglianza corrisponde all’affermazione che \\(B\\) non fornisce alcun contributo alla certezza di \\(A\\). In questo caso si dice che \\(A\\) e \\(B\\) condizionalmente indipendenti dato \\(C\\), scritto simbolicamente come: \\((A \\perp\\!\\!\\!\\!\\perp B \\mid C)\\).\nIn maniera equivalente, l’indipendenza condizionale \\((A \\perp\\!\\!\\!\\!\\perp B \\mid C)\\) si verifica se:\n\\[\nP(A, B \\mid C) = P(A \\mid C) P(B \\mid C).\n\\]\nUn esempio è il seguente (da Wikipedia). Siano due eventi le probabilità che le persone \\(A\\) e \\(B\\) tornino a casa in tempo per la cena, e il terzo evento è il fatto che una tempesta di neve ha colpito la città. Mentre sia \\(A\\) che \\(B\\) hanno una probabilità più piccola di tornare a casa in tempo per la cena di quando non c’è la neve, tali probabilità sono indipendenti l’una dall’altra. Cioè, sapere che \\(A\\) è in ritardo non ci dice nulla sul fatto che \\(B\\) sia in ritardo o meno – \\(A\\) e \\(B\\) potrebbero vivere in quartieri diversi, percorrere distanze diverse e utilizzare mezzi di trasporto diversi. Tuttavia, se sapessimo che \\(A\\) e \\(B\\) vivono nello stesso quartiere, usano lo stesso mezzo di trasporto e lavorano nello stesso luogo, allora i due eventi non sarebbero condizionatamente indipendenti."
  },
  {
    "objectID": "016_conditional_prob.html#commenti-e-considerazioni-finali",
    "href": "016_conditional_prob.html#commenti-e-considerazioni-finali",
    "title": "8  Probabilità condizionata: significato, teoremi, eventi indipendenti",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa probabilità condizionata è importante perché ci fornisce uno strumento per precisare il concetto di indipendenza statistica. Una delle domande più importanti delle analisi statistiche è infatti quella che si chiede se due variabili siano associate tra loro oppure no. In questo capitolo abbiamo discusso il concetto di indipendenza (come contrapposto al concetto di associazione); in seguito vedremo come sia possibile fare inferenza sull’associazione tra variabili.\n\n\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and bayesian modeling. Chapman; Hall/CRC."
  },
  {
    "objectID": "017_bayes_theorem.html#definizione",
    "href": "017_bayes_theorem.html#definizione",
    "title": "9  Il teorema di Bayes",
    "section": "\n9.1 Definizione",
    "text": "9.1 Definizione\n\nTeorema 9.1 Sia \\((H_i)_{i\\geq 1}\\) una partizione dell’evento certo \\(\\Omega\\) e sia \\(E \\subseteq \\Omega\\) un evento tale che \\(P(E) > 0\\), allora, per \\(i = 1, \\dots, \\infty\\):\n\\[\n{\\mbox{P}}(H_i \\mid E) = \\frac{{\\mbox{P}}(E \\mid H_i){\\mbox{P}}(H_i)}{\\sum_{j=1}^{\\infty}{\\mbox{P}}(H_j)P(E \\mid H_j)}.\n\\tag{9.1}\\]\n\nL’Equazione 9.1 contiene tre concetti fondamentali. I primi due distinguono il grado di fiducia precedente al verificarsi dell’evidenza \\(E\\) da quello successivo al verificarsi dell’evidenza \\(E\\). Pertanto, dati gli eventi \\(H, E \\subseteq \\Omega,\\) si definisce\n\n\nprobabilità a priori, \\(P(H)\\), la probabilità attribuita al verificarsi dell’ipotesi \\(H\\) prima di sapere che si è verificato l’evento \\(E\\);\n\nprobabilità a posteriori, \\(P(H \\mid E)\\), la probabilità assegnata ad \\(H\\) una volta che sia noto \\(E\\), ovvero l’aggiornamento della probabilità a priori alla luce della nuova evidenza \\(E\\).\n\nIl terzo concetto definisce la probabilità che ha l’evento \\(E\\) di verificarsi quando è vera l’ipotesi \\(H\\), ovvero la probabilità dell’evidenza in base all’ipotesi. Pertanto, dati gli eventi \\(H, E \\subseteq \\Omega\\) si definisce\n\n\nverosimiglianza di \\(H\\) dato \\(E\\), \\(P(E \\mid H)\\), la probabilità condizionata che si verifichi \\(E\\), se è vera \\(H\\).\n\nSi noti che, per il calcolo della quantità a denominatore della Equazione 9.1, si ricorre al teorema della probabilità assoluta.\n\nEsercizio 9.1 Considerando una partizione dell’evento certo \\(\\Omega\\) in due soli eventi che chiamiamo ipotesi \\(H_1\\) e \\(H_2\\). Supponiamo conosciute le probabilità a priori \\(P(H_1)\\) e \\(P(H_2)\\). Consideriamo un terzo evento \\(E \\subseteq \\Omega\\) con probabilità non nulla di cui si conosce la verosimiglianza, ovvero si conoscono le probabilità condizionate \\({\\mbox{P}}(E \\mid H_1)\\) e \\(P(E \\mid H_2)\\). Supponendo che si sia verificato l’evento \\(E\\), vogliamo conoscere le probabilità a posteriori delle ipotesi, ovvero \\(P(H_1 \\mid E)\\) e \\(P(H_2 \\mid E)\\).\n\n\n\n\n\nFigura 9.1: Partizione dell’evento certo in due eventi chiamati ‘ipotesi’. L’evidenza \\(E\\) è un sottoinsieme dello spazio campione.\n\n\n\n\n\nSoluzione. Per trovare le probabilità cercate scriviamo:\n\\[\n\\begin{split}\nP(H_1 \\mid E) &= \\frac{P(E \\cap H_1)}{P(E)}\\notag\\\\\n              &= \\frac{P(E \\mid H_1) P(H_1)}{P(E)}.\n\\end{split}\n\\]\nSapendo che \\(E = (E \\cap H_1) \\cup (E \\cap H_2)\\) e che \\(H_1\\) e \\(H_2\\) sono eventi disgiunti, ovvero \\(H_1 \\cap H_2 = \\emptyset\\), ne segue che possiamo calcolare \\({\\mbox{P}}(E)\\) utilizzando il teorema della probabilità assoluta:\n\\[\n\\begin{split}\nP(E) &= P(E \\cap H_1) + P(E \\cap H_2)\\notag\\\\\n     &= P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2).\n\\end{split}\n\\]\nSostituendo tale risultato nella formula precedente otteniamo:\n\\[\nP(H_1 \\mid E) = \\frac{P(E \\mid H_1)P(H_1)}{P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2)}.\n\\tag{9.2}\\]\n\n\n\n\n\n\n\nUn lettore attento si sarà reso conto che, in precedenza, abbiamo già applicato il teorema di Bayes quando abbiamo risolto l’Esempio 8.1. In quel caso, le due ipotesi erano “malattia presente”, che possiamo denotare con \\(M\\), e “malattia assente”, \\(M^\\complement\\). L’evidenza \\(E\\) era costituita dal risultato positivo al test, ovvero \\(+\\). Con questa notazione l’Equazione 9.2 diventa:\n\\[\nP(M \\mid +) = \\frac{P(+ \\mid M) P(M)}{P(+ \\mid M) P(M) + P(+ \\mid M^\\complement) P(M^\\complement)}\n\\]\nInserendo i dati dell’Esempio 8.1 nella formula precedente, otteniamo\n\\[\n\\begin{align}\nP(M \\mid +) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "017_bayes_theorem.html#aggiornamento-bayesiano",
    "href": "017_bayes_theorem.html#aggiornamento-bayesiano",
    "title": "9  Il teorema di Bayes",
    "section": "\n9.2 Aggiornamento bayesiano",
    "text": "9.2 Aggiornamento bayesiano\nIl teorema di Bayes rende esplicito il motivo per cui la probabilità non possa essere pensata come uno stato oggettivo, quanto piuttosto come un’inferenza soggettiva e condizionata. Il denominatore del membro di destra della Equazione 9.1 è un semplice fattore di normalizzazione. Nel numeratore compaiono invece due quantità: \\({\\mbox{P}}(H_i\\)) e \\({\\mbox{P}}(E \\mid H_i)\\). La probabilità \\({\\mbox{P}}(H_i\\)) è la probabilità probabilità a priori (prior) dell’ipotesi \\(H_i\\) e rappresenta l’informazione che l’agente bayesiano possiede a proposito dell’ipotesi \\(H_i\\). Diremo che \\({\\mbox{P}}(H_i)\\) codifica il grado di fiducia che l’agente ripone in \\(H_i\\) precedentemente al verificarsi dell’evidenza \\(E\\). Nell’interpretazione bayesiana, \\({\\mbox{P}}(H_i)\\) rappresenta un giudizio personale dell’agente e non esistono criteri esterni che possano determinare se tale giudizio sia coretto o meno. La probabilità condizionata \\({\\mbox{P}}(E \\mid H_i)\\) rappresenta invece la verosimiglianza di \\(H_i\\) dato \\(E\\) e descrive la plausibilità che si verifichi l’evento \\(E\\) se è vera l’ipotesi \\(H_i\\). Il teorema di Bayes descrive la regola che l’agente deve seguire per aggiornare il suo grado di fiducia nell’ipotesi \\(H_i\\) alla luce del verificarsi dell’evento \\(E\\). La \\({\\mbox{P}}(H_i \\mid E)\\) è chiamata probabilità a posteriori dato che rappresenta la nuova probabilità che l’agente assegna all’ipotesi \\(H_i\\) affinché rimanga consistente con le nuove informazioni fornitegli da \\(E\\).\nLa probabilità a posteriori dipende sia dall’evidenza \\(E\\), sia dalla conoscenza a priori dell’agente \\({\\mbox{P}}(H_i)\\). È dunque chiaro come non abbia senso parlare di una probabilità oggettiva: per il teorema di Bayes la probabilità è definita condizionatamente alla probabilità a priori, la quale a sua volta, per definizione, è un’assegnazione soggettiva. Ne segue pertanto che ogni probabilità deve essere considerata come una rappresentazione del grado di fiducia soggettiva dell’agente.\nDato che ogni assegnazione probabilistica rappresenta uno stato di conoscenza e che ciascun particolare stato di conoscenza è arbitrario, un accordo tra agenti diversi non è richiesto. Ciò nonostante, la teoria delle probabilità ci fornisce uno strumento che, alla luce di nuove evidenze, consente di aggiornare in un modo razionale il grado di fiducia che attribuiamo ad un’ipotesi, via via che nuove evidenze vengono raccolte, in modo tale da formulare un’ipotesi a posteriori la quale non è mai definitiva, ma può sempre essere aggiornata in base alle nuove evidenze disponibili. Questo processo si chiama aggiornamento bayesiano."
  },
  {
    "objectID": "017_bayes_theorem.html#commenti-e-considerazioni-finali",
    "href": "017_bayes_theorem.html#commenti-e-considerazioni-finali",
    "title": "9  Il teorema di Bayes",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa riflessione epistemologica contemporanea ha ampiamente messo in luce come la conoscenza non possa essere identificata con la certezza, ovvero con la garanzia razionale della verità. Da ciò deriva che qualunque giudizio deve necessariamente essere inteso come una decisione presa in condizioni d’incertezza. Stando così le cose, non si può più considerare la logica deduttiva, modellata sulle forme della dimostrazione matematica, come quella più adeguata al ragionamento scientifico. La ricerca scientifica ha invece bisogno di una logica dell’incertezza e questa viene fornita dalla teoria delle probabilità e, specialmente, da quello schema di inferenza noto come teorema di Bayes. È proprio in questi termini che può essere compresa quella rivoluzione metodologica contemporanea che, tra le altre cose, si è posta il problema di porre rimedio alla crisi della replicabilità dei risultati della ricerca (Ioannidis, 2005) che sta affligendo molti ambiti della ricerca scientifica, inclusa la psicologia. Per un approfondimento a questo tema rimando, nuovamente, al testo Bernoulli’s fallacy (Clayton, 2021).\nIn questo capitolo abbiamo descritto il teorema di Bayes facendo riferimento alle variabili casuali discrete. Il caso discreto, tuttavia, nonostante la sua apparente semplicità matematica, è il più contro-intuitivo. È molto più “naturale”, in termini psicologici, pensare al teorema di Bayes facendo riferimento alle variabili casuali continue. Questo sarà l’oggetto del Capitolo 16.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClayton, A. (2021). Bernoulli’s fallacy: Statistical illogic and the crisis of modern science. Columbia University Press.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS Medicine, 2(8), e124."
  },
  {
    "objectID": "018_expval_var.html#valore-atteso",
    "href": "018_expval_var.html#valore-atteso",
    "title": "10  Indici di posizione, di varianza e di associazione di variabili casuali",
    "section": "\n10.1 Valore atteso",
    "text": "10.1 Valore atteso\nQuando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual è il suo “valore tipico”. La nozione di “valore tipico”, tuttavia, è ambigua. Infatti, essa può essere definita in almeno tre modi diversi:\n\nla media (somma dei valori divisa per il numero dei valori),\nla mediana (il valore centrale della distribuzione, quando la variabile è ordinata in senso crescente o decrescente),\nla moda (il valore che ricorre più spesso).\n\nPer esempio, la media di \\(\\{3, 1, 4, 1, 5\\}\\) è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è \\(3\\) e la moda è \\(1\\). Tuttavia, la teoria delle probabilità si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per “valore tipico” quando facciamo riferimento alle variabili casuali. Giungiamo così alla seguente definizione. \n\nDefinizione 10.1 Sia \\(Y\\) è una variabile casuale discreta che assume i valori \\(y_1, \\dots, y_n\\) con distribuzione \\(P(Y = y_i) = p(y_i)\\). Per definizione il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), è\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^n y_i \\cdot p(y_i).\n\\tag{10.1}\\]\n\nA parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale è definito come la somma di tutti i valori che la variabile casuale può prendere, ciascuno pesato dalla probabilità con cui il valore è preso.\n\nEsercizio 10.1 Si calcoli il valore atteso della variabile casuale \\(Y\\) corrispondente al lancio di una moneta equilibrata (testa: Y = 1; croce: Y = 0).\n\n\nSoluzione. \\[\n\\mathbb{E}(Y) = \\sum_{i=1}^{2} y_i \\cdot P(y_i) = 0 \\cdot \\frac{1}{5} + 1 \\cdot \\frac{1}{5} = 0.5.\n\\]\n\n\nEsercizio 10.2 Si calcoli il valore atteso della variabile casuale \\(Y\\) corrispondente ai punti ottenuti dal lancio di un dado equilibrato.\n\n\nSoluzione. \\[\n\\mathbb{E}(Y) = \\sum_{i=1}^{6} y_i \\cdot P(y_i) = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + \\dots + 6 \\cdot \\frac{1}{6} = \\frac{21}{6} = 3.5.\n\\]\n\n\n10.1.1 Interpretazione\nChe interpretazione può essere assegnata alla nozione di valore atteso? Bruno de Finetti adottò lo stesso termine di previsione (e lo stesso simbolo) tanto per la probabilità che per il valore atteso. Si può pertanto dire che, dal punto di vista bayesiano, il valore atteso è l’estensione naturale della nozione di probabilità soggettiva.\n\n10.1.2 Proprietà del valore atteso\nLa proprietà più importante del valore atteso è la linearità: il valore atteso di una somma di variabili casuali è uguale alla somma dei lori rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{10.2}\\]\nL’Equazione 10.2 sembra ragionevole quando \\(X\\) e \\(Y\\) sono indipendenti, ma è anche vera quando \\(X\\) e \\(Y\\) sono associati. Abbiamo anche che\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{10.3}\\]\nL’Equazione 10.3 ci dice che possiamo estrarre una costante dall’operatore di valore atteso. Tale proprietà si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali \\(X\\) e \\(Y\\) sono indipendenti, abbiamo che\n\\[\n\\mathbb{E}(X Y) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{10.4}\\]\n\nEsercizio 10.3 Si considerino le seguenti variabili casuali: \\(Y\\), ovvero il numero che si ottiene dal lancio di un dado equilibrato, e \\(Y\\), il numero di teste prodotto dal lancio di una moneta equilibrata. Si trovi il valore atteso di \\(X+Y\\).\n\n\nSoluzione. Per risolvere il problema iniziamo a costruire lo spazio campionario dell’esperimento casuale consistente nel lancio di un dado e di una moneta.\n\n\n\n\n\n\n\n\n\n\n\n\\(x \\textbackslash y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\\(x \\textbackslash y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campionario avrà la stessa probabilità di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nPossiamo ottenere lo stesso risultato usanlo l’Equazione 10.2:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsercizio 10.4 Si considerino le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso del prodotto delle variabili casuali \\(X\\) e \\(Y\\).\n\n\nSoluzione. La distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\n\n\n\\(x \\textbackslash y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(XY) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l’Equazione 10.4. Infatti, il valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerciò\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\nIn altri termini, se \\(\\mathbb{E}(X Y) \\neq \\mathbb{E}(X) \\mathbb{E}(Y)\\), allora le variabili causuali \\(X\\) e \\(Y\\) non sono indipendenti (cioè sono associate).\n\n\n10.1.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\) il valore atteso diventa:\n\\[\n\\mathbb{E}(Y) = \\int_{-\\infty}^{+\\infty} y p(y) \\,\\operatorname{d}\\!y.\n\\tag{10.5}\\]\nAnche in questo caso il valore atteso è una media ponderata della \\(y\\), nella quale ciascun possibile valore \\(y\\) è ponderato per il corrispondente valore della densità \\(p(y)\\). Possiamo leggere l’integrale pensando che \\(y\\) rappresenti l’ampiezza delle barre infinitamente strette di un istogramma, con la densità \\(p(y)\\) che corrisponde all’altezza di tali barre e la notazione \\(\\int_{-\\infty}^{+\\infty}\\) che corrisponde ad una somma.1\n\n10.1.3.1 Moda\nUn’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\n\\[\n\\mbox{Mo}(Y) = \\mbox{argmax}_y p(y).\n\\tag{10.6}\\]\n\n\n\n\n\n\nLa notazione \\(\\mbox{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo."
  },
  {
    "objectID": "018_expval_var.html#varianza",
    "href": "018_expval_var.html#varianza",
    "title": "10  Indici di posizione, di varianza e di associazione di variabili casuali",
    "section": "\n10.2 Varianza",
    "text": "10.2 Varianza\nLa seconda più importante proprietà di una variabile casuale, dopo che conosciamo il suo valore atteso, è la varianza.\n\nDefinizione 10.2 Se \\(Y\\) è una variabile casuale discreta con distribuzione \\(p(y)\\), per definizione la varianza di \\(Y\\), \\(\\mathbb{V}(Y)\\), è\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big].\n\\tag{10.7}\\]\n\nA parole: la varianza è la deviazione media quadratica della variabile dalla sua media.2 Se denotiamo \\(\\mathbb{E}(Y) = \\mu\\), la varianza \\(\\mathbb{V}(Y)\\) diventa il valore atteso di \\((Y - \\mu)^2\\).\n\nEsercizio 10.5 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\n\n\nSoluzione. La variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot 0.0278 + (3-7)^2 \\cdot 0.0556 + \\dots + (12 - 7)^2 \\cdot 0.0278 \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\n10.2.1 Formula alternativa per la varianza\nC’è un modo più semplice per calcolare la varianza:\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big] &= \\mathbb{E}\\big(Y^2 - 2Y\\mathbb{E}(Y) + \\mathbb{E}(Y)^2\\big)\\notag\\\\\n&= \\mathbb{E}(Y^2) - 2\\mathbb{E}(Y)\\mathbb{E}(Y) + \\mathbb{E}(Y)^2,\n\\end{align}\n\\]\ndato che \\(\\mathbb{E}(Y)\\) è una costante. Pertanto\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2.\n\\tag{10.8}\\]\nA parole: la varianza è la media dei quadrati meno il quadrato della media della variabile.\n\nEsercizio 10.6 Consideriamo la variabile casuale \\(Y\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\n\n\nSoluzione. Il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(Y) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(Y^2\\) è\n\\[\n\\mathbb{E}(Y^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\n10.2.2 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\), la varianza diventa:\n\\[\n\\mathbb{V}(Y) = \\int_{-\\infty}^{+\\infty} \\large[y - \\mathbb{E}(Y)\\large]^2 p(y) \\,\\operatorname {d}\\!y.\n\\tag{10.9}\\]\nCome nel caso discreto, la varianza di una v.c. continua \\(Y\\) misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori \\(y\\) dalla loro media."
  },
  {
    "objectID": "018_expval_var.html#deviazione-standard",
    "href": "018_expval_var.html#deviazione-standard",
    "title": "10  Indici di posizione, di varianza e di associazione di variabili casuali",
    "section": "\n10.3 Deviazione standard",
    "text": "10.3 Deviazione standard\nQuando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell’unità di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato deviazione standard e solitamente è denotato dalla lettera greca \\(\\sigma\\).\n\nDefinizione 10.3 Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:\n\\[\n\\sigma_Y = \\sqrt{\\mathbb{V}(Y)}.\n\\tag{10.10}\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale misura approssimativamente la distanza tipica o prevista dei possibili valori \\(y\\) dalla loro media.\n\nEsercizio 10.7 Per i dadi equilibrati dell’Esercizio 10.5, la deviazione standard della variabile casuale \\(S\\) è uguale a \\(\\sqrt{5.833} = 2.415\\)."
  },
  {
    "objectID": "018_expval_var.html#standardizzazione",
    "href": "018_expval_var.html#standardizzazione",
    "title": "10  Indici di posizione, di varianza e di associazione di variabili casuali",
    "section": "\n10.4 Standardizzazione",
    "text": "10.4 Standardizzazione\n\nDefinizione 10.4 Data una variabile casuale \\(Y\\), si dice variabile standardizzata di \\(Y\\) l’espressione\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}.\n\\tag{10.11}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\)."
  },
  {
    "objectID": "018_expval_var.html#momenti-di-variabili-casuali",
    "href": "018_expval_var.html#momenti-di-variabili-casuali",
    "title": "10  Indici di posizione, di varianza e di associazione di variabili casuali",
    "section": "\n10.5 Momenti di variabili casuali",
    "text": "10.5 Momenti di variabili casuali\n\nSi chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{10.12}\\]\nSe \\(X\\) è una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i).\n\\tag{10.13}\\]\n\nI momenti sono importanti parametri indicatori di certe proprietà di \\(X\\). I più noti sono senza dubbio quelli per \\(q = 1\\) e \\(q = 2\\). Il momento del primo ordine corrisponde al valore atteso di \\(X\\). Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di \\(X\\), operando una traslazione \\(x_0 = x − \\mathbb{E}(X)\\) che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza."
  },
  {
    "objectID": "018_expval_var.html#covarianza",
    "href": "018_expval_var.html#covarianza",
    "title": "10  Indici di posizione, di varianza e di associazione di variabili casuali",
    "section": "\n10.6 Covarianza",
    "text": "10.6 Covarianza\nLa covarianza quantifica la tendenza delle variabili casuali \\(X\\) e \\(Y\\) a “variare assieme”. Per esempio, l’altezza e il peso delle giraffe producono una covarianza positiva perché all’aumentare di una di queste due quantità tende ad aumentare anche l’altra. La covarianza misura la forza e la direzione del legame lineare tra due variabili casuali \\(X\\) ed \\(Y\\). Si utilizza la notazione \\(\\mbox{Cov}(X,Y)=\\sigma_{xy}\\).\n\nDefinizione 10.5 Date due variabili casuali \\(X\\), \\(Y\\), chiamiamo covarianza tra \\(X\\) ed \\(Y\\) il numero\n\\[\n\\mbox{Cov}(X,Y) = \\mathbb{E}\\Bigl(\\bigl(X - \\mathbb{E}(X)\\bigr) \\bigl(Y - \\mathbb{E}(Y)\\bigr)\\Bigr),\n\\tag{10.14}\\]\ndove \\(\\mathbb{E}(X)\\) e \\(\\mathbb{E}(Y)\\) sono i valori attesi di \\(X\\) ed \\(Y\\).\n\nIn maniera esplicita,\n\\[\n\\mbox{Cov}(X,Y) = \\sum_{(x,y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y).\n\\tag{10.15}\\]\nLa definizione è analoga, algebricamente, a quella di varianza e risulta infatti\n\\[\n\\mathbb{V}(x) = \\mbox{Cov}(X, X)\n\\]\ne\n\\[\n\\mbox{Cov}(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X).\n\\tag{10.16}\\]\n\nDimostrazione. L’Equazione 10.16 si ricava nel modo seguente:\n\\[\n\\begin{align}\n\\mbox{Cov}(X,Y) &= \\mathbb{E}\\Bigl(\\bigl(X-\\mathbb{E}(X)\\bigr) \\bigl(Y-\\mathbb{E}(Y)\\bigr)\\Bigr)\\notag\\\\\n          %&= \\mathbb{E}(XY) - \\mathbb{E}(Y)X -\\mathbb{E}(X)Y + \\mathbb{E}(X)\\mathbb{E}(Y) )\\notag\\\\\n          &= \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X) - \\mathbb{E}(X)\\mathbb{E}(Y) + \\mathbb{E}(X)\\mathbb{E}(Y)\\notag\\\\\n          &= \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X)\\notag.\n\\end{align}\n\\]\n\n\nEsercizio 10.8 Consideriamo le variabili casuali definite nell’Esercizio 10.4. Si calcoli la covarianza di \\(X\\) e \\(Y\\).\n\n\nSoluzione. Abbiamo che \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). Ne segue che la covarianza di \\(X\\) e \\(Y\\) è:\n\\[\n\\begin{align}\n\\mbox{Cov}(X,Y) &= \\sum_{(x,y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y)\\notag\\\\\n&= (0-1.5)(0-0.5)\\cdot \\frac{1}{8} + (0-1.5)(1-0.5) \\cdot 0 \\\\\n   &\\qquad + (1-1.5)(0-0.5)\\cdot \\frac{2}{8} + (1-1.5)(1-0.5) \\cdot \\frac{1}{8} \\notag\\\\\n    &\\qquad+ (2-1.5)(0-0.5) \\cdot \\frac{1}{8} + (2-1.5)(1-0.5) \\cdot \\frac{2}{8} \\\\\n   &\\qquad+ (3-1.5)(0-0.5) \\cdot 0 +  (3-1.5)(1-0.5)\\cdot\\frac{1}{8} \\notag\\\\\n   &= \\frac{1}{4}. \\notag\n\\end{align}\n\\]\nLo stesso risultato può essere trovato usando l’Equazione 10.16. Iniziamo a calcolare il valore atteso del prodotto \\(XY\\):\n\\[\n\\mathbb{E}(XY) = 0 \\cdot\\frac{4}{8} + 1 \\cdot\\frac{1}{8} + 2 \\cdot\\frac{2}{8} + 3 \\cdot\\frac{1}{8} = 1.0.\n\\]\nDunque, la covarianza tra \\(X\\) e \\(Y\\) diventa\n\\[\n\\begin{align}\n\\mbox{Cov}(X,Y) &= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\notag\\\\\n&= 1 -  1.5\\cdot 0.5 \\notag\\\\\n&= 0.25.\\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "018_expval_var.html#correlazione",
    "href": "018_expval_var.html#correlazione",
    "title": "10  Indici di posizione, di varianza e di associazione di variabili casuali",
    "section": "\n10.7 Correlazione",
    "text": "10.7 Correlazione\nLa covarianza dipende dall’unità di misura delle due variabili e quindi non consente di stabilire l’intensità della relazione. Una misura standardizzata della relazione che intercorre fra due variabili è invece rappresentata dalla correlazione. La correlazione si ottiene dividendo la covarianza per le deviazioni standard delle due variabili aleatorie.\n\nDefinizione 10.6 Il coefficiente di correlazione tra \\(X\\) ed \\(Y\\) è il numero definito da\n\\[\n\\rho(X,Y) =\\frac{\\mbox{Cov}(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}}.\n\\tag{10.17}\\]\n\nSi può anche scrivere \\(\\rho_{X,Y}\\) al posto di \\(\\rho(X,Y)\\).\nIl coefficiente di correlazione \\(\\rho_{xy}\\) è un numero puro, cioè non dipende dall’unità di misura delle variabili, e assume valori compresi tra -1 e +1."
  },
  {
    "objectID": "018_expval_var.html#proprietà",
    "href": "018_expval_var.html#proprietà",
    "title": "10  Indici di posizione, di varianza e di associazione di variabili casuali",
    "section": "\n10.8 Proprietà",
    "text": "10.8 Proprietà\n\nLa covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è nulla: \\(\\mbox{Cov}(c,X) = 0;\\)\n\nla covarianza è simmetrica: \\(\\mbox{Cov}(X,Y) = \\mbox{Cov}(Y,X);\\)\n\nvale \\(-1 \\leq \\rho(X,Y) \\leq 1;\\)\n\nla correlazione non dipende dall’unità di misura: \\(\\rho(aX, bY) = \\rho(X,Y), \\quad \\forall a, b > 0;\\)\n\nse \\(Y = a + bX\\) è una funzione lineare di \\(X\\) con costanti \\(a\\) e \\(b\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\);\nla covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, è uguale al prodotto delle costanti per la covarianza tra \\(X\\) e \\(Y\\): \\(\\mbox{Cov}(aX,bY) = ab \\;\\mbox{Cov}(X,Y)\\);\nvale \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2 \\cdot \\mbox{Cov}(X,Y)\\);\nvale \\(\\mbox{Cov}(X + Y, Z) = \\mbox{Cov}(X,Z) + \\mbox{Cov}(Y,Z);\\)\n\nper una sequenza di variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\[\\mathbb{V}\\left( \\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i,j: i<j}cov(X_i, X_j);\\]\n\nvale \\(\\mbox{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_jY_j\\right) = \\sum_{i=1}^n \\sum_{j=1}^m a_j b_j\\mbox{Cov}(X_j, Y_j);\\)\n\nse \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\[\\mbox{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_jX_j\\right) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i).\\]\n\n\n\n10.8.1 Incorrelazione\n\nDefinizione 10.7 Si dice che \\(X\\) ed \\(Y\\) sono incorrelate, o linermente indipendenti, se la loro covarianza è nulla,\n\\[\n\\sigma_{XY} = \\mathbb{E} \\big[(X - \\mu_X) (y-\\mu_u) \\big] = 0,\n\\tag{10.18}\\]\nche si può anche scrivere come\n\\[\n\\rho_{XY} = 0, \\quad \\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\]\n\nSi introduce così un secondo tipo di indipendenza, più debole, dopo quello di indipendenza stocastica. Viceversa, però, se \\(\\mbox{Cov}(X, Y) = 0\\), non è detto che \\(X\\) ed \\(Y\\) siano indipendenti.\n\nEsercizio 10.9 Siano \\(X\\) e \\(Y\\) due variabili aleatorie discrete avente una distribuzione di massa di probabilità congiunta pari a\n\\[\nf_{XY}(x,y) = \\frac{1}{4} \\quad (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}\n\\]\ne zero altrimenti. Le due variabili aleatorie \\(X\\) e \\(Y\\) sono mutuamente indipendenti?\n\n\nSoluzione. La distribuzione marginale della \\(X\\) è\n\\[\n\\begin{cases}\nX = 0, \\quad  P_X = 1/4, \\\\\nX = 1, \\quad P_X = 2/4, \\\\\nX = 2, \\quad P_X = 1/4.\n\\end{cases}\n\\]\n\\[\n\\mathbb{E}(X) = 0 \\frac{1}{4} + 1 \\frac{2}{4} + 2 \\frac{1}{4} = 1.\n\\]\n\\[\n\\mathbb{E}(X^2) = 0^2 \\frac{1}{4} + 1^2 \\frac{2}{4} + 2^2 \\frac{1}{4} = \\frac{3}{2}.\n\\]\n\\[\n\\mathbb{V}(X) = \\frac{3}{2} - 1^2 = \\frac{1}{2}.\n\\]\nLa distribuzione marginale della \\(Y\\) è\n\\[\n\\begin{cases}\nY = -1, \\quad  P_Y = 1/4, \\\\\nY = 0, \\quad P_Y = 2/4, \\\\\nY = 1, \\quad P_Y = 1/4.\n\\end{cases}\n\\]\n\\[\n\\mathbb{E}(Y) = 0 \\frac{2}{4} + 1 \\frac{1}{4} + (-1) \\frac{1}{4} = 0.\n\\]\n\\[\n\\mathbb{E}(Y^2) = 0^2 \\frac{2}{4} + 1^2 \\frac{1}{4} + (-1)^2 \\frac{1}{4} = \\frac{1}{2}.\n\\]\n\\[\n\\mathbb{V}(X) = \\frac{1}{2} - 0^2 = \\frac{1}{2}.\n\\]\nCalcoliamo ora la covarianza tra \\(X\\) e \\(Y\\):\n\\[\n\\mathbb{E}(XY) = \\sum_x\\sum_y xy f_{XY} (x,y) =\n(0\\cdot 0)\\frac{1}{4} +\n(1\\cdot 1)\\frac{1}{4} +\n(1\\cdot -1)\\frac{1}{4} +\n(2\\cdot 0)\\frac{1}{4} = 0.\n\\]\n\\[\n\\mbox{Cov}(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y) = 0 - 1\\cdot0 = 0.\n\\]\nQuindi le due variabili aleatorie hanno covarianza pari a zero. Tuttavia, esse non sono indipendenti, in quanto non è vero che\n\\[\nf_{XY} (x,y) = f_X(x) f_Y(y)\n\\]\nper tutti gli \\(x\\) e \\(y\\).\n\nIn conclusione, anche se la condizione di indipendenza implica una covarianza nulla, l’esempio precedente mostra come l’inverso non sia necessariamente vero: la covarianza può essere zero anche se due variabili casuali non sono indipendenti."
  },
  {
    "objectID": "018_expval_var.html#conclusioni",
    "href": "018_expval_var.html#conclusioni",
    "title": "10  Indici di posizione, di varianza e di associazione di variabili casuali",
    "section": "Conclusioni",
    "text": "Conclusioni\nLa densità di probabilità congiunta bivariata tiene simultaneamente conto del comportamento di due variabili casuali \\(X\\) e \\(Y\\) e di come esse si influenzano. Se \\(X\\) e \\(Y\\) sono legate linearmente, allora il coefficiente di correlazione\n\\[\\begin{equation}\n\\rho = \\frac{\\mbox{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\\notag\n\\end{equation}\\]\nfornisce l’indice maggiormente utilizzato per descrivere l’intensità e il segno dell’associazione lineare. Nel caso di un’associazione lineare perfetta, \\(Y = a + bX\\), avremo \\(\\rho = 1\\) con \\(b\\) positivo ed \\(\\rho = -1\\) con \\(b\\) negativo. Se il coefficiente di correlazione è pari a 0 le variabili si dicono incorrelate. Condizione sufficiente (ma non necessaria) affinché \\(\\rho = 0\\) è che le due variabili siano tra loro indipendenti."
  },
  {
    "objectID": "019_joint_prob.html#sec-fun-join-prob",
    "href": "019_joint_prob.html#sec-fun-join-prob",
    "title": "11  Probabilità congiunta",
    "section": "\n11.1 Funzione di probabilità congiunta",
    "text": "11.1 Funzione di probabilità congiunta\nDopo aver trattato della distribuzione di probabilità di una variabile casuale, la quale associa ad ogni evento elementare dello spazio campione uno ed un solo numero reale, è naturale estendere questo concetto al caso di due o più variabili casuali. Iniziamo a descrivere il caso discreto con un esempio. Consideriamo l’esperimento casuale corrispondente al lancio di tre monete equilibrate. Lo spazio campione è\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\}.\n\\]\nDato che i tre lanci sono tra loro indipendenti, non c’è ragione di aspettarsi che uno degli otto risultati possibili dell’esperimento sia più probabile degli altri, dunque possiamo associare a ciascuno degli otto eventi elementari dello spazio campione la stessa probabilità, ovvero 1/8.\nDefiniamo sullo spazio campione \\(\\Omega\\) le seguenti variabili casuali:\n\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) = “numero di realizzazioni con il risultato testa nei tre lanci”,\n\n\\(Y \\in \\{0, 1\\}\\) = “numero di realizzazioni con il risultato testa nel primo lancio”.\n\nIndicando con T = ‘testa’ e C = ‘croce’, si ottiene la situazione riportata nella Tabella 11.1.\n\n\nTabella 11.1: Spazio campione dell’esperimento consistente nel lancio di tre monete equilibrate su cui sono state definite le variabili aleatorie \\(X\\) = ‘numero di realizzazioni con il risultato testa nei tre lanci’ e \\(Y\\) = ‘numero di realizzazioni con il risultato testa nel primo lancio’.\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\n\nCi poniamo il problema di associare un valore di probabilità ad ogni coppia \\((x, y)\\) definita su \\(\\Omega\\). La coppia \\((X = 0, Y = 0)\\) si realizza in corrispondenza di un solo evento elementare, ovvero CCC; avrà dunque una probabilità pari a\n\\[\nP(X=0, Y=0) = P(CCC) = 1/8.\n\\]\nNel caso della coppia \\((X = 1, Y = 0)\\) ci sono due eventi elementari che danno luogo al risultato considerato, ovvero, CCT e CTC. La probabilità dell’evento composto \\(P(X=1, Y=0)\\) è dunque uguale alla somma delle probabilità dei due eventi elementari che lo costituiscono, cioé\n\\[\nP(X=1, Y=0) = P(\\mbox{CCT}) + P(\\mbox{CTC}) = 1/8 + 1/8 = 1/4.\n\\]\nDi seguito sono riportati i calcoli per tutte le possibili coppie \\(X, Y\\):\n\\[\n\\begin{align}\nP(X = 0, Y = 0) &= P(\\omega_8 = CCC) = 1/8; \\notag\\\\\nP(X = 1, Y = 0) &= P(\\omega_5 = CCT) + P(\\omega_6 = CTC) = 2/8; \\notag\\\\\nP(X = 1, Y = 1) &= P(\\omega_7 = TCC) = 1/8; \\notag\\\\\nP(X = 2, Y = 0) &= P(\\omega_4 = CTT) = 1/8; \\notag\\\\\nP(X = 2, Y = 1) &= P(\\omega_3 = TCT) + P(\\omega_2 = TTC) = 2/8; \\notag\\\\\nP(X = 3, Y = 1) &= P(\\omega_1 = TTT) = 1/8; \\notag\n\\end{align}\n\\]\nLe probabilità così trovate sono riportate nella Tabella 11.2 che descrive la distribuzione di probabilità congiunta delle variabili casuali \\(X\\) (“numero di realizzazioni con il risultato testa nei tre lanci”) e \\(Y\\) (“numero di realizzazioni con il risultato testa nel primo lancio”) per l’esperimento casuale che consiste nel lancio di tre monete equilibrate.\n\n\nTabella 11.2: Distribuzione di probabilità congiunta per i risultati dell’esperimento consistente nel lancio di tre monete equilibrate.\n\n\\(x \\textbackslash y\\)\n0\n1\n\n\n\n0\n1/8\n0\n\n\n1\n2/8\n1/8\n\n\n2\n1/8\n2/8\n\n\n3\n0\n1/8\n\n\n\n\nIn generale, possiamo dire che, dato uno spazio campione discreto \\(\\Omega\\), è possibile associare ad ogni evento elementare \\(\\omega_i\\) dello spazio campione una coppia di numeri reali \\((x, y)\\), essendo \\(x = X(\\omega)\\) e \\(y = Y(\\omega)\\), il che ci conduce alla seguente definizione.\n\nDefinizione 11.1 Siano \\(X\\) e \\(Y\\) due variabili casuali. La funzione che associa ad ogni coppia \\((x, y)\\) un valore di probabilità prende il nome di funzione di probabilità congiunta:\n\\[\nP(x, y) = P(X = x, Y = y).\n\\]\n\nIl termine “congiunta” deriva dal fatto che questa probabilità è legata al verificarsi di una coppia di valori, il primo associato alla variabile casuale \\(X\\) ed il secondo alla variabile casuale \\(Y\\). Nel caso di due sole variabili casuali si parla di distribuzione bivariata, mentre nel caso di più variabili casuali si parla di distribuzione multivariata.\n\n11.1.1 Proprietà\nUna distribuzione di massa di probabilità congiunta bivariata deve soddisfare due proprietà:\n\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\);\nla probabilità totale deve essere uguale a 1: \\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1.\\)\n\n\n11.1.2 Eventi\nSi noti che dalla probabilità congiunta possiamo calcolare la probabilità di qualsiasi evento definito in base alle variabili aleatorie \\(X\\) e \\(Y\\). Per capire come questo possa essere fatto, consideriamo nuovamente l’esperimento casuale discusso in precedenza.\n\nEsercizio 11.1 Per la distribuzione di massa di probabilità congiunta riportata nella tabella Tabella 11.2 si trovi la probabilità dell’evento \\(X+Y \\leq 1\\).\n\n\nSoluzione. Per trovare la probabilità richiesta dobbiamo sommare le probabilità associate a tutte le coppie \\((x,y)\\) che soddisfano la condizione \\(X+Y \\leq 1\\), ovvero\n\\[\nP_{XY}(X+Y \\leq 1) = P_{XY}(0, 0)+ P_{XY}(0, 1) + P_{XY}(1, 0) = 3/8.\n\\]\n\n\n11.1.3 Funzioni di probabilità marginali\nLa distribuzione marginale di un sottoinsieme di variabili casuali è la distribuzione di probabilità delle variabili contenute nel sottoinsieme. Come spiegato da Wikipedia: > il termine variabile marginale è usato per riferirsi a quelle variabili nel sottoinsieme delle variabili che vengono trattenute ovvero utilizzate. Questo termine, marginale, è attribuito ai valori ottenuti ad esempio sommando in una tabella di valori lungo le righe oppure lungo le colonne, trascrivendo il risultato appunto a margine rispettivamente della riga o colonna sommata. La distribuzione delle variabili marginali (la distribuzione marginale) è ottenuta mediante marginalizzazione sopra le variabili da “scartare”, e le variabili scartate sono dette fuori marginalizzate.\nNel caso di due variabili casuali discrete \\(X\\) e \\(Y\\) di cui conosciamo la distribuzione congiunta, la distribuzione marginale di \\(X\\), \\(P(X=x)\\), è dunque\n\\[\nP(X = x) = \\sum_y P(X, Y = y) = \\sum_y P(X \\mid Y = y) P(Y = y),\n\\]\ndove \\(P(X = x,Y = y)\\) è la distribuzione congiunta di \\(X, Y\\), mentre \\(P(X = x \\mid Y = y)\\) è la distribuzione condizionata di \\(X\\) dato \\(Y\\).\nLe probabilità bivariate marginali e congiunte di variabili casuali discrete sono spesso rappresentate mediante tabelle di contingenza. Si noti che \\(P(X = x)\\) e \\(P(Y = y)\\) sono normalizzate:\n\\[\n\\sum_x P(X=x) = 1.0, \\quad \\sum_y P(Y=y) = 1.0.\n\\]\nNel caso continuo si sostituisce l’integrazione alla somma – si veda la Sezione 11.1.4.\n\nEsercizio 11.2 Per l’esperimento casuale descritto nella Sezione 11.1, si calcolino le probabilità marginali di \\(X\\) e \\(Y\\).\n\n\nSoluzione. Come indicato nella Tabella 11.3, \\(P_X\\) si ottiene sommando su ciascuna riga fissata la colonna \\(j\\), \\(P_X(X = j) = \\sum_y p_{xy}(x = j, y)\\) e \\(P_Y\\) si trova sommando su ciascuna colonna fissata la riga \\(i,\\) \\(P_Y (Y = i) = \\sum_x p_{xy}(x, y = i)\\).\n\n\nTabella 11.3: Distribuzione di probabilità congiunta \\(P(X,Y)\\) per i risultati dell’esperimento consistente nel lancio di tre monete equilibrate e probabilità marginali \\(P(X)\\) e \\(P(Y)\\).\n\n\\(x \\textbackslash y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n11.1.4 Marginalizzazione di variabili casuali continue\nNella trattazione della statistca bayesiana useremo spesso il concetto di “marginalizzazione” e vedremo equazioni come la seguente:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) = \\int_{\\theta} p(y \\mid \\theta) p(\\theta),\n\\tag{11.1}\\]\nladdove \\(y\\) e \\(\\theta\\) sono due variabili casuali continue – nello specifico, con \\(y\\) denoteremo i dati e con \\(\\theta\\) i parametri di un modello statistico. Alla luce di quanto detto sopra, è possibiile pensare al caso continuo indicato nella Equazione 11.1 come all’estensione dell’esempio discusso in questo capitolo ad un numero infinito di valori delle due variabili continue (qui \\(y\\) e \\(\\theta\\))."
  },
  {
    "objectID": "019_joint_prob.html#valore-atteso-di-una-funzione-di-una-variabile-casuale",
    "href": "019_joint_prob.html#valore-atteso-di-una-funzione-di-una-variabile-casuale",
    "title": "11  Probabilità congiunta",
    "section": "\n11.2 Valore atteso di una funzione di una variabile casuale",
    "text": "11.2 Valore atteso di una funzione di una variabile casuale\nA volte ci viene data una variabile casuale $ X$e dobbiamo lavorare con una funzione di \\(X\\). Se \\(X\\) è una variabile casuale e \\(h(X)\\) è una funzione di \\(X\\), allora anche \\(h(X)\\) è una variabile casuale. Se si vuole calcolare il valore atteso di \\(h(X)\\), lo si può fare usando la funzione di massa di probabilità o la funzione di densità di probabilità di \\(X\\); non è necessario conoscere la funzione di massa di probabilità (o la funzione di densità di probabilità) di \\(h(X)\\).\n\nEsercizio 11.3 Sia \\(X\\) una variabile casuale discreta. Si trovi \\(\\mathbb{E}(aX + b)\\).\n\n\nSoluzione. \\(\\mathbb{E}(aX + b) = a\\mathbb{E}(X) + b = a \\sum_{x \\in \\Omega} xP(x) + b.\\) Si noti che la soluzione ha richiesto l’uso \\(P(x)\\), e non di \\(P(aX + b)\\).\n\n\nNota. Il risultato precedente è valido per variabili casuali continua dove la somma viene sostituita da un integrale."
  },
  {
    "objectID": "019_joint_prob.html#valore-atteso-di-una-funzione-di-molteplici-variabili-casuali",
    "href": "019_joint_prob.html#valore-atteso-di-una-funzione-di-molteplici-variabili-casuali",
    "title": "11  Probabilità congiunta",
    "section": "\n11.3 Valore atteso di una funzione di molteplici variabili casuali",
    "text": "11.3 Valore atteso di una funzione di molteplici variabili casuali\nA volte ci vengono fornite due variabili casuali \\(X\\) e \\(Y\\) e dobbiamo lavorare con una funzione di \\(X\\) e \\(Y\\). Se \\(X\\) e \\(Y\\) sono variabili casuali e \\(h(X, Y)\\) è una funzione di \\(X\\) e \\(Y\\), allora anche \\(h( X, Y)\\) è una variabile casuale. Se si desidera calcolare la media di \\(h(X, Y)\\), lo si può fare utilizzando la funzione di massa di probabilità congiunta (o la funzione di densità di probabilità congiunta di \\(X\\) e \\(Y\\)); non è necessario conoscere la funzione di massa di probabilità congiunta (o la funzione di massa congiunta funzione di densità di probabilità) di \\(h(X, Y)\\).\n\nEsercizio 11.4  \nSiano \\(X\\) e \\(Y\\) due variabili casuali discrete con distribuzione di massa di probabilità congiunta\n\\[\nP_{XY} (1,1) = 1/3; \\quad P_{XY}  (1,2) = 1/8; \\quad P_{XY} (2,1) = 1/2; \\quad P_{XY} (2,2) = 1/24.\n\\]\nSi trovi il valore atteso di \\(g(X, Y) = XY\\).\n\n\nSoluzione. \\[\n\\begin{align}\n\\mathbb{E}g(X, Y) &= \\mathbb{E}(XY) \\notag\\\\\n&= \\sum_{x=1}^2 \\sum_{y=1}^2 x y P_{XY}(x, y) \\notag\\\\\n&= 1 \\cdot 1 \\cdot \\frac{1}{3} +  \n   1 \\cdot 2 \\cdot \\frac{1}{8} +\n   2 \\cdot 1 \\cdot \\frac{1}{2} +\n   2 \\cdot 2 \\cdot \\frac{1}{24}\\notag\\\\\n&= \\frac{7}{4}.\\notag\n\\end{align}\n\\]\n\n\nEsercizio 11.5 Sia \\(X_1, X_2, \\dots, X_n\\) una sequenza di variabili casuali i.i.d., ciascuna con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Si trovi il valore atteso di \\(X = X_1 + X_2 + \\dots + X_n\\).\n\n\nSoluzione. \\(\\mathbb{E}(X) = \\mathbb{E}(X_1) + \\mathbb{E}(X_2) + \\dots + \\mathbb{E}(X_n) = \\sum_{i=1}^n \\mathbb{E}(X_i) = n \\mu.\\)\n\n\nEsercizio 11.6 \nSia \\(X_1, X_2, \\dots, X_n\\) una sequenza di variabili casuali i.i.d., ciascuna con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Si definisca una nuova variabile casuale\n\\[\n\\bar{X} = \\frac{X_1 + X_2 + \\dots + X_n}{n}\n\\]\ndetta media campionaria. Si trovi il valore atteso di \\(\\bar{X}\\).\n\n\nSoluzione. \\(\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) = \\mu.\\)"
  },
  {
    "objectID": "019_joint_prob.html#distribuzioni-condizionali",
    "href": "019_joint_prob.html#distribuzioni-condizionali",
    "title": "11  Probabilità congiunta",
    "section": "\n11.4 Distribuzioni condizionali",
    "text": "11.4 Distribuzioni condizionali\nSe \\(X\\) e \\(Y\\) sono variabili casuali distribuite congiuntamente, conoscere il valore di \\(X\\) può modificare le probabilità relative alla variabile casuale \\(Y\\). Per calcolare questa nuova probabilità, è necessaria l’idea di una distribuzione condizionale.\n\nDefinizione 11.2 Siano \\(X\\) e \\(Y\\) variabili casuali discrete distribuite congiuntamente. Definiamo la funzione di massa di probabilità condizionata di \\(X\\) dato che \\(Y = y\\) nei termini seguenti:\n\\[\nP_{X \\mid Y} (x \\mid y) = P(X = x \\mid Y = y) = \\frac{P_{XY} (x, y)}{P_Y(y)}\n\\]\n\n\nEsercizio 11.7 \nSupponiamo che \\(X\\) e \\(Y\\) siano variabili casuali discrete con valori 1, 2, 3, 4 e che per \\(x,y = 1, 2, 3, 4\\) la funzione di massa di probabilità congiunta sia data da\n\\[\n\\begin{equation}\n  P_{XY}(x,y) =\n    \\begin{cases}\n      \\frac{1}{16} & \\text{se $x = y$}\\\\\n      \\frac{2}{16} & \\text{se $x < y$}\\\\\n      0 & \\text{se $x > y$}\n    \\end{cases}       \n\\end{equation}\n\\]\nSi trovi la funzione di probabilità condizionata di \\(Y\\) dato che \\(X = 3\\).\n\n\nSoluzione. La distribuzione congiunta di massa di probabilità è la seguente:\n\n\n\\(x \\textbackslash y\\)\n1\n2\n3\n4\n\\(P_X(x)\\)\n\n\n\n1\n1/16\n2/16\n2/16\n2/16\n7/16\n\n\n2\n0\n1/16\n2/16\n2/16\n5/16\n\n\n3\n0\n0\n1/16\n2/16\n3/16\n\n\n4\n0\n0\n0\n1/16\n1/16\n\n\n\\(P_Y(y)\\)\n1/16\n3/16\n5/16\n7/16\n1.0\n\n\n\nDunque otteniamo\n\\[\nP_{Y\\mid X}(1 \\mid 3) =  \\frac{P_{XY}(3,1)}{P_X(3)} = 0\n\\]\n\\[\nP_{Y\\mid X}(2 \\mid 3) =  \\frac{P_{XY}(3,2)}{P_X(3)} = 0\n\\]\n\\[\nP_{Y\\mid X}(3 \\mid 3) =  \\frac{P_{XY}(3,3)}{P_X(3)} = \\frac{(1/16)}{(3/16)} = \\frac{1}{3}\n\\]\n\\[\nP_{Y\\mid X}(4 \\mid 3) =  \\frac{P_{XY}(3,4)}{P_X(3)} = \\frac{(2/16)}{(3/16)} = \\frac{2}{3}\n\\]"
  },
  {
    "objectID": "019_joint_prob.html#valore-atteso-condizionato",
    "href": "019_joint_prob.html#valore-atteso-condizionato",
    "title": "11  Probabilità congiunta",
    "section": "\n11.5 Valore atteso condizionato",
    "text": "11.5 Valore atteso condizionato\nUn valore atteso condizionato è un valore atteso, o media, calcolato utilizzando una funzione di massa di probabilità condizionale (o una funzione di densità di probabilità condizionale).\n\nDefinizione 11.3 Siano \\(X\\) e \\(Y\\) variabili casuali discrete congiunte. Definiamo il valore atteso condizionato di \\(X\\) dato che \\(Y = y\\) come\n\\[\n\\begin{align}\n\\mathbb{E} (X \\mid Y = y) &= \\sum_x x P(X = x \\mid Y = y)\\notag\\\\\n&= \\sum_x x P_{X \\mid Y}(x \\mid y) \\notag\n\\end{align}\n\\]\n\n\nEsercizio 11.8 Si trovi il valore atteso condizionato dell’Esercizio 11.7 dato che \\(X = 3\\).\n\n\nSoluzione. Abbiamo che\n\\[\n\\begin{align}\n\\mathbb{E} (X \\mid Y = 3) &= \\sum_x x P(X = x \\mid Y = 3)\\notag\\\\\n&= \\frac{1 \\cdot P_{XY}(3,1)}{P_X(3)} + \\frac{2 \\cdot P_{XY}(3,2)}{P_X(3)} +\n\\frac{3 \\cdot P_{XY}(3,3)}{P_X(3)} + \\frac{4 \\cdot P_{XY}(3,4)}{P_X(3)} \\notag\\\\\n&= 3 \\cdot \\frac{1}{3} + 4 \\cdot \\frac{2}{3} \\notag\\\\\n&= \\frac{11}{3} \\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "019_joint_prob.html#indipendenza",
    "href": "019_joint_prob.html#indipendenza",
    "title": "11  Probabilità congiunta",
    "section": "\n11.6 Indipendenza",
    "text": "11.6 Indipendenza\nLa nozione di indipendenza per le variabili casuali è molto simile alla nozione di indipendenza per gli eventi. Due variabili casuali sono indipendenti se la conoscenza relativa a una di esse non influisce sulle probabilità dell’altra. Nel caso di due variabili casuali discrete, presentiamo qui una definizione di indipendenza formulatanei termini della loro distribuzione di massa di probabilità congiunta.\n\nDefinizione 11.4 Due variabili casuali \\(X\\) e \\(Y\\) distribuite congiuntamente si dicono indipendenti se e solo se\n\\[\nP_{X, Y}(x, y) = P_X(x) P_Y(y).\n\\]\n\nA parole, se due variabili discrete \\(X\\) e \\(Y\\) non si influenzano, ovvero se sono statisticamente indipendenti, allora la distribuzione di massa di probabilità congiunta si ottiene come prodotto delle funzioni di probabilità marginali di \\(X\\) e \\(Y\\). Se \\(P_{X, Y}(x, y) \\neq P_X(x) P_Y(y)\\), allora le due variabili si dicono associate.\nVedremo in seguito come una misura del grado di associazione lineare tra due variabili casuali è fornita dalla covarianza (o dalla correlazione)."
  },
  {
    "objectID": "019_joint_prob.html#commenti-e-considerazioni-finali",
    "href": "019_joint_prob.html#commenti-e-considerazioni-finali",
    "title": "11  Probabilità congiunta",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn alcuni casi, diverse variabili casuali possono essere associate a ciascuna unità statistica della popolazione. Ad esempio, immaginiamo di scegliere uno studente a caso dall’elenco di tutti gli studenti iscritti a un’università e di misurare l’altezza e il peso di quello studente. A ogni individuo nella popolazione degli studenti corrispondono dunque due variabili casuali, altezza e peso. Quando due o più variabili casuali sono associate a ciascun elemento di una popolazione, si dice che le variabili casuali sono distribuite congiuntamente. In questo capitolo abbiamo visto come si possa rappresentare la distribuzione di massa di probabilità congiunta di due variabili casuali discrete e come si possano ottenere le distribuzioni marginali delle due variabili. Abbiamo anche esaminato i concetti di distribuzione marginale, distribuzione condizionata e indipendenza."
  },
  {
    "objectID": "020_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "href": "020_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "title": "12  La densità di probabilità",
    "section": "\n12.1 Spinner e variabili casuali continue uniformi",
    "text": "12.1 Spinner e variabili casuali continue uniformi\nConsideriamo il seguente esperimento casuale. Facciamo ruotare ad alta velocità uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma (individuata dall’angolo acuto con segno tra il suo asse e l’asse orizzontale del goniometro). Chiamiamo \\(\\Theta\\) la variabile casuale “pendenza dello spinner” – Figura 12.1. Nella trattazione seguente useremo i gradi e, di conseguenza, \\(\\Theta \\in [0, 360]\\).\n\n\n\n\nFigura 12.1: Uno spinner che riposa a 36 gradi, o il dieci percento del percorso intorno al cerchio. La pendenza dello spinner può assumere qualunque valore tra 0 e 360 gradi.\n\n\n\n\nCosa implica per \\(\\Theta\\) dire che lo spinner è simmetrico? Possiamo dire che, in ciascuna prova, la rotazione dello spinner produce un angolo qualunque da 0 a 360 gradi. In altri termini, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilità di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, poiché 36 gradi è un decimo del percorso intorno al cerchio, la probabilità di ottenere un qualsiasi intervallo di 36 gradi sarà sempre uguale al 10%. Ovvero \\(\\mbox{P}(0 \\leq \\Theta \\leq 36) \\ = \\ \\frac{1}{10}\\) e \\(\\mbox{P}(200 \\leq \\Theta \\leq 236) \\ = \\ \\frac{1}{10}\\).\nÈ importante notare che le probabilità precedenti non si riferiscono al fatto che \\(\\Theta\\) assume uno specifico valore, ma piuttosto all’evento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilità che la pendenza \\(\\Theta\\) dello spinner cada in intervallo è la frazione del cerchio rappresentata dall’intervallo, cioè,\n\\[\n\\mbox{P}(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}, \\qquad 0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360.\n\\]\nLa ragione di questo è che le variabili casuali continue non hanno una massa di probabilità. Invece, una massa di probabilità viene assegnata alla realizzazione della variabile casuale in un intervallo di valori.\n\n12.1.1 Il paradosso delle variabili casuali continue\nNel nostro esempio, la pendenza dello spinner è esattamente 36 gradi; ma avrebbe anche potuto essere 36.0376531 gradi, o qualunque altro valore in quell’intorno. Qual è la probabilità che la pendenza dello spinner sia esattamente 36? Paradossalmente, la risposta è zero:\n\\[\n\\mbox{P}(\\Theta = 36) = 0.\n\\]\nInfatti, se la probabilità di un qualunque valore fosse maggiore di zero, ogni altro possibile valore dovrebbe avere la stessa probabilità, dato che abbiamo assunto che tutti i valori \\(\\Theta\\) siano egualmente probabili. Ma se poi andiamo a sommare tutte queste probabilità il totale diventerà maggiore di uno, il che non è possibile.\nNel caso delle variabili casuali continue dobbiamo dunque rinunciare a qualcosa, e quel qualcosa è l’idea che, in una distribuzione continua, ciascun valore puntuale della variabile casuale possa avere una massa di probabilità maggiore di zero. Il paradosso sorge perché una realizzazione della variabile casuale continua produce sempre un qualche numero, ma ciscuno di tali numeri ha probabilità nulla."
  },
  {
    "objectID": "020_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "020_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "12  La densità di probabilità",
    "section": "\n12.2 La funzione di ripartizione per una variabile casuale continua",
    "text": "12.2 La funzione di ripartizione per una variabile casuale continua\nSupponiamo che \\(\\Theta \\sim \\mathcal{U}(0, 360)\\) sia la pendenza dello spinner. La funzione di ripartizione (ovvero, la distribuzione cumulativa) è definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = \\mbox{P}(\\Theta \\leq \\theta).\n\\]\nCioè, è la probabilità che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\). In questo caso, poiché si presume che lo spinner sia simmetrico, la funzione di distribuzione cumulativa è\n\\[\nF_{\\Theta}(\\theta) = \\frac{\\theta}{360}.\n\\]\nQuesta è una funzione lineare di \\(\\theta\\), cioè \\(\\frac{1}{360} \\cdot \\theta\\), come indicato dal grafico della Figura 12.2.\n\n\n\n\nFigura 12.2: Funzione di distribuzione cumulativa per l’angolo \\(\\theta\\) (in gradi) risultante da una rotazione di uno spinner simmetrico. La linea tratteggiata mostra il valore a 180 gradi, che corrisponde ad una probabilità di 0.5, e la linea tratteggiata a 270 gradi, che corrisponde ad una probabilità di 0.75.\n\n\n\n\nPossiamo verificare questo risultato mediante simulazione. Per stimare la funzione di ripartizione, simuliamo \\(M\\) valori \\(\\theta^{(m)}\\) e poi li ordiniamo in ordine crescente.\n\n\n\n\nFigura 12.3: Grafico della funzione di ripartizione di una variabile casuale \\(\\Theta\\) che rappresenta il risultato di una rotazione di uno spinner simmetrico. Come previsto, tale funzione è una semplice funzione lineare perché la variabile sottostante \\(\\Theta\\) ha una distribuzione uniforme.\n\n\n\n\nAnche con M = 1000, tale grafico è praticamente indistinguibile da quello prodotto per via analitica.\nCome nel caso delle variabili casuali discrete, la funzione di ripartizione può essere utilizzata per calcolare la probabilità che la variabile casuale assuma valori in un certo intervallo. Ad esempio\n\\[\\begin{align}\n\\mbox{P}(180 < \\Theta \\leq 270) &= \\mbox{P}(\\Theta \\leq 270) \\ - \\ \\mbox{P}(\\Theta \\leq 180) \\notag\\\\\n&= F_{\\Theta}(270) - F_{\\Theta}(180)\\notag\\\\\n&= \\frac{3}{4} - \\frac{1}{2} \\notag\\\\\n&= \\frac{1}{4}.\n\\end{align}\\]"
  },
  {
    "objectID": "020_density_func.html#la-distribuzione-uniforme",
    "href": "020_density_func.html#la-distribuzione-uniforme",
    "title": "12  La densità di probabilità",
    "section": "\n12.3 La distribuzione uniforme",
    "text": "12.3 La distribuzione uniforme\nDopo avere visto come generare numeri casuali uniformi da 0 a 360, consideriamo ora una variabile casuale che assume valori nell’intervallo da 0 a 1. Chiamiamo tale variabile casuale \\(\\Theta\\) e assumiamo che abbia una distribuzione continua uniforme sull’intervallo [0, 1]:\n\\[\n\\Theta \\sim \\mathcal{U}(0, 1).\n\\]\nPoiché le probabilità assumono valori nell’intervallo [0, 1], possiamo pensare a \\(\\Theta\\) come ad un valore di probabilità preso a caso in ciascuna realizzazione dell’esperimento casuale.\nLa distribuzione uniforme è la più semplice delle distribuzioni di densità di probabilità. Per chiarire le proprietà di tale distribuzione, iniziamo con una simulazione e generiamo 10,000 valori casuali di \\(\\Theta\\). Creiamo poi un istogramma che descrive la distribuzione delle 10,000 realizzazioni \\(\\Theta\\) che abbiamo trovato. Alcuni valori \\(\\Theta\\) sono forniti di seguito.\n\n#>  [1] 0.113703411 0.622299405 0.609274733 0.623379442 0.860915384 0.640310605\n#>  [7] 0.009495756 0.232550506 0.666083758 0.514251141\n\n\n\n\n\nFigura 12.4: Istogramma di \\(10\\,000\\) realizzazioni \\(\\Theta \\sim \\mbox{Uniform}(0, 1)\\).\n\n\n\n\nÈ chiaro che, all’aumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell’istogramma tenderà a diventare una linea retta. Ciò significa che la funzione di densità di una variabile casuale uniforme continua è una costante. Cioè, se \\(\\Theta \\sim \\mathcal{U} (a, b)\\), allora \\(p_{\\Theta}(\\theta) = c\\), dove \\(c\\) è una costante.\n\n\n\n\nFigura 12.5: Distribuzione uniforme\n\n\n\n\nDalla Figura 12.5 vediamo che l’area sottesa alla funzione di densità è \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\),\n\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - a}.\n\\]\nOvvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora\n\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b),\n\\]\nladdove\n\\[\n\\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}.\n\\]\nIn conclusione, la densità di una variabile casuale uniforme continua non dipende da \\(\\theta\\) — è costante e identica per ogni possibile valore \\(\\theta\\).2 Vedremo nel prossimo Paragrafo che, eseguendo una trasformazione su questa variabile casuale uniforme, possiamo creare altre variabili casuali di interesse.\n\nSi consideri una variabile casuale uniforme \\(X\\) definita sull’intervallo [0, 100]. Si trovi la probabilità \\(P(20 < X < 60)\\).\nPer trovare la soluzione è sufficiente calcolare l’area di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilità cercata è dunque \\(P(20 < X < 60) = 40 \\cdot 0.01 = 0.4\\)."
  },
  {
    "objectID": "020_density_func.html#dagli-istogrammi-alle-densità",
    "href": "020_density_func.html#dagli-istogrammi-alle-densità",
    "title": "12  La densità di probabilità",
    "section": "\n12.4 Dagli istogrammi alle densità",
    "text": "12.4 Dagli istogrammi alle densità\nNon esiste l’equivalente di una funzione di massa di probabilità per le variabili casuali continue. Esiste invece una funzione di densità di probabilità la quale, nei termini di una simulazione, può essere concepita nel modo seguente: avendo a disposizione un numero enorme di casi, quando l’intervallo \\(\\Delta\\) di ciascuna classe \\(\\rightarrow\\) 0, il profilo dell’istogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) è detta funzione di densità di probabilità.\nCome si trasformano gli istogrammi all’aumentare del numero di osservazioni? Per fare un esempio, considereremo una funzione di una variabile casuale uniforme \\([0, 1]\\). Nello specifico, esamineremo la funzione logit.\n\\[\n\\alpha = \\log \\left(\\frac{\\theta}{1-\\theta}\\right)\n\\]\nAlcuni valori logit presi a caso sono stampati di seguito.\n\n#> [1] -2.053458\n#> [1] 0.4993195\n#> [1] 0.4442646\n#> [1] 0.5039172\n#> [1] 1.822914\n#> [1] 0.5767125\n#> [1] -4.647369\n#> [1] -1.193965\n#> [1] 0.6905252\n#> [1] 0.05702001\n\nNei grafici seguenti, la numerosità cresce da \\(10\\) a \\(1\\,000\\,000\\).\n\n\n\n\nFigura 12.6: Istogramma di \\(M\\) campioni casuali \\(\\Theta \\sim \\mbox{Uniform}(0, 1)\\) trasformati in valori \\(\\Phi = \\mbox{logit}(\\Theta).\\) Il profilo limite dell’istogramma è evidenziato nella figura in basso a destra che è stata costruita usando \\(1\\,000\\,000\\) di osservazioni.\n\n\n\n\nIn un istogramma, l’area di ciascuna barra è proporzionale alla frequenza relativa delle osservazioni in quel’intervallo. Perché tutti gli intervalli hanno la stessa ampiezza, anche l’altezza di ciascuna barra sarà proporzionale alla frequenza relativa delle osservazioni in quel’intervallo.\nNella simulazione, possiamo pensare all’area di ciascuna barra dell’istogramma come alla stima della probabilità che la variabile casuale assuma un valore compreso nell’intervallo considerato. All’aumentare del numero \\(M\\) di osservazioni, le probabilità stimate si avvicinano sempre di più ai veri valori della probabilità. All’aumentare del numero degli intervalli (quando l’ampiezza \\(\\Delta\\) dell’intervallo \\(\\rightarrow\\) 0), il profilo dell’istogramma tende a diventare una curva continua. Tale curva continua è la funzione di densità di probabilità della variabile casuale. Per l’esempio presente, con \\(M =1\\,000\\,000\\), otteniamo il grafico riportato nella figura @ref(fig:hist-dens-example).\n\n\n\n\nFigura 12.7: Istogramma di \\(M = 1\\,000\\,000\\) campioni casuali \\(\\Theta \\sim \\mbox{Uniform}(0,1)\\) trasformati in valori \\(\\Phi = \\mbox{logit}(\\Theta)\\). La spezzata nera congiunge i punti centrali superiori delle barre dell’istogramma. Nel limite, quando il numero di osservazioni e di barre tende all’infinito, tale spezzata approssima la funzione di densità di probabilità della variabile casuale.\n\n\n\n\nNella statistica descrittiva abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un metodo non parametrico per stimare la funzione di densità di probabilità di una variabile casuale."
  },
  {
    "objectID": "020_density_func.html#funzione-di-densità-di-probabilità",
    "href": "020_density_func.html#funzione-di-densità-di-probabilità",
    "title": "12  La densità di probabilità",
    "section": "\n12.5 Funzione di densità di probabilità",
    "text": "12.5 Funzione di densità di probabilità\nPer descrivere le probabilità che possono essere associate ad una variabile casuale continua \\(X\\) è necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due proprietà:\n\n\n\\(p(x) \\geq 0, \\forall x\\), ovvero, l’ordinata della funzione di densità è 0 o positiva;\n\n\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l’area sottesa dalla \\(p(x)\\) è unitaria3;\n\n\\(p(a < x < b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l’area sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilità che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\n\nInterpretazione. È possibile che \\(p(x) > 1\\), quindi una densità di probabilità non può essere interpretata come una probabilità. Piuttosto, la densità \\(p(x)\\) può essere utilizzata per confrontare la fiducia relativa che può essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui è disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) > p(x_l)\\), allora possiamo concludere che è più probabile, in termini relativi, osservare realizzazioni \\(X\\) nell’intorno di \\(x_k\\) piuttosto che nell’intorno di \\(x_l\\)."
  },
  {
    "objectID": "020_density_func.html#la-funzione-di-ripartizione",
    "href": "020_density_func.html#la-funzione-di-ripartizione",
    "title": "12  La densità di probabilità",
    "section": "\n12.6 La funzione di ripartizione",
    "text": "12.6 La funzione di ripartizione\nLa funzione di ripartizione \\(F(X)\\) è quella funzione che associa a ogni valore di una variabile casuale \\(X\\) la probabilità che la variabile assuma valore minore o uguale a un prefissato valore \\(x_k\\). Come nel caso discreto, anche nel caso continuo la funzione di ripartizione è sempre non negativa, monotona non decrescente tra \\(0\\) e \\(1\\), tale che:\n\\[\n\\lim_{x \\to -\\infty} F_x(X) = F_X(-\\infty) = 0, \\quad \\lim_{x \\to +\\infty} F_X(X) = F_X(+\\infty) = 1.\n\\]\n\n\n\n\n\nSe \\(X\\) è una variabile aleatoria continua, la funzione di ripartizione è:\n\\[\nF(x_k) = P(X \\leq x_k) = \\int_{-\\infty}^{x_k} f(x) \\,\\operatorname {d}\\!x .\n\\]"
  },
  {
    "objectID": "020_density_func.html#media-e-mediana",
    "href": "020_density_func.html#media-e-mediana",
    "title": "12  La densità di probabilità",
    "section": "\n12.7 Media e mediana",
    "text": "12.7 Media e mediana\nConcludiamo questo capitolo con alcune considerazioni relative al contronto tra la media (valore atteso) e la mediana, nel caso di variabili casuali continue.\nPer distribuzioni simmetriche, sappiamo che la media e la mediana sono uguali. Chiediamoci ora cosa succede, nel caso di variabili casuali continue, nel caso di distribuzioni asimmetriche.\nLa mediana indica il punto in cui la “massa totale” della distribuzione è suddivisa in due porzioni uguali. Nel caso della densità di probabilità, ciascuna di queste porzioni rappresenta un’area uguale, \\(A_1 = A_2 = 1/2\\) poiché l’area totale sottesa alla funzione di densità è 1 per definizione.\n\n\n\n\nFigura 12.8: Qual è la differenza tra mediana e media in una funzione di densità?\n\n\n\n\nLa Figura 12.8 mostra come differiscono i due concetti di mediana (indicata dalla linea verticale) e media (indicata dal “punto di equilibrio” triangolare). A sinistra, per una densità di probabilità simmetrica, la media e la mediana coincidono. A destra, una piccola porzione della distribuzione è stata spostata all’estremo destro. Questa modifica non ha influito sulla posizione della mediana, poiché le aree a destra e a sinistra della linea verticale sono ancora uguali. In altri termini, la mediana, \\(x_m\\), divide l’area sottesa alla funzione di densità in due porzioni uguali:\n\\[\n\\int_{-\\infty}^{x_m} p(x) dx = \\int_{x_m}^{-\\infty} p(x) dx = \\frac{1}{2}.\n\\]\nSegue da tale definizione che la mediana è il valore \\(x\\) per il quale la distribuzione cumulativa soddisfa\n\\[\nF(x_m) = \\frac{1}{2}.\n\\]\nTuttavia, il fatto che una parte della massa sia stata allontanata verso destra porta a uno spostamento della media della distribuzione, per compensare tale cambiamento. In altre parole, la media contiene più informazioni sulla distribuzione “spaziale” delle osservazioni, rispetto alla mediana. Ciò deriva dal fatto che la media della distribuzione (il valore atteso) è una “somma” – cioè è un integrale – di termini cha hanno la forma \\(x p(x) \\Delta x\\). Quindi la posizione lungo l’asse \\(x\\), ovvero \\(x\\), e non solo la “massa”, \\(p(x) \\Delta x\\), influenza il contributo che le componenti della distribuzione hanno sulla media."
  },
  {
    "objectID": "distr.html",
    "href": "distr.html",
    "title": "Parte 3: Distribuzioni di v.c. discrete e continue",
    "section": "",
    "text": "In questa parte della dispensa verranno presentate le più importanti distribuzioni di massa di probabilità e di densità di probabilità."
  },
  {
    "objectID": "022_discr_rv_distr.html#una-prova-bernoulliana",
    "href": "022_discr_rv_distr.html#una-prova-bernoulliana",
    "title": "13  Distribuzioni di v.c. discrete",
    "section": "\n13.1 Una prova Bernoulliana",
    "text": "13.1 Una prova Bernoulliana\nSe un esperimento casuale ha solo due esiti possibili, allora le repliche indipendenti di questo esperimento sono chiamate “prove Bernoulliane” (il lancio di una moneta è il tipico esempio).\n\nDefinizione 13.1 Viene detta variabile di Bernoulli una variabile casuale discreta \\(Y = \\{0, 1\\}\\) con la seguente distribuzione di probabilità:\n\\[\nP(Y \\mid \\theta) =\n  \\begin{cases}\n    \\theta     & \\text{se $Y = 1$}, \\\\\n    1 - \\theta & \\text{se $Y = 0$},\n  \\end{cases}\n\\]\ncon \\(0 \\leq \\theta \\leq 1\\). Convenzionalmente l’evento \\(\\{Y = 1\\}\\) con probabilità \\(\\theta\\) viene chiamato “successo” mentre l’evento \\(\\{Y = 0\\}\\) con probabilità \\(1-\\theta\\) viene chiamato “insuccesso”.\n\nApplicando l’operatore di valore atteso e di varianza, otteniamo\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= 0 \\cdot P(Y=0) + 1 \\cdot P(Y=1) = \\theta, \\\\\n\\mathbb{V}(Y) &= (0 - \\theta)^2 \\cdot P(Y=0) + (1 - \\theta)^2 \\cdot P(Y=1) = \\theta(1-\\theta).\n\\end{align}\n\\tag{13.1}\\]\nScriviamo \\(Y \\sim \\mbox{Bernoulli}(\\theta)\\) per indicare che la variabile casuale \\(Y\\) ha una distribuzione Bernoulliana di parametro \\(\\theta\\).\n\nEsercizio 13.1 Nel caso del lancio di una moneta equilibrata la variabile casuale di Bernoulli assume i valori \\(0\\) e \\(1\\). La distribuzione di massa di probabilità è pari a \\(\\frac{1}{2}\\) in corrispondenza di entrambi i valori. La funzione di distribuzione vale \\(\\frac{1}{2}\\) per \\(Y = 0\\) e \\(1\\) per \\(Y = 1\\)."
  },
  {
    "objectID": "022_discr_rv_distr.html#una-sequenza-di-prove-bernoulliane",
    "href": "022_discr_rv_distr.html#una-sequenza-di-prove-bernoulliane",
    "title": "13  Distribuzioni di v.c. discrete",
    "section": "\n13.2 Una sequenza di prove Bernoulliane",
    "text": "13.2 Una sequenza di prove Bernoulliane\nLa distribuzione binomiale è rappresentata dall’elenco di tutti i possibili numeri di successi \\(Y = \\{0, 1, 2, \\dots n\\}\\) che possono essere osservati in \\(n\\) prove Bernoulliane indipendenti di probabilità \\(\\theta\\), a ciascuno dei quali è associata la relativa probabilità. Esempi di una distribuzione binomiale sono i risultati di una serie di lanci di una stessa moneta o di una serie di estrazioni da un’urna (con reintroduzione). La distribuzione binomiale di parametri \\(n\\) e \\(\\theta\\) è in realtà una famiglia di distribuzioni: al variare dei parametri \\(\\theta\\) e \\(n\\) variano le probabilità.\n\nDefinizione 13.2 La probabilità di ottenere \\(y\\) successi e \\(n-y\\) insuccessi in \\(n\\) prove Bernoulliane è data dalla distribuzione binomiale:\n\\[\n\\begin{align}\nP(Y=y) &= \\binom{n}{y} \\theta^{y} (1-\\theta)^{n-y} \\notag \\\\\n&= \\frac{n!}{y!(n-y)!} \\theta^{y} (1-\\theta)^{n-y},\n\\end{align}\n\\tag{13.2}\\]\ndove \\(n\\) = numero di prove Bernoulliane, \\(\\theta\\) = probabilità di successo in ciascuna prova e \\(y\\) = numero di successi.\n\n\nDimostrazione. L’Equazione 13.2 può essere derivata nel modo seguente. Indichiamo con \\(S\\) il successo e con \\(I\\) l’insuccesso di ciascuna prova. Una sequenza di \\(n\\) prove Bernoulliane darà come esito una sequenza di \\(n\\) elementi \\(S\\) e \\(I\\). Ad esempio, una sequenza che contiene \\(y\\) successi è la seguente:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ volte} \\overbrace{II\\dots I}^\\text{$n-y$ volte}\n\\]\nEssendo \\(\\theta\\) la probabilità di \\(S\\) e \\(1-\\theta\\) la probabilità di \\(I\\), la probabilità di ottenere la specifica sequenza riportata sopra è\n\\[\n\\begin{equation}\n\\overbrace{\\theta \\theta\\dots \\theta}^\\text{$y$ volte} \\overbrace{(1-\\theta)(1-\\theta)\\dots (1-\\theta)}^\\text{$n-y$ volte} = \\theta^y \\cdot (1-\\theta)^{n-y}.\n\\end{equation}\n\\tag{13.3}\\]\nNon siamo però interessati alla probabilità di una specifica sequenza di \\(S\\) e \\(I\\) ma, bensì, alla probabilità di osservare una qualsiasi sequenza di \\(y\\) successi in \\(n\\) prove. In altre parole, vogliamo la probabilità dell’unione di tutti gli eventi corrispondenti a \\(y\\) successi in \\(n\\) prove.\nÈ immediato notare che una qualsiasi altra sequenza contenente esattamente \\(y\\) successi avrà sempre come probabilità \\(\\theta^y \\cdot (1-\\theta)^{n-y}\\): il prodotto infatti resta costante anche se cambia l’ordine dei fattori.1 Per trovare il risultato cercato dobbiamo moltiplicare l’Equazione 13.3 per il numero di sequenze possibili di \\(y\\) successi in \\(n\\) prove.\nIl numero di sequenze che contengono esattamente \\(y\\) successi in \\(n\\) prove. La risposta è fornita dal coefficiente binomiale:\n\\[\n\\begin{equation}\n\\binom{n}{y} = \\frac{n!}{y!(n-y)!},\n\\end{equation}\n\\tag{13.4}\\]\ndove il simbolo \\(n!\\) si legge \\(n\\) fattoriale ed è uguale al prodotto di \\(n\\) numeri interi decrescenti a partire da \\(n\\). Per definizione \\(0! = 1\\).\nEssendo la probabilità dell’unione di \\(K\\) elementi incompatibili uguale alla somma delle loro rispettive probabilità, e dato che le sequenze di \\(y\\) successi in \\(n\\) prove hanno tutte la stessa probabilità, per trovare la formula della distributione binomiale Equazione 13.2 è sufficiente moltiplicare l’Equazione 13.3 per l’Equazione 13.4.\n\nLa distribuzione di probabilità di alcune distribuzioni binomiali, per due valori di \\(n\\) e \\(\\theta\\), è fornita nella Figura 13.1.\n\n\n\n\nFigura 13.1: Alcune distribuzioni binomiali. Nella figura, il parametro \\(\\theta\\) è indicato con \\(p\\).\n\n\n\n\n\nEsercizio 13.2 Usando l’Equazione 13.2, si trovi la probabilità di \\(y = 2\\) successi in \\(n = 4\\) prove Bernoulliane indipendenti con \\(\\theta = 0.2\\)\n\n\nSoluzione. Abbiamo\n\\[\n\\begin{aligned}\nP(Y=2) &= \\frac{4!}{2!(4-2)!} 0.2^{2} (1-0.2)^{4-2} \\notag  \\\\\n&= \\frac{4 \\cdot 3 \\cdot 2 \\cdot 1}{(2 \\cdot 1)(2 \\cdot 1)}\n0.2^{2} 0.8^{2} = 0.1536. \\notag\n\\end{aligned}\n\\]\nRipetendo i calcoli per i valori \\(y = 0, \\dots, 4\\) troviamo la distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\n\ny\nP(Y = y)\n\n\n\n0\n0.4096\n\n\n1\n0.4096\n\n\n2\n0.1536\n\n\n3\n0.0256\n\n\n4\n0.0016\n\n\nsum\n1.0\n\n\n\nLo stesso risultato si può trovare in Python.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom\n\n\nn = 4\np = 0.2\nx = np.arange(0, n+1)\nx\n#> array([0, 1, 2, 3, 4])\n\n\nbinomial_pmf = binom.pmf(x, n, p)\nprint(binomial_pmf)\n#> [0.4096 0.4096 0.1536 0.0256 0.0016]\n\n\n\nEsercizio 13.3 Lanciando \\(5\\) volte una moneta onesta, qual è la probabilità che esca testa almeno tre volte?\n\n\nSoluzione. In Python, la soluzione si trova con\n\nbinom.pmf(3, n=5, p=0.5) + binom.pmf(4, n=5, p=0.5) +  binom.pmf(5, n=5, p=0.5)\n#> 0.49999999999999983\n\nAlternativamente, possiamo trovare la probabilità dell’evento complementare a quello definito dalla funzione di ripartizione.\n\n1 - binom.cdf(2, n=5, p=0.5)\n#> 0.5\n\n\n\n13.2.1 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si trovano nel modo seguente:\n\\[\n\\begin{align}\n\\mu    &= n\\theta,  \\notag \\\\\n\\sigma &= \\sqrt{n\\theta(1-\\theta)}.\n\\end{align}\n\\tag{13.5}\\]\n\nDimostrazione. Essendo \\(Y\\) la somma di \\(n\\) prove Bernoulliane indipendenti \\(Y_i\\), è facile vedere che\n\\[\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = n\\theta, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = n \\theta (1-\\theta).\n\\end{align}\\]\n\n\nEsercizio 13.4 Si trovino il valore atteso e la varianza del lancio di quattro monete con probabilità di successo pari a \\(\\theta = 0.2\\).\n\n\nSoluzione. Il valore atteso è \\(\\mu = n \\theta = 4 \\cdot 0.2 = 0.8.\\) Ciò significa che, se l’esperimento casuale venisse ripetuto infinite volte, l’esito testa verrebbe osservato un numero medio di volte pari a 0.8. La varianza è \\(n \\theta (1-\\theta) = 4 \\cdot 0.2 \\cdot (1 - 0.2) = 0.64\\)."
  },
  {
    "objectID": "022_discr_rv_distr.html#distribuzione-di-poisson",
    "href": "022_discr_rv_distr.html#distribuzione-di-poisson",
    "title": "13  Distribuzioni di v.c. discrete",
    "section": "\n13.3 Distribuzione di Poisson",
    "text": "13.3 Distribuzione di Poisson\nLa distribuzione di Poisson è una distribuzione di probabilità discreta che esprime le probabilità per il numero di eventi che si verificano successivamente ed indipendentemente in un dato intervallo di tempo, sapendo che mediamente se ne verifica un numero \\(\\lambda\\). La distribuzione di Poisson serve dunque per contare il numero di volte in cui un evento ha luogo in un determinato intervallo di tempo. La stessa distribuzione può essere estesa anche per contare gli eventi che hanno luogo in una determinata porzione di spazio.\n\nLa distribuzione di Poisson può essere intesa come limite della distribuzione binomiale, dove la probabilità di successo \\(\\theta\\) è pari a \\(\\frac{\\lambda}{n}\\) con \\(n\\) che tende a \\(\\infty\\):\n\\[\\begin{equation}\n\\lim_{y \\rightarrow \\infty} \\binom{n}{y} \\theta^y (1-\\theta)^{n-y} = \\frac{\\lambda^y}{y!}e^{-\\lambda}.\n\\end{equation}\\]\n\nAlcune distribuzioni di Poisson sono riportate nella figura Figura 13.2.\n\n\n\n\nFigura 13.2: Alcune distribuzioni di Poisson.\n\n\n\n\n\nEsercizio 13.5 Supponiamo che un evento accada 300 volte all’ora. Si vuole determinare la probabilità che in un minuto accadano esattamente 3 eventi.\n\n\nSoluzione. Il numero medio di eventi in un minuto è pari a\n\nlambda <- 300 / 60\nlambda\n#> [1] 5\n\nQuindi la probabilità che in un minuto si abbiano 3 eventi è pari a\n\ny <- 3\n(lambda^y / factorial(y)) * exp(-lambda)\n#> [1] 0.1403739\n\n\n\nEsercizio 13.6 Per i dati dell’Esercizio 13.5, si trovi la probabilità che un evento accada almeno 8 volte in un minuto.\n\n\nSoluzione. La probabilità cercata è\n\\[\np(y \\geq 8) = 1 - p (y \\leq 7) = 1- \\sum_{i = 0}^7 \\frac{\\lambda^7}{7!}e^{-\\lambda},\n\\]\ncon \\(\\lambda = 5\\).\nSvolgendo i calcoli in R otteniamo:\n\n1 - ppois(q = 7, lambda = 5)\n#> [1] 0.1333717\nppois(q = 7, lambda = 5, lower.tail = FALSE)\n#> [1] 0.1333717\n\n\n\nEsercizio 13.7 Sapendo che un evento avviene in media 6 volte al minuto, si calcoli (a) la probabilità di osservare un numero di eventi uguale o inferiore a 3 in un minuto, e (b) la probabilità di osservare esattamente 2 eventi in 30 secondi.\n\n\nSoluzione. Per la domanda (a), \\(\\lambda = 6\\) e la probabilità richiesta è\n\nppois(q = 3, lambda = 6, lower.tail = TRUE)\n#> [1] 0.1512039\n\nNel caso di (b), \\(\\lambda = 6 / 2\\) e la probabilità richiesta è\n\ndpois(x = 2, lambda = 3)\n#> [1] 0.2240418\n\n\n\n13.3.1 Alcune proprietà della variabile di Poisson\n\nIl valore atteso, la moda e la varianza della variabile di Poisson sono uguali a \\(\\lambda\\).\nLa somma \\(Y_1 + \\dots + Y_n\\) di \\(n\\) variabili casuali indipendenti con distribuzioni di Poisson di parametri \\(\\lambda_{1},\\dots,\\lambda_{n}\\) segue una distribuzione di Poisson di parametro \\(\\lambda = \\lambda_{1}+\\dots+\\lambda_{n}\\).\nLa differenze di due variabili di Poisson non è una variabile di Poisson. Basti infatti pensare che può assumere valori negativi."
  },
  {
    "objectID": "022_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "022_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "13  Distribuzioni di v.c. discrete",
    "section": "\n13.3 Distribuzione discreta uniforme",
    "text": "13.3 Distribuzione discreta uniforme\nUna distribuzione discreta uniforme è una distribuzione di probabilità discreta che è uniforme su un insieme, ovvero che attribuisce ad ogni elemento dell’insieme discreto e finito \\(S\\) su cui è definita la stessa probabilità \\(p\\) di verificarsi.\nSi consideri una variabile casuale \\(X\\) con supporto \\(1, 2, \\dots, m\\). Un esperimento casuale in cui si verifica questa distribuzione è la scelta casuale di un intero compreso tra 1 e \\(m\\) inclusi. Sia \\(X\\) il numero scelto. Allora\n\\[\nP(X = x) = \\frac{1}{m}, \\quad x = 1, \\dots, m.\n\\]\nIl valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^m x f_X(x) = \\sum_{x=1}^m x \\frac{1}{m} = \\frac{1}{m} (1 + 2 + \\dots + m) = \\frac{m+1}{2},\n\\]\ndove abbiamo utilizzato l’identità \\(1+2+···+m = m(m+1)/2\\).\nPer trovare la varianza, prima calcoliamo\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{m} \\sum_{x=1}^m x^2,\n\\] e poi troviamo\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\left[\\mathbb{E}(X)\\right]^2.\n\\]"
  },
  {
    "objectID": "022_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "022_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "13  Distribuzioni di v.c. discrete",
    "section": "\n13.4 Distribuzione beta-binomiale",
    "text": "13.4 Distribuzione beta-binomiale\nLa distribuzione beta-binomiale di parametri \\(N\\), \\(\\alpha\\) e \\(\\beta\\) è una distribuzione discreta con una funzione di massa di probabilità uguale a\n\\[\n\\mbox{BetaBinomial}(y \\mid N, \\alpha, \\beta) = \\binom{N}{y} \\frac{B(y + \\alpha, N-y+\\beta)}{B(\\alpha, \\beta)},\n\\tag{13.6}\\]\ndove la funzione beta è \\(B(u, v) = \\frac{\\Gamma(u)\\Gamma(v)}{\\Gamma(u+v)}\\)."
  },
  {
    "objectID": "022_discr_rv_distr.html#commenti-e-considerazioni-finali",
    "href": "022_discr_rv_distr.html#commenti-e-considerazioni-finali",
    "title": "13  Distribuzioni di v.c. discrete",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa distribuzione binomiale è una distribuzione di probabilità discreta che descrive il numero di successi in un processo di Bernoulli, ovvero la variabile aleatoria \\(Y = Y_1 + \\dots + Y_n\\) che somma \\(n\\) variabili casuali indipendenti di uguale distribuzione di Bernoulli \\(\\mathcal{B}(\\theta)\\), ognuna delle quali può fornire due soli risultati: il successo con probabilità \\(\\theta\\) e l’insuccesso con probabilità \\(1 - \\theta\\).\nLa distribuzione binomiale è molto importante per le sue molte applicazioni. Nelle presenti dispense dedicate all’analisi bayesiana, è importante perché costituisce il fondamento del caso più semplice dell’aggiornamento bayesiano, ovvero il caso Beta-Binomiale. Il modello Beta-Binomiale fornisce un esempio paradigmatico dell’approccio bayesiano all’inferenza e sarà trattato in maniera analitica nei capitoli successivi. È dunque importante che le proprietà della distribuzione binomiale risultino ben chiare."
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "023_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.1 Distribuzione Gaussiana",
    "text": "14.1 Distribuzione Gaussiana\nNon c’è un’unica distribuzione gaussiana (o normale): la distribuzione gaussiana è una famiglia di distribuzioni. Tali distribuzioni sono dette “gaussiane” in onore di Carl Friedrich Gauss (uno dei più grandi matematici della storia il quale, tra le altre cose, scoprì l’utilità di tale funzione di densità per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densità alle misurazioni dell’uomo. Karl Pearson usò per primo il termine “distribuzione normale” anche se ammise che questa espressione “ha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell’altro, non siano normali.”\n\n14.1.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre notò che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Con 10 prove e una probabilità di successo di 0.9 in ciascuna prova, la distribuzione è chiaramente asimmetrica.\n\n\n\n\nFigura 14.1: Probabilità del numero di successi in \\(N = 10\\) prove bernoulliane indipendenti, ciascuna con una probabilità di successo di 0.90. Il risultato è una distribuzione \\(\\mbox{Bin}(y \\mid 10, 0.9)\\). Con solo dieci prove, la distribuzione è fortemente asimmetrica negativa.\n\n\n\n\nMa se aumentiamo il numero di prove di un fattore di 100 a N = 1000, senza modificare la probabilità di successo di 0.9, la distribuzione assume una forma campanulare quasi simmetrica. Dunque, de Moivre scoprì che, quando N è grande, la funzione gaussiana (che introdurremo qui sotto), nonostante sia la densità di v.a. continue, fornisce una buona approssimazione alla funzione di massa di probabilità binomiale.\n\n\n\n\nFigura 14.2: Probabilità del numero di successi in \\(N = 1000\\) prove bernoulliane indipendenti, ciascuna con una probabilità di successo di 0.90. Il risultato è una distribuzione \\(\\mbox{Bin}(y \\mid 1000, 0.9)\\). Con mille prove, la distribuzione è quasi simmetrica a forma campanulare.\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione."
  },
  {
    "objectID": "023_cont_rv_distr.html#normal-random-walk",
    "href": "023_cont_rv_distr.html#normal-random-walk",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.2 La Normale prodotta con una simulazione",
    "text": "14.2 La Normale prodotta con una simulazione\nMcElreath (2020) illustra come sia possibile giungere alla distribuzione Normale mediante una simulazione. Supponiamo che vi siano mille persone tutte allineate su una linea di partenza. Quando viene dato un segnale, ciascuna persona lancia una moneta e fa un passo in avanti oppure all’indietro a seconda che sia uscita testa o croce. Supponiamo che la lunghezza di ciascun passo vari da 0 a 1 metro. Ciascuna persona lancia una moneta 16 volte e dunque compie 16 passi.\nAlla conclusione di queste passeggiate casuali (random walk) non possiamo sapere con esattezza dove si troverà ciascuna persona, ma possiamo conoscere con certezza le caratteristiche della distribuzione delle mille distanze dall’origine. Per esempio, possiamo predire in maniera accurata la proporzione di persone che si sono spostate in avanti oppure all’indietro. Oppure, possiamo predire accuratamente la proporzione di persone che si troveranno ad una certa distanza dalla linea di partenza (es., a 1.5 m dall’origine).\nQueste predizioni sono possibili perché tali distanze si distribuiscono secondo la legge Normale. I risultati di una tale simulazione sono riportati nella Figura 14.3.\n\n\n\n\nFigura 14.3: Passeggiata casuale di 4, 8 e 16 passi. La spezzata nera indica la media delle distanze dall’origine come funzione del numero di passi.\n\n\n\n\nUn kernel density plot delle distanze ottenute dopo 4, 8 e 16 passi è riportato nella Figura 14.4. Nel pannello di destra, al kernel density plot è stata sovrapposta una densità Normale di opportuni parametri (linea tratteggiata).\n\n\n\n\nFigura 14.4: Kernel density plot dei risultati della passeggiata casuale riportata nella figura precente, dopo 4, 8 e 16 passi. Nel pannello di destra, una densità Normale di opportuni parametri è sovrapposta all’istogramma lisciato.\n\n\n\n\nQuesta simulazione mostra che qualunque processo nel quale viene sommato un certo numero di valori casuali, tutti provenienti dalla medesima distribuzione, converge ad una distribuzione Normale. Non importa quale sia la forma della distribuzione di partenza: essa può essere uniforme, come nell’esempio presente, o di qualunque altro tipo. La forma della distribuzione da cui viene realizzato il campionamento determina la velocità della convergenza alla Normale. In alcuni casi la convergenza è lenta; in altri casi la convergenza è molto rapida (come nell’esempio presente).\nDa un punto di vista formale, diciamo che una variabile casuale continua \\(Y\\) ha una distribuzione Normale se la sua densità è\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{14.1}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma > 0\\) sono i parametri della distribuzione.\nLa densità normale è unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densità in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell’Equazione 14.1 viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densità Normali tutte con media 0 e con deviazioni standard 0.25, 0.5, 1 e 2 è fornita nella Figura 14.5.\n\n\n\n\nFigura 14.5: Alcune distribuzioni Normali.\n\n\n\n\n\n14.2.1 Concentrazione\nÈ istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma < Y < \\mu + \\sigma) &= P (-1 < Z < 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma < Y < \\mu + 2\\sigma) &= P (-2 < Z < 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma < Y < \\mu + 3\\sigma) &= P (-3 < Z < 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media è superiore a 3 volte la deviazione standard presenti un carattere di eccezionalità perché meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n14.2.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) è l’area sottesa alla curva di densità \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\tag{14.2}\\]\npertanto le probabilità \\(P(Y < y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\n\nEsercizio 14.1 Usiamo \\(\\mathsf{R}\\) per calcolare la funzione di ripartizione della Normale. La funzione pnorm(q, mean, sd) restituisce la funzione di ripartizione della Normale con media mean e deviazione standard sd, ovvero l’area sottesa alla funzione di densità di una Normale con media mean e deviazione standard sd nell’intervallo \\([-\\infty, q]\\).\nPer esempio, in precedenza abbiamo detto che il 68% circa dell’area sottesa ad una Normale è compresa nell’intervallo \\(\\mu \\pm \\sigma\\). Verifichiamo per la distribuzione del QI \\(\\sim \\mathcal{N}(\\mu = 100, \\sigma = 15)\\):\n\nfrom statistics import NormalDist\nNormalDist(mu=100, sigma=15).cdf(100+15) - NormalDist(mu=100, sigma=15).cdf(100-15)\n#> 0.6826894921370859\n\nIl 95% dell’area è compresa nell’intervallo \\(\\mu \\pm 1.96 \\cdot\\sigma\\):\n\nNormalDist(mu=100, sigma=15).cdf(100+1.96*15) - NormalDist(mu=100, sigma=15).cdf(100-1.96*15)\n#> 0.9500042097035593\n\nQuasi tutta la distribuzione è compresa nell’intervallo \\(\\mu \\pm 3 \\cdot\\sigma\\):\n\nNormalDist(mu=100, sigma=15).cdf(100+3*15) - NormalDist(mu=100, sigma=15).cdf(100-3*15)\n#> 0.9973002039367398\n\n\n\n14.2.3 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale è l’insieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL’area sottesa alla curva di densità di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) è uguale all’area sottesa alla densità Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) è il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l’area sottesa nella semiretta \\([1, \\infty)\\) è uguale all’area sottesa nella semiretta \\((-\\infty, 1]\\) e quest’ultima coincide con \\(F(-1)\\). Analogamente, l’area sottesa nell’intervallo \\([y_a, y_b]\\), con \\(y_a < y_b\\), è pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema è quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z < z) = p\\). Il valore \\(z\\) cercato è detto quantile di ordine \\(p\\) della Normale standard e può essere trovato mediante un software.\n\nEsercizio 14.2 Supponiamo che l’altezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un’altezza compresa tra \\(1.7\\) e \\(1.8\\) m.\n\n\nSoluzione. Il problema ci chiede di trovare l’area sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell’intervallo \\([1.7, 1.8]\\):\n\n\n\n\n\n\n\n\nLa risposta si trova utilizzando la funzione di ripartizione \\(F(X)\\) della legge \\(\\mathcal{N}(1.7, 0.1)\\) in corrispondenza dei due valori forniti dal problema: \\(F(X = 1.8) - F(X = 1.7)\\). Utilizzando la seguente istruzione\n\nNormalDist(mu=1.7, sigma=0.1).cdf(1.8) - NormalDist(mu=1.7, sigma=0.1).cdf(1.7)\n#> 0.34134474606854315\n\notteniamo il \\(34.13\\%\\).\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l’intervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell’intervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\nNormalDist(mu=0.0, sigma=1.0).cdf(1.0) - NormalDist(mu=0.0, sigma=1.0).cdf(0.0)\n#> 0.3413447460685429\n\nIl modo più semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilità richiesta non è altro che la metà dell’area sottesa dalle distribuzioni Normali nell’intervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\n\n\n14.2.3.1 Funzione di ripartizione della normale standard e funzione logistica\nSi noti che la funzione logistica (in blu), pur essendo del tutto diversa dalla Normale dal punto di vista formale, assomiglia molto alla Normale standard quando le due cdf hanno la stessa varianza."
  },
  {
    "objectID": "023_cont_rv_distr.html#teorema-del-limite-centrale",
    "href": "023_cont_rv_distr.html#teorema-del-limite-centrale",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.3 Teorema del limite centrale",
    "text": "14.3 Teorema del limite centrale\nLaplace dimostrò il teorema del limite centrale (TLC) nel 1812. Il TLC dice che se prendiamo una sequenza di variabili casuali indipendenti e le sommiamo, tale somma tende a distribuirsi come una Normale. Inoltre, il TLC specifica, sulla base dei valori attesi e delle varianze delle v.c. che vengono sommate, quali sono i parametri della distribuzione Normale così ottenuta.\n\nTeorema 14.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(\\mbox{SD}(Y_i) = \\sigma\\). Si definisca una nuova v.c. come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tenderà ad una Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard che sarà più piccola della deviazione standard originaria di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{1}{\\sqrt{n}} \\cdot \\sigma \\right).\n\\]\n\nIl TLC può essere generalizzato a variabili che non hanno la stessa distribuzione purché siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l’altezza dell’uomo adulto di entrambi i generi, sono il risultato di una serie di effetti additivi relativamente piccoli, la cui combinazione porta alla normalità, indipendentemente da come gli effetti additivi sono distribuiti. Questo è il motivo per cui la distribuzione normale forniscre una buona rappresentazione della distribuzione di molti fenomeni naturali."
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "023_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.4 Distribuzione Chi-quadrato",
    "text": "14.4 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libertà. La densità di probabilità di \\(\\chi^2_{~\\nu}\\) è\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x > 0,\n\\]\ndove \\(C_{\\nu}\\) è una costante positiva.\nLa Figura 14.6 mostra alcune distribuzioni Chi-quadrato variando il parametro \\(\\nu\\).\n\n\n\n\nFigura 14.6: Alcune distribuzioni Chi-quadrato.\n\n\n\n\n\n14.4.1 Proprietà\n\nLa distribuzione di densità \\(\\chi^2_{~\\nu}\\) è asimmetrica.\nIl valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) è uguale a \\(\\nu\\).\nLa varianza di una variabile \\(\\chi^2_{~\\nu}\\) è uguale a \\(2\\nu\\).\nPer \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\).\nSe \\(X\\) e \\(Y\\) sono due variabili casuali chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libertà, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende a qualunque numero finito di variabili casuali chi-quadrato indipendenti."
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "023_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.5 Distribuzione \\(t\\) di Student",
    "text": "14.5 Distribuzione \\(t\\) di Student\nDalle distribuzioni Normale e Chi-quadrato deriva un’altra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}\\) e \\(W \\sim \\chi^2_{~\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto\n\\[\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\tag{14.3}\\]\ndefinisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si usa scrivere \\(T \\sim t_{\\nu}\\). L’andamento della distribuzione \\(t\\) di Student è simile a quello della distribuzione Normale, ma ha una dispersione maggiore (ha le code più pesanti di una Normale, ovvero ha una varianza maggiore di 1).\nLa Figura 14.7 mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\).\n\n\n\n\nFigura 14.7: Alcune distribuzioni \\(t\\) di Student.\n\n\n\n\n\n14.5.1 Proprietà\nLa variabile casuale \\(t\\) di Student soddisfa le seguenti proprietà:\n\nPer \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard \\(\\mathcal{N}(0, 1)\\).\nLa densità della \\(t_{\\nu}\\) è una funzione simmetrica con valore atteso nullo.\nPer \\(\\nu > 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\); pertanto è sempre maggiore di 1 e tende a 1 per \\(\\nu \\rightarrow \\infty\\)."
  },
  {
    "objectID": "023_cont_rv_distr.html#funzione-beta",
    "href": "023_cont_rv_distr.html#funzione-beta",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.6 Funzione beta",
    "text": "14.6 Funzione beta\nLa funzione beta di Eulero è una funzione matematica, non una densità di probabilità. La menzioniamo qui perché viene utilizzata nella distribuzione Beta. La funzione beta si può scrivere in molti modi diversi; per i nostri scopi la scriveremo così:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{14.4}\\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, ovvero il fattoriale discendente, cioè\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\n\nEsercizio 14.4 \nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione beta assume il valore\n\nalpha <- 3\nbeta <- 9\nbeta(alpha, beta)\n#> [1] 0.002020202\n\nPer chiarire, lo stesso risultato si ottiene con\n\n((2) * (8 * 7 * 6 * 5 * 4 * 3 * 2)) / \n  (11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2)\n#> [1] 0.002020202\n\novvero\n\ngamma(alpha) * gamma(beta) / gamma(alpha + beta)\n#> [1] 0.002020202"
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-beta",
    "href": "023_cont_rv_distr.html#distribuzione-beta",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.7 Distribuzione Beta",
    "text": "14.7 Distribuzione Beta\nLa distribuzione Beta è una distribuzione usata per modellare percentuali e proporzioni in quanto è definita sull’intervallo \\((0; 1)\\) – ovvero, non include i valori 0 o 1.\n\nDefinizione 14.1 Sia \\(\\pi\\) una variabile casuale che può assumere qualsiasi valore compreso tra 0 e 1, cioè \\(\\pi \\in [0, 1]\\). Diremo che \\(\\pi\\) segue la distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\), \\(\\pi \\sim \\text{Beta}(\\alpha, \\beta)\\), se la sua densità è\n\\[\n\\begin{align}\n\\text{Beta}(\\pi \\mid \\alpha, \\beta) &= \\frac{1}{B(\\alpha, \\beta)}\\pi^{\\alpha-1} (1-\\pi)^{\\beta-1}\\notag\\\\\n&=  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\pi^{\\alpha-1} (1-\\pi)^{\\beta-1} \\quad \\text{per } \\pi \\in [0, 1]\\,,\n\\end{align}\n\\tag{14.5}\\]\nladdove \\(B(\\alpha, \\beta)\\) è la funzione beta di Eulero.\n\nI termini \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione Beta e devono essere entrambi positivi. Tali parametri possono essere interpretati come l’espressione delle nostre credenze a priori relative ad una sequenza di prove Bernoulliane. Il parametro \\(\\alpha\\) rappresenta il numero di “successi” e il parametro \\(\\beta\\) il numero di “insuccessi”:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nIl rapporto \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha+b)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) è una costante di normalizzazione:\n\\[\n\\int_0^1 \\pi^{\\alpha-1} (1-\\pi)^{\\beta-1} = \\frac{\\Gamma(\\alpha+b)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\,.\n\\]\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\) abbiamo\n\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef integrand(p, a, b):\n    return p**(a-1) * (1-p)**(b-1)\n\na = 3\nb = 9\nresult, error = quad(integrand, 0, 1, args=(a, b))\nprint(result)\n#> 0.00202020202020202\n\novvero\n\nimport math\n\na = 3\nb = 9\n\nresult = math.gamma(a) * math.gamma(b) / math.gamma(a + b)\nprint(result)\n#> 0.00202020202020202\n\novvero\n\nsc.beta(a, b)\n#> 0.00202020202020202\n\nIl valore atteso, la moda e la varianza di una distribuzione Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\pi) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\tag{14.6}\\]\n\\[\n\\mbox{Mo}(\\pi) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\tag{14.7}\\]\n\\[\n\\mathbb{V}(\\pi) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\tag{14.8}\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un’illustrazione è fornita dalla seguente GIF animata.\nSi può ottenere una rappresentazione grafica della distribuzione \\(\\mbox{Beta}(\\pi \\mid \\alpha, \\beta)\\) nel modo seguente.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import beta\nimport math\n\na, b = 3, 9\n\nx = np.linspace(0.001, 0.999, num=100)\n\nplt.plot(x, beta.pdf(x, a, b), 'r-')\nplt.xlim(0.0, 1.0)\n#> (0.0, 1.0)\nplt.title('Distribuzione Beta')\nplt.xlabel('Valori di una variabile casuale X (0, 1)')\nplt.ylabel('Densità')\nplt.show()\n\n\n\n\n\n\n\nLa funzione beta_mean_mode_variance() ci restituisce la media, moda e varianza della distribuzione Beta.\n\ndef beta_mean_mode_variance(alpha, beta):\n    mean = alpha / (alpha + beta)\n    mode = (alpha - 1) / (alpha + beta - 2)\n    variance = alpha * beta / ((alpha + beta)**2 * (alpha + beta + 1))\n    return mean, mode, variance\n\nPer esempio:\n\nalpha = 3\nbeta = 9\nmean, mode, variance = beta_mean_mode_variance(alpha, beta)\nprint(f'Mean: {mean}, Mode: {mode}, Variance: {variance}')\n#> Mean: 0.25, Mode: 0.2, Variance: 0.014423076923076924\n\n\nNota. Attenzione alle parole: in questo contesto, il termine “beta” viene utilizzato con tre significati diversi:\n\nla distribuzione di densità Beta,\nla funzione matematica beta,\nil parametro \\(\\beta\\)."
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "023_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.8 Distribuzione di Cauchy",
    "text": "14.8 Distribuzione di Cauchy\nLa distribuzione di Cauchy è un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libertà. È definita da una densità di probabilità che corrisponde alla seguente funzione, dipendente da due parametri \\(\\theta\\) e \\(d\\) (con la condizione \\(d > 0\\)),\n\\[\nf(x; \\theta, d) = \\frac{1}{\\pi d} \\frac{1}{1 + \\left(\\frac{x - \\theta}{d} \\right)^2},\n\\tag{14.9}\\]\ndove \\(\\theta\\) è la mediana della distribuzione e \\(d\\) ne misura la larghezza a metà altezza."
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-log-normale",
    "href": "023_cont_rv_distr.html#distribuzione-log-normale",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.9 Distribuzione log-normale",
    "text": "14.9 Distribuzione log-normale\nSia \\(y\\) una variabile casuale avente distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo poi una nuova variabile casuale \\(x\\) attraverso la relazione\n\\[\nx = e^y \\quad \\Longleftrightarrow \\quad y = \\log x.\n\\] Il dominio di definizione della \\(x\\) è il semiasse \\(x > 0\\) e la densità di probabilità \\(f(x)\\) è data da\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\frac{1}{x} \\exp \\left\\{-\\frac{(\\log x -  \\mu)^2}{2 \\sigma^2} \\right\\}.\n\\tag{14.10}\\]\nQuesta funzione di densità è chiamata log-normale.\nIl valore atteso e la varianza di una distribuzione log-normale sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(x) = \\exp \\left\\{\\mu + \\frac{\\sigma^2}{2} \\right\\}.\n\\]\n\\[\n\\mathbb{V}(x) = \\exp \\left\\{2 \\mu + \\sigma^2 \\right\\} \\left(\\exp \\left\\{\\sigma^2 \\right\\}  -1\\right).\n\\]\nSi può dimostrare che il prodotto di variabili casuali log-normali ed indipendenti segue una distribuzione log-normale."
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-di-pareto",
    "href": "023_cont_rv_distr.html#distribuzione-di-pareto",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.10 Distribuzione di Pareto",
    "text": "14.10 Distribuzione di Pareto\nLa distribuzione paretiana (o distribuzione di Pareto) è una distribuzione di probabilità continua e così chiamata in onore di Vilfredo Pareto. La distribuzione di Pareto è una distribuzione di probabilità con legge di potenza utilizzata nella descrizione di fenomeni sociali e molti altri tipi di fenomeni osservabili. Originariamente applicata per descrivere la distribuzione del reddito in una società, adattandosi alla tendenza che una grande porzione di ricchezza è detenuta da una piccola frazione della popolazione, la distribuzione di Pareto è diventata colloquialmente nota e indicata come il principio di Pareto, o “regola 80-20”. Questa regola afferma che, ad esempio, l’80% della ricchezza di una società è detenuto dal 20% della sua popolazione. Viene spesso applicata nello studio della distribuzione del reddito, della dimensione dell’impresa, della dimensione di una popolazione e nelle fluttuazioni del prezzo delle azioni.\nLa densità di una distribuzione di Pareto è\n\\[\nf(x)=(x_m/x)^\\alpha,\n\\tag{14.11}\\]\ndove \\(x_m\\) (parametro di scala) è il minimo (necessariamente positivo) valore possibile di \\(X\\) e \\(\\alpha\\) è un parametro di forma.\n\n\n\n\n\n\n\n\nLa distribuzione di Pareto ha una asimmetria positiva. Il supporto della distribuzione di Pareto è la retta reale positiva. Tutti i valori devono essere maggiori del parametro di scala \\(x_m\\), che è in realtà un parametro di soglia."
  },
  {
    "objectID": "023_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "href": "023_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questa dispensa le densità continue che useremo più spesso sono la distribuzione gaussiana e la distribuzione Beta. Faremo un uso limitato della distribuzione \\(t\\) di Student e della distribuzione di Cauchy. Le altre distribuzioni qui descritte sono stato presentate per completezza.\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press."
  },
  {
    "objectID": "024_likelihood.html#modello-binomiale",
    "href": "024_likelihood.html#modello-binomiale",
    "title": "15  La funzione di verosimiglianza",
    "section": "\n15.1 Modello binomiale",
    "text": "15.1 Modello binomiale\nPer chiarire il concetto di verosimiglianza consideriamo innanzitutto il caso più semplice, ovvero quello Binomiale.\nPer \\(n\\) prove Bernoulliane indipendenti, le quali producono \\(y\\) successi e (\\(n-y\\)) insuccessi, la funzione nucleo di verosimiglianza (ovvero, la funzione di verosimiglianza da cui sono state escluse tutte le costanti moltiplicative che non hanno alcun effetto su \\(\\hat{\\theta}\\)) è\n\\[\n\\mathcal{L}(p \\mid y) = \\theta^y (1-\\theta)^{n - y}.\\notag\n\\tag{15.1}\\]\nPer fare un esempio pratico, consideriamo la ricerca di Zetsche et al. (2019). Questi ricercatori hanno trovato che, su 30 pazienti clinicamente depressi, 23 manifestavano delle aspettative distorsione negativamente relativamente al loro umore futuro. Se i dati di Zetsche et al. (2019) vengono riassunti mediante una proporzione (ovvero, 23/30), allora è sensato adottare un modello probabilistico binomiale quale meccanismo generatore dei dati:\n\\[\ny  \\sim \\mbox{Bin}(n, \\theta),\n\\tag{15.2}\\]\nladdove \\(\\theta\\) è la probabiltà che una prova Bernoulliana assuma il valore 1 e \\(n\\) corrisponde al numero di prove Bernoulliane. Questo modello assume che le prove Bernoulliane \\(y\\) che costituiscono il campione siano tra loro indipendenti e che ciascuna abbia la stessa probabilità \\(\\theta \\in [0, 1]\\) di essere un “successo” (valore 1). In altre parole, il modello generatore dei dati avrà la seguente funzione di massa di probabilità\n\\[\np(y \\mid \\theta)\n\\ = \\\n\\mbox{Bin}(y \\mid n, \\theta).\n\\]\nNei capitoli precedenti è stato mostrato come, sulla base del modello binomiale, sia possibile assegnare una probabilità a ciascun possibile valore \\(y \\in \\{0, 1, \\dots, n\\}\\) assumendo noto il valore del parametro \\(\\theta\\). Ma ora abbiamo il problema inverso, ovvero quello di fare inferenza su \\(\\theta\\) alla luce dei dati campionari \\(y\\). In altre parole, riteniamo di conoscere il modello probabilistico che ha generato i dati, ma di tale modello non conosciamo i parametri: vogliamo dunque ottenere informazioni su \\(\\theta\\) avendo osservato i dati \\(y\\). Per fare questo, in un ottica bayesiana, è innanzitutto necessario definire la funzione di verosimiglianza.\nPer i dati di Zetsche et al. (2019), la funzione di verosimiglianza corrisponde alla funzione binomiale di parametro \\(\\theta \\in [0, 1]\\) sconosciuto. Abbiamo osservato \\(y\\) = 23 successi, in \\(n\\) = 30 prove.\n\nn = 30\ny = 23\n\nLa funzione di verosimiglianza dunque diventa\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} \\theta^{23} + (1-\\theta)^7.\n\\tag{15.3}\\]\nPer costruire la funzione di verosimiglianza dobbiamo applicare l’Equazione 15.3 tante volte, cambiando ogni volta il valore \\(\\theta\\), ma tenendo sempre costante il valore dei dati. Nella seguente simulazione considereremo 100 possibili valori \\(\\theta \\in [0, 1]\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom\nimport math\nplt.style.use(\"seaborn-v0_8\")\n\ntheta = np.linspace(0.0, 1.0, num=100)\nprint(theta)\n#> [0.         0.01010101 0.02020202 0.03030303 0.04040404 0.05050505\n#>  0.06060606 0.07070707 0.08080808 0.09090909 0.1010101  0.11111111\n#>  0.12121212 0.13131313 0.14141414 0.15151515 0.16161616 0.17171717\n#>  0.18181818 0.19191919 0.2020202  0.21212121 0.22222222 0.23232323\n#>  0.24242424 0.25252525 0.26262626 0.27272727 0.28282828 0.29292929\n#>  0.3030303  0.31313131 0.32323232 0.33333333 0.34343434 0.35353535\n#>  0.36363636 0.37373737 0.38383838 0.39393939 0.4040404  0.41414141\n#>  0.42424242 0.43434343 0.44444444 0.45454545 0.46464646 0.47474747\n#>  0.48484848 0.49494949 0.50505051 0.51515152 0.52525253 0.53535354\n#>  0.54545455 0.55555556 0.56565657 0.57575758 0.58585859 0.5959596\n#>  0.60606061 0.61616162 0.62626263 0.63636364 0.64646465 0.65656566\n#>  0.66666667 0.67676768 0.68686869 0.6969697  0.70707071 0.71717172\n#>  0.72727273 0.73737374 0.74747475 0.75757576 0.76767677 0.77777778\n#>  0.78787879 0.7979798  0.80808081 0.81818182 0.82828283 0.83838384\n#>  0.84848485 0.85858586 0.86868687 0.87878788 0.88888889 0.8989899\n#>  0.90909091 0.91919192 0.92929293 0.93939394 0.94949495 0.95959596\n#>  0.96969697 0.97979798 0.98989899 1.        ]\n\nPer esempio, ponendo \\(\\theta = 0.1\\) otteniamo il seguente valore dell’ordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.1^{23} + (1-0.1)^7.\n\\]\n\nbinom.pmf(23, 30, 0.1)\n#> 9.7371682902e-18\n\nPonendo \\(\\theta = 0.2\\) otteniamo il seguente valore dell’ordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.2^{23} + (1-0.2)^7.\n\\]\n\nbinom.pmf(23, 30, 0.2)\n#> 3.58141723492221e-11\n\nSe ripetiamo questo processo 100 volte, una volta per ciascuno dei valori \\(\\theta\\) considerati, otteniamo 100 coppie di punti \\(\\theta\\) e \\(f(\\theta)\\).\n\ndef like(n, r, theta):\n  return math.comb(n, r) * theta**r * (1-theta)**(n-r)\n\nLa curva che interpola tali punti è la funzione di verosimiglianza. La Figura 15.1 fornisce una rappresentazione grafica di tale funzione.\n\nn = 30\nr = 23\nplt.plot(theta, like(n=n, r=r, theta=theta), 'r-')\nplt.title('Funzione di verosimiglianza', fontsize=16)\nplt.xlabel('Valore della variabile casuale theta [0, 1]', fontsize=14)\nplt.ylabel('Verosimiglianza', fontsize=14)\nplt.show()\n\n\n\nFigura 15.1: Funzione di verosimiglianza nel caso di 23 successi in 30 prove.\n\n\n\n\n\n15.1.1 Interpretazione\nCome possiamo interpretare la curva che abbiamo ottenuto? Per alcuni valori \\(\\theta\\) la funzione di verosimiglianza assume valori piccoli; per altri valori \\(\\theta\\) la funzione di verosimiglianza assume valori più grandi. Questi ultimi sono i valori \\(\\theta\\) più credibili e il valore 23/30 = 0.767 (la moda della funzione di verosimiglianza) è il valore più credibile di tutti.\n\ninput_list = like(n=n, r=r, theta=theta)\nmax = input_list[0]\nindex = 0\nfor i in range(1,len(input_list)):\n    if input_list[i] > max:\n        max = input_list[i]\n        index = i\nprint(f'Index of the maximum value is : {index}')\n#> Index of the maximum value is : 76\n\n\ntheta[76]\n#> 0.7676767676767677\n\nSi noti che, anziché usare la funzione like() che (per chiarezza) abbiamo definito sopra, in una maniera del tutto equivalente è possibile usare la funzione binom.pmf().\n\nn = 30\nr = 23\nplt.plot(theta,  binom.pmf(r, n, theta), 'r-')\nplt.title('Funzione di verosimiglianza', fontsize=16)\nplt.xlabel('Valore della variabile casuale theta [0, 1]', fontsize=14)\nplt.ylabel('Verosimiglianza', fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\n15.1.2 La log-verosimiglianza\nDal punto di vista pratico risulta più conveniente utilizzare, al posto della funzione di verosimiglianza, il suo logaritmo naturale, ovvero la funzione di log-verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta).\n\\tag{15.4}\\]\nPoiché il logaritmo è una funzione strettamente crescente (usualmente si considera il logaritmo naturale), allora \\(\\mathcal{L}(\\theta)\\) e \\(\\ell(\\theta)\\) assumono il massimo (o i punti di massimo) in corrispondenza degli stessi valori di \\(\\theta\\):\n\\[\n\\hat{\\theta} = \\mbox{argmax}_{\\theta \\in \\Theta} \\ell(\\theta) = \\mbox{argmax}_{\\theta \\in \\Theta} \\mathcal{L}(\\theta).\n\\]\nPer le proprietà del logaritmo, la funzione nucleo di log-verosimiglianza della binomiale è\n\\[\n\\begin{aligned}\n\\ell(\\theta \\mid y) &= \\log \\mathcal{L}(\\theta \\mid y) \\notag\\\\\n          &= \\log \\left(\\theta^y (1-\\theta)^{n - y} \\right) \\notag\\\\\n          &= \\log \\theta^y + \\log \\left( (1-\\theta)^{n - y} \\right) \\notag\\\\\n          &= y \\log \\theta + (n - y) \\log (1-\\theta).\\notag\n\\end{aligned}\n\\]\nSi noti che non è necessario lavorare con i logaritmi, ma è fortemente consigliato. Il motivo è che i valori della verosimiglianza, in cui si moltiplicano valori di probabilità molto piccoli, possono diventare estremamente piccoli – qualcosa come \\(10^{-34}\\). In tali circostanze, non è sorprendente che i programmi dei computer mostrino problemi di arrotondamento numerico. Le trasformazioni logaritmiche risolvono questo problema.\nSvolgiamo nuovamente il problema precedente usando la log-verosimiglianza per trovare il massimo della funzione di log-verosimiglianza. Ora utilizziamo la funzione binom.logpmf().\nLa funzione di log-verosimiglianza è rappresentata nella Figura 15.2.\n\nn = 30\nr = 23\nplt.plot(theta, binom.logpmf(r, n, theta), 'r-')\nplt.title('Funzione di log-verosimiglianza', fontsize=16)\nplt.xlabel('Valore della variabile casuale theta [0, 1]', fontsize=14)\nplt.ylabel('Log-verosimiglianza', fontsize=14)\nplt.show()\n\n\n\nFigura 15.2: Funzione di log-verosimiglianza nel caso di 23 successi in 30 prove.\n\n\n\n\nIl risultato replica quello trovato in precedenza con la funzione di verosimiglianza.\n\ninput_list = binom.logpmf(r, n, theta)\n\n\nmax = input_list[0]\nindex = 0\nfor i in range(1,len(input_list)):\n    if input_list[i] > max:\n        max = input_list[i]\n        index = i\nprint(f'Index of the maximum value is : {index}')\n#> Index of the maximum value is : 76\n\n\ntheta[index]\n#> 0.7676767676767677"
  },
  {
    "objectID": "024_likelihood.html#modello-gaussiano",
    "href": "024_likelihood.html#modello-gaussiano",
    "title": "15  La funzione di verosimiglianza",
    "section": "\n15.2 Modello gaussiano",
    "text": "15.2 Modello gaussiano\nOra che abbiamo capito come costruire la funzione verosimiglianza di una binomiale è relativamente semplice fare un passo ulteriore e considerare la verosimiglianza del caso di una funzione di densità, ovvero nel caso di una variabile casuale continua. Consideriamo qui il caso della Normale. La densità di una distribuzione Normale di parametri \\(\\mu\\) e \\(\\sigma\\) è\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left\\{-\\frac{1}{2\\sigma^2}(y-\\mu)^2\\right\\}.\n\\tag{15.5}\\]\nCostruiamo dunque la funzione di verosimiglianza nel caso dell’Equazione 15.5.\n\n15.2.1 Una singola osservazione\nEsaminiamo prima il caso in cui i dati corrispondono ad una singola osservazione \\(y\\). Poniamo\n\ny = 114\n\nL’Equazione 15.5 dipende dai parametri \\(\\mu\\) e \\(\\sigma\\) e dai dati \\(y\\). Per semplicità, ipotizziamo \\(\\sigma\\) noto e uguale a 15. Nell’esercizio considereremo 1000 valori \\(\\mu\\) compresi tra 70 e 160.\n\nmu = np.linspace(70.0, 160.0, num=1000)\n\nDato che consideriamo 1000 possibili valori \\(\\mu\\), per costruire la funzione di verosimiglianza applicheremo 1000 volte l’Equazione 15.5. In ciascun passo dell’esercizio inseriremo nell’Equazione 15.5\n\nil singolo valore \\(y\\) considerato (che viene mantenuto costante),\nil valore \\(\\sigma\\) assunto noto (anch’esso costante),\nuno alla volta ciascuno dei valori \\(\\mu\\) che abbiamo definito sopra (quindi, nelle 1000 applicazioni dell’Equazione 15.5, il valore \\(\\mu\\) è l’unico che varia: \\(y\\) e \\(\\sigma\\) sono mantenuti costanti).\n\nLa distribuzione Gaussiana è implementata in Python mediante norm.pdf(). La funzione norm.pdf() richiede tre argomenti: il valore \\(y\\) (o il vettore \\(y\\)), la media, ovvero il parametro \\(\\mu\\), e la deviazione standard, ovvero il parametro \\(\\sigma\\).\nApplicando la funzione norm.pdf() 1000 volte, una volta per ciascuno dei valori \\(\\mu\\) che abbiamo definito (e tenendo fissi \\(y = 114\\) e \\(\\sigma = 15\\)), otteniamo 1000 valori \\(f(\\mu)\\).\n\nfrom scipy.stats import norm\n\nf_mu = norm.pdf(y, loc=mu, scale=15)\n\nLa funzione di verosimiglianza è la curva che interpola i punti \\(\\big(\\mu, f(\\mu)\\big)\\).\n\nplt.plot(mu, f_mu, 'r-')\nplt.title('Funzione di verosimiglianza', fontsize=16)\nplt.xlabel('Valore della variabile casuale mu [70, 160]', fontsize=14)\nplt.ylabel('Verosimiglianza', fontsize=14)\nplt.xlim([70, 160])\n#> (70.0, 160.0)\nplt.show()\n\n\n\n\n\n\n\nSi noti che la funzione di verosimiglianza così trovata ha la forma della distribuzione Gaussiana. Nel caso di una singola osservazione, ma solo in questo caso, ha anche un’area unitaria.\nPer l’esempio presente, la moda della funzione di verosimiglianza è 114.\n\n15.2.2 Un campione di osservazioni\nConsideriamo ora il caso più generale, ovvero quello di un campione di \\(n\\) osservazioni. Possiamo immaginare un campione casuale \\(y_1, y_2, \\dots, y_n\\) estratto da una popolazione \\(\\mathcal{N}(\\mu, \\sigma)\\) come una sequenza di realizzazioni indipendenti ed identicamente distribuite (di seguito, i.i.d.) della medesima variabile casuale \\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\). I parametri sconosciuti sono \\(\\theta = \\{\\mu, \\sigma\\}\\).\nSe le variabili casuali \\(y_1, y_2, \\dots, y_n\\) sono i.i.d., la loro densità congiunta è data da: \\[\\begin{align}\nf(y \\mid \\theta) &= f(y_1 \\mid \\theta) \\cdot f(y_2 \\mid \\theta) \\cdot \\; \\dots \\; \\cdot f(y_n \\mid \\theta)\\notag\\\\\n                 &= \\prod_{i=1}^n f(y_i \\mid \\theta),\n\\end{align}\\]\nladdove \\(f(\\cdot)\\) è la densità Gaussiana di parametri \\(\\mu, \\sigma\\). Tenendo costanti i dati \\(y\\), la funzione di verosimiglianza diventa:\n\\[\\begin{equation}\n\\mathcal{L}(\\theta \\mid y) = \\prod_{i=1}^n f(y_i \\mid \\theta).\n\\end{equation}\\]\nPer chiarire la formula precedente, consideriamo un esempio che utilizza come dati i valori BDI-II dei trenta soggetti del campione clinico di Zetsche et al. (2020).\n\ny = [26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, \n    31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22]\n\nCi poniamo l’obiettivo di creare la funzione di verosimiglianza per questi dati, supponendo di sapere (in base ai risultati di ricerche precedenti) che i punteggi BDI-II si distribuiscono secondo la legge Normale e supponendo \\(\\sigma\\) noto e uguale alla deviazione standard del campione.\n\ntrue_sigma = np.std(y)\ntrue_sigma \n#> 6.495810615739622\n\nAbbiamo visto in precedenza che, per una singola osservazione, la funzione di verosimiglianza è la densità Gaussiana espressa in funzione dei parametri (in questo caso, solo \\(\\mu\\)). Per un campione di osservazioni i.i.d., ovvero \\(y = (y_1, y_2, \\dots, y_n)\\), la verosimiglianza è la funzione di densità congiunta \\(f(y \\mid \\mu, \\sigma)\\) espressa in funzione dei parametri. Dato che le osservazioni sono i.i.d., la densità congiunta è data dal prodotto delle densità delle singole osservazioni.\nPoniamoci il problema di trovare l’ordinata della funzione di log-verosimiglianza per le 30 osservazioni del campione in corrispondenza di \\(\\mu = \\mu_0\\)\nPer la prima osservazione del campione (\\(y_1 = 26\\)) abbiamo\n\\[\nf(26 \\mid \\mu_0, \\sigma=6.50) = \\frac{1}{{6.50 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(26 - \\mu_0)^2}{2\\cdot 6.50^2}}\\right\\}.\n\\]\nSe consideriamo tutte le osservazioni, la densità congiunta è data dal prodotto delle densità delle singole osservazioni: \\(f(y \\mid \\mu, \\sigma = 6.50) = \\, \\prod_{i=1}^n f(y_i \\mid \\mu, \\sigma = 6.50)\\). Utilizzando i dati del campione, e assumendo \\(\\sigma = 6.50\\), l’ordinata della funzione di verosimiglianza in corrispondenza di \\(\\mu_0\\) è uguale a\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\mu_0, \\sigma=6.50 \\mid y) =& \\, \\prod_{i=1}^{30} f(y_i \\mid \\mu_0, \\sigma = 6.50) = \\notag\\\\\n& \\frac{1}{{6.50 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(26 - \\mu_0)^2}{2\\cdot 6.50^2}}\\right\\} \\times \\notag\\\\\n& \\frac{1}{{6.61 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(35 - \\mu_0)^2}{2\\cdot 6.50^2}}\\right\\} \\times  \\notag\\\\\n& \\vdots \\notag\\\\\n& \\frac{1}{{6.61 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(22 - \\mu_0)^2}{2\\cdot 6.50^2}}\\right\\}.\n\\end{aligned}\n\\]\nÈ più conveniente svolgere i calcoli usando il logaritmo della verosimiglianza. In Python definiamo la funzione di log-verosimiglianza, log_likelihood(), che prende come argomenti y, mu e sigma = 6.50.\n\ndef log_likelihood(y, mu, sigma = true_sigma):\n    return np.sum(norm.logpdf(y, loc=mu, scale=15))\n\nConsideriamo il valore \\(\\mu_0 = \\bar{y}\\), ovvero\n\nbar_y = np.mean(y)\nprint(bar_y)\n#> 30.933333333333334\n\nL’ordinata della funzione di log-verosimiglianza in corrispondenza di \\(\\mu = 30.93\\) è\n\nprint(log_likelihood(y, 30.93, sigma = true_sigma))\n#> -111.62269980698424\n\nTroviamo ora i valori della log-verosimiglianza per ciascuno dei 1000 valori \\(\\mu\\) nell’intervallo \\([\\bar{y} - 2 \\sigma, \\bar{y} + 2 \\sigma]\\). Iniziamo a definire mu.\n\nmu = np.linspace(np.mean(y) - 2*np.std(y), np.mean(y) + 2*np.std(y), num=100)\n\nTroviamo il valore dell’ordinata della funzione di log-verosimiglianza in corrispondenza di ciascuno dei 1000 valori mu che abbiamo definito.\n\nll = [log_likelihood(y, mu_val, true_sigma) for mu_val in mu]\n\nNel caso di un solo parametro sconosciuto (nel caso presente, \\(\\mu\\)) è possibile rappresentare la log-verosimiglianza con una curva che interpola i punti (mu, ll). Tale funzione descrive la credibilità relativa che può essere attribuita ai valori del parametro \\(\\mu\\) alla luce dei dati osservati.\n\nplt.plot(mu, ll, 'r-')\nplt.title('Funzione di log-verosimiglianza', fontsize=16)\nplt.xlabel('Valore della variabile casuale mu', fontsize=14)\nplt.ylabel('Log-verosimiglianza', fontsize=14)\nplt.axvline(x=np.mean(y), color='k', alpha=0.2, ls='--')\nplt.show()\n\n\n\nFigura 15.3: Log-verosimiglianza del parametro \\(\\mu\\) per i dati di Zetsche et al. (2019).\n\n\n\n\n\n15.2.3 Massima verosimiglianza\nIl valore \\(\\mu\\) più credibile corrisponde al massimo della funzione di log-verosimiglinza e viene detto stima di massima verosimiglianza.\nIl massimo della funzione di log-verosimiglianza, ovvero 30.93 nel caso dell’esempio presente, è identico alla media dei dati campionari. Tale risultato, ottenuto per via numerica, può essere dimostrato formalmente (ma non lo faremo qui). Usando la notazione matematica possiamo dire che cerchiamo l’argmax dell’equazione precedente rispetto a \\(\\theta\\), ovvero\n\\[\n\\hat{\\theta} = \\text{argmax}_{\\theta} \\prod_{i=1}^n f(y_i \\mid \\theta).\n\\]\nQuesto problema si risolve calcolando le derivate della funzione rispetto a \\(\\theta\\), ponendo le derivate uguali a zero e risolvendo. Saltando tutti i passaggi algebrici di questo procedimento, per \\(\\mu\\) si trova\n\\[\\begin{equation}\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n y_i\n\\end{equation}\\]\ne\n\\[\\begin{equation}\n\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^n\\frac{1}{n}(y_i- \\mu)^2}.\n\\end{equation}\\]\nIn altri termini, la s.m.v. del parametro \\(\\mu\\) è la media del campione e la s.m.v. del parametro \\(\\sigma\\) è la deviazione standard del campione.\n\nEsercizio 15.1 Dalla Figura 15.3 notiamo che il massimo della funzione di log-verosimiglianza calcolata per via numerica, ovvero 30.93, è identico alla media dei dati campionari e corrisponde al risultato teorico atteso."
  },
  {
    "objectID": "024_likelihood.html#commenti-e-considerazioni-finali",
    "href": "024_likelihood.html#commenti-e-considerazioni-finali",
    "title": "15  La funzione di verosimiglianza",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nNella funzione di verosimiglianza i dati (osservati) vengono trattati come fissi, mentre i valori del parametro (o dei parametri) \\(\\theta\\) vengono variati: la verosimiglianza è una funzione di \\(\\theta\\) per il dato fisso \\(y\\). Pertanto, la funzione di verosimiglianza riassume i seguenti elementi: un modello statistico che genera stocasticamente i dati (in questo capitolo abbiamo esaminato due modelli statistici: quello binomiale e quello Normale), un intervallo di valori possibili per \\(\\theta\\) e i dati osservati \\(y\\).\nNella statistica frequentista l’inferenza si basa solo sui dati a disposizione e qualunque informazione fornita dalle conoscenze precedenti non viene presa in considerazione. Nello specifico, nella statistica frequentista l’inferenza viene condotta massimizzando la funzione di (log) verosimiglianza, condizionatamente ai valori assunti dalle variabili casuali campionarie. Le basi dell’inferenza frequentista, dunque, sono state riassunte in questo Capitolo. Nella statistica bayesiana, invece, l’inferenza statistica viene condotta combinando la funzione di verosimiglianza con le distribuzioni a priori dei parametri incogniti \\(\\theta\\). Ciò verrà discusso nei Capitoli successivi.\nLa differenza fondamentale tra inferenza bayesiana e frequentista è dunque che i frequentisti non ritengono utile descrivere i parametri in termini probabilistici: i parametri dei modelli statistici vengono concepiti come fissi ma sconosciuti. Nell’inferenza bayesiana, invece, i parametri sconosciuti sono intesi come delle variabili casuali e ciò consente di quantificare in termini probabilistici il nostro grado di intertezza relativamente al loro valore.\n\n\n\n\n\n\nZetsche, U., Bürkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688."
  },
  {
    "objectID": "bayes_inference.html",
    "href": "bayes_inference.html",
    "title": "Parte 4: Inferenza bayesiana",
    "section": "",
    "text": "In questa sezione della dispensa verrà discusso l’argomento più difficile, quello dell’inferenza bayesiana.\n\nNel Capitolo 16 verrà introdotto il flusso di lavoro bayesiano.\nIl Capitolo 17 spiega cosa significa, in termini bayesiani, fare un’inferenza. Sarà considerato qui il caso più semplice, ovvero quello di una proporzione.\nIl Capitolo 18 mostra come la distribuzione a posteriori possa essere derivata per via analitica nel caso delle famiglie coniugate di distribuzioni. Verrà qui esaminato lo schema beta-binomiale.\nIl Capitolo 19 discute l’influenza della distribuzione a priori sulla distribuzione a posteriori.\nIl Capitolo 20 mostra come la distribuzione a posteriori possa essere approssimata per via numerica, quando una derivazione formale non è possibile. Verranno descritto il metodo basato su griglia e l’algoritmo di Metropolis.\nIl Capitolo 21 fornisce un’introduzione al linguaggio di programmazione probabilistico Stan. L’algoritmo di Metropolis fornisce sempre una buona approssimazione alla distribuzione a posteriori. Ma ha lo svantaggio di essere poco efficiente – ovvero di richiedere un numero molto grande di iterazioni per produrre un’approssimazione accettabile. Nel caso di modelli statistici complessi, le simulazioni MCMC richiedono un tempo molto lungo (si parla di ore, giorni, settimane…). In tali circostanze è ovvio che l’efficienza del campionamento diventa importante. L’algoritmo di Metropolis è molto semplice ma è poco efficiente. Recentemente sono stati sviluppati algoritmi molto più efficienti. Il linguaggio probabilistico Stan implementa il campionamento hamiltoniano che, correntemente, è il campionamento MCMC più efficiente. Tale metodo di campionamento è anche implementato in software che sono più semplici da usare di Stan (si veda, ad esempio, la funzione brm() del pacchetto \\(\\mathsf{R}\\) brms). Tuttavia, per scopi didattici, nel testo presente useremo Stan."
  },
  {
    "objectID": "025_intro_bayes.html#fondamenti-dellanalisi-dei-dati-bayesiana",
    "href": "025_intro_bayes.html#fondamenti-dellanalisi-dei-dati-bayesiana",
    "title": "16  Credibilità, modelli e parametri",
    "section": "\n16.1 Fondamenti dell’analisi dei dati bayesiana",
    "text": "16.1 Fondamenti dell’analisi dei dati bayesiana\nL’analisi dei dati bayesiana si basa su due idee fondamentali.\n\nLa prima idea è la riallocazione della credibilità tra le possibilità.\n\nLa seconda idea è che le possibili ipotesi, a cui attribuiamo diversi gradi di credibilità, corrispondono ai valori dei parametri di un modello statistico.\n\n\n16.1.1 Prima idea: riallocazione della credibilità\nConsideriamo la prima idea. Kruschke (2014) la descrive mediante un riferimento letterario. Il detective immaginario Sherlock Holmes spesso diceva al suo compagno, il dottor Watson: “Quante volte ti ho detto che quando hai eliminato l’impossibile, tutto ciò che rimane, per quanto improbabile, deve essere la verità?” (Doyle, 1890, cap. 6). Anche se il ragionamento di Holmes o Watson o Doyle non è mai stato descritto come un’inferenza bayesiana, in realtà lo è. Nei romanzi di Doyle, Sherlock Holmes ragiona nel modo seguente. Holmes inizia a elencare i vari sospetti di un crimine. A priori, attribuisce un certo grado di credibilità alla possibilità che il colpevole sia uno dei sospetti considerati. In seguito, Holmes raccoglie sistematicamente le prove che escludono alcuni possibili sospetti. Se è possibile escludere tutti i possibili sospetti tranne uno, allora Sherlock Holmes conclude attribuendo una piena credibilità all’idea che il colpevole sia il sospetto rimanente, anche se all’inizio questa idea poteva sembrare poco credibile.\nKruschke (2014) esprime il ragionamento “bayesiano” di Sherlock Holmes mediante la seguente figura. Supponiamo che vi siano quattro possibili ipotesi rispetto ad un fenomeno (nella figura “Possibilities”): A, B, C, D. Queste ipotesi possono corrispondere, ad esempio, ai quattro sospettati.\n\n\n\n\n\n\n\n\nLa riga superiore riporta la credibilità a priori che viene assegnata all’ipotesi che ciascun sospettato sia il colpevole. Nella prima colonna, la credibilità a priori si distribuisce equamente tra i quattro sospettati. Si noti che all’intera credibilità a priori assegniamo il valore 1; se ci sono quattro sospettati, e non abbiamo modo di distinguere tra essi, allora la credibilità dell’ipotesi che uno di essi sia il colpevole vale 0.25. Se i dati a disposizione consentono di escludere il sospettato A allora, a posteriori, la credibilità si ridistribuisce tra i tre rimanenti sospettati come indicato nella figura (ovvero, la credibilità dell’ipotesi che uno di essi sia il colpevle varrà 1/3).\nIl passaggio dalla distribuzione a priori a quella a posteriori si dice aggiornamento bayesiano. Per il caso rappresentato nella prima colonna, l’aggiornamento bayesiano (ovvero, la riallocazione della credibilità alla luce dei dati a disposizione) ha consentito di escludere un sospettato. Nella seconda colonna, a priori si considera impossibile il sospettato A, per cui la credibilità di distribuisce equamente tra i rimanenti tre sospettati. Supponendo che i dati consentano di escludere la possibilità B, l’aggiornamento bayesiano ci porta alla distribuzione a posteriori della credibilità che si distribuisce equamente tra C e D. In questo caso, sono stati esclusi due sospettati, ma non è possibile decidere tra C e D. Infine, il caso più fortunato è descritto nell’ultima colonna; in questo caso, a priori, possiamo escludere A e B. I dati ci consentono di escludere C. Dunque, a posteriori, siamo sicuri (la credibilità è 1) che D sia il colpevole.\nL’analisi bayesiana procede allo stesso modo: distribuisce la credibilità a priori tra una serie di possibilità. Vengono poi acquisite le informazioni fornite dai dati. Sulla base di tali informazioni si ottiene un nuova distribuzione della credibilità tra le possibilità. Tale aggiornamento delle credenze conduce alla distribuzione a posteriori, la quale descrive il modo in cui abbiamo modificato le nostre credenze a priori alla luce delle informazioni fornite dai dati.\n\n16.1.1.1 I dati sono rumorosi e le inferenze sono probabilistiche\nI casi della figura precedente presupponevano che i dati avessero relazioni deterministiche con le possibili cause. Ad esempio, Sherlock Holmes potrebbe aver trovato un’impronta sulla scena del crimine e identificato la taglia e il tipo di scarpa con assoluta certezza, escludendo così completamente o implicando un particolare sospettato.\nNella ricerca scientifica la situazione è più complessa in quanto le relazioni tra i dati e le cause soggiacenti sono solo probabilistiche (non deterministiche). Un vero investigatore potrebbe misurare l’impronta di una scarpa e i dettagli del suo battistrada, ma queste misurazioni restringerebbero solo probabilisticamente la gamma delle scarpe possibili che potrebbero aver prodotto l’impronta. Al di fuori dei romanzi di Arthur Conan Doyle, le misure non sono mai perfette e l’impronta è solo una rappresentazione imperfetta della scarpa che l’ha prodotta. La relazione tra la causa (cioè la scarpa) e l’effetto misurato (cioè l’impronta) viene complicata dalla presenza del “rumore della misurazione”.\nNella ricerca scientifica, le misurazioni sono fortemente contaminate da molteplici influenze estranee, nonostante gli enormi sforzi dei ricercatori per limitare la loro influenza. Per esempio, in uno studio sull’apprendimento della statistica da parte degli studenti di psicologia, un ricercatore potrebbe dividere gli studenti in due gruppi: un gruppo sperimentale (che affianca lo studio del materiale dell’esame con una serie di esercitazioni nelle quali viene utilizzato un software per l’analisi dei dati) e un gruppo di controllo (che studia il materiale dell’esame su un testo e si limita a svolgere degli esercizi scolastici carta-e-penna). Supponiamo che il ricercatore misuri la prestazione all’esame dei due gruppi. È chiaro che la prestazione all’esame per ogni singolo studente, al di là dell’effetto della manipolazione sperimentale, può variare notevolmente a seconda di molte altre influenze, come la motivazione, l’ansia, la possibilità di usare un computer, le conoscenze informatiche, la preparazione pregressa nelle materie quantitative, la quantità e qualità dello studio, ecc. I dati risultanti, quindi, saranno estremamente rumorosi, con un’enorme variabilità all’interno di ciascun gruppo e un’enorme sovrapposizione tra i gruppi. Pertanto, ci saranno molti studenti del gruppo sperimentale che faranno meglio all’esame della media gruppo di controllo e viceversa. Da queste due distribuzioni di voti all’esame, molto disperse e sovrapposte, vogliamo inferire qual è la differenza media tra i due gruppi e quanto possiamo essere certi che vi sia una differenza. Tutte le misurazioni scientifiche (i dati) includono un certo grado di “rumore”. Le tecniche di analisi dei dati sono progettate per inferire le tendenze sottostanti presenti in dati rumorosi. A differenza di Sherlock Holmes, che sulla base di un’osservazione esclude completamente un sospettato, nella ricerca scientifica vengono raccolti dei dati che modificano solo incrementalmente la credibilità che può essere attribuita alle possibili tendenze suggerite dai dati. In questo insegnamento vedremo molti esempi realistici di questo processo. Uno dei maggiori vantaggi dell’analisi bayesiana è il fatto che essa consente di utilizzare la teoria delle probabilità per riallocare la credibilità tra le ipotesi, alla luce delle informazioni fornite dai dati, in un modo non arbitrario e automatico.\n\n16.1.1.2 Esempio: fake news nei post Twitter\nPer chiarire, consideriamo ora un esempio discusso da Johnson et al. (2022). Esaminiamo un insieme di 150 post Twitter.\n\n\n\nIn questo data set la proporzione di notizie false è 60 / 150 = 0.4.\n\n#>   type   n\n#>   fake  60\n#>   real  90\n#>  Total 150\n\nNei post Twitter esaminati, alcuni post contengono dei punti esclamativi, altri no. Consideriamo la distribuzione dei punti esclamativi rispetto al tipo di notizie (false, vere).\n\n#>  title_has_excl fake real\n#>           FALSE   44   88\n#>            TRUE   16    2\n#>           Total   60   90\n\nDelle notizie false, i punti esclamativi sono presenti nel 16/60 = 0.2667 \\(\\times 100\\) dei casi; delle notizie vere, i punti esclamativi sono presenti solo nel 2/90 = 0.0222 \\(\\times 100\\) dei casi.\nDal punto di vista di un’analisi Bayesiana, sappiamo che il 40% delle notizie sono false. Questa è la nostra informazione a priori. Ma abbiamo anche un’informazione sulla distribuzione dei punti esclamativi nelle notizie vere e false. Ci chiediamo: qual è la probabilità a posteriori che una notizia sia falsa se contiene un punto esclamativo?\nLe caratteristiche di vero/falso e di presenza/assenza di punti esclametivi variano in maniera casuale tra le varie notizie postate su Twitter. Per cui dobbiamo rapprensentare questa variazione casuale mediante un modello probabilistico.\nProbabilità a priori\nSappiamo dai dati a disposizione che il 40% delle notizie sono false e il 60% sono vere. Se \\(F\\) indica falso e \\(F^c\\) indica vero, abbiamo\n\\[\nP(F) = 0.40 \\quad \\text{e} \\quad P(F^c) = 0.60.\n\\]\nProbabilità condizionata\nLa frequenza con cui si osservano i punti esclamativi dipende dal tipo di notizia (vera/falsa). Calcoliamo dunque la probabilità condizionata di un punto esclamativo (\\(E\\)) dato il tipo di notizia:\n\\[\nP(E \\mid F) = 0.267 \\quad \\text{e} \\quad P(E \\mid F^c) = 0.022.\n\\]\nVerosimiglianza\nLa verosimiglianza con consente di confrontare la plausibilità relativa dei dati \\(E\\) in relazione agli eventi \\(F\\) e \\(F^c\\). In precedenza abbiamo presentato la verosimiglianza discutendo la distribuzione binomiale. Supponendo che i nostri dati \\(y\\) siano il numero di successi in \\(n\\) prove Bernoulliane, la distribuzione di probabilità del numero di successi in \\(n\\) prove, \\(p(y \\mid \\theta)\\), è data dalla distribuzione Binomiale nel caso di \\(n\\) prove con probabilità di successo uguale a \\(\\theta\\). In tali circostanze, fissato il numero di successi \\(y\\), la verosimiglianza si trova applicando la formula Binomiale per tutti i valori possibili di \\(\\theta\\). Quindi, abbiamo denotato la funzione di verosimiglianza come \\(p(\\theta \\mid y)\\).\nNel caso presente, Johnson et al. (2022) fanno notare come la distribuzione di probabilità (condizionata) della presenza di un punto esclamativo sia data da \\(P(E\\mid F)\\) e \\(P(E\\mid F^c)\\). Quindi, la funzione di verosimiglianza diventa \\(P(F \\mid E)\\) e \\(P(F^c \\mid E)\\). Ovvero\n\n\n\n\n\n\n\n\n\n\nStatistica\nNotizia Falsa (\\(F\\))\nNotizia Vera (\\(F^c\\))\nTotale\n\n\n\nProbabilità a priori\n0.400\n0.600\n1.000\n\n\nVerosimiglianza\n0.267\n0.022\n0.289\n\n\n\n\n\nCostante di normalizzazione\nL’ultima informazione di cui abbiamo bisogno è la probabilità marginale di osservare i punti esclamativi in tutti i post Twitter, o \\(P(E)\\), che rappresenta la costante di normalizzazione, ovvero\n\\[\nP(F)P(E \\mid F) + P(F^c) P(E \\mid F^c) = 0.12.\n\\]\n\n\n\nProbabilità a posteriori\nLa probabilità a posteriori \\(P(F \\mid E)\\) che una notizia sia falsa dato che il post Twitter contiene un punto esclamativo è data dalla regola di Bayes:\n\\[\n\\text{probabilità a posteriori} = \\frac{\\text{probabilità a priori} \\times \\text{verosimiglianza}}{\\text{costante di normalizzazione}}\n\\]\novvero\n\\[\nP(F \\mid E) = \\frac{P(F) P(E | F)}{P(E)} = \\frac{0.40 \\cdot 0.267}{0.12} = 0.889.\n\\]\nSi noti che la probabilità a priori che una notizia sia falsa era 0.40. Alla luce della conoscenza che il post Twitter contiene un punto esclamativo abbiamo trovato una probabilità a posteriori uguale a 0.889. Quindi, l’informazione relativa alla presenza di un punto esclamativo ha mutato drasticamente la credibilità del valore di verità della notizia.\n\n16.1.2 Seconda idea: le possibilità sono valori di parametri in un modello statistico\nNel precedente ragionamento “bayesiano” di Sherlock Holmes, le possibilità corrispondevano alle quattro modalità di una variabile discreta: la variabile era “i sospettati del crimine” e le modalità erano A, B, C e D. In statistica, lavorare con variabili discrete è complicato. È più semplice svolgere l’aggiornamento bayesiano mediante gli strumenti della teoria delle probabilità se vengono invece utilizzate variabili continue. In tali circostanze, le “possibilità” corrispondono ai valori dei parametri in un modello statistico. Possiamo chiarire questa affermazione nel modo seguente.\nConsideriamo una distribuzione di differenze di punteggi BDI-II misurati prima e dopo un intervento psicologico: se l’intervento funziona i punteggi BDI-II saranno minori dopo l’intervento e dunque la differenza prima - dopo sarà positiva. L’intervento però non ha gli stessi effetti sui diversi partecipanti per cui, in uno studio, osserviamo una distribuzione di punteggi (prima - dopo). Supponiamo che tale distrinuzione di punteggi sia rappresentata dall’istogramma illustrato nella figura seguente.\n\n\n\n\n\n\n\n\nAll’istogramma è sovrapposta una distribuzione Gaussiana di parametri \\(\\mu\\) = 5 e \\(\\sigma\\) = 4. Questa scelta per i valori dei parametri sembra appropriata per descrivere i dati a disposizione. Qui in basso mostriamo gli stessi dati ipotetici con sovrapposta una diversa distribuzione Gaussiana, di parametri \\(\\mu\\) = 3.5 e \\(\\sigma\\) = 5. Anche se questa seconda distribuzione Gaussiana è plausibile, sicuramente descrive i dati in una maniera peggiore del caso precedente.\n\n\n\n\n\n\n\n\nIl ruolo dell’inferenza bayesiana è quello di calcolare l’esatta credibilità relativa dei valori dei parametri candidati, tenendo anche conto delle loro probabilità a priori. In applicazioni realistiche, i valori dei parametri candidati possono formare un continuum infinito. Il parametro \\(\\mu\\) della distribuzione normale può assumere qualsiasi valore da \\(-\\infty\\) a \\(+\\infty\\). L’inferenza bayesiana opera senza problemi su continui infiniti.\nCi sono due principali desiderata per una descrizione matematica dei dati. In primo luogo, la descrizione matematica dovrebbe essere comprensibile. Così come sarebbe inutile descrivere i dati in una lingua che non conosciamo, sarebbe inutile descrivere i dati con una forma matematica che non comprendiamo, con parametri che non possiamo interpretare. Nel caso di una distribuzione normale, ad esempio, il parametro \\(\\mu\\) medio e il parametro \\(\\sigma\\) sono facilmente interpretabili in quanto corrispondono agli indici di posizione e di scala della distribuzione. In questo insegnamento useremo descrizioni matematiche dei dati dotate di parametri a cui è possibile assegnare un’interpretazione intuitiva. In questo contest, possiamo dire che l’analisi bayesiana procede alla riallocazone della credibilità dei valori dei parametri all’interno di uno spazio di possibilità definito dal modello statistico che è stato scelto.\nIl secondo desideratum di una modellizzazione matematica è che dovrebbe essere descrittivamente adeguata, il che significa, all’incirca, che il modello matematico (in questo caso, la curva Normale) dovrebbe “assomigliare” ai dati. Non dovrebbero esserci discrepanze sistematiche importanti tra le tendenze dei dati e la forma del modello. Il problema di decidere se un’apparente discrepanza sia importante o meno non è un problema facile da risolvere. Nelle prime fasi della ricerca, dunque, le nostre aspettative si limitano ad una descrizione approssimativa e “abbastanza buona” dei dati, perché è in grado di catturare tendenze significative nei dati che sono interessanti e nuove rispetto alle nostre conoscenze precedenti. Man mano che il campo della ricerca matura, i ricercatori si pongono il problema di ottenere descrizioni sempre più quantitativamente accurate del fenomeno oggetto di studio. L’analisi bayesiana è molto utile per valutare la credibilità relativa di diverse possibili modellizzazioni matematiche dei dati.\nÈ importante capire che le descrizioni matematiche dei dati non sono necessariamente spiegazioni causali del fenomeno di interesse. Dire che i dati sono ben descritti da una distribuzione normale con media di 5 e deviazione standard di 4 non spiega quale sia il processo che rappresenta la causa sottostante del fatto che i datti assumono la forma osservata. I parametri di un modello come la distribuzione normale, ad esempio, non hanno necessariamente un significato in relazione alle cause dell’efficacia (o non efficacia) di un intervento psicologico, ad esempio. Meglio sarebbe esprimere le possibili cause dell’efficiacia dell’intervento psicologico nei termini di un modello matematico per poi usare i dati, e l’analisi bayesiana, per stimare i parametri del modello (ovvero, per attribuire un “peso” alle possibili cause). Tuttavia, ma procedere in questo modo è possibile solo in pochi casi. Solitamente la psicologia si accontenta di descrivere le differenze medie tra gruppi, senza un’indagine puntuale delle cause di tali differenze."
  },
  {
    "objectID": "025_intro_bayes.html#modellizzazione-bayesiana",
    "href": "025_intro_bayes.html#modellizzazione-bayesiana",
    "title": "16  Credibilità, modelli e parametri",
    "section": "\n16.2 Modellizzazione bayesiana",
    "text": "16.2 Modellizzazione bayesiana\nLa moderna statistica bayesiana viene per lo più eseguita utilizzando un linguaggio di programmazione probabilistico implementato su computer. Ciò ha cambiato radicalmente il modo in cui venivano eseguite le statistiche bayesiane anche fin pochi decenni fa. La complessità dei modelli che possiamo costruire è aumentata e la barriera delle competenze matematiche e computazionali che sono richieste è diminuita. Inoltre, il processo di modellazione iterativa è diventato, sotto molti aspetti, molto più facile da eseguire. Anche se formulare modelli statistici complessi è diventato più facile che mai, la statistica è un campo pieno di sottigliezze che non scompaiono magicamente utilizzando potenti metodi computazionali. Pertanto, avere una buona preparazione sugli aspetti teorici, specialmente quelli rilevanti per la pratica, è estremamente utile per applicare efficacemente i metodi statistici.\n\nNell’approccio bayesiano all’inferenza statistica si prende in considerazione una variabile casuale \\(Y\\) di cui si conosce la distribuzione a meno di un parametro \\(\\theta\\). Nel caso dell’esempio precedente, la variabile \\(Y\\) è la distribuzione delle differenze pre/post dei punteggi BDI-II. Immaginiamo di assumere che \\(Y\\) dia una variabile Gaussiana di cui non conosciamo il parametro \\(\\mu\\) (media) ma di cui conosciamo \\(\\sigma\\).\nSecondo l’approccio bayesiano, è possibile modellare l’incertezza sul valore del parametro ignoto rappresentandolo con una variabile casuale continua \\(\\Theta\\) avente come supporto l’insieme dei valori ammissibili per il parametro cercato. Nel caso dell’esempio considerato, ciò significa che consideriamo \\(\\mu\\) come una variabile casuale il cui supporto è \\([-\\infty, \\infty]\\).\nLa funzione di densità \\(p(\\theta)\\) prende il nome di distribuzione a priori e rappresenta la sintesi delle opinioni e delle informazioni che si hanno sul parametro prima dell’osservazione dei dati. Nell’esempio, anche se \\(\\mu\\) può assumere valori nell’intervallo \\([-\\infty, \\infty]\\), non tutti questi valori sono plausibili. Ad esempio, una differenza di un milione, sulla scala del BDI-II, è senza senso. A priori, potremmo dunque descrivere la nostra incertezza su \\(\\mu\\) mediante una funzione di densità la cui massa è compresa nell’intervallo, diciamo, [-20, 20]. In assenza di altre informazioni, questa gamma di valori sembra ragionevole. Inoltre, se non abbiamo motivo di credere che l’intervento psicologico sarà sicuramente efficace, la funzione di densità che descrive la nostra incertezza su \\(\\mu\\) potrebbe avere media pari a zero. Pertanto, la nostra incertezza iniziale su \\(\\mu\\) potrebbe essere descritta mediante una \\(\\mathcal{N}(0, 7)\\).\nL’aggiornamento dell’incertezza su \\(\\theta\\) è determinata dal verificarsi dell’evidenza \\(y\\), ovvero dall’osservazione dei risultati di un esperimento casuale. Nel caso dell’esempio, potremmo pensare di misurare il BDI-II prima e dopo l’intervento su 30 pazienti.\nLe informazioni provenienti dal campione osservato \\(y = (y_1, \\dots, y_n)\\) sono contenute nella funzione \\(p(y \\mid \\theta)\\), che, osservata come funzione di \\(\\theta\\) per \\(y\\), prende il nome di funzione di verosimiglianza. In precedenza abbiamo visto come sia possibile costruire la funzione di verosimiglianza Gaussiana nel caso di \\(\\mu\\) incognito e \\(\\sigma\\) noto. Per continuare con l’esempio in discussione, potremmo pensare di costruire la funzione di verosimiglianza in questo modo. La funzione di verosimiglianza così costruita ci direbbe qual è la verosimiglianza relativa dei valori del parametro \\(\\mu\\) alla luce dei dati osservati (e assumendo \\(\\sigma\\) come noto).\nL’aggiornamento delle conoscenze a priori incorporate nella distribuzione iniziale \\(p(\\theta)\\) in seguito al verificarsi di \\(Y = y\\) (evidenza empirica) avviene attraverso il teorema di Bayes in cui \\(p(\\theta \\mid y)\\) risulta proporzionale al prodotto della probabilità a priori e della verosimiglianza e prende il nome di distribuzione a posteriori:\n\\[\\begin{equation}\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int_{\\Theta}p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\!\\theta} \\quad \\theta \\in \\Theta.\n(\\#eq:bayes-intro)\n\\end{equation}\\]\nNel caso dell’esempio in discussione, la distribuzione a posteriori del parametro \\(\\mu\\) fornisce una descrizione della nostra incertezza relativamente all’efficacia media dell’intervento psicologico. Se, diciamo, la gran parte della massa della distribuzione a posteriori include valori positivi, ciò ci fornisce evidenza che l’intervento psicologico sia stato, in media, efficace (cioè, ha portato ad una riduzione dei valori BDI-II). Se invece la massa della distribuzione a posteriori del parametro \\(\\mu\\) è ripartita in manera bilanciata tra valori negativi e valori positivi, allora non c’è evidenza che l’intervento psicologico sia stato efficace (per alcuni pazienti ha prodotto un miglioramento, per altri un peggioramento).\nPossiamo dunque dire che, nell’esempio, la distribuzione a posteriori del parametro \\(\\mu\\) descrive la credibilità che possiamo attribuire all’efficacia dell’intervento psicologico dopo avere esaminato i dati a disposizione, e includendo le evidenze a priori."
  },
  {
    "objectID": "025_intro_bayes.html#flusso-di-lavoro-bayesiano",
    "href": "025_intro_bayes.html#flusso-di-lavoro-bayesiano",
    "title": "16  Credibilità, modelli e parametri",
    "section": "\n16.3 Flusso di lavoro bayesiano",
    "text": "16.3 Flusso di lavoro bayesiano\nIn pratica, Martin et al. (2022) descrivono la modellazione bayesiana distinguendo tre passaggi.\n\nDati alcuni dati e alcune ipotesi su come questi dati potrebbero essere stati generati, si progetta un modello statistico combinando e trasformando variabili casuali.\nSi usa il teorema di Bayes per condizionare il modello ai dati. Questo processo viene chiamato “inferenza” e come risultato si ottiene una distribuzione a posteriori.\n\nSi critica il modello utilizzando criteri diversi, inclusi i dati e la nostra conoscenza del dominio, per verificare se abbia senso. Poiché in generale siamo incerti sul modello, a volte si confrontano modelli diversi.\n\nQuesti tre passaggi vengono eseguiti in modo iterativo e danno luogo a quello che è chiamato “flusso di lavoro bayesiano” (bayesian workflow).\nEsaminiamo ora più nei dettagli le varie fasi del flusso di lavoro bayesiano.\n\n16.3.1 Notazione\nPer fissare la notazione, nel seguito \\(y\\) rappresenterà i dati e \\(\\theta\\) rappresenterà i parametri incogniti di un modello statistico. Sia \\(y\\) che \\(\\theta\\) vengono concepiti come variabili casuali. Con \\(x\\) vengono invece denotate le quantità note, come ad esempio i predittori del modello lineare. Per rappresentare in un modo conciso i modelli probabilistici viene usata una notazione particolare. Ad esempio, invece di scrivere \\(p(\\theta) = \\mbox{Beta}(1, 1)\\) scriviamo \\(\\theta \\sim \\mbox{Beta}(1, 1)\\). Il simbolo “\\(\\sim\\)” viene spesso letto “è distribuito come”. Possiamo anche pensare che significhi che \\(\\theta\\) costituisce un campione casuale estratto dalla distribuzione Beta(1, 1). Allo stesso modo, ad esempio, la verosimiglianza del modello binomiale può essere scritta come \\(y \\sim \\text{Bin}(n, \\theta)\\).\n\n16.3.2 Distribuzioni a priori\nQuando adottiamo un approccio bayesiano, i parametri della distribuzione di riferimento non venono considerati come delle costanti incognite ma bensì vengono trattati come variabili casuali; di conseguenza, i parametri assumono una particolare distribuzione che nelle statistica bayesiana viene definita “a priori”. I parametri \\(\\theta\\) possono assumere delle distribuzioni a priori differenti: a seconda delle informazioni disponibili bisogna selezionare una distribuzione di \\(\\theta\\) in modo tale che venga assegnata una probabilità maggiore a quei valori del parametro che si ritengono più plausibili. Idealmente, le credenze a priori che portano alla specificazione di una distribuzione a priori dovrebbero essere supportate da una qualche motivazione, come ad esempio i risultati di ricerche precedenti.\n\n\n\n16.3.2.1 Tipologie di distribuzioni a priori\nPossiamo distinguere tra diverse distribuzioni a priori in base a quanto fortemente impegnano il ricercatore a ritenere come credibile un particolare intervallo di valori dei parametri. Un caso estremo è quello che rivela una totale assenza di conoscenze a priori, il che conduce alle distribuzioni a priori non informative, ovvero quelle che assegnano lo stesso livello di credibilità a tutti i valori dei parametri. Le distribuzioni a priori informative, d’altra parte, possono essere debolmente informative o fortemente informative, a seconda del modo in cui lo sperimentatore distribuisce la credibilità nello spazio del parametro. Un caso estremo di credenza a priori è quello che assegna tutta la credibilità ad un singolo valore del parametro. La figura seguente mostra alcuni esempi di distribuzioni a priori per il modello Binomiale:\n\ndistribuzione non informativa: \\(\\theta_c \\sim \\mbox{Beta}(1,1)\\);\ndistribuzione debolmente informativa: \\(\\theta_c \\sim \\mbox{Beta}(5,2)\\);\ndistribuzione fortemente informativa: \\(\\theta_c \\sim \\mbox{Beta}(50,20)\\);\n\nvalore puntuale: \\(\\theta_c \\sim \\mbox{Beta}(\\alpha, \\beta)\\) con \\(\\alpha, \\beta \\rightarrow \\infty\\) e \\(\\frac{\\alpha}{\\beta} = \\frac{5}{2}\\).\n\n\n\n\n\nEsempi di distribuzioni a priori per il parametro \\(\\theta_c\\) nel Modello Binomiale.\n\n\n\n\n\n16.3.2.2 Selezione della distribuzione a priori\nLa selezione delle distribuzioni a priori è stata spesso vista come una delle scelte più importanti che un ricercatore fa quando implementa un modello bayesiano in quanto può avere un impatto sostanziale sui risultati finali. La soggettività delle distribuzioni a priori è evidenziata dai critici come un potenziale svantaggio dei metodi bayesiani. A questa critica, Schoot et al. (2021) rispondono dicendo che le distribuzioni a priori svolgono due importanti ruoli statistici: quello della “regolarizzazione della stima”, ovvero, il processo che porta ad indebolire l’influenza indebita di osservazioni estreme, e quello del miglioramento dell’efficenza della stima, ovvero, la facilitazione dei processi di calcolo numerico di stima della distribuzione a posteriori. L’effetto della distribuzione a priori sulla distribuzione a posteriori verrà discusso in dettaglio nel Capitolo @ref(chapter-balance). Inoltre, Schoot et al. (2021) notano che, a proposito di scelte “soggettive”, al di là della scelta delle distribuzioni a priori, ci sono molti elementi del processo di inferenza statistica che risultano sicuramente “soggettivi” (cioè, arbitrari), in particolare la scelta del modello statistico e le ipotesi sulla distribuzione degli errori. Risultano inoltre “soggettivi” il modo di operazionalizzare la variabile dipendente, il tipo di confronti da esaminare e tante altre dimensioni dell’inferenza statistica. Per cui, il confronto tra statistica bayesiana e frequentista non può essere sicuramente svolto nei termini delle dimensioni oggettivo/soggettivo.\n\n16.3.3 La funzione di verosimiglianza\nLa funzione di verosimiglianza per due casi tipici, quello binomiale e quello Normale, è stata descritta nel Capitolo @ref(ch:likelihood).\n\nNota. Seguendo una pratica comune, all’interno di un framework bayesiano spesso useremo la notazione \\(p(\\cdot)\\) per rappresentare due quantità differenti, ovvero la funzione di verosimiglianza e la distribuzione a priori. Questo piccolo abuso di notazione riflette il seguente punto di vista: anche se la verosimiglianza non è una funzione di densità di probabilità, noi non vogliamo stressare questo aspetto, ma vogliamo piuttosto pensare alla verosimiglianza e alla distribuzione a priori come a due elementi che sono egualmente necessari per calcolare la distribuzione a posteriori. In altri termini, per così dire, questa notazione assegna lo stesso status epistemico alle due diverse quantità che si trovano al numeratore della regola di Bayes.\n\n\n16.3.4 La verosimiglianza marginale\nPer il calcolo di \\(p(\\theta \\mid y)\\) è necessario dividere il prodotto tra la distribuzione a priori e la verosimiglianza per una costante di normalizzazione. Tale costante di normalizzazione, detta verosimiglianza marginale, ha lo scopo di fare in modo che \\(p(\\theta \\mid y)\\) abbia area unitaria.\n\nSi noti che la verosimiglianza marginale (ovvero, l’integrale al denominatore della @ref(eq:bayes-intro)) è spesso di difficile risoluzione analitica per cui l’inferenza bayesiana solitamente procede attraverso metodi di ricampionamento e metodi iterativi, quali le Catene di Markov Monte Carlo (MCMC).\n\n16.3.5 La distribuzione a posteriori\nLa distribuzione a postreriori si trova applicando il teorema di Bayes:\n\\[\n\\text{probabilità a posteriori} = \\frac{\\text{probabilità a priori} \\cdot \\text{verosimiglianza}}{\\text{costante di normalizzazione}}\n\\]\nNei Capitoli successivi vedremo come calcolare la distribuzione a posteriori. Ci sono due metodi:\n\nun metodo esatto, che può essere usato nel caso delle distribuzioni a priori coniugate;\nun metodo approssimato, che può sempre essere usato, ma è computazionalmente intensivo.\n\n\n16.3.6 Distribuzione predittiva a priori\nLa distribuzione a posteriori è l’oggetto centrale nella statistica bayesiana, ma non è l’unico. Oltre a fare inferenze sui valori dei parametri, potremmo voler fare inferenze sui dati. Questo può essere fatto calcolando la distribuzione predittiva a priori:\n\\[\\begin{equation}\np(y^*) = \\int_\\Theta p(y^* \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\!\\theta .\n(\\#eq:prior-pred-distr)\n\\end{equation}\\]\nLa @ref(eq:prior-pred-distr) descrive la distribuzione prevista dei dati in base al modello (che include la distribuzione a priori e la verosimiglianza), ovvero descrive i dati \\(y^*\\) che ci aspettiamo di osservare, dato il modello, prima di avere osservato i dati del campione.\nÈ possibile utilizzare campioni dalla distribuzione predittiva a priori per valutare e calibrare i modelli utilizzando le nostre conoscenze dominio-specifiche. Ad esempio, ci possiamo chiedere: “È sensato che un modello dell’altezza umana preveda che un essere umano sia alto -1.5 metri?”. Già prima di misurare una singola persona, possiamo renderci conto dell’assurdità di questa domanda. Se la distribuzione prevista dei dati consente domande di questo tipo (ovvero, prevede di osservare dati che risultano insensati alla luce delle nostre conoscenze dominio-specifiche), è chiaro che il modello deve essere riformulato.\n\n\n\n\n16.3.7 Distribuzione predittiva a posteriori\nUn’altra quantità utile da calcolare è la distribuzione predittiva a posteriori:\n\\[\\begin{equation}\np(\\tilde{y} \\mid y) = \\int_\\Theta p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta .\n(\\#eq:post-pred-distr)\n\\end{equation}\\]\nQuesta è la distribuzione dei dati attesi futuri \\(\\tilde{y}\\) alla luce della distribuzione a posteriori \\(p(\\theta \\mid y)\\), che a sua volta è una conseguenza del modello adottato (distribuzione a priori e verosimiglianza) e dei dati osservati. In altre parole, questi sono i dati che il modello si aspetta dopo aver osservato i dati de campione. Dalla @ref(eq:post-pred-distr) possiamo vedere che le previsioni sui dati attesi futuri sono calcolate integrando (o marginalizzando) sulla distribuzione a posteriori dei parametri. Di conseguenza, le previsioni calcolate in questo modo incorporano l’incertezza relativa alla stima dei parametri del modello."
  },
  {
    "objectID": "025_intro_bayes.html#commenti-e-considerazioni-finali",
    "href": "025_intro_bayes.html#commenti-e-considerazioni-finali",
    "title": "16  Credibilità, modelli e parametri",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nQuesto Capitolo ha brevemente passato in rassegna i concetti di base dell’inferenza statistica bayesiana. In base all’approccio bayesiano, invece di dire che il parametro di interesse di un modello statistico ha un valore vero ma sconosciuto, diciamo che, prima di eseguire l’esperimento, è possibile assegnare una distribuzione di probabilità, che chiamano stato di credenza, a quello che è il vero valore del parametro. Questa distribuzione a priori può essere nota (per esempio, sappiamo che la distribuzione dei punteggi del QI è normale con media 100 e deviazione standard 15) o può essere del tutto arbitraria. L’inferenza bayesiana procede poi nel modo seguente: si raccolgono alcuni dati e si calcola la probabilità dei possibili valori del parametro alla luce dei dati osservati e delle credenze a priori. Questa nuova distribuzione di probabilità è chiamata “distribuzione a posteriori” e riassume l’incertezza dell’inferenza.\n\n\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, J. (2014). Doing bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMartin, O. A., Kumar, R., & Lao, J. (2022). Bayesian modeling and computation in python. CRC Press.\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., & Yau, C. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primer, 1(1), 1–26."
  },
  {
    "objectID": "026_subj_prop.html#ch-prior-discr-binom",
    "href": "026_subj_prop.html#ch-prior-discr-binom",
    "title": "17  Pensare ad una proporzione in termini soggettivi",
    "section": "\n17.1 Inferenza bayesiana con una distribuzione a priori discreta",
    "text": "17.1 Inferenza bayesiana con una distribuzione a priori discreta\nNei problemi tradizionali di teoria delle probabilità ci sono molti esempi che riguardano l’estrazione di palline colorate da un’urna. In questi esempi ci viene fornito il numero di palline di vari colori presenti nell’urna e ci viene chiesto di calcolare le probabilità di vari eventi. Ad esempio, in un’urna ci sono 40 palline bianche e 20 rosse. Se estrai due palline a caso, qual è la probabilità che entrambe siano bianche?\nL’approccio bayesiano considera uno scenario diverso, ovvero quello in cui non conosciamo le proporzioni delle palline colorate presenti nell’urna. Cioè, nell’esempio precedente, sappiamo solo che nell’urna ci sono due tipi di palline colorate, ma non sappiamo che 40 sono bianche (proporzione di bianco = \\(2/3\\)) e 20 sono rosse (proporzione di rosso = \\(1/3\\)). Ci poniamo la seguente domanda: è possibile inferire le proporzioni di palline nell’urna estraendo un campione di palline dall’urna e osservando i colori delle palline estratte? Espresso in questo modo, questo diventa un problema di inferenza statistica, perché stiamo cercando di inferire la proporzione \\(\\theta\\) della popolazione sulla base di un campione casuale. Per continuare con l’esempio precedente, quello che vogliamo fare è inferire \\(\\theta\\), ad esempio, la proporzione di palline rosse nell’urna, alla luce del numero di palline rosse e bianche nel campione.\nLe proporzioni assomigliano alle probabilità. Ricordiamo che sono state proposte tre diverse interpretazioni del concetto di probabilità.\n\nIl punto di vista classico: è necessario enumerare tutti gli eventi elementari dello spazio campione nel quale ciascun risultato è ugualmente probabile.\nIl punto di vista frequentista: è necessario ripetere l’esperimento esperimento casuale (cioè l’estrazione del campione) molte volte in condizioni identiche.\nLa visione soggettiva: è necessario esprimere la propria opinione sulla probabilità di un evento unico e irripetibile.\n\nLa visione classica non sembra potere funzionare qui, perché sappiamo solo che ci sono due tipi di palline colorate e che il numero totale di palline è 60. Anche se estraiamo un campione di 10 palline, possiamo solo osservare la proporzione di palline rosse nel campione. Non c’è modo per potere stabilire che, nello spazio campione, ogni risultato è ugualmente probabile.\nLa visione frequentista potrebbe funzionare nel caso presente. Possiamo considerare il processo del campionamento (cioè l’estrazione di un campione casuale di 10 palline dall’urna) come un esperimento casuale che produce una proporzione campionaria \\(p\\). Potremmo quindi pensare di ripetere l’esperimento casuale molte volte nelle stesse condizioni, ottenere una serie di proporzioni campionarie \\(p\\) e infine riassumere in qualche modo questa distribuzione di statistiche campionarie. Ripetendo l’esperimento casuale tante volte è possibile ottenere una stima abbastanza accurata della proporzione \\(\\theta\\) di palline rosse nell’urna. Questo processo è fattibile, ma però è noioso, dispendioso in termini di tempo e soggetto ad errori.\nLa visione soggettivista concepisce invece la probabilità sconosciuta \\(\\theta\\) come un’opinione soggettiva di cui possiamo essere più o meno certi. Questa opinione soggettiva dipende da due tipi di evidenze: le nostre credenze iniziali e le nuove informazioni fornite dai dati che abbiamo osservato. Vedremo in questo capitolo come sia possibile combinare le credenze iniziali rispetto al possibile valore \\(\\theta\\) con le evidenze fornite dai dati per giungere ad una nuova credenza a posteriori su \\(\\theta\\). In particolare, vedremo come si possa pensare in termini soggetti a delle quantità sconosciute (in questo caso, \\(\\theta\\)) usando le distribuzioni di probabilità.\nEssendo una proporzione, \\(\\theta\\) può assumere valori compresi tra 0 e 1. È possibile pensare che \\(\\theta\\) sia uguale, ad esempio, a 0.5. Ciò significa assegnare all’evento \\(\\theta = 0.5\\) la probabilità 1; in altri termini, significa dire che siamo assolutamente certi che la quantità sconosciuta \\(\\theta\\) abbia il valore di 0.5. Questa posizione, però, è troppo estrema: non possiamo essere assolutamente certi che una quantità sconosciuta abbia uno specifico valore; altrimenti non sarebbe una quantità sconosciuta. Invece, sembra più sensato pensare che \\(\\theta\\) può, in linea di principio, assumere diversi valori e attribuire a tali valori livelli diversi di certezza soggettiva.\nConsideriamo, ad esempio, 10 possibili valori \\(\\theta\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nfrom scipy.stats import uniform\nplt.style.use(\"seaborn-v0_8\")\n\na = 0\nb = 1\nsize = 11\ntheta = np.linspace(a, b, size)\nprint(theta)\n#> [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n\nSe non abbiamo alcun motivo di pensare diversamente, possiamo assegnare a ciascun valore \\(\\theta\\) la stessa credibilità.\nLe distribuzioni hanno una forma generale e una forma “frozen”. La forma generale è tale per cui i parametri della distribuzione devono essere assegnati come argomenti ad ogni chiamata. La forma ‘frozen’ crea un oggetto nel quale i parametri della distribuzione sono stati fissati usando i valori che sono stati assengati. Nel caso presente, i parametri sono \\(a\\) e \\(b\\).\n\nunif_distr = uniform(loc=a, scale=b)\nprint(unif_distr)\n#> <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa57bc0efa0>\n\nCon i parametri fissati, per i valori che abbiamo scelto per theta, la distribuzione uniforme discreta diventa la seguente.\n\nunif_distr_pdf = unif_distr.pdf(theta) / 11\nprint(unif_distr_pdf)\n#> [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n#>  0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n\n\nplt.stem(theta, unif_distr_pdf, markerfmt=' ')\n#> <StemContainer object of 3 artists>\nplt.title('Distribuzione a priori', fontsize=16)\nplt.xlabel('theta', fontsize=14)\nplt.ylabel('Probabilità', fontsize=14)\nplt.show()\n\n\n\nFigura 17.1: Distribuzione a priori per il parametro \\(\\theta\\) (versione 1).\n\n\n\n\nOppure, per qualche ragione, potremmo pensare che i valori centrali della distribuzione di \\(\\theta\\) siamo più credibili dei valori estremi. Tale opinione soggettiva può essere descritta dalla seguente distribuzione di massa di probabilità.\n\nnot_unif_distr_pdf = [0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05]\nplt.stem(theta, not_unif_distr_pdf, markerfmt=' ')\n#> <StemContainer object of 3 artists>\nplt.title('Distribuzione a priori', fontsize=16)\nplt.xlabel('theta', fontsize=14)\nplt.ylabel('Probabilità', fontsize=14)\nplt.show()\n\n\n\nFigura 17.2: Distribuzione a priori per il parametro \\(\\theta\\) (versione 2).\n\n\n\n\nLa prima distribuzione di probabilità è chiamata distribuzione discreta uniforme perché attribuisce la stessa probabilità (ovvero, 1/10) ad ogni elemento dell’insieme discreto su cui è definita (ovvero, \\(0.1, 0.2, \\dots, 1.0\\)). Anche la seconda distribuzione è discreta, ma non è uniforme: riteniamo più credibile che \\(\\theta\\) assuma un valore nell’insieme \\(\\{0.4, 0.5, 0.6, 0.7\\}\\) piuttosto che nell’insieme \\(\\{0.1, 0.2, 0.3, 0.8, 0.9, 1.0\\}\\).\nLe credenze relative alla credibilità dei possibili valori che \\(\\theta\\) possono assumere forme diverse e corrispondono a quella che viene chiamata la distribuzione a priori, ovvero descrivono le credenze iniziali relative alla quantità sconosciuta di interesse.\nLa procedura di inferenza bayesiana “aggiorna” tali credenze a priori utilizzando le informazioni fornite da un campione di dati. Usando il teorema di Bayes, le informazioni fornite dai dati vengono combinate con le nostre credenze precedenti relative alla quantità sconosciuta \\(\\theta\\) per giungere ad una credenza detta “a posteriori”.\nSupponendo che i dati corrispondano all’osservazione di 12 palline rosse in 20 estrazioni con rimessa dall’urna, usiamo ora la seconda delle distribuzioni a priori descritte sopra per ottenere la distribuzione a posteriori.\nIl teorema di Bayes specifica la distribuzione a posteriori come il prodotto della verosimiglianza e della distribuzione a priori, diviso per una costante di normalizzazione:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)}.\n\\]\nPer trovare la funzione di verosimiglianza, \\(p(y \\mid \\theta)\\), è necessario pensare a come sono stati ottenuti i dati. I dati corrispondono ai risultati di 20 estrazioni con rimessa da un’urna. Se l’estrazione è casuale con reinserimento, allora i dati (12 successi in 20 prove) possono essere intesi come il risultato di un esperimento casuale binomiale. Usando \\(\\textsf{R}\\), la funzione di verosimiglianza può essere generata mediante la funzione dbinom().\n\nfrom scipy.stats import binom\n\nlk = binom.pmf(12, 20, theta)\nlk\n#> array([0.00000000e+00, 5.42259544e-08, 8.65659248e-05, 3.85928193e-03,\n#>        3.54974396e-02, 1.20134354e-01, 1.79705788e-01, 1.14396740e-01,\n#>        2.21608768e-02, 3.55776487e-04, 0.00000000e+00])\n\nPer i 10 valori \\(\\theta\\) considerati, la funzione di verosimiglianza assume la forma indicata dalla Figura 17.3.\n\nplt.stem(theta, lk, markerfmt=' ')\n#> <StemContainer object of 3 artists>\nplt.title('Funzione di verosimiglianza', fontsize=16)\nplt.xlabel('theta', fontsize=14)\nplt.ylabel('Probabilità', fontsize=14)\nplt.show()\n\n\n\nFigura 17.3: Verosimiglianza del modello binomiale nel caso di 12 successi in 20 prove.\n\n\n\n\nPer calcolare la distribuzione a posteriori dobbiamo fare il prodotto (elemento per elemento) del vettore che contiene i valori della distribuzione a priori e del vettore che contiene i valori della funzione di verosimiglianza. Tale prodotto andrà poi diviso per una costante di normalizzazione, \\(p(y)\\).\nPer la legge della probabilità totale, il denominatore corrisponde alla probabilità marginale dei dati \\(y\\) ed è uguale alla somma dei prodotti tra la distribuzione a priori e la funzione di verosimiglianza.\n\nnp.sum(not_unif_distr_pdf * lk)\n#> 0.08002663388085006\n\nLa distribuzione a posteriori di \\(\\theta\\) sarà dunque uguale al prodotto della distribuzione a priori per la verosimiglianza, diviso per la costante di normalizzazione (probabilità marginale dei dati).\n\npost = (not_unif_distr_pdf * lk) / np.sum(not_unif_distr_pdf * lk)\nprint(post)\n#> [0.00000000e+00 3.38799421e-08 5.40856966e-05 2.41124845e-03\n#>  7.76248059e-02 2.62706437e-01 3.92975580e-01 2.50159584e-01\n#>  1.38459383e-02 2.22286300e-04 0.00000000e+00]\n\nVerifichiamo\n\nnp.sum(post)\n#> 1.0000000000000002\n\nUna rappresentazione grafica della distribuzione a posteriori di \\(\\theta\\) è fornita dalla Figura 17.4.\n\nplt.stem(theta, post, markerfmt=' ')\n#> <StemContainer object of 3 artists>\nplt.title('Distribuzione a posteriori', fontsize=16)\nplt.xlabel('theta', fontsize=14)\nplt.ylabel('Probabilità', fontsize=14)\nplt.show()\n\n\n\nFigura 17.4: Distribuzione a posteriori per il modello binomiale con 12 successi in 20 prove e la distribuzione a priori indicata in Figura 17.2.\n\n\n\n\nConoscendo la distribuzione a posteriori di \\(\\theta\\) diventa possibile calcolare altre quantità di interesse. Per esempio, la moda a posteriori di \\(\\theta\\) si ricava direttamente dal grafico precedente, e corrisponde a 0.6. La media a posteriori si trova con la formula del valore atteso delle v.c..\n\nnp.sum(theta * post)\n#> 0.5853112012901504\n\nLo stesso si può dire della varianza della distribuzione a posteriori.\n\nnp.sum(theta**2 * post) - (np.sum(theta * post))**2\n#> 0.0088174094860623\n\nUsando questo metodo possiamo trovare la distribuzione a posteriori di \\(\\theta\\) nel caso di qualunque distribuzione a priori discreta.\nVerifichiamo i calcoli svolti usando R. Nel caso di una distribuzione a priori discreta, il calcolo della distribuzione a posteriori è implementata nella funzione bayesian_crank() del pacchetto ProbBayes. Dato che ProbBayes non è su CRAN, può essere installato nel modo seguente.\n\nlibrary(\"devtools\")\ninstall_github(\"bayesball/ProbBayes\")\n\nUna volta installato, il pacchetto può essere caricato normalmente.\n\nlibrary(\"ProbBayes\")\n\nPer usare bayesian_crank() procediamo come indicato di seguito.\n\ntheta = seq(0.1, 1, length.out = 10)\np2 <- c(\n  0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05\n)\nd <- tibble(p = theta, Prior = p2)\ny <- 12\nn <- 20\nd$Likelihood <- dbinom(y, prob = d$p, size = n)\ndf <- bayesian_crank(d)\ndf %>% as.data.frame()\n#>      p Prior   Likelihood      Product    Posterior\n#> 1  0.1 0.050 5.422595e-08 2.711298e-09 3.387994e-08\n#> 2  0.2 0.050 8.656592e-05 4.328296e-06 5.408570e-05\n#> 3  0.3 0.050 3.859282e-03 1.929641e-04 2.411248e-03\n#> 4  0.4 0.175 3.549744e-02 6.212052e-03 7.762481e-02\n#> 5  0.5 0.175 1.201344e-01 2.102351e-02 2.627064e-01\n#> 6  0.6 0.175 1.797058e-01 3.144851e-02 3.929756e-01\n#> 7  0.7 0.175 1.143967e-01 2.001943e-02 2.501596e-01\n#> 8  0.8 0.050 2.216088e-02 1.108044e-03 1.384594e-02\n#> 9  0.9 0.050 3.557765e-04 1.778882e-05 2.222863e-04\n#> 10 1.0 0.050 0.000000e+00 0.000000e+00 0.000000e+00\n\nCalcoliamo la media della distribuzione a posteriori\n\nsum(df$p * df$Posterior)\n#> [1] 0.5853112\n\ne la varianza della distribuzione a posteriori\n\nsum(df$p^2 * df$Posterior) - (sum(df$p * df$Posterior))^2\n#> [1] 0.008817409\n\nI risultati replicano quelli trovati sopra."
  },
  {
    "objectID": "026_subj_prop.html#ch-prior-cont-binom",
    "href": "026_subj_prop.html#ch-prior-cont-binom",
    "title": "17  Pensare ad una proporzione in termini soggettivi",
    "section": "\n17.2 Inferenza bayesiana con una distribuzione a priori continua",
    "text": "17.2 Inferenza bayesiana con una distribuzione a priori continua\nIl caso di una distribuzione a priori discreta è stato discusso solo per scopi didattici. In generale, l’uso di una distribuzione a priori discreta non è una buona scelta per rappresentare le nostre credenze a priori sul parametro sconosciuto. Infatti, per definizione, una distribuzione a priori discreta può rappresentare solo alcuni dei possibili valori del parametro – nel caso discusso sopra, ad esempio, non abbiamo considerato il valore 0.55. Sembra dunque più sensato descrivere le nostre credenze a priori sul parametro utilizzando una distribuzione continua.\nCerchiamo una funzione di densità con supporto in \\([0, 1]\\). Il candidato naturale è fornito dalla funzione Beta (si veda il Capitolo 14). Come per le altre funzioni di densità, abbiamo a disposizione quattro funzioni \\(\\textsf{R}\\) che ci consentono di manipolare facilmente questa densità.\nAd esempio, possiamo valutare la funzione di densità \\(\\mbox{Beta}(1, 1)\\) in corrispondenza dei valori \\(p = 0.5\\) e \\(p = 0.8\\), che dovrebbe essere entrambi uguali a 1, e in corrispondenza di \\(p = 1.2\\), che dovrebbe essere ugualea 0 poiché questo valore è al di fuori dell’intervallo \\([ 0, 1]\\).\n\nfrom scipy.stats import beta\n\nprint(beta.pdf([0.5, 0.8, 1.2], 1, 1))\n#> [1. 1. 0.]\n\nOppure possiamo valutare la funzione distribuzione \\(\\mbox{Beta}(1, 1)\\) in corrispondenza dei punti 0.5 e 0.8.\n\nprint(beta.cdf([0.5, 0.8], 1, 1))\n#> [0.5 0.8]\n\nOppure possiamo calcolare la probabilità \\(P(0.5 < p < 0.8)\\).\n\nprint(beta.cdf(0.8, 1, 1) - beta.cdf(0.5, 1, 1))\n#> 0.30000000000000004\n\nPossiamo trovare i quantili della distribuzione \\(\\mbox{Beta}(1, 1)\\) di ordine 0.5 e 0.8.\n\nprint(beta.ppf([0.5, 0.8], 1, 1))\n#> [0.5 0.8]\n\nInfine, è possibile simulare dei valori casuali dalla distribuzione \\(\\mbox{Beta}(a, b)\\). Se vogliamo 5 valori da una \\(\\mbox{Beta}(2, 10)\\), scriviamo:\n\nfrom numpy.random import default_rng\nrng = default_rng()\n\nrng.beta(2, 10, 5)\n#> array([0.11506325, 0.1731984 , 0.17169031, 0.2328708 , 0.15457095])\n\n\n17.2.1 Quali parametri per la distribuzione Beta?\nSe usiamo una distribuzione Beta per rappresentare le nostre credenze a priori sul parametro \\(\\theta\\) (probabilità di successo), allora dobbiamo porci il problema di scegliere i parametri che definiscono la distribuzione Beta che meglio rappresenta le nostre opinioni a priori. Il modo più ovvio per ottenere questo risultato è per prove ed errori. Oppure, possiamo individuare i parametri \\(\\alpha\\) e \\(\\beta\\) della distribuzione interpretando \\(\\alpha\\) come la nostra stima a priori del numero di “successi”, \\(\\beta\\) come a nostra stima a priori del numero di “insuccessi” e \\(\\alpha + \\beta\\) come il numero di prove del campione. Ad esempio, se pensiamo che, su 30 prove, verranno osservati 10 successi, otteniamo una \\(\\mbox{Beta}(10, 20)\\).\n\na = 10\nb = 20\nx = np.linspace(beta.ppf(0.01, a, b),\n                beta.ppf(0.99, a, b), 100)\nplt.plot(x, beta.pdf(x, a, b),\n       'r-', lw=2, alpha=0.6, label='beta pdf')\nplt.xlabel('Valore della variabile casuale X [0, 1]', fontsize=14)\nplt.ylabel('Densità', fontsize=14)\n\n\n\n\n\n\n\nIn alternativa, potremmo specificare la distribuzione a priori definendo la mediana e un quantile della distribuzione. Per esempio, le nostre opinioni a priori sul parametro potrebbero essere tali per cui pensiamo che la mediana della distribuzione sia 0.25 e il quantile della distribuzione di ordine 0.9 sia 0.5. In questo caso potremmo usare i parametri \\(\\alpha = 2\\) e \\(\\beta = 5\\).\n\na = 2\nb = 5\nx = np.linspace(beta.ppf(0.01, a, b),\n                beta.ppf(0.99, a, b), 100)\nplt.plot(x, beta.pdf(x, a, b),\n       'r-', lw=2, alpha=0.6, label='beta pdf')\nplt.xlabel('Valore della variabile casuale X [0, 1]', fontsize=14)\nplt.ylabel('Densità', fontsize=14)\n\n\n\n\n\n\n\n\nprint(beta.median(2, 5))\n#> 0.26444998329566005\n\n\nprint(beta.ppf(0.9, 2, 5))\n#> 0.5103163065514917"
  },
  {
    "objectID": "026_subj_prop.html#commenti-e-considerazioni-finali",
    "href": "026_subj_prop.html#commenti-e-considerazioni-finali",
    "title": "17  Pensare ad una proporzione in termini soggettivi",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questo capitolo abbiamo introdotto la procedura dell’aggiornamento bayesiano nel caso di una distribuzione a priori discreta. Abbiamo anche anticipato alcune informazioni che si dimostreranno utili quando dovremo affrontare il caso in cui viene utilizzata una distribuzione a priori continua. Se viene utilizzata una distribuzione a priori continua, al denominatore del rapporto di Bayes troviamo un integrale che, in generale, non può essere risolto per via analitica. Il caso dell’inferenza su una proporzione, in cui la distribuzione a priori è una distribuzione Beta e la verosimiglianza è binoniale, rappresenta un’eccezione, è un caso nel quale le proprietà della distribuzione a posteriori si posso derivare per via analitica. Questo argomento verrà affrontato nel prossimo capitolo.\n\n\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and bayesian modeling. Chapman; Hall/CRC."
  },
  {
    "objectID": "029_conjugate_families.html#lo-schema-beta-binomiale",
    "href": "029_conjugate_families.html#lo-schema-beta-binomiale",
    "title": "18  Distribuzioni coniugate",
    "section": "\n18.1 Lo schema beta-binomiale",
    "text": "18.1 Lo schema beta-binomiale\nEsiste una particolare classe di distribuzioni a priori, dette distribuzioni a priori coniugate al modello, che godono di un’importante proprietà: se la distribuzione iniziale appartiene a tale classe, anche la distribuzione finale vi appartiene, cioé ha la stessa forma funzionale, e l’aggiornamento della fiducia si riduce alla modifica dei parametri della distribuzione a priori. Ad esempio, se la distribuzione a priori è una Beta e la verosimiglianza è binomiale, allora la distribuzione a posteriori sarà anch’essa una distribuzione Beta.\nDa un punto di vista matematico, le distribuzioni a priori coniugate sono la scelta più conveniente in quanto consentono di calcolare analiticamente la distribuzione a posteriori con “carta e penna”, senza la necessità di ricorrere a calcoli complessi. Da una prospettiva computazionale moderna, però, le distribuzioni a priori coniugate generalmente non sono migliori delle alternative, dato che i moderni metodi computazionali consentono di eseguire l’inferenza praticamente con qualsiasi scelta delle distribuzioni a priori, e non solo con le distribuzioni a priori che risultano matematicamente convenienti. Tuttavia, le famiglie coniugate offronto un utile ausilio didattico nello studio dell’inferenza bayesiana. Questo è il motivo per cui le esamineremo qui. Nello specifico, esamineremo quello che viene chiamato lo schema beta-binomiale.\nPer fare un esempio concreto, consideriamo nuovamente i dati di Zetsche et al. (2019): nel campione di 30 partecipanti clinici le aspettative future di 23 partecipanti risultano negativamente distorte mentre quelle di 7 partecipanti risultano positivamente distorte. Nel seguito, indicheremo con \\(\\theta\\) la probabilità che le aspettative di un paziente clinico siano distorte negativamente. Ci poniamo il problema di ottenere una stima a posteriori di \\(\\theta\\) avendo osservato 23 “successi” in 30 prove. I dati osservati (\\(y = 23\\)) possono essere considerati la manifestazione di una variabile casuale Bernoulliana, dunque la verosimiglianza è binomiale. In tali circostanze, se viene scelta una distribuzione a priori Beta, allora anche la distribuzione a posteriori sarà una Beta.\n\n18.1.1 La distribuzione a priori\nÈ possibile esprimere diverse credenze iniziali rispetto a \\(\\theta\\) mediante la distribuzione Beta. Ad esempio, la scelta di una \\(\\mbox{Beta}(\\alpha = 4, \\beta = 4)\\) quale distribuzione a priori per il parametro \\(\\theta\\) corrisponde alla credenza a priori che associa all’evento “presenza di una aspettativa futura distorta negativamente” una grande incertezza: il valore 0.5 è il valore di \\(\\theta\\) più plausibile, ma anche gli altri valori del parametro (tranne gli estremi) sono ritenuti piuttosto plausibili. Questa distribuzione a priori esprime la credenza che sia egualmente probabile per un’aspettativa futura essere distorta negativamente o positivamente.\n\nlibrary(\"bayesrules\")\nplot_beta(alpha = 4, beta = 4, mean = TRUE, mode = TRUE)\n\n\n\n\n\n\n\nPossiamo quantificare la nostra incertezza calcolando, con un grado di fiducia del 95%, la regione nella quale, in base a tale credenza a priori, si trova il valore del parametro. Per ottenere tale intervallo di credibilità a priori, usiamo la funzione qbeta() di \\(\\mathsf{R}\\). Nella funzione qbeta() i parametri \\(\\alpha\\) e \\(\\beta\\) sono chiamati shape1 e shape2.\n\nqbeta(c(0.025, 0.975), shape1 = 4, shape2 = 4)\n#> [1] 0.1840516 0.8159484\n\nSe poniamo \\(\\alpha=10\\) e \\(\\beta=10\\), anche questa scelta descrive una credenza a priori per la quale è egualmente probabile osservare un’aspettativa futura distorta negativamente o positivamente.\n\nplot_beta(alpha = 10, beta = 10, mean = TRUE, mode = TRUE)\n\n\n\n\n\n\n\nTuttavia, in questo caso la nostra certezza a priori sul valore del parametro è maggiore, come indicato dall’intervallo di ordine 0.95.\n\nqbeta(c(0.025, 0.975), shape1 = 10, shape2 = 10)\n#> [1] 0.2886432 0.7113568\n\nQuale distribuzione a priori dobbiamo scegliere? In un problema concreto di analisi dei dati, la scelta della distribuzione a priori dipende dalle credenze a priori che vogliamo includere nell’analisi dei dati. Se non abbiamo alcuna informazione a priori, allora è possibile usare \\(\\alpha=1\\) e \\(\\beta=1\\), che corrisponde ad una distribuzione a priori uniforme. Ma l’uso di distribuzioni a priori uniformi è sconsigliato per vari motivi, inclusa l’instabilità numerica della stima dei parametri. In tali circostanze sarebbe preferibile usare una distribuzione a priori debolmente informativa, come una \\(\\mbox{Beta}(2, 2)\\).\nNella discussione presente, quale distribuzione a priori useremo una \\(\\mbox{Beta}(2, 10)\\).\n\\[\np(\\theta) = \\frac{\\Gamma(12)}{\\Gamma(2)\\Gamma(10)}\\theta^{2-1} (1-\\theta)^{10-1}.\n\\]\n\nplot_beta(alpha = 2, beta = 10, mean = TRUE, mode = TRUE)\n\n\n\n\n\n\n\nTale distribuzione a priori è del tutto inappropriata per i dati di Zetsche et al. (2019). La \\(\\mbox{Beta}(2, 10)\\) esprime la credenza che \\(\\theta < 0.5\\), con il valore più plausibile pari a cicrca 0.1. Ma non c’è motivo di pensare, a priori, che, per questa popolazione, vi sia una bassa probabilità di un’aspettativa futura distorta negativamente – piuttosto è vero il contrario. La \\(\\mbox{Beta}(2, 10)\\) verrà usata qui solo per mostrare l’effetto che ha una tale scelta sulla distribuzione a posteriori.\n\n18.1.2 La distribuzione a posteriori\nUna volta scelta una distribuzione a priori di tipo Beta, i cui parametri rispecchiano le nostre credenze iniziali su \\(\\theta\\), la distribuzione a posteriori viene specificata dalla formula di Bayes:\n\\[\n\\text{distribuzione a posteriori} = \\frac{\\text{verosimiglianza}\\cdot\\text{distribuzione a priori}}{\\text{verosimiglianza marginale}}.\n\\]\nPer i dati presenti la verosimiglianza è binomiale per cui abbiamo\n\\[\np(\\theta \\mid n=30, y=23) = \\frac{\\Big[\\binom{30}{23}\\theta^{23}(1-\\theta)^{30-23}\\Big]\\Big[\\frac{\\Gamma(12)}{\\Gamma(2)\\Gamma(10)}\\theta^{2-1} (1-\\theta)^{10-1}\\Big]}{p(y = 23)},\n\\]\nladdove \\(p(y = 23)\\), ovvero la verosimiglianza marginale, è una costante di normalizzazione.\nRiscriviamo l’equazione precedente in termini più generali:\n\\[\np(\\theta \\mid n, y) = \\frac{\\Big[\\binom{n}{y}\\theta^{y}(1-\\theta)^{n-y}\\Big]\\Big[\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\theta^{a-1} (1-\\theta)^{b-1}\\Big]}{p(y)}.\n\\]\nRaccogliendo tutte le costanti otteniamo:\n\\[\np(\\theta \\mid n, y) =\\left[\\frac{\\binom{n}{y}\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}}{p(y)}\\right] \\theta^{y}(1-\\theta)^{n-y}\\theta^{a-1} (1-\\theta)^{b-1}.\n\\]\nSe ignoriamo il termine costante all’interno della parentesi quadra il termine di destra dell’equazione precedente identifica il kernel della distribuzione a posteriori e corrisponde ad una Beta non normalizzata di parametri \\(a + y\\) e \\(b + n - y\\):\n\\[\n\\begin{align}\np(\\theta \\mid n, y) &\\propto \\theta^{y}(1-\\theta)^{n-y}\\theta^{a-1} (1-\\theta)^{b-1},\\notag\\\\\n&\\propto \\theta^{a+y-1}(1-\\theta)^{b+n-y-1}.\n\\end{align}\n\\]\nPer ottenere una distribuzione di densità, dobbiamo aggiungere una costante di normalizzazione al kernel della distribuzione a posteriori. In base alla definizione della distribuzione Beta, ed essendo \\(a' = a+y\\) e \\(b' = b+n-y\\), tale costante di normalizzazione è uguale a\n\\[\n\\frac{\\Gamma(a'+b')}{\\Gamma(a')\\Gamma(b')} = \\frac{\\Gamma(a+b+n)}{\\Gamma(a+y)\\Gamma(b+n-y)}.\n\\]\nPossiamo dunque concludere, nel caso dello schema beta-binomiale, che la distribuzione a posteriori è una \\(\\mbox{Beta}(a+y, b+n-y)\\):\n\\[\n\\mbox{Beta}(a+y, b+n-y) = \\frac{\\Gamma(a+b+n)}{\\Gamma(a+y)\\Gamma(b+n-y)} \\theta^{a+y-1}(1-\\theta)^{b+n-y-1}.\n\\]\nIn sintesi, per i dati in discussione, moltiplicando verosimiglianza \\(\\mbox{Bin}(n = 30, y = 23 \\mid \\theta)\\) per la la distribuzione a priori \\(\\theta \\sim \\mbox{Beta}(2, 10)\\) e dividendo per la costante di normalizzazione, si ottiene la distribuzione a posteriori \\(p(\\theta \\mid n, y) \\sim \\mbox{Beta}(25, 17)\\).\nQuesto è un esempio di analisi coniugata. La presente combinazione di verosimiglianza e distribuzione a priori è chiamata caso coniugato beta-binomiale ed è descritta dal seguente teorema.\n\nTeorema 18.1 Sia data la funzione di verosimiglianza \\(\\mbox{Bin}(n, y \\mid \\theta)\\) e sia \\(\\mbox{Beta}(\\alpha, \\beta)\\) una distribuzione a priori. In tali circostanze, la distribuzione a posteriori del parametro \\(\\theta\\) sarà una distribuzione \\(\\mbox{Beta}(\\alpha + y, \\beta + n - y)\\).\n\nÈ facile calcolare il valore atteso a posteriori di \\(\\theta\\). Essendo \\(\\mathbb{E}[\\mbox{Beta}(\\alpha, \\beta)] = \\frac{\\alpha}{\\alpha + \\beta}\\), il risultato cercato diventa\n\\[\n\\mathbb{E}_{\\text{post}} [\\mathrm{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta +n}.\n\\tag{18.1}\\]\n\nEsercizio 18.1 Si rappresenti in maniera grafica e si descriva in forma numerica l’aggiornamento bayesiano beta-binomiale per i dati di Zetsche et al. (2019). Si assuma una distribuzione a priori \\(\\mbox{Beta}(2, 10)\\).\n\n\nSoluzione. Per i dati in questione, l’aggiornamento bayesiano può essere rappresentato in forma grafica usando la funzione plot_beta_binomial() del pacchetto bayesrules:\n\nbayesrules::plot_beta_binomial(\n  alpha = 2, beta = 10, y = 23, n = 30\n  ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUn sommario delle distribuzioni a priori e a posteriori può essere ottenuto, ad esempio, usando la funzione summarize_beta_binomial() del pacchetto bayesrules:\n\nbayesrules:::summarize_beta_binomial(\n  alpha = 2, beta = 10, y = 23, n = 30\n)\n#>       model alpha beta      mean mode         var        sd\n#> 1     prior     2   10 0.1666667  0.1 0.010683761 0.1033623\n#> 2 posterior    25   17 0.5952381  0.6 0.005603016 0.0748533\n\n\n\nEsercizio 18.2 Per i dati di Zetsche et al. (2019), si trovino la media, la moda, la deviazione standard della distribuzione a posteriori di \\(\\theta\\). Si trovi inoltre l’intervallo di credibilità a posteriori del 95% per il parametro \\(\\theta\\).\n\n\nSoluzione. L’intervallo di credibilità a posteriori del 95% per il parametro \\(\\theta\\) si trova usando il Teorema Teorema 18.1.\n\nqbeta(c(0.025, 0.975), shape1 = 25, shape2 = 17)\n#> [1] 0.4450478 0.7368320\n\nLa media della distribuzione a posteriori si trova con l’Equazione 18.1.\n\n25 / (25 + 17)\n#> [1] 0.5952381\n\nLa moda della distribuzione a posteriori si trova usando le proprietà della distribuzione Beta.\n\n(25 - 1) / (25 + 17 - 2)\n#> [1] 0.6\n\nLa deviazione standard della distribuzione a posteriori si trova usando le proprietà della distribuzione Beta.\n\nsqrt((25 * 17) / ((25 + 17)^2 * (25 + 17 + 1)))\n#> [1] 0.0748533\n\n\n\nEsercizio 18.3 Si trovino i parametri e le proprietà della distribuzione a posteriori del parametro \\(\\theta\\) per i dati dell’esempio relativo alla ricerca di Stanley Milgram discussa da Johnson et al. (2022).\nNel 1963, Stanley Milgram presentò una ricerca sulla propensione delle persone a obbedire agli ordini di figure di autorità, anche quando tali ordini possono danneggiare altre persone (Milgram, 1963). Nell’articolo, Milgram descrive lo studio come\n\nconsist[ing] of ordering a naive subject to administer electric shock to a victim. A simulated shock generator is used, with 30 clearly marked voltage levels that range from IS to 450 volts. The instrument bears verbal designations that range from Slight Shock to Danger: Severe Shock. The responses of the victim, who is a trained confederate of the experimenter, are standardized. The orders to administer shocks are given to the naive subject in the context of a “learning experiment” ostensibly set up to study the effects of punishment on memory. As the experiment proceeds the naive subject is commanded to administer increasingly more intense shocks to the victim, even to the point of reaching the level marked Danger: Severe Shock.\n\nAll’insaputa del partecipante, gli shock elettrici erano falsi e l’attore stava solo fingendo di provare il dolore dello shock.\n\n\nSoluzione. Johnson et al. (2022) fanno inferenza sui risultati dello studio di Milgram mediante il modello Beta-Binomiale. Il parametro di interesse è \\(\\theta\\), la probabiltà che una persona obbedisca all’autorità (in questo caso, somministrando lo shock più severo), anche se ciò significa recare danno ad altri. Johnson et al. (2022) ipotizzano che, prima di raccogliere dati, le credenze di Milgram relative a \\(\\theta\\) possano essere rappresentate mediante una \\(\\mbox{Beta}(1, 10)\\). Sia \\(y = 26\\) il numero di soggetti che, sui 40 partecipanti allo studio, aveva accettato di infliggere lo shock più severo. Assumendo che ogni partecipante si comporti indipendentemente dagli altri, possiamo modellare la dipendenza di \\(y\\) da \\(\\theta\\) usando la distribuzione binomiale. Giungiamo dunque al seguente modello bayesiano Beta-Binomiale:\n\\[\n\\begin{align}\ny \\mid \\theta & \\sim \\mbox{Bin}(n = 40, \\theta) \\notag\\\\\n\\theta & \\sim \\text{Beta}(1, 10) \\; . \\notag\n\\end{align}\n\\]\nUsando le funzioni di bayesrules possiamo facilmente calcolare i parametri e le proprietà della distribuzione a posteriori.\n\nbayesrules::summarize_beta_binomial(\n  alpha = 1, beta = 10, y = 26, n = 40\n)\n#>       model alpha beta       mean      mode         var         sd\n#> 1     prior     1   10 0.09090909 0.0000000 0.006887052 0.08298827\n#> 2 posterior    27   24 0.52941176 0.5306122 0.004791057 0.06921746\n\nIl processo di aggiornamento bayesiano è descritto dalla figura ottenuta con la funzione bayesrules::plot_beta_binomial().\n\nbayesrules::plot_beta_binomial(\n  alpha = 1, beta = 10, y = 26, n = 40\n  )"
  },
  {
    "objectID": "029_conjugate_families.html#inferenza-bayesiana-con-distribuzioni-a-priori-continue",
    "href": "029_conjugate_families.html#inferenza-bayesiana-con-distribuzioni-a-priori-continue",
    "title": "18  Distribuzioni coniugate",
    "section": "\n18.2 Inferenza bayesiana con distribuzioni a priori continue",
    "text": "18.2 Inferenza bayesiana con distribuzioni a priori continue\nL’inferenza bayesiane sulla proporzione \\(\\theta\\) si basa su vari riepiloghi della distribuzione a posteriori Beta. Il riepilogo che si calcola dalla distribuzione a posteriori dipende dal tipo di inferenza. Consideriamo qui su due tipi di inferenza:\n\nproblemi in cui si è interessati a valutare la plausibilità che il parametro assuma valori contenuti in un dato intervallo di valori,\nstime dell’intervallo che contiene il parametro ad un dato livello di probabilità soggettiva.\n\n\n18.2.1 Verifica di ipotesi bayesiana\nNell’esempio in discussione sui dati di Zetsche et al. (2019), la nostra credenza a posteriori relativa a \\(\\theta\\) (ovvero, la probabilità che l’aspettativa dell’umore futuro sia distorta negativamente) è descritta da una distribuzione Beta(25,17). Una volta definita la distribuzione a posteriori, ci possiamo porre altre domande. Per esempio: qual è la probabilità che \\(\\theta\\) sia maggiore di 0.5?\nUna risposta a questa domanda si può trovare usando la funzione pbeta().\n\n1 - pbeta(0.5, 25, 17)\n#> [1] 0.8944882\n\nOppure, in maniera equivalente, con la funzione ProbBayes::beta_area().\n\nProbBayes::beta_area(lo = 0.5, hi = 1.0, shape_par = c(25, 17))\n\n\n\n\n\n\n\nQuesto calcolo può anche essere svolto mediante simulazione. Dato che conosciamo la distribuzione target, è possibile ricavare un campione casuale di osservazioni da una tale distribuzione per poi riassumere il campione in modo tale da trovare \\(\\theta > 0.5\\).\n\nnsim <- 1e6\ntheta_samples <- rbeta(nsim, 25, 17)\nsum(theta_samples > 0.5) / nsim\n#> [1] 0.894317\n\nIl risultato della simulazione è molto simile a quello ottenuto in precedenza.\n\n18.2.2 Intervalli di credibilità\nUn secondo tipo di inferenza bayesiana è quella che ci porta a costruire gli intervalli di credibilità. Un intervallo di credibilità di ordine \\(a \\in [0, 1]\\) è l’intervallo di valori che contiene una proporzione della distribuzione a posteriori pari ad \\(a\\).\nLa funzione ProbBayes::beta_interval() consente di calcolare l’intervallo di credibilità che lascia la stessa probabilità nelle due code. Per esempio, l’intervallo di credibilità all’89% per la distribuzione a posteriori dell’esempio relativo ai dati di Zetsche et al. (2019) è il seguente.\n\nProbBayes::beta_interval(0.89, c(25, 17))\n\n\n\n\n\n\n\nPer i dati di Zetsche et al. (2019), l’intervallo di credibilità all’50% è il seguente.\n\nProbBayes::beta_interval(0.5, c(25, 17))"
  },
  {
    "objectID": "029_conjugate_families.html#principali-distribuzioni-coniugate",
    "href": "029_conjugate_families.html#principali-distribuzioni-coniugate",
    "title": "18  Distribuzioni coniugate",
    "section": "\n18.3 Principali distribuzioni coniugate",
    "text": "18.3 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori le quali producono una distribuzione a posteriori che ha la stessa densità della distribuzione a priori. Sono elencate qui sotto le più note coniugazioni tra modelli statistici e distribuzioni a priori.\n\nPer il modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribizione iniziale è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione finale è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nPer il modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribizione iniziale è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione finale è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nPer il modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribizione iniziale è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione finale è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nPer il modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribizione iniziale è \\(\\mbox{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione finale è \\(\\mbox{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\)."
  },
  {
    "objectID": "029_conjugate_families.html#commenti-e-considerazioni-finali",
    "href": "029_conjugate_families.html#commenti-e-considerazioni-finali",
    "title": "18  Distribuzioni coniugate",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLo scopo di questo Capitolo è stato quello di mostrare come sia possibile integrare le conoscenze a priori (espresse nei termini di una distribuzione a priori) con le evidenze fornite dai dati (espresse nei termini della funzione di verosimiglianza), così da determinare, mediante il teorema di Bayes, una distribuzione a posteriori, la quale condensa l’incertezza che abbiamo sul parametro sconosciuto \\(\\theta\\). Per illustrare tale problema, abbiamo considerato una situazione nella quale \\(\\theta\\) corrisponde alla probabilità di successo in una sequenza di prove Bernoulliane. In tali circostanze è ragionevole esprimere le credenze a priori mediante la densità Beta, con opportuni parametri. L’inferenza rispetto a \\(\\theta\\) può essere dunque svolta utilizzando una distribuzione a priori Beta e una verosimiglianza binomiale. In tali circostanze, la distribuzione a posteriori diventa essa stessa una distribuzione Beta. Questo è il cosiddetto schema beta-binomiale. Dato che utilizza una distribuzione a priori coniugata, lo schema beta-binomiale rende possibile la determinazione analitica dei parametri della distribuzione a posteriori.\n\n\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMilgram, S. (1963). Behavioral study of obedience. The Journal of Abnormal and Social Psychology, 67(4), 371–378.\n\n\nZetsche, U., Bürkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688."
  },
  {
    "objectID": "030_balance_prior_post.html#il-test-di-benchdel",
    "href": "030_balance_prior_post.html#il-test-di-benchdel",
    "title": "19  L’influenza della distribuzione a priori",
    "section": "\n19.1 Il test di Benchdel",
    "text": "19.1 Il test di Benchdel\nNel fumetto di Alison Bechdel The Rule, un personaggio afferma di guardare un film solo se soddisfa le seguenti tre regole (Bechdel, 1986): almeno due caratteri nel film devono essere donne; queste due donne si parlano; parlano di qualcosa altro oltre a parlare di qualche uomo.\nQuesti criteri costituiscono il test di Bechdel per la rappresentazione delle donne nei film. Johnson et al. (2022) pongono la seguente domanda “Quale percentuale dei film che avete visto supera il test di Bechdel?”.\nSia \\(\\pi \\in [0, 1]\\) una variabile casuale che indica la proporzione sconosciuta di film che superano il test di Bechdel. Tre amiche — la femminista, l’ignara e l’ottimista — hanno opionioni diverse su \\(\\pi\\). Riflettendo sui film che ha visto, la femminista capisce che nella maggioranza dei film mancano personaggi femminili forti. L’ignara non ricorda bene i film che ha visto, quindi non sa quanti film superano il test di Bechdel. Infine, l’ottimista pensa che, in generale, le donne siano ben rappresentate all’interno dei film: secondo lei quasi tutti i film superano il test di Bechdel. Le tre amiche hanno dunque tre modelli a priori diversi di \\(\\pi\\).\nAbbiamo visto in precedenza come sia possibile usare la distribuzione Beta per rappresentare le credenze a priori. Ponendo la gran parte della massa della probabilità a priori su valori \\(\\pi < 0.5\\), la distribuzione a priori \\(\\text{Beta}(5, 11)\\) riflette il punto di vista femminista secondo il quale la maggioranza dei film non supera il test di Bechdel. Al contrario, la \\(\\text{Beta}(14,1)\\) pone la gran parte della massa della distribuzione a priori su valori \\(\\pi\\) prossimi a 1, e corrisponde quindi alle credenze a priori dell’amica ottimista. Infine, una \\(\\text{Beta}(1 ,1)\\) o \\(\\mbox{Unif}(0, 1)\\), assegna lo stesso livello di plausibilità a tutti i valori \\(\\pi \\in [0, 1]\\), e corrisponde all’incertezza a priori dell’ignara.\nNell’esempio di Johnson et al. (2022), le tre amiche decidono di rivedere un campione di \\(n\\) film e di registrare \\(y\\), ovvero il numero di film che superano il test di Bechdel. Se \\(y\\) corrisponde al numero di “successi” in un numero fisso di \\(n\\) prove Bernoulliane i.i.d., allora la dipendenza di \\(y\\) da \\(\\pi\\) viene specificata da un modello binomiale. Quindi, per ciascuna delle tre amiche è possibile scrivere un modello beta-binomiale\n\\[\\begin{align}\nY \\mid \\pi & \\sim \\mbox{Bin}(n, \\pi)  \\notag\\\\\n\\pi & \\sim \\mbox{Beta}(\\alpha, \\beta) \\notag\n\\end{align}\\]\nche utilizza diversi parametri \\(\\alpha\\) e \\(\\beta\\) per la distribuzione a priori e che conduce a tre diverse distribuzioni a posteriori per il parametro sconosciuto \\(\\pi\\):\n\\[\\begin{equation}\n\\pi \\mid (Y = y) \\sim \\mbox{Beta}(\\alpha + y, \\beta + n - y).\n\\end{equation}\\]\nJohnson et al. (2022) si chiedono come le credenze a priori delle tre amiche influenzano le credenze a posteriori a cui esse giungono dopo avere osservato i dati. Si chiedono inoltre in che modo la dimensione del campione moduli l’influenza della distribuzione a priori sulla distribuzione a posteriori.\nPer rispondere a queste domande, Johnson et al. (2022) consideriamo tre diversi scenari:\n\ngli stessi dati osservati, ma distribuzioni a priori diverse;\ndati diversi, ma la stessa distribuzione a priori;\ndati diversi e distribuzioni a priori diverse."
  },
  {
    "objectID": "030_balance_prior_post.html#stessi-dati-diverse-distribuzioni-a-priori",
    "href": "030_balance_prior_post.html#stessi-dati-diverse-distribuzioni-a-priori",
    "title": "19  L’influenza della distribuzione a priori",
    "section": "\n19.2 Stessi dati, diverse distribuzioni a priori",
    "text": "19.2 Stessi dati, diverse distribuzioni a priori\nIniziamo con lo scenario che descrive il caso in cui abbiamo gli stessi dati ma diverse distribuzioni a priori. Supponiamo che le tre amiche decidano di guardare insieme 20 film selezionati a caso.\n\ndata(bechdel, package = \"bayesrules\")\nset.seed(84735)\nbechdel_20 <- bechdel %>% \n  sample_n(20)\nbechdel_20 %>% \n  head(3)\n#> # A tibble: 3 × 3\n#>    year title      binary\n#>   <dbl> <chr>      <chr> \n#> 1  2005 King Kong  FAIL  \n#> 2  1983 Flashdance PASS  \n#> 3  2013 The Purge  FAIL\n\nDi questi 20 film, solo il 45% (\\(y\\) = 9) passa il test di Bechdel.\n\nbechdel_20 %>% \n  janitor::tabyl(binary) %>% \n  janitor::adorn_totals(\"row\")\n#>  binary  n percent\n#>    FAIL 11    0.55\n#>    PASS  9    0.45\n#>   Total 20    1.00\n\nEsaminiamo le tre distribuzioni a posteriori. Per la femminista usiamo una distribuzione a priori \\(\\text{Beta}(5, 11)\\).\n\nbayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 9, n = 20\n  ) \n\n\n\n\n\n\n\n\nbayesrules:::summarize_beta_binomial(\n  alpha = 5, beta = 11, y = 9, n = 20\n)\n#>       model alpha beta      mean      mode        var         sd\n#> 1     prior     5   11 0.3125000 0.2857143 0.01263787 0.11241827\n#> 2 posterior    14   22 0.3888889 0.3823529 0.00642309 0.08014418\n\nPer l’ottimista usiamo una distribuzione a priori \\(\\text{Beta}(14, 1)\\).\n\nbayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 9, n = 20\n) \n\n\n\n\n\n\n\n\nbayesrules:::summarize_beta_binomial(\n  alpha = 14, beta = 1, y = 9, n = 20\n)\n#>       model alpha beta      mean      mode         var         sd\n#> 1     prior    14    1 0.9333333 1.0000000 0.003888889 0.06236096\n#> 2 posterior    23   12 0.6571429 0.6666667 0.006258503 0.07911070\n\nInfine, per l’ignara usiamo una distribuzione a priori \\(\\text{Beta}(1, 1)\\).\n\nbayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 9, n = 20\n)\n\n\n\n\n\n\n\n\nbayesrules:::summarize_beta_binomial(\n  alpha = 1, beta = 1, y = 9, n = 20\n)\n#>       model alpha beta      mean mode        var        sd\n#> 1     prior     1    1 0.5000000  NaN 0.08333333 0.2886751\n#> 2 posterior    10   12 0.4545455 0.45 0.01077973 0.1038255\n\nPer calcolare la distribuzione a posteriori, ho usato le funzioni del pacchetto bayesrules. Ma per lo schema beta-binomiale è facile trovare i parametri della distribuzione a posteriori. Per esempio, nel caso dell’amica femminista, la distribuzione a posteriori è una Beta di parametri\n\\[\n\\alpha_{post} = \\alpha_{prior} + y = 5+9 = 14\n\\]\ne\n\\[\n\\beta_{post} = \\beta_{prior} + n - y = 11 + 20 - 9 = 22.\n\\]\nL’aggiornamento bayesiano indica che le tre amiche otterranno valori molto diversi per la media (o la moda) a posteriori del parametro \\(\\pi\\). Dunque, anche dopo avere visto 20 film, le tre amiche non si trovano d’accordo su quale sia la proporzione di film che passano il test di Bechdel.\nQuesto non dovrebbe sorprenderci. L’amica ottimista aveva opinioni molto forti sul valore di \\(\\pi\\) e i pochi nuovi dati che le sono stati forniti non sono riusciti a convincerla a cambiare idea: pensa ancora che i valori \\(\\pi > 0.5\\) siano i più credibili. Lo stesso si può dire, all’estremo opposto, dell’amica femminista: anche lei continua a pensare che i valori \\(\\pi < 0.5\\) siano i più credibili. Infine, l’ignara non aveva nessuna opinione a priori su \\(\\pi\\) e, anche dopo avere visto 20 film, continua a pensare che il valore \\(\\pi\\) più credibile sia quello intermedio, nell’intorno di 0.5.\nIn conclusione, quando i dati sono deboli (ovvero, quando il campione è piccolo), l’aggiornamento bayesiano altera solo in piccola misura le distribuzioni a priori."
  },
  {
    "objectID": "030_balance_prior_post.html#dati-diversi-stessa-distribuzione-a-priori",
    "href": "030_balance_prior_post.html#dati-diversi-stessa-distribuzione-a-priori",
    "title": "19  L’influenza della distribuzione a priori",
    "section": "\n19.3 Dati diversi, stessa distribuzione a priori",
    "text": "19.3 Dati diversi, stessa distribuzione a priori\nSupponiamo ora che l’amica ottimista abbia tre amiche, Maria, Anna e Sara, tutte ottimiste come lei. L’ottimista chiede a Maria, Anna e Sara di fare loro stesse l’esperimento descritto in precedenza. Maria guarda 13 film; di questi 6 passano il test di Bechdel. Anna guarda 63 film; di questi 29 passano il test di Bechdel. Sara guarda 99 film; di questi 46 passano il test di Bechdel.\nSupponiamo che Maria, Anna e Sara condividano la stessa credenza a priori su \\(\\pi\\): ovvero, Beta(14, 1). In tali circostanze e, alla luce dei dati osservati, cosa possiamo dire delle tre distribuzioni a posteriori?\n\np1 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 6, n = 13\n  ) + \n  theme(legend.position = \"none\") \np2 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 29, n = 63\n  ) + \n  theme(legend.position = \"none\") \np3 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \np1 + p2 + p3\n\n\n\nFigura 19.1: Aggiornamento bayesiano per le credenze di Maria (sinistra, 16 film), Anna (centro, 63 film) e Sara (destra, 99 film).\n\n\n\n\nIn conclusione, dalla Figura 19.1 notiamo due cose. Primo, all’aumentare delle informazioni disponibili (ovvero, al crescere dell’ampiezza del campione), la distribuzione a posteriori si allontana sempre di più dalla distribuzione a priori e si avvicina sempre di più alla verosimiglianza. Secondo, all’aumentare dell’ampiezza del campione la varianza della distribuzione a posteriori diminuisce sempre di più — ovvero, diminuisce l’incertezza su quelli che sono i valori \\(\\pi\\) più credibili."
  },
  {
    "objectID": "030_balance_prior_post.html#dati-diversi-diverse-distribuzioni-a-priori",
    "href": "030_balance_prior_post.html#dati-diversi-diverse-distribuzioni-a-priori",
    "title": "19  L’influenza della distribuzione a priori",
    "section": "\n19.4 Dati diversi, diverse distribuzioni a priori",
    "text": "19.4 Dati diversi, diverse distribuzioni a priori\nLa Figura 19.2 illustra le distribuzioni a posteriori che si ottengono incrociando tre diversi set di dati (\\(y\\) = 6, \\(n\\) = 13;, \\(y\\) = 29, \\(n\\) = 63; \\(y\\) = 66, \\(n\\) = 99) con tre diverse distribuzioni a priori, \\(\\mbox{Beta}(14, 1)\\), \\(\\mbox{Beta}(5, 11)\\) e \\(\\mbox{Beta}(1, 1)\\).\n\np1 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 6, n = 13\n  ) +\n  theme(legend.position = \"none\") \np2 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 29, n = 63\n  ) +\n  theme(legend.position = \"none\") \np3 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \np4 <- bayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 6, n = 13\n  ) +\n  theme(legend.position = \"none\") \np5 <- bayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 29, n = 63\n  ) +\n  theme(legend.position = \"none\") \np6 <- bayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \np7 <- bayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 6, n = 13\n  ) +\n  theme(legend.position = \"none\") \np8 <- bayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 29, n = 63\n  ) +\n  theme(legend.position = \"none\") \np9 <- bayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \n(p1 + p2 + p3) / (p4 + p5 + p6) / (p7 + p8 + p9)\n\n\n\nFigura 19.2: Sulle colonne (a partire da sinistra) i dati utilizzati sono, rispettivamente, (y = 6, n = 13), (y = 29, n = 63) e (y = 66, n = 99). Sulle righe (a partire dall’alto), le distribuzioni a priori usate sono: Beta(14, 1), Beta(5, 11) e Beta(1, 1).\n\n\n\n\nIn conclusione, la Figura 19.2 ci consente di concludere quanto segue: se il campione è grande, una distribuzione a priori debolmente informativa ha uno scarso effetto sulla distribuzione a posteriori; se il campione è piccolo, invece, anche una distribuzione a priori debolmente informativa ha un grande effetto sulla distribuzione a posteriori."
  },
  {
    "objectID": "030_balance_prior_post.html#collegare-le-intuizioni-alla-teoria",
    "href": "030_balance_prior_post.html#collegare-le-intuizioni-alla-teoria",
    "title": "19  L’influenza della distribuzione a priori",
    "section": "\n19.5 Collegare le intuizioni alla teoria",
    "text": "19.5 Collegare le intuizioni alla teoria\nIl compromesso che abbiamo osservato nell’esempio precedente, ovvero l’equilibrio che si ottiene tra la distribuzione a priori e le evidenze fornite dai dati, è molto vicino alle nostre intuizioni. Ma è anche il frutto di una necessità matematica. È infatti possibile riscrivere l’Equazione 18.1 nel modo seguente\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta +n}\\notag\\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\tag{19.1}\\]\nL’Equazione 19.1 indica che il valore atteso a posteriori è una media pesata fra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata di successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Quindi, quando \\(n\\) è grande rispetto ad \\(\\alpha + \\beta\\), contano molto i dati osservati e contano poco le credenze a priori. Viceversa, quando \\(n\\) è piccolo rispetto a \\(\\alpha + \\beta\\), i dati contano poco rispetto alla credenza a priori.\nQueste osservazioni ci fanno capire come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se vogliamo assumere una totale ignoranza rispetto al fenomeno in esame, la scelta coerente è \\(\\alpha = \\beta = 1\\) (ogni valore di \\(\\theta\\) è ugualmente credibile); se invece abbiamo delle forti credenze a priori, allora possiamo scegliere \\(\\alpha\\) così che sia uguale al valore atteso a priori, mentre \\(\\alpha + \\beta\\) esprime l’importanza che diamo all’informazione a priori: maggiore è il valore di \\(\\alpha + \\beta\\), tanti più dati serviranno per allontanare la distribuzione a posteriori dalla distribuzione a priori. Infine, se \\(n\\) è grande, la distribuzione a posteriori avrà una scarsa influenza sulla distribuzione a priori, a meno di scelte estreme."
  },
  {
    "objectID": "030_balance_prior_post.html#commenti-e-considerazioni-finali",
    "href": "030_balance_prior_post.html#commenti-e-considerazioni-finali",
    "title": "19  L’influenza della distribuzione a priori",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa conclusione che possiamo trarre dall’esempio discusso da Johnson et al. (2022) è molto chiara: l’aggiornamento bayesiano può essere paragonato ai processi di ragionamento del senso comune. Quando le nuove evidenze (i dati) sono deboli, non c’è ragione di cambiare idea (le nostre credenze “a posteriori” sono molto simili a ciò che pensavamo prima di avere osservato i dati). Quando le nuove evidenze sono irrefutabili, invece, è necessario modificare le nostre credenze sulla base di ciò che ci dicono i dati, quali che siano le nostre credenze pregresse — non farlo significherebbe vivere in un mondo di fantasia e avere scarse possibilità di sopravvivere nel mondo empirico. L’aggiornamento bayesiano, dunque, non fa altro che esprimere in maniera quantitativa e precisa ciò che ci dicono le nostre intuizioni.\nAlla luce di quanto detto sopra, è sorprendente che l’approccio frequentista neghi questa logica. I test frequentisti non tengono conto delle conoscenze pregresse. Dunque, se un test frequentista, calcolato su un piccolo campione (ovvero, quando i dati sono molto deboli), suggerisce che dovremmo farci un’opinione di un certo tipo sul fenomeno in esame, l’indicazione è quella di prendere seriamente in considerazione il risultato del test (ovvero di modificare le nostre credenze) quali che siano le evidenze precedenti – le quali, in generale, potrebbero mostrare che il risultato del test non ha alcun senso. Un tale modo di pensare viene preso sul serio da coloro che, nella comunità scientifica, seguono l’approccio frequentista. Dato che in questo Capitolo abbiamo parlato di fumetti, concluderei dicendo che il significato della presente discussione è catturata nella maniera più chiara possibile in questa famosa striscia.\n\n\n\n\n\n\n\nBechdel, A. (1986). Dykes to watch out for. Firebrand Books.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press."
  },
  {
    "objectID": "036_posterior_sim.html#metodo-basato-su-griglia",
    "href": "036_posterior_sim.html#metodo-basato-su-griglia",
    "title": "20  Approssimazione della distribuzione a posteriori",
    "section": "\n20.1 Metodo basato su griglia",
    "text": "20.1 Metodo basato su griglia\nIl metodo basato su griglia (grid-based) è un metodo numerico esatto basato su una griglia di punti uniformemente spaziati. Anche se la maggior parte dei parametri è continua (ovvero, in linea di principio ciascun parametro può assumere un numero infinito di valori), possiamo ottenere un’eccellente approssimazione della distribuzione a posteriori considerando solo una griglia finita di valori dei parametri. Con un tale metodo, dunque, la densità di probabilità a posteriori può essere approssimata tramite le densità di probabilità calcolate in ciascuna cella della griglia.\nIl metodo basato su griglia si sviluppa in quattro fasi:\n\nfissare una griglia discreta di possibili valori \\(\\theta\\);\nvalutare la distribuzione a priori \\(p(\\theta)\\) e la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) in corrispondenza di ciascun valore \\(\\theta\\) della griglia;\nottenere un’approssimazione discreta della densità a posteriori:\n\nper ciascun valore \\(\\theta\\) della griglia, calcolare il prodotto \\(p(\\theta) p(y \\mid \\theta)\\);\nnormalizzare i prodotti così ottenuti in modo tale che la loro somma sia 1;\n\n\nselezionare \\(n\\) valori casuali della griglia in modo tale da ottenere un campione casuale delle densità a posteriori normalizzate.\n\nÈ possibile migliorare l’approssimazione aumentando il numero di punti della griglia. Infatti utilizzando un numero infinito di punti si otterrebbe la descrizione esatta della distribuzione a posteriori, dovendo però pagare il costo dell’utilizzo di infinite risorse di calcolo. Il limite maggiore dell’approccio basato su griglia è proprio questo: al crescere della dimensionalità \\(n\\) dello spazio dei parametri, i punti della griglia necessari per avere una buona stima crescono esponenzialmente con \\(n\\), rendendo questo metodo inattuabile per problemi complessi.\n\n20.1.1 Modello Beta-Binomiale\nPer fare un esempio, utilizziamo il metodo basato su griglia nel caso dello schema beta-binomiale di cui conosciamo la soluzione esatta. Esaminiamo nuovamente i dati di Zetsche et al. (2019): 23 “successi” in 30 prove Bernoulliane indipendenti.\nImponendo alla distribuzione a priori su \\(\\theta\\) (probabilità di successo in una singola prova, laddove per “successo” si intende una aspettativa distorta negativamente dell’umore futuro) una \\(\\mbox{Beta}(2, 10)\\) per descrivere la nostra incertezza sul parametro prima di avere osservato i dati, il modello diventa:\n\\[\n\\begin{align}\nY \\mid \\theta & \\sim \\mbox{Bin}(n = 30, \\theta), \\notag\\\\\n\\theta & \\sim \\mbox{Beta}(2, 10).\\notag\n\\end{align}\n\\]\nIn queste circostanze, l’aggiornamento bayesiano produce una distribuzione a posteriori Beta di parametri 25 (\\(y + \\alpha\\) = 23 + 2) e 17 (\\(n - y + \\beta\\) = 30 - 23 + 10):\n\\[\n\\theta \\mid (y = 23) \\sim \\mbox{Beta}(25, 17).\\notag\n\\]\nPer approssimare una tale distribuzione a posteriori, scriviamo una funzione che produce l’approssimazione della distribuzione a posteriori basata su griglia usando la procedura descritta nel capitolo precedente.\n\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"seaborn-v0_8\")\n\ndef posterior_grid_approx(grid_points=20, success=23, trials=30):\n    \"\"\"\n    \"\"\"\n    # define grid\n    p_grid = np.linspace(0, 1, grid_points)\n\n    # define prior\n    unstd_prior = stats.beta.pdf(p_grid, 2, 10)\n    prior = unstd_prior / sum(unstd_prior)\n\n    # compute likelihood at each point in the grid\n    likelihood = stats.binom.pmf(success, trials, p_grid)\n\n    # compute product of likelihood and prior\n    unstd_posterior = likelihood * prior\n\n    # standardize the posterior, so it sums to 1\n    posterior = unstd_posterior / unstd_posterior.sum()\n    return p_grid, posterior\n\nFissiamo una griglia di \\(n = 1000\\) valori equispaziati. Usando la funzione precedente, creaiamo un grafico della stima della distribuzione a posteriori a cui è stata sovrapposta l’esatta distribuzione a posteriori \\(\\mbox{Beta}(25, 17)\\)).\n\npoints = 1000\nw, n = 23, 30\np_grid, posterior = posterior_grid_approx(points, w, n)\nplt.plot(p_grid, posterior, '-', label='y = {}\\nn = {}'.format(w, n))\n\na = 25\nb = 17\nx = np.linspace(stats.beta.ppf(0.01, a, b),\n                stats.beta.ppf(0.99, a, b), 1000)\nplt.plot(x, stats.beta.pdf(x, a, b)/1000,\n       'r--', lw=3, alpha=0.75, label='Beta(25, 17)')\n\nplt.xlabel(\"Probabilità di un'aspettativa negativa\", fontsize=14)\nplt.ylabel('Densità', fontsize=14)\nplt.title('Distribuzione a posteriori', fontsize=16)\nplt.legend(loc=0);\nplt.show()\n\n\n\n\n\n\n\nIn conclusione, il metodo basato su griglia è molto intuitivo e non richiede particolari competenze di programmazione per essere implementato. Inoltre, fornisce un risultato che, per tutti gli scopi pratici, può essere considerato come un campione casuale estratto da \\(p(\\theta \\mid y)\\). Tuttavia, anche se tale metodo fornisce risultati accuratissimi, esso ha un uso limitato. A causa della maledizione della dimensionalità1, tale metodo può solo essere usato nel caso di semplici modelli statistici, con non più di due parametri. Nella pratica concreta tale metodo viene dunque sostituito da altre tecniche più efficienti in quanto, anche nei più comuni modelli utilizzati in psicologia, vengono solitamente stimati centinaia se non migliaia di parametri."
  },
  {
    "objectID": "036_posterior_sim.html#chapter-simulazioneMC",
    "href": "036_posterior_sim.html#chapter-simulazioneMC",
    "title": "20  Approssimazione della distribuzione a posteriori",
    "section": "\n20.2 Metodo Monte Carlo",
    "text": "20.2 Metodo Monte Carlo\nI metodi più ampiamente adottati nell’analisi bayesiana per la costruzione della distribuzione a posteriori per modelli complessi sono i metodi di campionamento MCMC. Tali metodi consentono al ricercatore di decidere quali distribuzioni a priori e quali distribuzioni di verosimiglianza usare sulla base di considerazioni teoriche soltanto, senza doversi preoccupare di altri vincoli. Dato che è basata su metodi computazionalmente intensivi, la stima numerica MCMC della funzione a posteriori può essere svolta soltanto mediante software. In anni recenti i metodi Bayesiani di analisi dei dati sono diventati sempre più popolari proprio perché la potenza di calcolo necessaria per svolgere tali calcoli è ora alla portata di tutti. Questo non era vero solo pochi decenni fa.\n\n20.2.1 Integrazione di Monte Carlo\nIl termine Monte Carlo si riferisce al fatto che la computazione fa ricorso ad un ripetuto campionamento casuale attraverso la generazione di sequenze di numeri casuali. Una delle sue applicazioni più potenti è il calcolo degli integrali mediante simulazione numerica. Un’illustrazione è fornita dal seguente esempio. Supponiamo di essere in grado di estrarre campioni casuali dalla distribuzione continua \\(p(\\theta \\mid y)\\) di media \\(\\mu\\). Se possiamo ottenere una sequenza di realizzazioni indipendenti\n\\[\n\\theta^{(1)}, \\theta^{(2)},\\dots, \\theta^{(T)} \\overset{\\text{iid}}{\\sim} p(\\theta \\mid y)\n\\]\nallora diventa possibile calcolare\n\\[\n\\mathbb{E}(\\theta \\mid y) = \\int \\theta p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta \\approx \\frac{1}{T} \\sum_{i=1}^T \\theta^{(t)}.\n\\]\nIn altre parole, l’aspettazione teorica di \\(\\theta\\) può essere approssimata dalla media campionaria di un insieme di realizzazioni indipendenti ricavate da \\(p(\\theta \\mid y)\\). Per la Legge Forte dei Grandi Numeri, l’approssimazione diventa arbitrariamente esatta per \\(T \\rightarrow \\infty\\).2\nQuello che è stato detto sopra non è altro che un modo sofisticato per dire che, se vogliamo calcolare un’approssimazione del valore atteso di una variabile casuale, non dobbiamo fare altro che la media aritmetica di un grande numero di realizzazioni indipendenti della variabile casuale. Come è facile intuire, l’approssimazione migliora al crescere del numero dei dati che abbiamo a disposizione.\nUn’altra importante funzione di \\(\\theta\\) è la funzione indicatore, \\(I(l < \\theta < u)\\), che assume valore 1 se \\(\\theta\\) giace nell’intervallo \\((l, u)\\) e 0 altrimenti. Il valore di aspettazione di \\(I(l < \\theta < u)\\) rispetto a \\(p(\\theta)\\) dà la probabilità che \\(\\theta\\) rientri nell’intervallo specificato, \\(Pr(l < \\theta < u)\\). Anche questa probabilità può essere approssimato usando l’integrazione Monte Carlo, ovvero prendendo la media campionaria del valore della funzione indicatore per ogni realizzazione \\(\\theta^{(t)}\\). È semplice vedere come\n\\[\nPr(l < \\theta < u) \\approx \\frac{\\text{numero di realizzazioni } \\theta^{(t)} \\in (l, u)}{T}.\n\\]\nAbbiamo fornito qui alcuni accenni relativi all’integrazione di Monte Carlo perché, nell’analisi bayesiana, il metodo Monte Carlo viene usato per ottenere un’approssimazione della distribuzione a posteriori, quando tale distribuzione non può essere calcolata con metodi analitici. In altre parole, il metodo Monte Carlo consente di ottenere un gran numero di valori \\(\\theta\\) che, nelle circostanze ideali, avrà una distribuzione identica alla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\n\n20.2.2 Campionamento dalla distribuzione a posteriori\nPoniamoci ora il problema di approssimare la distribuzione a posteriori con una simulazione. Consideriamo nuovamente i dati di Zetsche et al. (2019) (ovvero, 23 “successi” in 30 prove Bernoulliane) e, come in precedenza, assumiamo per \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(2, 10)\\).\n\nIn tali circostanze, la distribuzione a posteriori può essere ottenuta analiticamente tramite lo schema beta-binomiale ed è una \\(\\mbox{Beta}(25, 17)\\). Se vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto è\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 17} \\approx 0.5952.\n\\]\nÈ anche possibile ottenere il valore della media a posteriori con una simulazione numerica. Conoscendo la forma della la distribuzione a posteriori, possiamo estrarre un campione di osservazioni da una \\(\\mbox{Beta}(25, 17)\\) per poi calcolare la media delle osservazioni ottenute. Con poche osservazioni (diciamo 10) otteniamo un risultato molto approssimato.\n\nset.seed(84735)\nprint(mean(rbeta(1e2, shape1 = 25, shape2 = 17)), 6)\n#> [1] 0.584251\n\nL’approssimazione migliora all’aumentare del numero di osservazioni.\n\nprint(mean(rbeta(1e4, shape1 = 25, shape2 = 17)), 6)\n#> [1] 0.595492\nprint(mean(rbeta(1e6, shape1 = 25, shape2 = 17)), 6)\n#> [1] 0.595192\n\nLo stesso si può dire delle altre statistiche descrittive: moda, varianza, eccetera.\nQuesta simulazione, detta di Monte Carlo, produce il risultato desiderato perché\n\nsappiamo che la distribuzione a posteriori è una \\(\\mbox{Beta}(25, 17)\\),\nè possibile usare le funzioni \\(\\textsf{R}\\) per estrarre campioni casuali da una tale distribuzione.\n\nTuttavia, capita raramente di usare una distribuzione a priori coniugata alla verosimiglianza. Quindi, in generale, le due condizioni descritte sopra non si applicano. Ad esempio, nel caso di una verosimiglianza binomiale e di una distribuzione a priori gaussiana, la distribuzione a posteriori di \\(\\theta\\) è\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}.\n\\]\nUna tale distribuzione non è implementata in \\(\\textsf{R}\\); dunque non possiamo usare \\(\\textsf{R}\\) per ottenere campioni casuali da una tale distribuzione.\nIn tali circostanze, però, è possibile ottenere ottenere un campione causale dalla distribuzione a posteriori procedendo in un altro modo. Questo risultato si ottiene utilizzando i metodi Monte Carlo basati su Catena di Markov (MCMC). I metodi MCMC, di cui l’algoritmo di Metropolis è un caso particolare e ne rappresenta il primo esempio, sono una classe di algoritmi che consentono di ottenere campioni casuali da una distribuzione a posteriori senza dovere conoscere la rappresentazione analitica di una tale distribuzione.3 Le tecniche MCMC sono il metodo computazionale maggiormente usato per risolvere i problemi dell’inferenza bayesiana."
  },
  {
    "objectID": "036_posterior_sim.html#diagnostiche-della-soluzione-mcmc",
    "href": "036_posterior_sim.html#diagnostiche-della-soluzione-mcmc",
    "title": "20  Approssimazione della distribuzione a posteriori",
    "section": "\n20.4 Diagnostiche della soluzione MCMC",
    "text": "20.4 Diagnostiche della soluzione MCMC\nIn questo Capitolo abbiamo illustrato l’esecuzione di una singola catena di Markov in cui si parte un unico valore iniziale e si raccolgono i valori simulati da molte iterazioni. È possibile però che i valori di una catena siano influenzati dalla scelta del valore iniziale. Quindi una raccomandazione generale è di eseguire l’algoritmo di Metropolis più volte utilizzando diversi valori di partenza. In questo caso, si avranno più catene di Markov. Confrontando le proprietà delle diverse catene si esplora la sensibilità dell’inferenza alla scelta del valore di partenza. I software MCMC consentono sempre all’utente di specificare diversi valori di partenza e di generare molteplici catene di Markov.\n\n20.4.1 Stazionarietà\nUn punto importante da verificare è se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta “mixing”.\n\n20.4.1.1 Autocorrelazione\nInformazioni sul “mixing” della catena di Markov sono fornite dall’autocorrelazione. L’autocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore \\(m\\)-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantità \\(k\\) (dove \\(k\\) è l’entità del ritardo) per verificare quanto si correli al variare di \\(k\\). L’autocorrelazione di ordine 1 (lag 1) misura la correlazione tra valori successivi della catena di Markow (cioè, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-1)}\\)); l’autocorrelazione di ordine 2 (lag 2) misura la correlazione tra valori della catena di Markow separati da due “passi” (cioè, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-2)}\\)); e così via.\nL’autocorrelazione di ordine \\(k\\) è data da \\(\\rho_k\\) e può essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{\\mbox{Cov}(\\theta_m, \\theta_{m+k})}{\\mbox{Var}(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\tag{20.2}\\]\n\nEsercizio 20.1 Per fare un esempio pratico, simuliamo dei dati autocorrelati con la funzione \\(\\textsf{R}\\) colorednoise::colored_noise().\n\nsuppressPackageStartupMessages(library(\"colorednoise\"))\nset.seed(34783859)\nrednoise <- colored_noise(\n  timesteps = 30, mean = 0.5, sd = 0.05, phi = 0.3\n)\n\nL’autocorrelazione di ordine 1 è semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza. Nell’esempio, il vettore rednoise è una sequenza temporale di 30 elementi. Il vettore rednoise[-length(rednoise)] include gli elementi con gli indici da 1 a 29 nella sequenza originaria, mentre il vettore rednoise[-1] include gli elementi 2:30. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici \\((1, 2), (2, 3), \\dots (29, 30)\\) degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori rednoise[-length(rednoise)] e rednoise[-1] corrisponde all’autocorrelazione di ordine 1 della serie temporale.\n\ncor(rednoise[-length(rednoise)], rednoise[-1])\n#> [1] 0.3967366\n\nIl Correlogramma è uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall’autocorrelazione \\(\\rho_k\\) di una catena di Markov in funzione del ritardo (lag) \\(k\\) con cui l’autocorrelazione è calcolata: nel grafico ogni barretta verticale riporta il valore dell’autocorrelazione (sull’asse delle ordinate) in funzione del ritardo (sull’asse delle ascisse). In \\(\\textsf{R}\\), il correlogramma può essere prodotto con una chiamata a acf().\n\nacf(rednoise)\n\n\n\n\n\n\n\nNel correlogramma precedente vediamo che l’autocorrelazione di ordine 1 è circa pari a 0.4 e diminuisce per lag maggiori; per lag di 4, l’autocorrelazione diventa negativa e aumenta progressivamente fino ad un lag di 8; eccetera.\nIn situazioni ottimali l’autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per piccoli lag. Ciò indica che i valori della catena di Markov che si trovano a più di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del “mixing” della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l’autocorrelazione è quella di assottigliare l’output immagazzinando solo ogni \\(m\\)-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di thinning.\n\n\n20.4.2 Test di convergenza\nUn test di convergenza può essere svolto in maniera grafica mediante le tracce delle serie temporali (trace plot), cioè il grafico dei valori simulati rispetto al numero di iterazioni. Se la catena è in uno stato stazionario le tracce mostrano assenza di periodicità nel tempo e ampiezza costante, senza tendenze visibili o andamenti degni di nota. Un esempio di trace plot è fornito nella ?fig-sim-markov-chain-zetsche (destra).\nCi sono inoltre alcuni test che permettono di verificare la stazionarietà del campionatore dopo un dato punto. Uno è il test di Geweke che suddivide il campione, dopo aver rimosso un periodo di burn in, in due parti. Se la catena è in uno stato stazionario, le medie dei due campioni dovrebbero essere uguali. Un test modificato, chiamato Geweke z-score, utilizza un test \\(z\\) per confrontare i due subcampioni ed il risultante test statistico, se ad esempio è più alto di 2, indica che la media della serie sta ancora muovendosi da un punto ad un altro e quindi è necessario un periodo di burn-in più lungo."
  },
  {
    "objectID": "036_posterior_sim.html#commenti-e-considerazioni-finali",
    "href": "036_posterior_sim.html#commenti-e-considerazioni-finali",
    "title": "20  Approssimazione della distribuzione a posteriori",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn generale, la distribuzione a posteriori dei parametri di un modello statistico non può essere determinata per via analitica. Tale problema viene invece affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilità che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre più semplice l’uso dei metodi MCMC, insieme all’incremento della potenza di calcolo dei computer, ha contribuito a rendere sempre più popolare il metodo dell’inferenza bayesiana che, in questo modo, può essere estesa a problemi di qualunque grado di complessità.\n\n\n\n\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087–1092.\n\n\nZetsche, U., Bürkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688."
  },
  {
    "objectID": "040_beta_binomial_mod.html#il-presidente-trump-e-lidrossiclorochina",
    "href": "040_beta_binomial_mod.html#il-presidente-trump-e-lidrossiclorochina",
    "title": "21  Il modello beta-binomiale in linguaggio Stan",
    "section": "\n21.1 Il presidente Trump e l’idrossiclorochina",
    "text": "21.1 Il presidente Trump e l’idrossiclorochina\nPer fare un esempio concreto, consideriamo un set di dati reali. Cito dal Washington Post del 7 aprile 2020:\n\nOne of the most bizarre and disturbing aspects of President Trump’s nightly press briefings on the coronavirus pandemic is when he turns into a drug salesman. Like a cable TV pitchman hawking ‘male enhancement’ pills, Trump regularly extols the virtues of taking hydroxychloroquine, a drug used to treat malaria and lupus, as a potential ‘game changer’ that just might cure Covid-19.\n\nTralasciamo qui il fatto che il Donald Trump non sia un esperto in questo campo. Esaminiamo invece le evidenze iniziali a supporto dell’ipotesi che l’idrossiclorochina possa essere utile per la cura del Covid-19, ovvero le evidenze che erano disponibili nel momento in cui il Donald Trump ha fatto le affermazioni riportate sopra (in seguito, quest’idea è stata screditata). Tali evidenze sono state fornite da uno studio di Gautret et al. (2020). Il disegno sperimentale di Gautret et al. (2020) comprende, tra le altre cose, il confronto tra una condizione sperimentale e una condizione di controllo. Il confronto importante è tra la proporzione di paziente positivi al virus SARS-CoV-2 nel gruppo sperimentale (a cui è stata somministrata l’idrossiclorochina; 6 su 14) e la proporzione di paziente positivi nel gruppo di controllo (a cui non è stata somministrata l’idrossiclorochina; ovvero 14 su 16). Obiettivo di questo Capitolo è mostrare come si possa fare inferenza sui dati di Gautret et al. (2020) usando il linguaggio Stan. Per semplicità, iniziamo considerando solo il gruppo di controllo."
  },
  {
    "objectID": "040_beta_binomial_mod.html#una-proporzione",
    "href": "040_beta_binomial_mod.html#una-proporzione",
    "title": "21  Il modello beta-binomiale in linguaggio Stan",
    "section": "\n21.2 Una proporzione",
    "text": "21.2 Una proporzione\nSulla base di ciò che è stato detto nel Capitolo 18, sappiamo che, quando i dati sono rappresentati da una proporzione \\(\\theta\\), e quando utilizziamo una distribuzione a priori Beta per \\(\\theta\\), la distribuzione a posteriori di \\(\\theta\\) è specificata dallo schema beta-binomiale. Se scegliamo, ad esempio, una \\(\\mbox{Beta}(2, 2)\\) quale distribuzione a priori per \\(\\theta\\), il modello diventa:\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align}\ny &\\sim \\mbox{Bin}(n, \\theta) \\notag\\\\\n\\theta &\\sim \\mbox{Beta}(2, 2)\n\\end{align}\n\\tag{21.1}\\]\ndove la prima riga definisce la funzione di verosimiglianza e la seconda riga definisce la distribuzione a priori. Vediamo ora come specificare il modello beta-binomiale in linguaggio Stan."
  },
  {
    "objectID": "040_beta_binomial_mod.html#cmdstanr-gautret",
    "href": "040_beta_binomial_mod.html#cmdstanr-gautret",
    "title": "21  Il modello beta-binomiale in linguaggio Stan",
    "section": "\n21.3 Interfaccia cmdstanr\n",
    "text": "21.3 Interfaccia cmdstanr\n\nI modelli presentati in questo capitolo sono discussi da Gelman et al. (1995) mentre il codice è stato ricavato dalla seguente pagina web. In questo e nei successivi capitoli useremo Stan mediante l’interfaccia cmdstanr di CmdStan.\nIniziamo con il caricare i pacchetti necessari.\n\nlibrary(\"cmdstanr\")\nlibrary(\"posterior\")\navailableCores()\nSEED <- 84735 \n\nPer svolgere l’analisi mediante cmdstanr è necessario prima specificare la struttura del modello bayesiano nella notazione Stan e, poi, eseguire il campionamento dalla distribuzione a posteriori. Esaminiamo questi due passaggi per l’esempio presente.\n\n21.3.1 Fase 1\nNella prima fase dell’analisi dobbiamo definire i dati, i parametri e il modello. I dati devono essere contenuti in un oggetto di classe list.\n\ndata1_list <- list(\n  N = 16,\n  y = c(rep(1, 14), rep(0, 2))\n)\n\nIl modello è \\(\\mbox{Bin}(n, \\theta)\\). Oppure, dato che abbiamo specificato in input ciascuna singola osservazione, \\(\\mbox{Bernoulli}(\\theta)\\).\n\ny ~ bernoulli(theta);\n\nLa verosimiglianza dipende dal parametro theta. In Stan, è necessario specificare che theta è un numero reale compreso tra 0 e 1. Inoltre, è necessario imporre su \\(\\theta\\) una distribuzione a priori. Nel caso presente abbiamo scelto una \\(\\mbox{Beta}(2, 2)\\).\n\ntheta ~ beta(2, 2);\n\nMemorizziamo il modello beta-binomiale che abbiamo specificato in linguaggio Stan come stringa di caratteri.\n\nmodelString = \"\ndata {\n  int<lower=0> N;\n  array[N] int<lower=0, upper=1> y;\n}\nparameters {\n  real<lower=0, upper=1> theta;\n}\nmodel {\n  theta ~ beta(2, 2);\n  y ~ bernoulli(theta);\n}\n\"\n\nUtilizzando il seguente link si può ottenere una formattazione automatica del codice e anche, in qualche misura, una correzione della sintassi.\nSalviamo modelString in un file a cui assegniamo il nome oneprop.stan (si noti l’estensione .stan). Sul mio computer ho creato una cartella chiamata code dove salvo i file .stan. Se non vogliamo definire una sotto-cartella chiamata code, è sufficiente scrivere writeLines(modelString, con = \"oneprop.stan\").\n\nwriteLines(modelString, con = \"code/oneprop.stan\")\n\n\n21.3.2 Fase 2\nPer utilizzare il modello che abbiamo specificato, prima leggiamo l’indirizzo del file che contiene il codice Stan.\n\nfile <- file.path(\"code\", \"oneprop.stan\")\n\nPoi compiliamo il codice Stan. Questo crea un file eseguibile che, nel caso presente, abbiamo chiamato mod.\n\nmod <- cmdstan_model(file)\n\nPossiamo ora eseguire il campionamento MCMC con la seguente chiamata.\n\nfit1 <- mod$sample(\n  data = data1_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = 84735,\n  chains = 4L,\n  refresh = 0\n)\n\nSi noti che $sample() è un “metodo” che viene applicato al file eseguibile che abbiamo compilato, al quale è stato assegnato il nome mod.\nIl metodo $sample() richiede una serie di argomenti.\n\n\ndata, ovvero i dati in input in formato lista (nel caso presente, data1_list).\n\nchains specifica quante catene di Markov parallele eseguire. Eseguiamo qui quattro catene, quindi otterremo quattro campioni distinti di valori \\(\\pi\\).\n\niter specifica il numero desiderato di iterazioni o la lunghezza di ciascuna catena di Markov. Per impostazione predefinita, la prima metà di queste iterazioni è costituita da campioni “burn-in” o “warm-up” che verranno ignorati. La seconda metà è conservata e costituisce un campione della distribuzione a posteriori.\n\niter_warmup specifica il numero di campioni “warm-up” che vogliamo vengano ignorati.\n\nseed imposta il numero casuale che viene usato per generare il punto di partenza di ciascuna catena di Markov.\n\nAvendo assunto una distribuzione a priori per il parametro \\(\\theta\\), l’algoritmo procede in maniera ciclica, correggendo la distribuzione a priori di \\(\\theta\\) condizionandola ai valori già generati. Dopo un certo numero di cicli, necessari per portare l’algoritmo a convergenza, i valori estratti possono essere assunti come campionati dalla distribuzione a posteriori di \\(\\theta\\).\nAl crescere del numero di passi della catena, la distribuzione di target viene sempre meglio approssimata. All’inizio del campionamento, però, la distribuzione può essere significativamente lontana da quella stazionaria, e ci vuole un certo tempo prima di raggiungere la distribuzione stazionaria di equilibrio, detto, appunto, periodo di burn-in. I campioni provenienti da tale parte iniziale della catena vanno tipicamente scartati perché possono non rappresentare accuratamente la distribuzione a posteriori.\n\n21.3.3 Fase 3\nPossiamo ora fare inferenza usando i risultati ottenuti. Un sommario della distribuzione a posteriori si ottiene con il metodo summary().\n\nfit1$summary(c(\"theta\"))\n#> # A tibble: 1 × 10\n#>   variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 theta    0.798  0.808 0.0876 0.0872 0.638 0.924  1.00    5769.    6359.\n\nCreo un oggetto di classe stanfit.\n\nstanfit1 <- rstan::read_stan_csv(fit1$output_files())\n\nCalcolo le dimensioni dell’oggetto stanfit1.\n\ndim(as.matrix(stanfit1, pars = \"theta\"))\n#> [1] 16000     1\n\nStampo i primi 10 valori di stanfit1.\n\nas.matrix(stanfit1, pars = \"theta\") %>% \n  head(10)\n#>           parameters\n#> iterations    theta\n#>       [1,] 0.852111\n#>       [2,] 0.784496\n#>       [3,] 0.784496\n#>       [4,] 0.755076\n#>       [5,] 0.725578\n#>       [6,] 0.774385\n#>       [7,] 0.774385\n#>       [8,] 0.806225\n#>       [9,] 0.826550\n#>      [10,] 0.849894\n\nLa matrice precedente include i valori assunti dalla catena di Markov, ovvero un insieme di valori \\(\\theta\\) estratti dalla distribuzione a posteriori. Un tracciato della catena di Markov illustra questa esplorazione rappresentando il valore \\(\\theta\\) sulle ordinate e l’indice progressivo di in ogni iterazione sull’ascissa. Uso la funzione mcmc_trace() del pacchetto bayesplot per costruire il grafico che include tutte e quattro le catene di Markov.\n\nstanfit1 %>% \n  mcmc_trace(pars = c(\"theta\"), size = 0.1)\n\n\n\nFigura 21.1: Trace-plot per il parametro \\(\\theta\\) nel modello Beta-Binomiale.\n\n\n\n\nLa Figura 21.1 mostra che le catene esplorano uno spazio compreso approssimativamenre tra 0.5 e 0.95; questa figura descrive il comportamento longitudinale delle catene di Markov.\nPossiamo anche esaminare la distribuzione degli stati della catena di Markov, ovvero, dei valori che queste catene visitano lungo il loro percorso, ignorando l’ordine di queste visite. L’istogramma della Figura 21.2 fornisce una rappresentazione grafica di questa distribuzione per i 16000 valori complessivi delle quattro catene, ovvero per 4000 valori provienienti da ciascuna catena.\n\nmcmc_hist(stanfit1, pars = \"theta\") + \n  yaxis_text(TRUE) + \n  ylab(\"count\")\n\n\n\nFigura 21.2: Istogramma che illustra l’approssimazione della distribuzione a posteriori per il parametro \\(\\theta\\) nel modello Beta-Binomiale.\n\n\n\n\nNello schema beta-binomiale in cui la verosimiglianza è binomiale con 14 successi su 16 prove e in cui assumiamo una distribuzione a priori \\(\\mbox{Beta}(2, 2)\\) sul parametro \\(\\theta\\), la distribuzione a posteriori è una distribuzione Beta di parametri \\(\\alpha\\) = 2 + 14 e \\(\\beta\\) = 2 + 16 - 14. La Figura 21.3 riporta un kernel density plot per i valori delle quattro catene di Markov con sovrapposta in nero la densità \\(\\mbox{Beta}(16, 4)\\). Si noti come la distribuzione dei valori delle catene di Markov produca un’eccellente approssimazione alla distribuzione bersaglio.1\n\nmcmc_dens(stanfit1, pars = \"theta\") + \n  yaxis_text(TRUE) + \n  ylab(\"density\") +\n  stat_function(fun = dbeta, args = list(shape1 = 16, shape2=4))\n\n\n\nFigura 21.3: Istogramma che illustra l’approssimazione della distribuzione a posteriori per il parametro \\(\\theta\\) nel modello Beta-Binomiale. La curva nera rappresenta la corretta distribuzione a posteriori Beta(16, 4).\n\n\n\n\nUn intervallo di credibilità al 95% per \\(\\theta\\) si ottiene con la funzione posterior_interval().\n\nposterior1 <- extract(stanfit1)\nrstantools::posterior_interval(as.matrix(stanfit1), prob = 0.95)\n#>              2.5%       97.5%\n#> theta   0.5990419   0.9376123\n#> lp__  -12.5817650 -10.0086000\n\nSvolgendo un’analisi bayesiana simile a questa, Gautret et al. (2020) hanno trovato che gli intervalli di credibilità del gruppo di controllo e del gruppo sperimentale non si sovrappongono. Questo fatto viene interpretato dicendo che il parametro \\(\\theta\\) è diverso nei due gruppi. Sulla base di queste evidenza, Gautret et al. (2020) hanno concluso, con un grado di certezza soggettiva del 95%, che nel gruppo sperimentale vi è una probabilità più bassa di risultare positivi al SARS-CoV-2 rispetto al gruppo di controllo. In altri termini, l’analisi statistica condotta da Gautret et al. (2020) suggerisce che l’idrossiclorochina è una terapia efficace per il Covid-19."
  },
  {
    "objectID": "040_beta_binomial_mod.html#la-critica-di-hulme_2020",
    "href": "040_beta_binomial_mod.html#la-critica-di-hulme_2020",
    "title": "21  Il modello beta-binomiale in linguaggio Stan",
    "section": "\n21.4 La critica di Hulme et al. (2020)\n",
    "text": "21.4 La critica di Hulme et al. (2020)\n\nUn articolo pubblicato da Hulme et al. (2020) si è posto il problema di rianalizzare i dati di Gautret et al. (2020).2 Tra gli autori di questo articolo figura anche Eric-Jan Wagenmakers, uno psicologo molto conosciuto per i suoi contributi metodologici. Hulme et al. (2020) osservano che, nelle loro analisi statistiche, Gautret et al. (2020) hanno escluso alcuni dati. Nel gruppo sperimentale, infatti, vi erano alcuni pazienti i quali, anziché migliorare, sono in realtà peggiorati. L’analisi statistica di Gautret et al. (2020) ha escluso i dati di questi pazienti. Se consideriamo tutti i pazienti — non solo quelli selezionati da Gautret et al. (2020) — la situazione diventa la seguente:\n\ngruppo sperimentale: 10 positivi su 18;\ngruppo di controllo: 14 positivi su 16.\n\nL’analisi dei dati proposta da Hulme et al. (2020) richiede l’uso di alcuni strumenti statistici che, in queste dispense, non verranno discussi. Ma possiamo giungere alle stesse conclusioni raggiunte da questi ricercatori anche usando le procedure statistiche descritte nel Paragrafo successivo."
  },
  {
    "objectID": "040_beta_binomial_mod.html#due-proporzioni",
    "href": "040_beta_binomial_mod.html#due-proporzioni",
    "title": "21  Il modello beta-binomiale in linguaggio Stan",
    "section": "\n21.5 Due proporzioni",
    "text": "21.5 Due proporzioni\nSvolgiamo ora l’analisi statistica considerando tutti i dati, come suggerito da Hulme et al. (2020). Per fare questo verrà creato un modello bayesiano per fare inferenza sulla differenza tra due proporzioni. Dopo avere generato le distribuzioni a posteriori per le proporzioni di “successi” nei due gruppi, calcoleremo la quantità\n\\[\n\\omega = \\frac{\\theta_2 / (1-\\theta_2)}{\\theta_1 / (1-\\theta_1)},\n\\tag{21.2}\\]\novvero il rapporto tra gli Odds di positività tra i pazienti del gruppo di controllo e gli Odds di positività tra i pazienti del gruppo sperimentale. Se il valore dell’OR è uguale a 1, significa che l’Odds di positività nel gruppo di controllo è uguale all’Odds di positività nel gruppo sperimentale, cioè il fattore in esame (somministrazione dell’idrossiclorochina) è ininfluente sulla comparsa della malattia. L’inferenza statistica sull’efficacia dell’idrossiclorochina come terapia per il Covid-19 può dunque essere effettuata esaminando l’intervallo di credibilità al 95% per l’OR: se tale intervallo include il valore 1, allora non c’è evidenza che l’idrossiclorochina sia efficace come terapia per il Covid-19.\nNell’implementazione di questo modello, la quantità di interesse è l’odds ratio; tale quantità viene calcolata nel blocco generated quantities. Per i parametri \\(\\theta_1\\) e \\(\\theta_2\\) useremo delle distribuzioni a priori debolmente informative il cui scopo è la regolarizzazione dei dati.\nInseriscoo i dati dei due gruppi in un oggetto di classe list.\n\ndata_list <- list(\n  N1 = 18, \n  y1 = 10, \n  N2 = 16, \n  y2 = 14\n)\n\nDefinisco il modello in linguaggio Stan.\n\nmodelString <- \"\n//  Comparison of two groups with Binomial\ndata {\n  int<lower=0> N1; // number of experiments in group 1\n  int<lower=0> y1; // number of deaths in group 1\n  int<lower=0> N2; // number of experiments in group 2\n  int<lower=0> y2; // number of deaths in group 2\n}\nparameters {\n  real<lower=0, upper=1> theta1; // probability of death in group 1\n  real<lower=0, upper=1> theta2; // probability of death in group 2\n}\nmodel {\n  theta1 ~ beta(2, 2); // prior\n  theta2 ~ beta(2, 2); // prior\n  y1 ~ binomial(N1, theta1); // likelihood\n  y2 ~ binomial(N2, theta2); // likelihood\n}\ngenerated quantities {\n  real oddsratio = (theta2 / (1 - theta2)) / (theta1 / (1 - theta1));\n}\n\"\nwriteLines(modelString, con = \"code/twoprop1.stan\")\n\nSalvo il modello in un file.\n\nfile <- file.path(\"code\", \"twoprop1.stan\")\n\nCompilo il modello.\n\nmod <- cmdstan_model(file)\n\nEseguo il campionamento MCMC.\n\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nEsamino i risulati.\n\nstanfit <- rstan::read_stan_csv(fit$output_files())\n\n\nprint(\n  stanfit,\n  pars = c(\"theta1\", \"theta2\", \"oddsratio\"),\n  digits_summary = 3L\n)\n#> Inference for Stan model: twoprop1-202212211042-1-5ce99d.\n#> 4 chains, each with iter=6000; warmup=2000; thin=1; \n#> post-warmup draws per chain=4000, total post-warmup draws=16000.\n#> \n#>            mean se_mean    sd  2.5%   25%   50%   75%  97.5% n_eff Rhat\n#> theta1    0.546   0.001 0.103 0.344 0.475 0.546 0.620  0.740 12795    1\n#> theta2    0.798   0.001 0.087 0.601 0.744 0.808 0.862  0.937 14193    1\n#> oddsratio 4.721   0.043 4.411 0.906 2.166 3.514 5.698 15.558 10400    1\n#> \n#> Samples were drawn using NUTS(diag_e) at Wed Dec 21 10:42:11 2022.\n#> For each parameter, n_eff is a crude measure of effective sample size,\n#> and Rhat is the potential scale reduction factor on split chains (at \n#> convergence, Rhat=1).\n\nL’intervallo di credibilità del 95% per l’OR include il valore di 1.0 (ovvero, il valore che indica che gli Odds di positività sono uguali nei due gruppi). In base agli standard correnti, un risultato di questo tipo non viene considerato come evidenza sufficiente per potere concludere che il parametro \\(\\theta\\) assume un valore diverso nei due gruppi. In conclusione, se consideriamo tutti i dati, e non solo quelli selezionati da Gautret et al. (2020), non vi sono evidenze sull’efficacia dell’idrossiclorochina come terapia per il Covid-19."
  },
  {
    "objectID": "040_beta_binomial_mod.html#commenti-e-considerazioni-finali",
    "href": "040_beta_binomial_mod.html#commenti-e-considerazioni-finali",
    "title": "21  Il modello beta-binomiale in linguaggio Stan",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa ricerca di Gautret et al. (2020) include altre informazioni e altre analisi statistiche che non sono state qui considerate. Tuttavia, notiamo che la semplice analisi statistica che abbiamo qui descritto è stata in grado di replicare le conclusioni a cui sono giunti (per altra via) Hulme et al. (2020).\n\n\n\n\n\n\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M., Guo, J., Li, P., & Riddell, A. (2017). Stan: A probabilistic programming language. Journal of Statistical Software, 76(1), 1–32.\n\n\nEckhardt, R. (1987). Stan Ulam, John Von Neumann and the Monte Carlo Method. Los Alamos Science Special Issue.\n\n\nGautret, P., Lagier, J. C., Parola, P., Meddeb, L., Mailhe, M., Doudier, B., & Honoré, S. (2020). Hydroxychloroquine and azithromycin as a treatment of COVID-19: Results of an open-label non-randomized clinical trial. International Journal of Antimicrobial Agents.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nHulme, O. J., Wagenmakers, E. J., Damkier, P., Madelung, C. F., Siebner, H. R., Helweg-Larsen, J., & Madsen, K. H. (2020). Reply to gautret et al. 2020: A bayesian reanalysis of the effects of hydroxychloroquine and azithromycin on viral carriage in patients with COVID-19. medRxiv."
  },
  {
    "objectID": "041_mcmc_diagnostics.html#esame-dei-trace-plot",
    "href": "041_mcmc_diagnostics.html#esame-dei-trace-plot",
    "title": "22  Diagnostica delle catene markoviane",
    "section": "\n22.1 Esame dei trace plot\n",
    "text": "22.1 Esame dei trace plot\n\nLa convergenza e il “mixing” possono essere controllate mediante il trace plot che mostra l’andamento delle simulazioni e ci dice se stiamo effettivamente utilizzando una distribuzione limite. Consideriamo nuovamente il trace plot del simulazione Beta-Binomiale della figura Figura 22.1.\n\n\n\n\n\n\n\nFigura 22.1: Trace plot per il modello Beta-Binomiale dei dati di Gautret et al.(2020).\n\n\n\n\nLa Figura 22.1 fornisce un esempio perfetto di come dovrebbero apparire i trace plot. Quando le catene markoviane raggiungono uno stato stazionario e sono stabili ciò significa che hanno raggiunto la distribuzione stazionaria e il trace plot rivela un’assenza di struttura e diventa simile alla rappresentazione del rumore bianco, come nella Figura 22.1.\nUna mancanza di convergenza è invece indicata dalla Figura 22.21.\n\n\n\n\nFigura 22.2: Trace plots (a sinistra) e corrispondenti grafici di densità (a destra) di due ipotetiche catene di Markov. Queste figure forniscono due esempi di come potrebbero apparire delle catene di Markov non stazionarie. Le linee nere sovrapposte alle densità empiriche (a destra) rappresentano una ipotetica distribuzione target Beta(11,3).\n\n\n\n\nNel trace-plot della Figura 22.2 la tendenza verso il basso indica che la catena A non è stazionaria, ovvero non si mantiene costante all’evolversi nel tempo. La tendenza verso il basso suggerisce inoltre la presenza di una forte correlazione tra i valori della catena: il trace-plot non fornisce una rappresentazione di rumore indipendente. Tutto questo significa che la catena A “si sta mescolando lentamente”. Sebbene le catene di Markov siano intrinsecamente dipendenti, più si comportano come se fossero dei campioni casuali (rumorosi), minore è l’errore dell’approssimazione alla distribuzione a posteriori.\nLa catena B presenta un problema diverso. Come evidenziato dalle due linee completamente piatte nel tracciato, essa tende a bloccarsi quando visita valori bassi di \\(\\theta\\).\nGli istogrammi lisciati della Figura 22.2 (a destra) confermano che entrambe queste catene sono problematiche: infatti producono approssimazioni scadenti della distribuzione a posteriori che, nell’esempio di Johnson et al. (2022), è una \\(\\mbox{Beta}(11, 3)\\) (la curva nera nella figura). Consideriamo la catena A. Dal momento che si sta mescolando lentamente, nelle iterazioni eseguite ha esplorato unicamente i valori \\(\\theta\\) nell’intervallo da 0.6 a 0.9. Di conseguenza, la sua approssimazione della distribuzione a posteriori sopravvaluta la plausibilità dei valori \\(\\theta\\) in questo intervallo e, nel contempo, sottovaluta la plausibilità dei valori \\(\\theta\\) esterni a questo intervallo. Consideriamo ora la catena B. Rimanendo bloccata, la catena B campiona in maniera eccessiva alcuni valori nella coda sinistra della distribuzione a posteriori di \\(\\theta\\). Questo fenomeno produce i picchi che sono presenti nell’approssimazione alla distribuzione a posteriori.\nIn pratica, al di là dei presenti esempi “scolastici” (in cui disponiamo di una formulazione analitica della distribuzione a posteriori), non abbiamo mai il privilegio di poter confrontare i risultati del campionamento MCMC con la corretta distribuzione a posteriori. Ecco perché la diagnostica delle catene di Markov è così importante: se vediamo trace-plots come quelli della Figura 22.2, sappiamo che non abbiamo ottenuto una adeguata approssimazione della distribuzione a posteriori.\nIn tali circostanze possiamo ricorrere ad alcuni rimedi.\n\nControllare il modello. Siamo sicuri che le distribuzioni a priori e la verosimiglianza siano appropriate per i dati osservati?\nUtilizzare un numero maggiore di iterazioni. Alcune tendenze indesiderate a breve termine della catena possono appianarsi nel lungo termine."
  },
  {
    "objectID": "041_mcmc_diagnostics.html#confronto-delle-catene-parallele",
    "href": "041_mcmc_diagnostics.html#confronto-delle-catene-parallele",
    "title": "22  Diagnostica delle catene markoviane",
    "section": "\n22.2 Confronto delle catene parallele",
    "text": "22.2 Confronto delle catene parallele\nNella simulazione cmdstanr() per il modello beta-binomiale dei dati di Gautret et al. (2020) abbiamo utilizzato quattro catene di Markov parallele. Non solo è necessario che ogni singola catena sia stazionaria (come discusso sopra), ma è anche necessario che le quattro catene siano coerenti tra loro. Sebbene le catene esplorino percorsi diversi nello spazio dei parametri, quando convergono ad uno stato di equilibrio dovrebbero presentare caratteristiche simili e dovrebbero produrre approssimazioni simili alla distribuzione a posteriori. Per il caso beta-binomiale dei dati di Gautret et al. (2020), gli istogrammi lisciati della figura seguente indicano che le quattro catene producono approssimazioni della distribuzione a posteriori quasi indistinguibili tra loro. Ciò prova che la simulazione è stabile e contiene un nunero sufficiente di valori: l’esecuzione delle catene per un numero maggiore di iterazioni non porterebbe ad un miglioramento della stima della distribuzione a posteriori.\n\nmcmc_dens_overlay(stanfit1, pars = \"theta\") + \n  ylab(\"density\")\n\n\n\n\n\n\n\nPer fare un confronto, per lo stesso modello, consideriamo la simulazione di una catena di Markov più corta. La chiamata seguente richiede quattro catene parallele per sole 100 iterazioni ciascuna.\n\nbb_short <- mod$sample(\n  data = data1_list,\n  iter_sampling = 50*2L,\n  seed = 84735,\n  chains = 4L,\n  parallel_chains = 4L,\n  refresh = 0,\n  thin = 1\n)\nFALSE Running MCMC with 4 parallel chains...\nFALSE \nFALSE Chain 1 finished in 0.0 seconds.\nFALSE Chain 2 finished in 0.0 seconds.\nFALSE Chain 3 finished in 0.0 seconds.\nFALSE Chain 4 finished in 0.0 seconds.\nFALSE \nFALSE All 4 chains finished successfully.\nFALSE Mean chain execution time: 0.0 seconds.\nFALSE Total execution time: 0.2 seconds.\n\nstanfit_bb_short <- rstan::read_stan_csv(bb_short$output_files())\n\nDi seguito sono riportati i trace-plot e i corrispondenti istogrammi lisciati.\n\nmcmc_trace(stanfit_bb_short, pars = \"theta\")\n\n\n\n\n\n\n\n\nmcmc_dens_overlay(stanfit_bb_short, pars = \"theta\")\n\n\n\n\n\n\n\nAnche se i trace plot sembrano tutti mostrare un andamento casuale, gli istogrammi lisciati sono piuttosto diversi tra loro e producono approssimazioni diverse della distribuzione a posteriori. Di fronte a tale instabilità è chiaro che sarebbe un errore interrompere la simulazione dopo solo 100 iterazioni."
  },
  {
    "objectID": "041_mcmc_diagnostics.html#numerosita-campionaria-effettiva",
    "href": "041_mcmc_diagnostics.html#numerosita-campionaria-effettiva",
    "title": "22  Diagnostica delle catene markoviane",
    "section": "\n22.3 Numerosità campionaria effettiva",
    "text": "22.3 Numerosità campionaria effettiva\nNella simulazione del modello beta-binomiale per i dati di Gautret et al. (2020) abbiamo utilizzato quattro catene di Markov parallele che producono un totale di \\(N\\) = 16000 campioni dipendenti di \\(\\theta\\). Sapendo che l’errore dell’approssimazione alla distribuzione a posteriori è probabilmente più grande di quello che si otterrebbe usando 16000 campioni indipendenti, ci possiamo porre la seguente domanda: quanti campioni indipendenti sarebbero necessari per produrre un’approssimazione della distribuzione a posteriori equivalentemente a quella che abbiamo ottenuto? La numerosità campionaria effettiva (effective sample size, \\(N_{eff}\\)) fornisce una risposta a questa domanda.\nTipicamente, \\(N_{eff} < N\\), per cui il rapporto campionario effettivo (effective sample size ratio) \\(\\frac{N_{eff}}{N}\\) è minore di 1. Come regola euristica, viene considerato problematico un rapporto campionario effettivo minore del 10% del numero totale di campioni ottenuti nella simulazione (più basso è il rapporto campionario effettivo peggiore è il “mixing” della catena). La funzione bayesplot::neff_ratio() consente di calcolare il rapporto campionario effettivo. Per il modello Beta-Binomiale dei dati di Gautret et al. (2020), questo rapporto è di circa 0.34.\n\nbayesplot::neff_ratio(stanfit1, pars = c(\"theta\"))\n#> [1] 0.3629411\n\nCiò indica che l’accuratezza dell’approssimazione della distribuzione a posteriori di \\(\\theta\\) ottenuta mediante 16,000 campioni dipendenti è approssimativamente simile a quella che si potrebbe ottenere con\n\nbayesplot::neff_ratio(\n  stanfit1, pars = c(\"theta\")\n) * 16000\n#> [1] 5807.058\n\ncampioni indipendenti. In questo esempio, il rapporto campionario effettivo è maggiore di 0.1; dunque non ci sono problemi."
  },
  {
    "objectID": "041_mcmc_diagnostics.html#autocorrelazione",
    "href": "041_mcmc_diagnostics.html#autocorrelazione",
    "title": "22  Diagnostica delle catene markoviane",
    "section": "\n22.4 Autocorrelazione",
    "text": "22.4 Autocorrelazione\nNormalmente un algoritmo MCMC genera catene di Markov di campioni, ognuno dei quali è autocorrelato a quelli generati immediatamente prima e dopo di lui. Conseguentemente campioni successivi non sono indipendenti ma formano una catena di Markov con un certo grado di correlazione. Il valore \\(\\theta^{(i)}\\) tende ad essere più simile al valore \\(\\theta^{(i-1)}\\) che al valore \\(\\theta^{(i-2)}\\), o al valore \\(\\theta^{(i-3)}\\), eccetera. Una misura di ciò è fornita dall’autocorrelazione tra i valori consecutivi della catena.\nIl correlogramma per ciascuna delle quattro catene dell’esempio si produce con la seguente chiamata:\n\nbayesplot::mcmc_acf(stanfit1, pars = \"theta\")\n\n\n\n\n\n\n\nIl correlogramma mostra l’autocorrelazione in funzione di ritardi da 0 a 20. L’autocorrelazione di lag 0 è naturalmente 1 – misura la correlazione tra un valore della catena di Markov e se stesso. L’autocorrelazione di lag 1 è di circa 0.5, indicando una correlazione moderata tra i valori della catena che distano di solo 1 passo l’uno dall’altro. Successivamente, l’autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per un lag di 5. Questo risultato fornisce una conferma del fatto che la catena di Markov costituisce una buona approssimazione di un campione casuale di \\(p(\\theta \\mid y)\\).\nAl contrario, nella Figura 22.3 (a destra) (riprodotta da Johnson et al., 2022) vediamo un esempio nel quale il trace plot rivela una forte tendenza tra i valori di una catena di Markov e, dunque, una forte autocorrelazione.\n\n\n\n\nFigura 22.3: Trace plot (a sinistra) e correlogramma (a destra) di una catena di Markow in cui il mixing è lento – figura riprodotta da Johnson et al. (2022).\n\n\n\n\nQuesta osservazione è confermata nell’correlogramma (a destra). La lenta diminuzione della curva di autocorrelazione indica che la dipendenza tra i valori della catena non svanisce rapidamente. Con un lag di 20 la correlazione è addirittura pari a 0.9. Poiché i valori della catena sono fortemente associati tra loro, il “mixing” è lento: la simulazione richiede un numero molto grande di iterazioni per esplorare adeguatamente l’intera gamma di valori della distribuzione a posteriori.2\nIn presenza di catene di Markov non rapidly mixing sono possibili due rimedi.\n\nAumentare il numero di iterazioni. Anche una catena non rapidly mixing può produrre eventualmente una buona approssimazione della distribuzione a posteriori se il numero di iterazioni è sufficientemente grande.\n\nThinning. Per esempio, se la catena di Markov è costituita da 16000 valori di \\(\\theta\\), potremmo decidere di conservare solo ogni secondo valore e ignorare gli altri valori: \\(\\{\\theta^{(2)}, \\theta^{(4)}, \\theta^{(6)}, \\dots, \\theta^{(16000)}\\}\\). Oppure, potremmo decidere di conservare ogni decimo valore: \\(\\{\\theta^{(10)}, \\theta^{(20)}, \\theta^{(30)}, \\dots, \\theta^{(16000)}\\}\\). Scartando i campioni intermedi, è possibile rimuovere le forti correlazioni che sono presenti nel caso di lag più piccoli.\n\nVediamo ora come sia possibile estrarre i valodi di una catena dall’oggetto stanfit1.\n\n# valori delle 4 catene\nS <- ggmcmc::ggs(stanfit1)\nhead(S)\n#> # A tibble: 6 × 4\n#>   Iteration Chain Parameter value\n#>       <dbl> <int> <fct>     <dbl>\n#> 1         1     1 theta     0.628\n#> 2         2     1 theta     0.758\n#> 3         3     1 theta     0.719\n#> 4         4     1 theta     0.715\n#> 5         5     1 theta     0.856\n#> 6         6     1 theta     0.870\n\nLa prima catena può essere isolata nel modo seguente:\n\nS1 <- S %>% \n  dplyr::filter(\n    Chain == 1,\n    Parameter == \"theta\"\n  )\n\nUna serie temporale della catena si ottiene con la funzione ggmcmc::ggs_running().\n\nggmcmc::ggs_running(S1)\n\n\n\n\n\n\n\nIl grafico precedente mostra che, per il modello bayesiano che stiamo discutendo, una condizione di equilibrio della catena di Markov richiederebbe un numero maggiore di iterazioni di quelle che sono state effettivamente simulate.\nL’autocorrelazione di ordine 1 si ottiene nel modo seguente (si veda il Paragrafo @ref(approx-post-autocor)).\n\ncor(S1$value[-length(S1$value)], S1$value[-1])\n#> [1] 0.3819515\n\nQuesto valore corrisponde a ciò che è riportato nel correlogramma mostrato sopra."
  },
  {
    "objectID": "041_mcmc_diagnostics.html#statistica-hatr",
    "href": "041_mcmc_diagnostics.html#statistica-hatr",
    "title": "22  Diagnostica delle catene markoviane",
    "section": "\n22.5 Statistica \\(\\hat{R}\\)\n",
    "text": "22.5 Statistica \\(\\hat{R}\\)\n\nIn precedenza abbiamo detto che non solo è necessario che ogni singola catena sia stazionaria, è anche necessario che le diverse catene siano coerenti tra loro. La statistica \\(\\hat{R}\\) affronta questo problema calcolando il rapporto tra la varianza tra le catene markoviane e la varianza entro le catene. In una situazione ottimale \\(\\hat{R} = 1\\); se \\(\\hat{R}\\) è lontano da 1 questo vuol dire che non è ancora stata raggiunta la convergenza.\nÈ possibile calcolare \\(\\hat{R}\\) mediante la chiamata alla funzione bayesplot::rhat(). Per il modello Beta-Binomiale applicato ai dati di Gautret et al. (2020) abbiamo:\n\nbayesplot::rhat(stanfit1, pars = \"theta\")\n#> [1] 1.00039\n\nil che indica che il valore \\(\\hat{R}\\) ottenuto è molto simile al valore ottimale.\nIn maniera euristica, si può affermare che se \\(\\hat{R}\\) supera la soglia di 1.05 questo viene interpretato come evidenza che le diverse catene parallele non producono approssimazioni coerenti della distribuzione a posteriori, quindi la simulazione è instabile.\nUna rappresentazione grafica dei valori \\(\\hat{R}\\) per tutti i parametri del modello si ottiene con la seguente chiamata:\n\nggmcmc::ggs_Rhat(S) + xlab(\"R_hat\") + xlim(0.95, 1.05)"
  },
  {
    "objectID": "041_mcmc_diagnostics.html#diagnostica-di-convergenza-di-geweke",
    "href": "041_mcmc_diagnostics.html#diagnostica-di-convergenza-di-geweke",
    "title": "22  Diagnostica delle catene markoviane",
    "section": "\n22.6 Diagnostica di convergenza di Geweke",
    "text": "22.6 Diagnostica di convergenza di Geweke\nLa statistica diagnostica di convergenza di Geweke è basata su un test per l’uguaglianza delle medie della prima e dell’ultima parte di una catena di Markov (di default il primo 10% e l’ultimo 50% della catena). Se i due campioni sono estratti dalla distribuzione stazionaria della catena, le due medie sono statisticamente uguali e la statistica di Geweke ha una distribuzione asintotica Normale standardizzata.\nUtilizzando l’oggetto stanfit1, possiamo recuperare la statistica di Geweke nel modo seguente:\n\nfit_mcmc <- As.mcmc.list(\n  stanfit1,\n  pars = c(\"theta\")\n)\ncoda::geweke.diag(fit_mcmc, frac1 = .1, frac2 = .5) \n#> [[1]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#>  theta \n#> -0.017 \n#> \n#> \n#> [[2]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#>  theta \n#> 0.6504 \n#> \n#> \n#> [[3]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#>    theta \n#> -0.04024 \n#> \n#> \n#> [[4]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#> theta \n#> 1.315\n\nPer interpretare questi valori ricordiamo che la statistica di Geweke è uguale a zero quando le medie delle due porzioni della catena di Markov sono uguali. Valori maggiori di \\(\\mid 2 \\mid\\) suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria.\n\n\n\n\n\n\nGautret, P., Lagier, J. C., Parola, P., Meddeb, L., Mailhe, M., Doudier, B., & Honoré, S. (2020). Hydroxychloroquine and azithromycin as a treatment of COVID-19: Results of an open-label non-randomized clinical trial. International Journal of Antimicrobial Agents.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press."
  },
  {
    "objectID": "045_summarize_posterior.html#stima-puntuale",
    "href": "045_summarize_posterior.html#stima-puntuale",
    "title": "23  Sintesi a posteriori",
    "section": "\n23.1 Stima puntuale",
    "text": "23.1 Stima puntuale\nPer sintetizzare la distribuzione a posteriori in modo da giungere ad una stima puntuale di \\(\\theta\\) si è soliti scegliere tra moda, mediana o media a seconda del tipo di distribuzione con cui si ha a che fare e della sua forma. A moda, mediana e media a posteriori possiamo attribuire interpretazioni diverse.\n\nLa media è il valore atteso a posteriori del parametro.\nLa moda può essere interpretata come il singolo valore più credibile del parametro, alla luce dei dati, ovvero il valore che massimizza la distribuzione a posteriori del parametro \\(\\theta\\). Per questa ragione la moda viene detta massimo a posteriori, MAP. Il limite della moda quale statistica riassuntiva della distribuzione a posteriori è che, talvolta, la distribuzione a posteriori è multimodale e il MAP non è necessariamente il valore “più credibile”.\nLa mediana è il valore del parametro tale per cui, su entrambi i lati di essa, giace il 50% della massa di probabilità a posteriori.\n\nLa misura di variabilità del parametro è la varianza a posteriori la quale, nel caso di una distribuzione a posteriori ottenuta per via numerica, si calcola con la formula della varianza che conosciamo rispetto alla tendenza centrale data dalla media a posteriori. La radice quadrata della varianza a posteriori è la deviazione standard a posteriori che descrive l’incertezza a posteriori circa il parametro di interesse nella stessa unità di misura dei dati.\nLe procedure bayesiane basate sui metodi MCMC utilizzano un numero finito di campioni dalla distribuzione stazionaria, e una tale caratteristica della simulazione introduce un ulteriore livello di incertezza nella stima del parametro. L’errore standard della stima (in inglese Monte Carlo standard error, MCSE) misura l’accuratezza della simulazione. La deviazione standard a posteriori e l’errore standard della stima sono due concetti completamente diversi. La deviazione standard a posteriori descrive l’incertezza circa il parametro (l’ampiezza della distribuzione a posteriori) ed è una funzione della dimensione del campione; il MCSE descrive invece l’incertezza nella stima del parametro dovuta alla simulazione MCMC ed è una funzione del numero di iterazioni nella simulazione."
  },
  {
    "objectID": "045_summarize_posterior.html#intervallo-di-credibilità",
    "href": "045_summarize_posterior.html#intervallo-di-credibilità",
    "title": "23  Sintesi a posteriori",
    "section": "\n23.2 Intervallo di credibilità",
    "text": "23.2 Intervallo di credibilità\nMolto spesso la stima puntuale è accompagnata da una stima intervallare (abbiamo già incontrato questo aspetto nel Capitolo Capitolo 18 discutendo lo schema beta-binomiale). Nella statistica bayesiana, se il parametro \\(\\theta \\in \\Theta\\) è monodimensionale, si dice intervallo di credibilità un intervallo di valori \\(I_{\\alpha}\\) che contiene la proporzione \\(1 - \\alpha\\) della massa di probabilità della funzione a posteriori:\n\\[\np(\\Theta \\in I_{\\alpha} \\mid y) = 1 - \\alpha.\n\\tag{23.1}\\]\nL’intervallo di credibilità ha lo scopo di esprimere il nostro grado di incertezza riguardo la stima del parametro. Se il parametro \\(\\theta\\) è multidimensionale, si parla invece di “regione di credibilità”.\nL’Equazione 23.1 non determina un unico intervallo di credibilità di ordine \\((1 - \\alpha) \\cdot 100\\%\\). In realtà esiste un numero infinito di tali intervalli. Ciò significa che dobbiamo definire alcune condizioni aggiuntive per la scelta dell’intervallo di credibilità. Esaminiamo due delle condizioni aggiuntive più comuni.\n\n23.2.1 Intervallo di credibilità a code uguali\nUn intervallo di credibilità a code uguali a livello \\(\\alpha\\) è un intervallo\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, 1 - q_{\\alpha/2}],\n\\]\ndove \\(q_z\\) è un quantile \\(z\\) della distribuzione a posteriori. Per esempio, l’intervallo di credibilità a code uguali al 95% è un intervallo\n\\[\nI_{0.05} = [q_{0.025}, q_{0.975}]\n\\]\nche lascia il 2.5% della massa di densità a posteriori in ciascuna coda.\n\n23.2.2 Intervallo di credibilità a densità a posteriori più alta\nNell’intervallo di credibilità a code uguali alcuni valori del parametro che sono inclusi nell’intervallo possono avere una credibilità a posteriori più bassa rispetto a quelli esterni all’intervallo. L’intrevallo di credibilità a densità a posteriori più alta (in inglese High Posterior Density Interval, HPD) è invece costruito in modo tale da assicurare di includere nell’intervallo tutti i valori \\(\\theta\\) che sono a posteriori maggiormente credibili. Graficamente questo intervallo può essere ricavato tracciando una linea orizzontale sulla rappresentazione della distribuzione a posteriori e regolando l’altezza della linea in modo tale che l’area sottesa alla curva sia pari a \\(1 - \\alpha\\). Questo tipo di intervallo è il più stretto possibile, tra tutti i possibili intervalli di credibilità allo stesso livello di fiducia. Se la distribuzione a posteriori è simmetrica unimodale, l’intervallo di credibilità a densità a posteriori più alta corrisponde all’intervallo di credibilità a code uguali.\n\n23.2.3 Interpretazione\nL’interpretazione dell’intervallo di credibilità è molto intuitiva: l’intervallo di credibilità è un intervallo di valori all’interno del quale cade il valore del parametro incognito con un particolare livello di probabilità soggettiva. Possiamo dire che, dopo aver visto i dati crediamo, con un determinato livello di probabilità soggettiva, che il valore del parametro (ad esempio, la dimensione dell’effetto di un trattamento) abbia un valore compreso all’interno dell’intervallo che è stato calcolato, laddove per probabilità soggettiva intendiamo “il grado di fiducia che lo sperimentatore ripone nel verificarsi di un evento”. Gli intervalli di credibilità si calcolano con un software."
  },
  {
    "objectID": "045_summarize_posterior.html#un-esempio-concreto",
    "href": "045_summarize_posterior.html#un-esempio-concreto",
    "title": "23  Sintesi a posteriori",
    "section": "\n23.3 Un esempio concreto",
    "text": "23.3 Un esempio concreto\nPer fare un esempio pratico, consideriamo nuovamente i valori del BDI-II dei 30 soggetti clinici di Zetsche et al. (2019).\n\ndf <- tibble(\n  y = c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n        24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n        41, 36, 26, 35, 33, 28, 27, 34, 27, 22)\n)\n\nUn valore BDI-II \\(\\geq 30\\) indica la presenza di un livello grave di depressione. Nel campione clinico di Zetsche et al. (2019), 17 pazienti su 30 manifestano un livello grave di depressione.\n\nsum(df$y > 29)\n#> [1] 17\n\nSupponiamo di volere stimare la distribuzione a posteriori della probabilità \\(\\theta\\) di depressione grave nei pazienti clinici, così come viene misurata dal test BDI-II, imponendo su \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(8, 2)\\).\nSappiamo che il modello Beta-Binomiale può essere espresso nella forma seguente:\n\\[\n\\begin{align}\nY | \\theta & \\sim \\mbox{Bin}(30, \\theta) \\notag\\\\\n\\theta & \\sim \\mbox{Beta}(8, 2) \\notag\n\\end{align}\n\\]\nLa corrispondente distribuzione a posteriori è una \\(\\mbox{Beta}(25, 15)\\).\n\\[\n\\begin{equation}\nf(\\theta | y = 17) = \\frac{\\Gamma(25 + 15)}{\\Gamma(25)\\Gamma(15)}\\theta^{25-1} (1-\\theta)^{15-1} \\;\\; \\text{ for } \\theta \\in [0,1] \\; .\n\\end{equation}\n\\tag{23.2}\\]\n\nplot_beta_binomial(alpha = 8, beta = 2, y = 17, n = 30)\n\n\n\n\n\n\n\n\n23.3.1 Stime puntuali della distribuzione a posteriori\nUna volta trovata l’intera distribuzione a posteriori, quale valore di sintesi è necessario riportare? Questa sembra una domanda innocente, ma in realtà è una domanda a cui è difficile rispondere. La stima bayesiana dei parametri è fornita dall’intera distribuzione a posteriori, ovvero non da un singolo numero, ma da una funzione che mappa ciascun valore del parametro ad un valore di credibilità. Non è quindi necessario scegliere una stima puntuale: in linea di principio, una stima puntuale non è quasi mai necessaria ed è spesso dannosa in quanto comporta una perdita di informazioni.\nTuttavia, talvolta una tale sintesi è richiesta. Diverse risposte sono allora possibili. La media della distribuzione a posteriori per \\(\\theta\\) per il presente esempio è\n\\[\n\\mathbb{E}(\\pi \\mid y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25+15} = 0.625.\n\\]\nUna stima del massimo della probabilità a posteriori, o brevemente massimo a posteriori, MAP (da maximum a posteriori probability), è la moda della distribuzione a posteriori. Nel caso presente, abbiamo\n\\[\n\\mbox{Mo}(\\pi \\mid y = 17) = \\frac{\\alpha-1}{\\alpha + \\beta-2} = \\frac{25-1}{25+15-2} = 0.6316.\n\\]\nGli stessi risultati si ottiengono usando la chiamata a bayesrules::summarize_beta_binomial().\n\nsummarize_beta_binomial(alpha = 8, beta = 2, y = 17, n = 30)\n#>       model alpha beta  mean      mode         var        sd\n#> 1     prior     8    2 0.800 0.8750000 0.014545455 0.1206045\n#> 2 posterior    25   15 0.625 0.6315789 0.005716463 0.0756073\n\nLa mediana si ottiene con qbeta().\n\nqbeta(.5, shape1 = 25, shape2 = 15)\n#> [1] 0.6271031\n\n\n23.3.2 Intervallo di credibilità\nÈ comune sintetizzare la distribuzione a posteriori mediante l’intervallo di credibilità. Per esempio, l’intervallo di credibilità a code uguali al 95% è dato dalla chiamata a qbeta().\n\nplot_beta_ci(alpha = 25, beta = 15, ci_level = 0.95)\n\n\n\n\n\n\n\n\nqbeta(c(0.025, 0.975), 25, 15)\n#> [1] 0.4717951 0.7663607\n\nIl calcolo precedente evidenzia l’interpretazione intuitiva dell’intervallo di credibilità. Tale intervallo, infatti, può essere interpretato nel modo seguente: possiamo attribuire una certezza soggettia del 95% all’evento che \\(\\theta\\) assuma un valore compreso tra 0.472 e 0.766.\nIl valore di 0.95 corrisponde all’area sottesa dalla distribuzione a posteriori nell’intervallo [0.472, 0.766].\n\\[\nP(\\theta \\in (0.472, 0.766) | Y = 17) = \\int_{0.472}^{0.766} f(\\theta \\mid y=17) d\\theta = 0.95\n\\]\n\npostFun <- function(theta) {\n  gamma(25 + 15) / \n    (gamma(25) * gamma(15)) * theta^24 * (1 - theta)^14\n}\nintegrate(\n  postFun, \n  lower = 0.4717951, \n  upper = 0.7663607\n)$value\n#> [1] 0.95\n\nPossiamo costruire diversi intervalli di credibilità a code equivalenti. Ad esempio, l’intervallo di credibilità compreso tra il 25-esimo e il 75-esimo percentile.\n\nqbeta(c(0.25, 0.75), 25, 15)\n#> [1] 0.5743878 0.6778673\n\nIn questo secondo caso, possiamo dire abbiamo una certezza soggettiva a posteriori del 50% che la probabilità di depressione grave tra i pazienti clinici sia un valore compreso tra 0.57 e 0.68.\nNon esiste un livello “corretto” di credibilità soggettiva. I ricercatori utilizzano livelli diversi, ad esempio il 50%, l’80% o il 95%, a seconda del contesto dell’analisi statistica. Ciascuno di questi intervalli fornisce un’immagine diversa della nostra comprensione della distribuzione a posteriori del parametro di interesse.\nNon è sempre appropriato riportare l’intervallo di credibilità a code uguali. Se la distribuzione a posteriori è fortemente asimmetrica è più appropriato riportare l’intervallo di credibilità a densità a posteriori più alta (HPD). L’intervallo HPD risulta più semplice da determinare quando la distribuzione a posteriori viene approssimata con il metodo MCMC.\n\n23.3.3 Probabilità della distribuzione a posteriori\nIl test di ipotesi è un compito comune dell’analisi della distribuzione a posteriori (si veda anche il Capitolo 18). Supponiamo che si voglia conoscere la probabilità a posteriori che \\(\\theta\\) sia superiore a 0.5. Per sapere quanto può essere ritenuto credibile l’evento \\(\\theta > 0.5\\) possiamo calcolare il seguente integrale:\n\\[\nP(\\theta > 0.5 \\; \\mid \\; y = 17) = \\int_{0.5}^{1}f(\\theta \\mid y=17)d\\theta \\;,\n\\]\ndove \\(f(\\cdot)\\) è la distribuzione \\(\\mbox{Beta}(25, 15)\\).\n\npbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = FALSE)\n#> [1] 0.9459355\n\n\npostFun <- function(theta) {\n  gamma(25 + 15) / (gamma(25) * gamma(15)) * theta^24 * (1 - theta)^14\n}\nintegrate(\n  postFun, \n  lower = 0.5, \n  upper = 1\n)$value\n#> [1] 0.9459355\n\n\n23.3.3.1 Fattore di Bayes\nÈ anche possibile formulare un test di ipotesi contrastando due ipotesi contrapposte. Per esempio, \\(H_1: \\theta \\geq 0.5\\) e \\(H_2: \\theta < 0.5\\). Ciò consente di calcolare l’odds a posteriori di \\(\\theta > 0.5\\):\n\\[\n\\begin{equation}\n\\text{poterior odds} = \\frac{H_1 \\mid y = 17}{H_2 \\mid y = 17}.\n\\end{equation}\n\\]\n\nposterior_odds <- \n  pbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = TRUE)\nposterior_odds\n#> [1] 17.49642\n\nL’odds a posteriori rappresenta l’aggiornamento delle nostre credenze dopo avere osservato \\(y = 17\\) in \\(n = 30\\).\nNel caso presente, l’odds a priori di \\(\\theta > 0.5\\) era pari a 50.2.\n\nprior_odds <- \n  pbeta(0.5, shape1 = 8, shape2 = 2, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 8, shape2 = 2, lower.tail = TRUE)\nprior_odds\n#> [1] 50.2\n\nIl fattore di Bayes (Bayes Factor; BF) confronta gli odds a posteriori con gli odds a priori e fornisce informazioni su quanto sia mutata la nostra comprensione relativa a \\(\\theta\\) dopo avere osservato i nostri dati del campione:\n\\[\n\\text{BF} = \\frac{\\text{odds a posteriori}}{\\text{odds a priori}}.\n\\]\nNel caso presente otteniamo un valore di 0.35.\n\nBF <- posterior_odds / prior_odds\nBF\n#> [1] 0.3485343\n\nQuindi, dopo avere osservato i dati, gli odds a posteriori della nostra ipotesi a proposito di \\(\\theta\\) sono pari a solo il 34% degli odds a priori.\nPer fare un altro esempio, consideriamo il caso in cui le credenze a priori rivelano una credenza diametralmente opposta rispetto a \\(\\theta\\) rispetto al caso precedente: prima avevamo \\(\\mbox{Beta}(8, 2)\\) mentre ora imponiamo su \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(2, 8)\\)). Con una tale scelta della distribuzione a priori, la distribuzione a posteriori diventa una \\(\\mbox{Beta}(19, 21)\\).\n\nsummarize_beta_binomial(alpha = 2, beta = 8, y = 17, n = 30)\n#>       model alpha beta  mean      mode         var         sd\n#> 1     prior     2    8 0.200 0.1250000 0.014545455 0.12060454\n#> 2 posterior    19   21 0.475 0.4736842 0.006082317 0.07798921\n\nCon questa diversa distribuzione a priori, il BF è uguale a 30.07.\n\nposterior_odds <- \n  pbeta(0.5, shape1 = 19, shape2 = 21, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 19, shape2 = 21, lower.tail = TRUE)\n\nprior_odds <- \n  pbeta(0.5, shape1 = 2, shape2 = 8, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 2, shape2 = 8, lower.tail = TRUE)\n\nBF <- posterior_odds / prior_odds\nBF\n#> [1] 30.07239\n\nIn alre parole, in questo secondo esempio gli odds a posteriori della nostra ipotesi a proposito di \\(\\theta\\) sono aumentati di 30 volte rispetto agli odds a priori.\nIn generale, in un test di ipotesi che contrappone un’ipotesi sostantiva \\(H_a\\) ad un’ipotesi nulla \\(H_0\\) il BF è un rapporto di odds per l’ipotesi sostantiva:\n\\[\n\\text{BF}\n= \\frac{\\text{posterior odds}}{\\text{prior odds}}\n= \\frac{P(H_a \\mid Y) / P(H_0 \\mid Y)}{P(H_a) / P(H_0)}\n\\; .\n\\]\n\n23.3.3.2 Interpretazione del fattore di Bayes\nEssendo un rapporto, il BF deve essere valutato rispetto al valore di 1. Ci sono tre possibilità:\n\nBF = 1: La credibilità di \\(H_a\\) non è cambiata dopo avere osservato i dati.\nBF > 1: La credibilità di \\(H_a\\) è aumentata dopo avere osservato i dati. Quindi maggiore è BF, più convincente risulta l’evidenza per \\(H_a\\).\nBF < 1: La credibilità di \\(H_a\\) è diminuita dopo avere osservato i dati.\n\nNon ci sono delle soglie universalmente riconosciute per interpretare il BF, ma uno schema popolare, proposto da Lee & Wagenmakers (2014), è il seguente:\n\n\nBF\nInterpretation\n\n\n\n> 100\nExtreme evidence for \\(H_a\\)\n\n\n\n30 - 100\nVery strong evidence for \\(H_a\\)\n\n\n\n10 - 30\nStrong evidence for \\(H_a\\)\n\n\n\n3 - 10\nModerate evidence for \\(H_a\\)\n\n\n\n1 - 3\nAnecdotal evidence for \\(H_a\\)\n\n\n\n1\nNo evidence\n\n\n1/3 - 1\nAnecdotal evidence for \\(H_0\\)\n\n\n\n1/10 - 1/3\nModerate evidence for \\(H_0\\)\n\n\n\n1/30 - 1/10\nStrong evidence for \\(H_0\\)\n\n\n\n1/100 - 1/30\nVery strong evidence for \\(H_0\\)\n\n\n\n< 1/100\nExtreme evidence for \\(H_0\\)\n\n\n\n\n23.3.3.3 Limiti del fattore di Bayes\nÈ importante notare che l’opinione maggiormente diffusa nella comunità scientifica incoraggia a non trarre conclusioni rigide dai dati utilizzando dei criteri fissati una volta per tutte. È stato ripetuto molte volte che l’esame di tutta la distribuzione a posteriori fornisce una misura olistica del nostro livello di incertezza riguardo all’affermazione (il parametro, ovvero l’ipotesi) che viene valutata e, dunque, è molto più informativo di una decisione binaria. Non è dunque possibile stabilire una soglia univoca per il BF che consenta di classificare le ipotesi dei ricercatori in una delle due categorie “vero” o “falso”. Invece, è più utile adottare una pratica interpretativa più flessibile in grado di tenere in considerazione il contesto e le potenziali implicazioni di ogni singolo test di ipotesi.\nLa discussione precedente mette inoltre in evidenza come il BF dipenda fortemente dalle caratteristiche della distribuzione a priori. Dato che la la distribuzione a priori è una scelta arbitraria del ricercatore, da ciò consegue che il BF contiene una componente intrinseca di arbitrarietà. Questo aspetto, tuttavia, è incompatibile con l’idea di un confronto con delle soglie “assolute”."
  },
  {
    "objectID": "045_summarize_posterior.html#la-funzione-di-perdita-attesa",
    "href": "045_summarize_posterior.html#la-funzione-di-perdita-attesa",
    "title": "23  Sintesi a posteriori",
    "section": "\n23.4 La funzione di perdita attesa",
    "text": "23.4 La funzione di perdita attesa\nIn generale, il modo più razionale per giungere ad una decisione statistica utilizzando l’intera distribuzione a posteriori è quello di usare la funzione di perdita (loss function). La funzione di perdita è un concetto nella teoria delle decisioni statistiche e consente di quantificare il costo che deriva dalla decisione di scegliere il valore \\(\\theta_0\\) quale stima del parametro, quando in realtà il parametro ha il valore \\(\\theta\\).\nPer chiarire che cosa si intende per funzione di perdita, esaminiamo qui un semplice esempio nel quale vengono considerati due soli valori di probabilità per l’evento target, anziché l’intera distribuzione a posteriori (il codice è ricavato da Schmettow, 2021).\nSi consideri la scelta di prendere o meno l’ombrello nell’uscire di casa. Le previsioni del tempo sono indicate di seguito.\n\nRisultato <-\n  tibble(\n    risultato = c(\"piove\", \"non piove\"),\n    prob = c(0.6, 0.4)\n  )\nRisultato\n#> # A tibble: 2 × 2\n#>   risultato  prob\n#>   <chr>     <dbl>\n#> 1 piove       0.6\n#> 2 non piove   0.4\n\nLe azioni possibili sono: prendo l’ombrello / non prendo l’ombrello.\n\nAzione <-\n  tibble(azione = c(\"prendo l'ombrello\", \"non prendo l'ombrello\"))\nAzione\n#> # A tibble: 2 × 1\n#>   azione               \n#>   <chr>                \n#> 1 prendo l'ombrello    \n#> 2 non prendo l'ombrello\n\nAssegniamo un costo massimo (4) alla conseguenza peggiore (“non prendo l’ombrello e piove”) e uno minimo (0) alla conseguenza migliore (“non prendo l’ombrello e non piove”).\n\nCosti <-\n  expand.grid(\n    azione = Azione$azione,\n    risultato = Risultato$risultato\n  ) %>%\n  inner_join(Risultato) %>%\n  mutate(costo = c(2, 4, 2, 0))\nCosti\n#>                  azione risultato prob costo\n#> 1     prendo l'ombrello     piove  0.6     2\n#> 2 non prendo l'ombrello     piove  0.6     4\n#> 3     prendo l'ombrello non piove  0.4     2\n#> 4 non prendo l'ombrello non piove  0.4     0\n\nCalcoliamo ora il costo atteso delle due azioni tenuto conto delle probabilità che si verifichi l’uno o l’altro stato del mondo. In altre parole ponderiamo il costo di ogni azione con la probabilità che si verifichi l’evento corrispondente.\n\nUtil <-\n  Costi %>%\n  mutate(costo_condizionato = prob * costo) %>%\n  group_by(azione) %>%\n  summarise(costo_atteso = sum(costo_condizionato))\nUtil\n#> # A tibble: 2 × 2\n#>   azione                costo_atteso\n#>   <fct>                        <dbl>\n#> 1 prendo l'ombrello              2  \n#> 2 non prendo l'ombrello          2.4\n\nLa regola della minimizzazione dei costi ci porta a scegliere l’alternativa che comporta il costo minore: nel nostro esempio, questo corrisponde all’azione “prendere l’ombrello”.\nLa stessa logica dell’esempio qui discusso può essere usata anche quando, anziché avere solo due valori per la probabilità dello stato del mondo (pioverà / non pioverà), utilizziamo l’intera distribuzione a posteriori (per esempio, quella relativa alla previsione di pioggia). Concludiamo questi brevi accenni relativi alla funzione di perdita con una considerazione di McElreath (2020): anche se gli statistici e i teorici dei giochi sono da tempo interessati alle funzioni di perdita e alle relazioni che intercorrono tra esse e l’inferenza bayesiana, i ricercatori non le usano quasi mai in modo esplicito."
  },
  {
    "objectID": "045_summarize_posterior.html#commenti-e-considerazioni-finali",
    "href": "045_summarize_posterior.html#commenti-e-considerazioni-finali",
    "title": "23  Sintesi a posteriori",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nQuesto capitolo introduce le procedure di base per la manipolazione della distribuzione a posteriori. Lo strumento fondamentale che è stato utilizzato è quello fornito dai campioni di valori del parametro che vengono estratti dalla distribuzione a posteriori. Lavorare con campioni di valori del parametro estratti dalla distribuzione a posteriori trasforma un problema di calcolo integrale in un problema di riepilogo dei dati. Abbiamo visto le procedure maggiormente usate che consentono di utilizzare i campioni a posteriori per produrre indici di sintesi della distribuzione a posteriori: gli intervalli di credibilità e le stime puntuali.\n\n\n\n\n\n\nLee, M. D., & Wagenmakers, E.-J. (2014). Bayesian cognitive modeling: A practical course. Cambridge university press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSchmettow, M. (2021). New statistics for design researchers. Springer.\n\n\nZetsche, U., Bürkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688."
  },
  {
    "objectID": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "href": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "title": "24  La predizione bayesiana",
    "section": "\n24.1 La distribuzione predittiva a posteriori",
    "text": "24.1 La distribuzione predittiva a posteriori\nUna volta costruita la distribuzione a posteriori del parametro o dei parametri sconosciuti, potremmo essere interessati a utilizzare il modello bayesiano allo scopo di prevedere la probabilità di risultati futuri basandoci sui dati già osservati. Questo tipo di analisi inferenziale va sotto il nome di analisi predittiva.\nL’esempio che considereremo qui nei dettagli riguarda il caso beta-binomiale, nel quale la distribuzione a priori per il parametro ignoto \\(\\theta\\) (ovvero, la probabilità di successo) è una distribuzione Beta, la verosimiglianza è binomiale e i dati sono costituiti dal numero \\(y\\) di successi in \\(n\\) prove Bernoulliane indipendenti. Nell’esempio che discuteremo useremo un’altra volta i dati del campione di pazienti clinici depressi di Zetsche et al. (2019). Supponendo di volere esaminare in futuro altri \\(m\\) pazienti clinici, ci chiediamo: quanti di essi manifesteranno una depressione grave?\nSiamo dunque interessati a predire i risultati che si potrebbero osservare in nuovi campioni di \\(m = 30\\) osservazioni. Denotiamo con \\(\\tilde{y}\\) la manifestazione della variabile casuale \\(\\tilde{Y}\\). In un nuovo campione di \\(m\\) osservazioni, \\(\\tilde{y}\\) assumerà il valore \\(\\tilde{y}_1\\) (ad es., 12), in un altro campione assumerà il valore \\(\\tilde{y}_2\\) (ad es., 23), e così via. Siamo interessati a descrivere la probabilità che \\(\\tilde{y}\\) assuma i valori \\(0, 1, 2, \\dots, 29, 30\\). Tale distribuzione (in questo caso) di massa di probabilità si chiama distribuzione predittiva a posteriori \\(p(\\tilde{Y} = \\tilde{y} \\mid Y = y)\\) e corrisponde alla probabilità assegnata a ciascuno dei possibili valori \\(\\tilde{y}\\) (\\(0, 1, 2, \\dots, 29, 30\\)) nei possibili campioni futuri di \\(m\\) osservazioni.\nIn questo Capitolo ci porremo il problema di trovare la distribuzione predittiva a posteriori nel caso beta-binomiale. Useremo tre metodi diversi:\n\nla soluzione analitica,\ni risultati di una simulazione,\nil campionamento MCMC.\n\nI tre metodi producono risultati equivalenti. In seguito useremo il metodo MCMC perché ci consente di trovare facilmente la risposta cercata, anche quando una soluzione analitica non è disponibile."
  },
  {
    "objectID": "046_bayesian_prediction.html#soluzione-analitica",
    "href": "046_bayesian_prediction.html#soluzione-analitica",
    "title": "24  La predizione bayesiana",
    "section": "\n24.2 Soluzione analitica",
    "text": "24.2 Soluzione analitica\nNel caso dell’esempio in discussione, la distribuzione di \\(\\tilde{Y}\\) dipende da \\(\\theta\\) e ciò che sappiamo di \\(\\theta\\) è sintetizzato nella distribuzione a posteriori \\(p(\\theta \\mid y)\\). Usando la regola della catena, possiamo scrivere la distribuzione congiunta di \\(\\tilde{y}\\) e \\(\\theta\\) nel modo seguente\n\\[\np(\\tilde{y}, \\theta \\mid y) = p(\\tilde{y} \\mid \\theta, y) p(\\theta \\mid y).\n\\]\nAssumendo che le osservazioni future \\(\\tilde{y}\\) e passate \\(y\\) siano condizionalmente indipendenti dato \\(\\theta\\), l’espressione precedente può essere scritta come\n\\[\np(\\tilde{y}, \\theta \\mid y) = p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y).\n\\]\nLa distribuzione predittiva a posteriori viene ottenuta dalla distribuzione congiunta di \\(\\tilde{y}\\) e \\(\\theta\\) integrando rispetto a \\(\\theta\\):\n\\[\np(\\tilde{y} \\mid y) = \\int_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta.\n\\tag{24.1}\\]\nNel caso dello schema beta-binomiale, la funzione \\(p(\\tilde{y} \\mid \\theta)\\) è binomiale di parametri \\(m\\) e \\(\\theta\\), e la distribuzione a posteriori \\(p(\\theta \\mid y)\\) è una \\(\\mbox{Beta}(\\alpha + y, \\beta + n - y)\\). Risolvendo l’integrale otteniamo:\n\\[\n\\begin{align}\np(\\tilde{y} \\mid y) &= \\int_0^1 p(\\tilde{y} \\mid \\theta)\np(\\theta \\mid y)\\,\\operatorname {d}\\!\\theta \\notag\\\\\n&= \\int_0^1 \\begin{pmatrix}m\\\\\\tilde{y}\\end{pmatrix}\n\\theta^{\\tilde{y}}\n(1-\\theta)^{m-\\tilde{y}} \\, \\mbox{Beta}(a+y,b+n-y) \\, d\\theta \\notag\\\\\n&= \\begin{pmatrix}{m}\\\\\\tilde{y}\\end{pmatrix} \\int_0^1 \\theta^{\\tilde{y}}\n(1-\\theta)^{m-\\tilde{y}} \\frac{1}{B(a+y, b+n-y)}\\theta^{a+y-1}(1-\\theta)^{b+n-y-1}\\notag\\\\\n&= \\begin{pmatrix}{ m }\\\\\\tilde{y}\\end{pmatrix} \\frac{1}{B(a+y, b+n-y)}\\int_0^1 \\theta^{\\tilde{y}+a+y-1}(1-\\theta)^{m-\\tilde{y}+b+n-y-1}\\notag\\\\\n&= \\begin{pmatrix}{ m }\\\\\\tilde{y}\\end{pmatrix} \\frac{B(\\tilde{y}+a+y,b+n-y+m-\\tilde{y})}{B(a+y, b+n-y)} \\; .\n\\end{align}\n\\tag{24.2}\\]\nIn conclusione, per lo schema beta-binomiale, la distribuzione predittiva a posteriori corrisponde ad una distribuzione di probabilità discreta chiamata distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha+y\\) e \\(\\beta+n-y\\).\n\\[\nf(\\tilde{y} \\mid y) = \\binom{m}{\\tilde{y}} \\frac{B(a+ y + \\tilde{y}, b + n - y + m - \\tilde{y})}{B(a+y, b+n-y)},\n\\tag{24.3}\\]\nNell’esempio relativo allo studio di Zetsche et al. (2019), la verosimiglianza è binomiale, i dati sono costituiti da 23 successi su 30 prove e la distribuzione a priori su \\(\\theta\\) è \\(\\mbox{Beta}(2, 10)\\). Di conseguenza, la distribuzione a posteriori è \\(\\mbox{Beta}(25, 17)\\). Vogliamo calcolare la distribuzione predittiva a posteriori per un nuovo campione, poniamo, di \\(m = 30\\) osservazioni (ma, in generale, \\(m\\) può essere diverso da \\(n\\)).\nIn base all’Equazione 24.3 sappiamo che la distribuzione predittiva a posteriori è una distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha+y\\) e \\(\\beta+n-y\\), dove \\(m\\) è il numero di prove nel nuovo campione, \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione a priori, e \\(y\\) e \\(n\\) sono le proprietà del campione corrente. Nel caso dell’esempio in discussione, \\(m = 30\\), \\(\\alpha = 2 + 23 = 25\\), \\(\\beta = 10 + 30 - 23 = 17\\). Possiamo svolgere i calcoli necessario usando le funzioni del pacchetto extraDistr. Per i parametri specificati sopra, un grafico della distribuzione predittiva a posteriori si ottiene nel modo seguente.\n\nprob <- extraDistr::dbbinom(0:30, 30, 25, 17)\ntibble(Y=0:30, Probability = prob) %>% \n  ProbBayes::prob_plot(Color = \"black\")\n\n\n\n\n\n\n\nLa distribuzione predittiva a posteriori illustrata nella figura precedente ci dice qual è la plausibilità relativa di osservare \\(0, 1, \\dots, 30\\) successi su \\(m = 30\\) prove in un futuro campione di osservazioni, alla luce dei dati che abbiamo osservato nel campione corrente (23 successi in 30 prove) e tenuto conto delle nostre opinioni a priori sulla plausibilità dei possibili valori \\(\\theta\\) (ovvero, \\(\\mbox{Beta}(2, 10)\\)).\nEsaminando la distribuzione predittiva notiamo che, nei possibili campioni futuri di 30 osservazioni, il valore \\(\\tilde{y}\\) più plausibile è 18. Tuttavia, \\(\\tilde{y}\\) può assumere anche altri valori e la distribuzione predittiva ci informa sulla plausibilità relativa di ciascuno dei possibili valori futuri \\(\\tilde{y}\\) – nel presente esempio, \\(\\tilde{y}\\) corrisponde al numero di pazienti clinici (su 30) che manifesteranno una depressione grave.\nÈ desiderabile costruire un intervallo che contiene le realizzazioni \\(\\tilde{y}\\) ad un livello specificato di probabilità. Supponiamo che il livello di probabilità richiesto sia 0.89. L’intervallo si costruisce aggiungendo valori \\(\\tilde{y}\\) all’intervallo (partendo da quello con la probabilità maggiore) fino a che il contenuto di probabilità dell’insieme eccede la soglia richiesta, nel caso present di 0.89. La procedura è implementata nella funzione discint() del pacchetto LearnBayes. Per i dati dell’esempio otteniamo\n\nLearnBayes::discint(cbind(0:30, prob), 0.89)\n#> $prob\n#> [1] 0.9152885\n#> \n#> $set\n#>  [1] 12 13 14 15 16 17 18 19 20 21 22 23\n\nSulla base delle informazioni disponibili, possiamo dunque prevedere, con un livello di certezza soggettiva che eccede la soglia di 0.91, che in un futuro campione di 30 soggetti clinici depressi, il numero di pazienti con depressione grave sarà compreso tra 12 e 23.\n\\[\nP(12 \\leq \\tilde{y} \\leq 23) = 0.9145.\n\\]\nIn conclusione, per il caso beta-binomiale, possiamo dire che la predizione bayesiana di una nuova osservazione futura è la realizzazione di una distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha + y\\), e \\(\\beta + n - y\\), dove \\(m\\) è il numero di prove nel nuovo campione, \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione a priori, e \\(y\\) e \\(n\\) sono le caratteristiche del campione."
  },
  {
    "objectID": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-simulazione",
    "href": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-simulazione",
    "title": "24  La predizione bayesiana",
    "section": "\n24.3 La distribuzione predittiva a posteriori mediante simulazione",
    "text": "24.3 La distribuzione predittiva a posteriori mediante simulazione\nIn situazioni dove è difficile derivare l’esatta distribuzione predittiva a posteriori è possibile ottenere un campione casuale di valori della distribuzione predittiva posteriori mediante simulazione. Facciamo un esempio riferito al caso che stiamo discutendo. È possibile svolgere la simulazione richiesta in due fasi. Supponiamo di volere ottenere un campione casuale di \\(n\\) osservazioni dalla distribuzione predittiva a posteriori. A tal fine dobbiamo (1) estrarre \\(n\\) valori a caso del parametro \\(\\theta\\) dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\): (2) con tali valori del parametro \\(\\theta\\) generiamo \\(n\\) valori casuali \\(\\tilde{y}\\); a tal fine usiamo il modello binomiale di parametri \\(m\\) e \\(\\theta_i\\) (con \\(i = 1, \\dots, n\\)). Otteniamo così \\(n\\) realizzazioni casuali di \\(n\\) distribuzioni binomiali aventi i parametri specificati sopra.\nVediamo come si fa in pratica con \\(\\mathsf{R}\\). Per l’esempio che stiamo discutendo, la distribuzione a posteriori è una \\(\\mbox{Beta}(25, 17)\\). Estraiamo 100,000 valori a caso da tale distribuzione.\n\nset.seed(12345)\nnrep <- 1e5\na <- 2\nb <- 10\nn <- 30\ny <- 23\npred_p_sim <- rbeta(nrep, a + y, b + n - y)\n\nI primi 10 valori così ottenuti sono riportati di seguito.\n\npred_p_sim[1:10]\n#>  [1] 0.5435206 0.5319551 0.6045577 0.6337146 0.7552324 0.5393935 0.6187069\n#>  [8] 0.6193819 0.6736216 0.6051480\n\nPer ciascuno dei valori \\(\\theta_i\\), con \\(i = 1, \\dots, 100,000\\), estraggo a caso un valore dalla distribuzione binomiale di parametri \\(n = 30\\) e \\(\\theta_i\\).\n\npred_y_sim <- rep(NA, nrep)\nfor (i in 1:nrep) {\n  pred_y_sim[i] <- rbinom(1, 30, pred_p_sim[i])\n}\n# In maniera equivalente posso fare:\n# pred_y_sim <- rbinom(1e5, n, pred_p_sim)\n\nCalcolo la proporzione di volte in cui sono stati osservai i valori \\(\\tilde{y} = 0, 1, \\dots, 30\\).\n\nppd <- table(pred_y_sim) / nrep\nppd\n#> pred_y_sim\n#>       3       4       5       6       7       8       9      10      11      12 \n#> 0.00002 0.00004 0.00011 0.00036 0.00096 0.00241 0.00533 0.01000 0.01753 0.02882 \n#>      13      14      15      16      17      18      19      20      21      22 \n#> 0.04290 0.06110 0.07812 0.09476 0.10763 0.11311 0.10821 0.09765 0.07982 0.06185 \n#>      23      24      25      26      27      28      29      30 \n#> 0.04156 0.02536 0.01299 0.00630 0.00224 0.00064 0.00016 0.00002\n\nCalcolo l’intervallo di valori \\(\\tilde{y}\\) a cui è associata una probabilità di 0.89 (per fare un confronto con il risultato ottenuto in precedenza).\n\nLearnBayes::discint(cbind(3:30, ppd), 0.89) \n#> $prob\n#>      12 \n#> 0.91553 \n#> \n#> $set\n#> 12 13 14 15 16 17 18 19 20 21 22 23 \n#> 12 13 14 15 16 17 18 19 20 21 22 23\n# i risultati minori di 3 non sono stati calcolati\n\nConfronto i risultati della simulazione con i valori esatti della distribuzione predittiva a posteriori. Di seguito riporto i risultati esatti.\n\nprob30 <- extraDistr::dbbinom(0:30, 30, 25, 17)\nLearnBayes::discint(cbind(0:30, prob30), 0.89)\n#> $prob\n#> [1] 0.9152885\n#> \n#> $set\n#>  [1] 12 13 14 15 16 17 18 19 20 21 22 23\n\nUn grafico con la distribuzione predittiva a posteriori esatta è fornito nella figura seguente.\n\ntibble(Y=0:30, Probability = prob30) %>% \n  ProbBayes::prob_plot(Color = \"black\")\n\n\n\n\n\n\n\nUna rappresentazione della distribuzione a posteriori ottenuta mediante simulazione è il seguente.\n\ntibble(Y=0:30, Probability = c(0, 0, 0, ppd)) %>% \n  ProbBayes::prob_plot(Color = \"black\")\n\n\n\n\n\n\n\nSi noti che i risultati della simulazione sono indistinguibili dalla soluzione esatta."
  },
  {
    "objectID": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-mcmc",
    "href": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-mcmc",
    "title": "24  La predizione bayesiana",
    "section": "\n24.4 La distribuzione predittiva a posteriori mediante MCMC",
    "text": "24.4 La distribuzione predittiva a posteriori mediante MCMC\nIl metodo basato su simulazione che abbiamo discusso sopra si basa sulla stessa logica usata dai metodi MCMC per ottenere un’approssimazione della distribuzione predittiva a posteriori. Mediante i metodi MCMC, le stime delle possibili osservazioni future \\(p(\\tilde{y} \\mid y)\\), chiamate \\(p(y^{rep} \\mid y)\\), si ottengono nel modo seguente:\n\ncampionare \\(\\theta_i \\sim p(\\theta \\mid y)\\), ovvero scegliere un valore a caso del parametro dalla distribuzione a posteriori;\ncampionare \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\), ovvero scegliere un’osservazione a caso dalla funzione di verosimiglianza condizionata al valore del parametro definito nel passo precedente.\n\nSe i due passaggi descritti sopra vengono ripetuti un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva a posteriori che, in teoria potrebbe essere ottenuta per via analitica.\n\nEsercizio 24.1 Utilizziamo il codice Stan per generare \\(p(y^{rep} \\mid y)\\) nel caso dell’inferenza su una proporzione.\n\nmodelString = \"\ndata {\n  int<lower=0> N;\n  array[N] int<lower=0, upper=1> y;\n}\nparameters {\n  real<lower=0, upper=1> theta;\n}\nmodel {\n  theta ~ beta(2, 10);\n  y ~ bernoulli(theta);\n}\ngenerated quantities {\n  array[N] int y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = bernoulli_rng(theta);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/betabin23-30-2-10.stan\")\n\nSi noti che nel nel blocco generated quantities sono state aggiunte le istruzioni necessarie per simulare \\(y^{rep}\\), ovvero, y_rep[n] = bernoulli_rng(theta). Una tale istruzione ci dice di generare un valore casuale di una variabile Bernoulliana di parametro \\(\\theta\\). Il valore \\(\\theta\\) è preso a caso dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). Il ciclo for specifica che tale operazione va ripetuta 30 volte per ciascuna iterazione MCMC.\nI dati dell’esempio sono forniti in formato list.\n\ndata_list <- list(\n  N = 30,\n  y = c(rep(1, 23), rep(0, 7))\n)\n\nCompiliamo il codice Stan.\n\nfile <- file.path(\"code\", \"betabin23-30-2-10.stan\")\nmod <- cmdstan_model(file)\n\nEseguiamo il campionamento MCMC.\n\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nPer comodità, trasformiamo l’oggetto fit in un oggetto di classe stanfit.\n\nstanfit <- rstan::read_stan_csv(fit$output_files())\n\nIl contenuto dell’oggetto stanfit può essere esaminato mediante la funzione extract().\n\nlist_of_draws <- extract(stanfit)\nprint(names(list_of_draws))\n#> [1] \"theta\" \"y_rep\" \"lp__\"\n\nDall’oggetto list_of_draws recuperiamo y_rep.\n\ny_bern <- list_of_draws$y_rep\ndim(y_bern)\n#> [1] 16000    30\nhead(y_bern)\n#>           \n#> iterations [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n#>       [1,]    1    1    1    1    0    1    1    1    1     1     1     1     1\n#>       [2,]    0    1    0    1    1    1    0    0    1     0     0     0     0\n#>       [3,]    0    1    0    1    1    1    0    0    1     1     1     0     1\n#>       [4,]    1    0    0    1    1    0    0    1    0     1     1     1     0\n#>       [5,]    0    0    0    1    1    0    1    1    0     1     0     0     1\n#>       [6,]    1    1    1    1    1    1    0    1    0     1     1     1     0\n#>           \n#> iterations [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24]\n#>       [1,]     0     1     1     1     1     1     0     0     1     0     1\n#>       [2,]     1     0     0     1     0     1     1     1     0     0     0\n#>       [3,]     0     0     1     0     1     1     0     1     0     0     1\n#>       [4,]     0     1     0     1     0     1     0     0     1     0     1\n#>       [5,]     0     0     1     1     1     1     1     0     1     0     1\n#>       [6,]     1     1     0     1     0     1     1     0     0     1     0\n#>           \n#> iterations [,25] [,26] [,27] [,28] [,29] [,30]\n#>       [1,]     1     1     1     1     1     1\n#>       [2,]     0     1     1     0     1     1\n#>       [3,]     1     1     1     1     1     0\n#>       [4,]     0     1     1     0     0     1\n#>       [5,]     0     0     0     0     1     0\n#>       [6,]     0     0     1     0     1     1\n\nDato che il codice Stan definisce un modello per i dati grezzi (ovvero, per ciascuna singola prova Bernoulliana del campione), ogni riga della matrice y_bern ha 30 colonne, ciascuna delle quali corrisponde ad un campione (\\(n\\) = 16,000 in questa simulazione) di possibili valori futuri \\(y_i \\in \\{0, 1\\}\\). In altre parole, abbiamo generato 16,000 campioni casuali di 30 osservazioni possibili osservazioni future.\nPer ottenere una stima della distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\), ovvero, per ottenere una stima della probabilità associata a ciascuno dei possibili numeri di successi, \\(\\tilde{y}\\), in \\(m = 30\\) nuove prove future, è sufficiente calcolare la proporzione di valori 1 in ciascuna riga della matrice y_bern.\n\ntibble(y_rep = rowSums(y_bern)) %>%\n  ggplot(aes(x = y_rep, after_stat(density))) +\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\nSi noti che l’istogramma così ottenuto è equivalente a quello trovato nella simulazione precedente."
  },
  {
    "objectID": "046_bayesian_prediction.html#i-metodi-per-la-valutazione-del-modello",
    "href": "046_bayesian_prediction.html#i-metodi-per-la-valutazione-del-modello",
    "title": "24  La predizione bayesiana",
    "section": "\n24.5 I metodi per la valutazione del modello",
    "text": "24.5 I metodi per la valutazione del modello\n\n24.5.1 Posterior predictive checks\nLa distribuzione predittiva a posteriori viene utilizzata per eseguire i cosiddetti controlli predittivi a posteriori (Posterior Predictive Checks, PPC). Nella distribuzione predittiva a posteriori, viene generato un campione di dati possibili futuri utilizzando le proprietà del modello adattato. È ovvio che tali dati possibili futuri devono almento essere coerenti con i dati del campione presente. I PPC eseguono un confronto grafico tra \\(p(y^{rep} \\mid y)\\) e i dati osservati \\(y\\): confrontando visivamente gli aspetti chiave dei dati previsti futuri \\(y^{rep}\\) e dei dati osservati \\(y\\) è possibile determinare se il modello è adeguato.\nOltre al confronto visivo tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\) è anche possibile un confronto tra la distribuzione di varie statistiche descrittive, i cui valori sono calcolati su diversi campioni \\(y^{rep}\\), e le corrispondenti statistiche calcolate sui dati osservati. Vengono solitamente considerate statistiche descrittive quali la media, la varianza, la deviazione standard, il minimo o il massimo, ma sono possibili confronti di questo tipo per qualunque altra statistica.\n\nEsercizio 24.2 Esaminiamo ora un set di dati che non seguono la distribuzione normale (Gelman et al., 2020). I dati corrispondono ad una serie di misurazioni prese da Simon Newcomb nel 1882 come parte di un esperimento per stimare la velocità della luce. A questi dati verrà (inappropriatamente) adattata una distribuzione normale. L’obiettivo dell’esempio è quello di mostrare come i PPC possono rivelare la mancanza di adattamento di un modello ai dati.\nI PPC mostrano che il modo più semplice per verificare l’adattamento del modello è quello di visualizzare \\(y^{rep}\\) insieme ai dati effettivi. Iniziamo a caricare i dati.\n\nlibrary(\"MASS\")\ndata(\"newcomb\")\n\nVisualizziamo la distribuzione dei dati con un istogramma.\n\ntibble(newcomb) %>%\n  ggplot(aes(x = newcomb, after_stat(density))) +\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\nCreiamo un oggetto di tipo list dove inserire i dati.\n\ndata_list <- list(\n  y = newcomb,\n  N = length(newcomb)\n)\n\nUtilizziamo il seguente codice Stan per il modello normale.\n\nmodelString <- \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  mu ~ normal(25, 10);\n  sigma ~ cauchy(0, 10);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/newcomb.stan\")\n\nAdattiamo il modello ai dati.\n\nfile <- file.path(\"code\", \"newcomb.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nOtteniamo le stime dei parametri \\(\\mu\\) e \\(\\sigma\\).\n\nfit$summary(c(\"mu\", \"sigma\"))\n#> # A tibble: 2 × 10\n#>   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu        26.2   26.2 1.33  1.30  24.0   28.4  1.00   13305.   11189.\n#> 2 sigma     10.9   10.8 0.958 0.943  9.40  12.5  1.00   12614.   10352.\n\nTrasformiamo l’oggetto fit in un formato stanfit.\n\nstanfit <- rstan::read_stan_csv(fit$output_files())\n\nRappresentiamo graficamente la distribuzione a posteriori di \\(\\mu\\).\n\nmu_draws <- as.matrix(stanfit, pars = \"mu\")\nmcmc_areas(mu_draws, prob = 0.95) # color 95% interval\n\n\n\n\n\n\n\nLa media campionaria è pari a 26.21.\n\nmean(newcomb)\n#> [1] 26.21212\n\nAnche se trova la media giusta, il modello non è comunque adeguato a prevedere le altre proprietà della \\(y\\). Estraiamo \\(y^{rep}\\) dall’oggetto stanfit.\n\ny_rep <- as.matrix(stanfit, pars = \"y_rep\")\ndim(y_rep)\n#> [1] 16000    66\n\nI valori y_rep sono i dati della distribuzione predittiva a posteriori che sono stati simulati usando gli stessi valori \\(X\\) dei predittori utilizzati per adattare il modello. Il confronto tra l’istogramma della \\(y\\) e gli istogrammi di diversi campioni \\(y^{rep}\\) mostra una scarsa corrispondenza tra i due.\n\nppc_hist(data_list$y, y_rep[1:8, ], binwidth = 1)\n\n\n\n\n\n\n\nAlla stessa conclusione si giunge tramite un confronto tra la funzione di densità empirica della \\(y\\) e quella di diversi campioni \\(y^{rep}\\).\n\nppc_dens_overlay(data_list$y, y_rep[1:50, ])\n\n\n\n\n\n\n\nGeneriamo ora i PPC per la media e il minimo della distribuzione.\n\nppc_stat_2d(data_list$y, y_rep, stat = c(\"mean\", \"min\"))\n\n\n\n\n\n\n\nIn conclusione, possiamo dire che mentre la media viene riprodotta accuratamente dal modello, ciò non è vero per il minimo della distribuzione. L’origine di questa mancanza di adattamento è il fatto che la distribuzione delle misurazioni della velocità della luce è asimmetrica negativa.\nDato che ci sono poche osservazioni nella coda negativa della distribuzione, solo per fare un esempio, utilizzeremo ora un secondo modello che ipotizza una distribuzione \\(t\\) di Student.\n\nmodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n  real<lower=0> nu;\n}\nmodel {\n  mu ~ normal(25, 10);\n  sigma ~ cauchy(0, 10);\n  nu ~ cauchy(0, 10);\n  y ~ student_t(nu, mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = student_t_rng(nu, mu, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/newcomb2.stan\")\n\nAdattiamo questo secondo modello ai dati.\n\nfile <- file.path(\"code\", \"newcomb2.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.2 seconds.\n#> Chain 2 finished in 0.3 seconds.\n#> Chain 3 finished in 0.3 seconds.\n#> Chain 4 finished in 0.4 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.3 seconds.\n#> Total execution time: 1.5 seconds.\n\nPer questo secondo modello il confronto tra la funzione di densità empirica della \\(y\\) e quella di diversi campioni \\(y^{rep}\\) risulta adeguato.\n\nstanfit <- rstan::read_stan_csv(fit$output_files())\ny_rep <- as.matrix(stanfit, pars = \"y_rep\")\nppc_dens_overlay(data_list$y, y_rep[1:50, ]) + xlim(0, 50)\n\n\n\n\n\n\n\nInoltre, anche la statistica “minimo della distribuzione” viene ben predetta dal modello.\n\nppc_stat_2d(data_list$y, y_rep, stat = c(\"mean\", \"min\"))\n\n\n\n\n\n\n\nIn conclusione, per le misurazioni della velocità della luce di Newcomb l’accuratezza predittiva del modello basato sulla distribuzione \\(t\\) di Student è chiaramente migliore di quella del modello normale."
  },
  {
    "objectID": "046_bayesian_prediction.html#distribuzione-predittiva-a-priori",
    "href": "046_bayesian_prediction.html#distribuzione-predittiva-a-priori",
    "title": "24  La predizione bayesiana",
    "section": "\n24.6 Distribuzione predittiva a priori",
    "text": "24.6 Distribuzione predittiva a priori\nNella sezione precedente abbiamo visto come la distribuzione predittiva è stata usata per generare nuovi dati previsti futuri. Più precisamente, mediante l’Equazione 24.1 abbiamo descritto la nostra incertezza sulla distribuzione di future osservazioni di dati, data la distribuzione a posteriori di \\(\\theta\\), ovvero tenendo conto della scelta del modello e della stima dei parametri mediante i dati osservati.\n\\[\np(\\tilde{y} \\mid y) = \\int_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta\\notag\n\\]\nSi noti che, nell’Equazione 24.1, \\(\\tilde{y}\\) è condizionato da \\(y\\) ma non da ciò che è incognito, ovvero \\(\\theta\\). La distribuzione predittiva a posteriori è ottenuta mediante marginalizzazione sopra i parametri incogniti \\(\\theta\\).\nIn un modello bayesiano dove \\(\\theta\\) ha una distribuzione a priori \\(p(\\theta)\\) e per \\(y\\) possiamo definire la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) possiamo scrivere la distribuzione congiunta \\(p(y, \\theta)\\) come il prodotto della verosimiglianza e della distribuzione a priori:\n\\[\np(y, \\theta) = p(y \\mid \\theta)p(\\theta).\n\\]\nUna rappresentazione alternativa della distribuzione congiunta \\(p(y, \\theta)\\) è\n\\[\np(y, \\theta) = p(\\theta \\mid y)p(y).\n\\]\nIl primo termine in questo prodotto, la densità \\(p(\\theta \\mid y)\\), è la densità a posteriori di \\(\\theta\\) date le osservazioni \\(y\\). Il secondo termine in questo prodotto, \\(p(y)\\), è la distribuzione predittiva a priori che rappresenta la distribuzione dei dati futuri previsti dal modello prima di avere osservato il campione \\(y\\). Se risulta che i dati osservati \\(y\\) non sono coerenti con la distribuzione predittiva a priori, ciò significa che il modello bayesiano non è specificato correttamente. In altre parole, questo ci dice che, in base al modello bayesiano che abbiamo formulato, è improbabile che si verifichino i dati che sono stati effettivamente osservati. Ovviamente, questo vuol dire che il modello è inadeguato.\nLa distribuzione predittiva a priori può essere ricavata facilmente se l’inferenza bayesiana viene svolta mediante i metodi MCMC. Per fare un esempio consideriamo nuovamente i dati di Zetsche et al. (2019), con 23 successi in 30 prove. Nella discussione precedente abbiamo svolto l’aggiornamento bayesiano imponendo su \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(2, 10)\\).\nNel caso di una verosimiglianza binomiale e di una distribuzione a priori Beta, la distribuzione predittiva a priori può essere costruita mediante la funzione LearnBayes::pbetap().\n\ndf <- tibble(\n  y = 0:30,\n  Probability = LearnBayes::pbetap(c(2, 10), 30, 0:30)\n)\ndf %>% \n  ProbBayes::prob_plot(Color = \"gray\", Size = 3) + \n  geom_point(data = tibble(y = 23, Probability = 0), size = 3) \n\n\n\n\n\n\n\nLa distribuzione predittiva a priori assegna livelli diversi di credibilità a ciascuno dei possibili risultati dell’esperimento casuale, ovvero il fatto di osservare 0, 1, , 30 successi in 30 prove Bernoulliane.\nNella distribuzione predittiva a priori riportata nel grafico precedente ho evidenziato il punto \\(y = 23\\), ovvero il numero di successi nel campione. Il grafico mostra che la distribuzione predittiva a priori assegna una credibilità quasi nulla all’evento \\(y = 23\\), ovvero ai dati che sono stati effettivamente osservati. Questo indica chiaramente che la distribuzione a priori \\(\\mbox{Beta}(2, 10)\\) non è adeguata per i dati che stiamo analizzando, così come avevamo in precedenza anticipato.\nSe viene invece utilizzata una distribuzione a priori debolmente informativa, o vero \\(\\mbox{Beta}(2, 2)\\), la distribuzione predittiva a priori assume la forma seguente.\n\ndf <- tibble(\n  y = 0:30,\n  Probability = LearnBayes::pbetap(c(2, 2), 30, 0:30)\n)\ndf %>% \n  ProbBayes::prob_plot(Color = \"gray\", Size = 3) + \n  geom_point(data = tibble(y = 23, Probability = 0), size = 3) \n\n\n\n\n\n\n\nIn questo secondo caso al valore \\(y\\) osservato viene assegnata una credibilità piuttosto alta. Ciò significa che una \\(\\mbox{Beta}(2, 2)\\) fornisce un’adeguata distribuzione a priori per i dati a disposizione.\nNella discussione dell’analisi dei dati di Zetsche et al. (2019), la \\(\\mbox{Beta}(2, 10)\\) è stata utilizzata quale distribuzione a priori solo per evidenziare le proprietà dell’aggiornamento bayesiano (la differenza tra la distribuzione a priori e la distribuzione a posteriori). La discussione presente chiarisce che la \\(\\mbox{Beta}(2, 10)\\) non è una buona scelta per la distribuzione a priori: sarebbe molto migliore la scelta di una \\(\\mbox{Beta}(2, 2)\\)."
  },
  {
    "objectID": "046_bayesian_prediction.html#commenti-e-considerazioni-finali",
    "href": "046_bayesian_prediction.html#commenti-e-considerazioni-finali",
    "title": "24  La predizione bayesiana",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nQuesto capitolo discute la predizione bayesiana e ne mostra un’applicazione nel caso dei controlli predittivi a posteriori. A questo proposito è necessario notare un punto importante: un buona corrispondenza tra \\(y\\) e \\(y^{rep}\\) costituisce una condizione necessaria ma non sufficiente per la validità del modello. Infatti, i PPC non sono in grado di garantire la generalizzabilità del modello a nuovi campioni di dati. D’altra parte, invece, se i PPC mostrano un cattivo adattamento del modello ai dati previsti futuri, questo ci dice chiaramente che il modello è specificato in maniera errata.\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\n\n\nZetsche, U., Bürkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688."
  },
  {
    "objectID": "050_normal_normal_mod.html#caso-normale-normale-con-varianza-nota",
    "href": "050_normal_normal_mod.html#caso-normale-normale-con-varianza-nota",
    "title": "25  Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)",
    "section": "\n25.1 Caso Normale-Normale con varianza nota",
    "text": "25.1 Caso Normale-Normale con varianza nota\nSupponiamo che i dati \\(y\\) siano un campione casuale estratto da una popolazione che segue la legge Normale. Ciò significa che le osservazioni possono essere considerate come una sequenza di variabili casuali indipendenti e identicamente distribuite. Supponiamo che ciascuna v.c. segua la distribuzione Normale. Abbiamo dunque\n\\[\nY_1, \\dots, Y_n  \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma).\n\\]\nIn precedenza abbiamo visto come, in tali circostanze, la verosimiglianza \\(p(y \\mid \\mu, \\sigma)\\) sia Normale. Per fare inferenza sul parametro \\(\\mu\\), facciamo due assunzioni: consideriamo \\(\\sigma\\) nota e imponiamo su \\(\\mu\\) una distribuzione a priori Normale. Questa situazione definisce lo schema coniugato Normale-Normale. Il caso Normale-Normale consente una derivazione analitica della distribuzione a posteriori \\(p(\\mu \\mid y)\\) (così come nel caso beta-binomiale era possibile una derivazione analitica della distribuzione a posteriori \\(p(\\theta \\mid y)\\)).\nLa trattazione matematica di una tale derivazione è piuttosto complessa e qui verrà solo accennata. Nel seguito, impareremo invece ad applicare la soluzione che viene ottenuta in tali circostanze; mostreremo inoltre come fare inferenza su \\(\\mu\\) mediante i metodi MCMC."
  },
  {
    "objectID": "050_normal_normal_mod.html#derivazione-analitica-della-distribuzione-a-posteriori-pmu-mid-y",
    "href": "050_normal_normal_mod.html#derivazione-analitica-della-distribuzione-a-posteriori-pmu-mid-y",
    "title": "25  Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)",
    "section": "\n25.2 Derivazione analitica della distribuzione a posteriori \\(p(\\mu \\mid y)\\)\n",
    "text": "25.2 Derivazione analitica della distribuzione a posteriori \\(p(\\mu \\mid y)\\)\n\nPer \\(\\sigma^2\\) nota, la famiglia della distribuzione Normale è coniugata a sé stessa: se la funzione di verosimiglianza è Normale, la scelta di una distribuzione a priori Normale per \\(\\mu\\) assicura che anche la distribuzione a posteriori \\(p(\\mu \\mid y)\\) sia Normale.\nPoniamoci dunque il problema di trovare \\(p(\\mu \\mid y)\\) nel caso di un campione casuale \\(Y_1, \\dots, Y_n \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma)\\), supponendo \\(\\sigma\\) perfettamente nota e imponendo su \\(\\mu\\) una distribuzione a priori Normale. Ricordiamo che la densità gaussiana è\n\\[\np(y_i \\mid \\mu, \\sigma) = \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_i - \\mu)^2}{2\\sigma^2}}\\right\\}.\n\\]\nEssendo le variabili i.i.d., possiamo scrivere la densità congiunta come il prodotto delle singole densità e quindi si ottiene\n\\[\np(y \\mid \\mu) = \\, \\prod_{i=1}^n p(y_i \\mid \\mu).\n\\]\nUna volta osservati i dati \\(y\\), la verosimiglianza diventa\n\\[\n\\begin{align}\np(y \\mid \\mu) =& \\, \\prod_{i=1}^n p(y_i \\mid \\mu) = \\notag\\\\\n& \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_1 - \\mu)^2}{2\\sigma^2}}\\right\\} \\times \\notag\\\\\n& \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_2 - \\mu)^2}{2\\sigma^2}}\\right\\} \\times  \\notag\\\\\n& \\vdots \\notag\\\\\n& \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_n - \\mu)^2}{2\\sigma^2}}\\right\\}.\n\\end{align}\n\\]\nSe la densità a priori \\(p(\\mu)\\) è gaussiana, allora anche la densità a posteriori \\(p(\\mu \\mid y)\\) sarà gaussiana. Poniamo\n\\[\np(\\mu) = \\frac{1}{{\\tau_0 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(\\mu - \\mu_0)^2}{2\\tau_0^2}}\\right\\},\n\\] {#eq:prior-mu-norm-norm}\novvero imponiamo a \\(\\mu\\) una distribuzione a priori gaussiana con media \\(\\mu_0\\) e varianza \\(\\tau_0^2\\). Ciò significa dire che, a priori, \\(\\mu_0\\) rappresenta il valore più verosimile per \\(\\mu\\), mentre \\(\\tau_0^2\\) quantifica il grado della nostra incertezza rispetto a tale valore.\nSvolgendo una serie di passaggi algebrici, si arriva alla distribuzione a posteriori\n\\[\np(\\mu \\mid y) = \\frac{1}{{\\tau_p \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(\\mu - \\mu_p)^2}{2\\tau_p^2}}\\right\\},\n\\tag{25.1}\\]\ndove\n\\[\n\\mu_p = \\frac{\\frac{1}{\\tau_0^2}\\mu_0+ \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\tau_0^2} + \\frac{n}{\\sigma^2}}\n\\tag{25.2}\\]\ne\n\\[\n\\tau_p^2 = \\frac{1}{\\frac {1}{\\tau_0^2}+ \\frac{n}{\\sigma^2}}.\n\\tag{25.3}\\]\nCiò significa che, se la distribuzione a priori \\(p(\\mu)\\) è gaussiana, allora anche la distribuzione a posteriori \\(p(\\mu \\mid y)\\) sarà gaussiana con valore atteso \\(\\mu_p\\) e varianza \\(\\tau_p^2\\) date dalle espressioni precedenti.\nIn conclusione, il risultato trovato indica che:\n\nil valore atteso a posteriori è una media pesata fra il valore atteso a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\); il peso della media campionaria è tanto maggiore tanto più è grande \\(n\\) (il numero di osservazioni) e \\(\\tau_0^2\\) (l’incertezza iniziale);\nl’incertezza (varianza) a posteriori \\(\\tau_p^2\\) è sempre più piccola dell’incertezza a priori \\(\\tau_0^2\\) e diminuisce al crescere di \\(n\\).\n\n\nEsercizio 25.1 Per esaminare un esempio pratico, consideriamo i 30 valori BDI-II dei soggetti clinici di Zetsche et al. (2019).\n\ndf <- data.frame(\n  y = c(\n    26.0, 35.0, 30, 25, 44, 30, 33, 43, 22, 43,\n    24, 19, 39, 31, 25, 28, 35, 30, 26, 31, 41,\n    36, 26, 35, 33, 28, 27, 34, 27, 22\n  )\n)\n\nSupponiamo che la varianza \\(\\sigma^2\\) della popolazione sia identica alla varianza del campione:\n\nsigma <- sd(df$y)\nsigma\n#> [1] 6.606858\n\nPer fare un esempio, imponiamo su \\(\\mu\\) una distribuzione a priori \\(\\mathcal{N}(25, 2)\\). In tali circostanze, la distribuzione a posteriori del parametro \\(\\mu\\) può essere determinata per via analitica e corrisponde ad una Normale di media e varianza definite dalle equazioni @ref(eq:post-norm-mup) e @ref(eq:post-norm-taup2). È possibile visualizzare tale distribuzione a posteriori usando la funzione plot_normal_normal() del pacchetto bayesrules.\n\nbayesrules::plot_normal_normal(\n  mean = 25, # media della distribuzione a priori per mu\n  sd = 2, # sd della distribuzione a priori per mu\n  sigma = sd(df$y), # sd del campione\n  y_bar = mean(df$y), # media del campione\n  n = length(df$y) # ampiezza campionaria\n)\n\n\n\n\n\n\n\nLa funzione bayesrules::summarize_normal_normal() fornisce una sintesi numerica della distribuzione a posteriori \\(p(\\mu \\mid y, \\sigma)\\).\n\nbayesrules::summarize_normal_normal(\n  mean = 25, # media della distribuzione a priori per mu\n  sd = 2, # sd della distribuzione a priori per mu\n  sigma= sd(df$y), # sd del campione\n  y_bar = mean(df$y), # media del campione\n  n = length(df$y) # ampiezza campionaria\n)\n#>       model     mean     mode      var       sd\n#> 1     prior 25.00000 25.00000 4.000000 2.000000\n#> 2 posterior 29.35073 29.35073 1.066921 1.032919\n\nVerifichiamo i risultati forniti da bayesrules::summarize_normal_normal() applicando le formule @ref(eq:post-norm-mup) e @ref(eq:post-norm-taup2). Definiamo la funzione della media della distribuzione a posteriori di \\(\\mu\\).\n\nmu_post <- function(tau_0, mu_0, sigma, ybar, n) {\n  (1/tau_0^2 * mu_0 + n/sigma^2 * ybar) / (1/tau_0^2 + n/sigma^2)\n}\n\nTroviamo la media a posteriori.\n\nmu_0 <- 25  # media della distribuzione a priori per mu\ntau_0 <- 2  # sd della distribuzione a priori per mu\nsigma <- sd(df$y) # sd del campione (assunta essere sigma)\nybar <- mean(df$y) # media del campione\nn <- length(df$y)\n\nmu_post(tau_0, mu_0, sigma, ybar, n) \n#> [1] 29.35073\n\nDefiniamo una funzione per la deviazione standard della distribuzione a posteriori di \\(\\mu\\).\n\ntau_post <- function(tau_0, sigma, n) {\n  sqrt(1 / (1/tau_0^2 + n/sigma^2))\n}\n\nTroviamo la deviazione standard a posteriori.\n\ntau_0 <- 2  # sd della distribuzione a priori per mu\nsigma <- sd(df$y) # sd del campione (assunta essere sigma)\nn <- length(df$y)\n\ntau_post(tau_0, sigma, n) \n#> [1] 1.032919\n\nI risultati così trovati riproducono quelli forniti da bayesrules::summarize_normal_normal()."
  },
  {
    "objectID": "050_normal_normal_mod.html#il-modello-normale-con-stan",
    "href": "050_normal_normal_mod.html#il-modello-normale-con-stan",
    "title": "25  Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)",
    "section": "\n25.3 Il modello Normale con Stan",
    "text": "25.3 Il modello Normale con Stan\nI priori coniugati Normali di una Normale non richiedono una approssimazione numerica ottenuta mediante metodi MCMC. Tuttavia, per fare un esercizio e per verificare che i risultati ottenuti mediante MCMC siano simili a quelli trovati per via analitica, ripetiamo l’esercizio precedente usando Stan.\n\n25.3.1 Versione 1 (\\(\\sigma\\) nota)\nCome in precedenza, impongo su \\(\\mu\\) una distribuzione a priori \\(\\mathcal{N}(25, 2)\\) e considero noto il parametro \\(\\sigma = 6.606858\\). Il modello dunque diventa il seguente.\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(25, 2) \\notag\\\\\n\\sigma &= 6.606858 \\notag\n\\end{align}\n\\]\nIn base al modello definito sopra, la variabile casuale \\(Y\\) segue la distribuzione Normale di parametri \\(\\mu\\) e \\(\\sigma\\). Il parametro \\(\\mu\\) è sconosciuto e abbiamo deciso di descrivere la nostra incertezza relativa ad esso mediante una distribuzione a priori Normale di media 25 e deviazione standard 2. Il parametro \\(\\sigma\\) è invece assunto essere noto e uguale a 6.606858. Usando il linguaggio Stan specifico il modello come segue.\n\nmodelString = \"\ndata {\n  int<lower=0> N;\n  real<lower=0> sigma;\n  vector[N] y;\n}\nparameters {\n  real mu;\n}\nmodel {\n  mu ~ normal(25, 2);\n  y ~ normal(mu, sigma);\n}\n\"\nwriteLines(modelString, con = \"code/normal_normal_1.stan\")\n\nSistemo i dati nel formato appropriato per Stan.\n\ndlist <- list(\n  N = length(df$y),\n  sigma = sd(df$y),\n  y = df$y\n)\n\nLeggo il file in cui ho salvato il codice Stan.\n\nfile <- file.path(\"code\", \"normal_normal_1.stan\")\n\nCompilo il modello.\n\nmod <- cmdstan_model(file)\n\nEseguo il campionamento MCMC.\n\nfit <- mod$sample(\n  data = dlist,\n  iter_sampling = 100000L,\n  iter_warmup = 2000L,\n  chains = 4L,\n  refresh = 0\n)\n\nUna sintesi della distribuzione a posteriori dei parametri si ottiene nel modo seguente.\n\nfit$summary(c(\"mu\"))\n#> # A tibble: 1 × 10\n#>   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu        29.4   29.4  1.04  1.04  27.6  31.1  1.00  153786.  188314.\n\nSi noti che le stime ottenute sono molto vicine ai valori teorici attesi, ovvero \\(\\mu_p\\) = 29.3527 contro un valore teorico di 29.35 e \\(\\tau_p\\) = 1.033 contro un valore teorico di 1.03.\nQui sotto è fornita una rappresentazione grafica dell’intera distribuzione a posteriori del parametro \\(\\mu\\).\n\nstanfit <- rstan::read_stan_csv(fit$output_files())\nmu_draws <- as.matrix(stanfit,pars =\"mu\")\nmcmc_areas(mu_draws,prob = 0.95) \n\n\n\n\n\n\n\nTrovo l’intervallo di credibilità al 95%.\n\npost <- fit$draws()\npost_parms <- subset_draws(post, c(\"mu\"))\nposterior::summarise_draws(\n  post_parms,\n  ~ quantile(.x, probs = c(0.025, 0.975))\n)\n#> # A tibble: 1 × 3\n#>   variable `2.5%` `97.5%`\n#>   <chr>     <dbl>   <dbl>\n#> 1 mu         27.3    31.4\n\nLe stime così trovate sono molto simili ai quantili di ordine 0.025 e 0.975 della vera distribuzione a posteriori di \\(\\mu\\).\n\nqnorm(c(0.025, 0.975), 29.35073, 1.032919)\n#> [1] 27.32625 31.37521\n\n\n25.3.2 Versione 2 (\\(\\sigma\\) incognita)\nÈ facile estendere il caso precedente alla situazione in cui il parametro \\(\\sigma\\) è incognito. Se non conosciamo \\(\\sigma\\), è necessario imporre su tale parametro una distribuzione a priori. Supponiamo di ipotizzare per \\(\\sigma\\) una distribuzione a priori \\(\\mbox{Cauchy}(0, 15)\\).\nMediante una \\(\\mbox{Cauchy}(0, 15)\\) descrivo il grado di plausibilità soggettiva che attribuisco ai possibili valori (> 0) del parametro \\(\\sigma\\). Ai valori prossimi allo 0 attribuisco la plausibilità maggiore; la plausibilità dei possibili valori \\(\\sigma\\) diminuisce progressivamente quando ci si allontana dallo 0, come indicato dalla curva della figura seguente. Ritengo poco plausibili valori \\(\\sigma\\) maggiori di 40, anche se non escludo completamente che \\(\\sigma\\) possa assumere un valore di questo tipo.\n\ncurve(\n  dcauchy(x, location = 0, scale = 15), \n  from = 0, to = 50, col = 'gray', lwd = 3,\n  ylab = \"Densità\",\n  xlab = \"sigma\"\n)\n\n\n\n\n\n\n\nIn questo secondo caso, più realistico, il modello diventa il seguente.\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(25, 2) \\notag\\\\\n\\sigma &\\sim \\mbox{Cauchy}(0, 15) \\notag\n\\end{align}\n\\]\nIl modello precedente è simile a quello esaminato in precedenza, eccetto che abbiamo quantificato la nostra incertezza relativa a \\(\\sigma\\) (che è ignota) mediante una distribuzione a priori \\(\\mbox{Cauchy}(0, 15)\\).\nLa procedura MCMC utilizzata da Stan è basata su un campionamento Monte Carlo Hamiltoniano che non richiede l’uso di distribuzioni a priori coniugate. Pertanto è possibile scegliere per i parametri una qualunque distribuzione a priori. Nel caso presente, appunto, per \\(\\sigma\\) ho scelto una \\(\\mbox{Cauchy}(0, 15)\\). Per un tale caso non è possibile ottenere la derivazione analitica della distribuzione a posteriori di \\(\\mu\\). È dunque necessario procedere con il campionamento MCMC.\nScrivo il modello in linguaggio in Stan.\n\nmodel_string_2 = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  mu ~ normal(25, 2);\n  sigma ~ cauchy(0, 15);\n  y ~ normal(mu, sigma);\n}\n\"\nwriteLines(model_string_2, con = \"code/normal_mod_2.stan\")\n\nCreo l’oggetto di classe list che contiene i dati.\n\ndlist2 <- list(\n  N = length(df$y),\n  y = df$y\n)\n\nLeggo il file con il codice Stan del modello.\n\nfile2 <- file.path(\"code\", \"normal_mod_2.stan\")\n\nCompilo il modello.\n\nmod2 <- cmdstan_model(file2)\n\nEseguo il campionamento MCMC.\n\nfit2 <- mod2$sample(\n  data = dlist2,\n  iter_sampling = 50000L,\n  iter_warmup = 2000L,\n  chains = 4L,\n  refresh = 0\n)\n\nIn questo modo ottengo le seguenti stime a posteriori dei parametri.\n\nfit2$summary(c(\"mu\", \"sigma\"))\n#> # A tibble: 2 × 10\n#>   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu       29.2   29.2   1.14 1.12  27.3  31.0   1.00  129256.  114237.\n#> 2 sigma     7.06   6.95  1.01 0.954  5.63  8.88  1.00  121123.  115765.\n\nDopo avere trasformato l’oggetto fit2 nel formato stanfit, trovo l’intervallo di credibilità al 95%.\n\nstanfit <- rstan::read_stan_csv(fit2$output_files())\nout <- rstantools::posterior_interval(\n  as.matrix(stanfit), \n  prob = 0.95\n)\nout\n#>             2.5%      97.5%\n#> mu     26.851295  31.331500\n#> sigma   5.418299   9.360616\n#> lp__  -76.415107 -72.666800\n\nCome in precedenza, uso la funzione mcmc_areas() per creare una rappresentazione grafica della distribuzione a posteriori di \\(\\mu\\).\n\nmu_draws <- as.matrix(stanfit, pars =\"mu\")\nmcmc_areas(mu_draws, prob = 0.95) \n\n\n\n\n\n\n\nConsiderati i dati osservati e le mie ipotesi a priori sui parametri, posso dunque concludere, con un grado di certezza soggettiva del 95%, che la media della popolazione dei punteggi BDI-II dei pazienti clinici depressi è compresa nell’intervallo [26.85, 31.33]."
  },
  {
    "objectID": "050_normal_normal_mod.html#commenti-e-considerazioni-finali",
    "href": "050_normal_normal_mod.html#commenti-e-considerazioni-finali",
    "title": "25  Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questo capitolo abbiamo visto come calcolare l’intervallo di credibilità per la media di una v.c. Normale. La domanda più ovvia di analisi dei dati, dopo avere visto come trovare l’intervallo di credibilità per la media di un solo gruppo, riguarda il confronto tra le medie di due gruppi. Il confronto tra le medie di due gruppi può essere considerato come un caso particolare di un metodo più generale di analisi dei dati, chiamato analisi di regressione lineare. Prima di discutere il problema del confronto tra le medie di due gruppi è dunque necessario esaminare il modello statistico della regressione lineare.\n\n\n\n\n\n\nZetsche, U., Bürkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688."
  },
  {
    "objectID": "051_reglin1.html#la-funzione-lineare",
    "href": "051_reglin1.html#la-funzione-lineare",
    "title": "26  Introduzione",
    "section": "\n26.1 La funzione lineare",
    "text": "26.1 La funzione lineare\nIniziamo con un ripasso sulla funzione di lineare. Si chiama funzione lineare una funzione del tipo\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono delle costanti. Il grafico di tale funzione è una retta di cui il parametro \\(b\\) è detto coefficiente angolare e il parametro \\(a\\) è detto intercetta con l’asse delle \\(y\\) [infatti, la retta interseca l’asse \\(y\\) nel punto \\((0,a)\\), se \\(b \\neq 0\\)].\nPer assegnare un’interpretazione geometrica alle costanti \\(a\\) e \\(b\\) si consideri la funzione\n\\[\ny = b x.\n\\]\nTale funzione rappresenta un caso particolare, ovvero quello della proporzionalità diretta tra \\(x\\) e \\(y\\). Il caso generale della linearità\n\\[\ny = a + b x\n\\]\nnon fa altro che sommare una costante \\(a\\) a ciascuno dei valori \\(y = b x\\). Nella funzione lineare \\(y = a + b x\\), se \\(b\\) è positivo allora \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) è negativo \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\) la retta è orizzontale, ovvero \\(y\\) non muta al variare di \\(x\\).\nConsideriamo ora più in dettaglio il coefficiente \\(b\\). Si consideri un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\), come indicato nella Figura 26.1. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono detti incrementi di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) è uguale al rapporto\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0},\n\\]\nindipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Il modo più semplice per assegnare un’interpretazione geometrica al coefficiente angolare (o pendenza) della retta è quello di porre \\(\\Delta x = 1\\). In tali circostanze, \\(b = \\Delta y\\).\n\n\n\n\nFigura 26.1: La funzione lineare \\(y = a + bx\\).\n\n\n\n\nPossiamo dunque dire che la pendenza \\(b\\) di un retta è uguale all’incremento \\(\\Delta y\\) associato ad un incremento unitario nella \\(x\\)."
  },
  {
    "objectID": "051_reglin1.html#una-media-per-ciascuna-osservazione",
    "href": "051_reglin1.html#una-media-per-ciascuna-osservazione",
    "title": "26  Introduzione",
    "section": "\n26.2 Una media per ciascuna osservazione",
    "text": "26.2 Una media per ciascuna osservazione\nIn precedenza abbiamo visto come stimare i parametri di un modello bayesiano nel quale le osservazioni sono indipendenti e identicamente distribuite secondo una densità gaussiana,\n\\[\nY_i \\stackrel{i.i.d.}{\\sim} \\mathcal{N}(\\mu, \\sigma), \\quad i = 1, \\dots, n.\n\\tag{26.1}\\]\nIl modello dell’Equazione 26.1 assume che ogni \\(Y_i\\) sia la realizzazione di una v.c. distribuita come \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Da un punto di vista bayesiano, questo modello può essere implementato assegnando delle distribuzioni a priori ai parametri \\(\\mu\\) e \\(\\sigma\\) e generando la verosimiglianza in base ai dati osservati.\n\\[\n\\begin{align}\nY_i \\mid \\mu, \\sigma & \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\notag\\\\\n\\mu    & \\sim \\mathcal{N}(\\mu_0, \\tau^2) \\notag\\\\\n\\sigma & \\sim \\mbox{Cauchy}(x_0, \\gamma) \\notag\n\\end{align}\n\\]\nCon queste informazioni, possono poi essere trovate le distribuzioni a posteriori dei parametri (Gelman et al., 2020). Vediamo ora come sia possibile estendere questo modello bayesiano in modo che possa descrivere la relazione lineare tra due variabili."
  },
  {
    "objectID": "051_reglin1.html#relazione-lineare-tra-la-media-y-mid-x-e-il-predittore",
    "href": "051_reglin1.html#relazione-lineare-tra-la-media-y-mid-x-e-il-predittore",
    "title": "26  Introduzione",
    "section": "\n26.3 Relazione lineare tra la media \\(y \\mid x\\) e il predittore",
    "text": "26.3 Relazione lineare tra la media \\(y \\mid x\\) e il predittore\nIl ricercatore si trova spesso nella condizione in cui osserva altre variabili di interesse associate a ciascuna risposta \\(y_i\\). Chiamiamo \\(x\\) una di tali variabili. Nel contesto del modello di regressione, la variabile \\(x\\) viene chiamata predittore (o variabile indipendente), in quanto il ricercatore è tipicamente interessato a predire \\(y_i\\) a partire dal valore assunto da \\(x_i\\). Chiediamoci dunque come si può estende il modello dell’Equazione 26.1 per lo studio della relazione tra \\(y_i\\) e \\(x_i\\).\nL’Equazione 26.1 assume una media \\(\\mu\\) comune per tutte le osservazioni \\(Y_i\\). Dal momento che desideriamo introdurre una nuova variabile \\(x_i\\) che assume un diverso valore per ciascuna osservazione \\(y_i\\), l’Equazione 26.1 può essere modificata così da sostituire alla media comune \\(\\mu\\) una media \\(\\mu_i\\) specifica a ciascuna \\(i\\)-esima osservazione:\n\\[\nY_i \\mid \\mu_i, \\sigma \\stackrel{ind}{\\sim} \\mathcal{N}(\\mu_i, \\sigma), \\quad i = 1, \\dots, n.\n\\tag{26.2}\\]\nSi noti che le osservazioni \\(Y_1, \\dots, Y_n\\) non sono più identicamente distribuite poiché hanno medie diverse, ma sono ancora indipendenti come indicato dalla notazione ind posta sopra il simbolo \\(\\sim\\) nell’Equazione 26.2.\nL’Equazione 26.2 afferma che ciascuna osservazione \\(Y_i\\) è estratta a caso dalla corrispondente distribuzione \\(\\mathcal{N}(\\mu_i, \\sigma)\\). Al fine di potere descrivere la relazione tra il predittore \\(x_i\\) e la risposta \\(Y_i\\), il modello di regressione assume che la media della distribuzione da cui abbiamo estratto \\(Y_i\\), ovvero \\(\\mu_i\\), sia una funzione lineare del predittore \\(x_i\\), ovvero\n\\[\n\\mu_i = \\beta_0 + \\beta_ 1 x_i, \\quad i = 1, \\dots, n.\n\\tag{26.3}\\]\nNell’Equazione 26.3, ciascuna \\(x_i\\) è una costante nota (ecco perché viene usata una lettera minuscola per la \\(x\\)) e \\(\\beta_0\\) e \\(\\beta_ 1\\) sono parametri incogniti. Questi parametri rappresentano l’intercetta e la pendenza della retta di regressione e sono delle variabili casuali.1 L’inferenza bayesiana procede assegnando una distribuzione a priori a \\(\\beta_0\\) e a \\(\\beta_1\\), trovando la verosimiglianza dei dati e calcolando la distribuzione a priori dei parametri \\(\\beta_0\\) e a \\(\\beta_1\\).\nNel modello dell’Equazione 26.3, la funzione lineare \\(\\beta_0 + \\beta_1 x_i\\) è interpretata come il valore atteso della \\(Y_i\\) per ciascun valore \\(x_i\\). L’intercetta \\(\\beta_0\\) rappresenta il valore atteso della \\(Y_i\\) quando \\(x_i = 0\\). La pendenza \\(\\beta_1\\) rappresenta l’incremento atteso della \\(Y_i\\) quando \\(x_i\\) aumenta di un’unità.\nÈ importante notare che la relazione lineare dell’Equazione 26.2 di parametri \\(\\beta_0\\) e \\(\\beta_1\\) descrive l’associazione tra la media \\(\\mu_i\\) e il predittore \\(x_i\\). In altri termini, tale relazione lineare fornisce una predizione sul valore atteso \\(\\mu_i\\), non sul valore effettivo di ciascuna osservazione \\(Y_i\\)."
  },
  {
    "objectID": "051_reglin1.html#il-modello-lineare",
    "href": "051_reglin1.html#il-modello-lineare",
    "title": "26  Introduzione",
    "section": "\n26.4 Il modello lineare",
    "text": "26.4 Il modello lineare\nSostituendo l’Equazione 26.3 nell’Equazione 26.2 otteniamo il modello lineare:\n\\[\nY_i \\mid \\beta_0, \\beta_ 1, \\sigma \\stackrel{ind}{\\sim} \\mathcal{N}(\\beta_0 + \\beta_ 1 x_i, \\sigma), \\quad i = 1, \\dots, n.\n\\tag{26.4}\\]\nL’Equazione 26.4 è dunque un caso speciale del modello di campionamento Normale, dove le \\(Y_i\\) seguono indipendentemente una densità Normale di media (\\(\\beta_0 + \\beta_ 1 x_i\\)) specifica per ciascuna osservazione, con una deviazione standard (\\(\\sigma\\)) comune a tutte le osservazioni. Poiché include un solo predittore (\\(x\\)), questo modello è chiamato modello di regressione lineare bivariato.\nIl modello di regressione lineare bivariato può essere rappresentato in forma geometrica come indicato nella Figura 26.2. La figura illustra che, in tale modello statistico, la variabile \\(x\\) è fissa per disegno – in altre parole, i valori \\(x\\) restano immutati tra campioni diversi. Potendo ipotizzare infiniti campioni tutti con gli stessi valori \\(x\\), in corrispondenza di ciascun valore \\(x_i\\) vi sarà una distribuzione di valori \\(y\\). La Figura 26.2 illustra il caso di tre valori \\(x\\). A ciascun valore \\(x_i\\), con \\(i = 1, 2, 3\\), corrisponde una distribuzione di valori \\(y\\) condizionati a \\(x_i\\), \\(p(y \\mid x_i)\\).\n\n\n\n\nFigura 26.2: Modello statistico di regressione lineare bivariato.\n\n\n\n\nIl modello statistico di regressione lineare assume che le distribuzioni condizionate \\(p(y \\mid x_i)\\) sono\n\\[\ny_i \\sim \\mathcal{N}(\\mu_i, \\sigma),\n\\]\n(assunzione di normalità), laddove\n\\[\n\\mu_i = \\mathbb{E}(y \\mid x_i) = \\alpha + \\beta x_i.\n\\]\nL’equazione precedente descrive l’assunzione di linearità.\nSi noti che il parametro \\(\\sigma\\) non ha un pedice: questo significa che il modello ipotizza una dispersione costante delle distribuzioni \\(p(y \\mid x_i), \\forall i\\). Tale assunzione va sotto il nome di omoschedasticità.\nSe questa è la struttura della popolazione, possiamo pensare ad un campione casuale di ampiezza \\(n\\) come ad una serie di coppie \\(x_i, y_i\\), con \\(i = 1, \\dots, n\\), nelle quali i valori \\(x\\) sono fissi per disegno e ciascun valore \\(y_i\\) è una realizzazione della variabile casuale \\(Y = y_i \\mid X = x_i\\). Questa è l’ultima assunzione del modello statistico lineare: l’indipendenza. In maniera equivalente possiamo dire che gli errori \\(\\varepsilon_i = y_i - \\hat{y}_i = y_i - (\\beta_0 + \\beta_1 x_i)\\) sono variabili casuali distribuite secondo la legge Normale di parametri \\(\\mathcal{N}(0, \\sigma)\\)."
  },
  {
    "objectID": "051_reglin1.html#commenti-e-considerazioni-finali",
    "href": "051_reglin1.html#commenti-e-considerazioni-finali",
    "title": "26  Introduzione",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIl modello di regressione lineare bivariato viene usato per descrivere la relazione lineare tra due variabili \\(x\\) e \\(Y\\), e per determinare il segno e l’intensità di tale relazione. Inoltre, il modello di regressione lineare consente di prevedere il valore della variabile dipendente \\(Y\\) in base al valore assunto dalla variabile indipendente \\(x\\).\n\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press."
  },
  {
    "objectID": "052_reglin2.html#stima-dei-coefficienti-di-regressione",
    "href": "052_reglin2.html#stima-dei-coefficienti-di-regressione",
    "title": "27  Regressione lineare bivariata",
    "section": "\n27.1 Stima dei coefficienti di regressione",
    "text": "27.1 Stima dei coefficienti di regressione\nIniziamo con il primo obiettivo, ovvero quello di trovare i coefficienti \\(a\\) e \\(b\\) che consentono di predire una componente di ciascuna osservazione \\(y\\) conoscendo \\(x\\). Quindi, nel caso presente, ci chiediamo quanto segue. Il primo bambino del campione ha un QI uguale a 65. Sua madre ha un QI di 121.12. Qual è la predizione migliore del QI del bambino che possiamo ottenere conoscendo il QI della madre?\nÈ chiaro, guardando i dati del campione, che non c’è una corrispondenza perfetta tra QI della madre e QI del bambino, tutt’altro! Infatti, se guardiamo il diagramma di dispersione ci rendiamo conto che i punti sono piuttosto lontani dalla retta che abbiamo sovrapposto alla nube di punti \\(x_i, y_i\\). Tuttavia, il diagramma di dispersione ci suggerisce che, al di là del rumore, c’è comunque una relazione tra le due variabili. Il nostro obiettivo è trovare un metodo quantitativo per descrivere una tale relazione.\nAbbiamo detto che è possibile prevedere una componente di \\(y_i\\) conoscendo \\(x_i\\). La componente \\(y_i\\) predicibile da \\(x_i\\) viene denotata da \\(\\hat{y}_i\\) e, nei termini del modello di regressione lineare è uguale a\n\\[\n\\hat{y}_i = a_i + bx_i.\n\\]\nL’equazione precedente è un’equazione lineare e, dal punto di vista geometrico, corrisponde ad una retta. Ci sono infinite equazioni che, in linea di principio, possiamo usare per descrivere la relazione tra \\(x\\) e \\(y\\). Abbiamo scelto la relazione lineare perché è la più semplice. Se guardiamo il diagramma di dispersione, infatti, non ci sono ragioni per descrivere la relazione tra il QI del bambino e il QI della madre con qualche curva, anziché con una retta. In altri campioni, una curva potrebbe essere più sensata di una retta, quale descrizione della relazione media tra \\(x\\) e \\(y\\), ma non nel caso presente. Ricordiamo il principio del rasoio di Occam (ovvero, il principio che sta alla base del pensiero scientifico moderno): se un modello semplice funziona, non c’è ragione di usare un modello più complesso.\nDunque, abbiamo capito che vogliamo descrivere la relazione media tra \\(x\\) e \\(y\\) con una retta, ovvero, mediante l’equazione lineare\n\\[\n\\hat{y}_i = a + b x_i.\n\\]\nL’equazione precedente ci dice che il modello lineare \\(a + b x_i\\) non è in grado di prevedere completamente i valori \\(y_i\\). Questo, in generale, non è mai possibile (ovvero, è possibile solo in un caso specifico che, nella realtà empirica, non si verifica mai). L’equazione precedente ci dice che possiamo prevedere solo una componente di ciascuna osservazione \\(y_i\\), ovvero quella componente che abbiamo denotato con \\(\\hat{y}_i\\). La componente che non possiamo prevedere con l’equazione \\(a + b x_i\\) viene detta residuo e si denota con \\(e_i\\):\n\\[\ne_i = y_i - \\hat{y}_i = y_i - (a + bx_i).\n\\]\nDal punto di vista geometrico, la componente erratica del modello, \\(e_i\\), corrisponde alla distanza verticale tra ciascun punto del diagramma a dispersione e la retta di regressione \\(a + bx\\). Diciamo che scomponiamo il valore di ciascuna osservazione \\(y_i\\) in due componenti nel senso che\n\\[\ny_i = \\hat{y}_i + e_i = (a + bx_i) + e_i.\n\\]\nIl primo obiettivo del modello di regressione è quello di trovare i coefficienti dell’equazione\n\\[\na + b x_i\n\\]\nche consente di trovare \\(\\hat{y}_i\\) conoscendo \\(x_i\\). Questi due coefficienti sono detti coefficienti di regressione.\nPer trovare i coefficienti di regressione dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo di tali vincoli è stato introdotto in precedenza: vogliamo che la retta \\(\\hat{y}_i = a + b x_i\\) passi per il punto \\((\\bar{x}, \\bar{y})\\). Il punto \\((\\bar{x}, \\bar{y})\\) corrisponde al baricentro del diagramma a dispersione.\nCi sono però infinite rette che passano per i punto \\((\\bar{x}, \\bar{y})\\). Tutte queste rette soddisfano la seguente proprietà:\n\\[\n\\sum_{i=1}^n e_i = 0,\n\\]\novvero, fanno in modo che la somma dei residui (positivi, per i punti che si trovano al di sopra della retta di regressione, negativi, per punti che si trovano al di sotto della retta di regressione) sia uguale a zero.\nQuesto significa che non possiamo selezionare una tra le infinite rette che passano per il punto \\((\\bar{x}, \\bar{y})\\) usando il criterio che ci porta a scegliere la retta che rende la più piccola possibile (ovvero, minimizza) la somma dei residui. Infatti, tutte le rette passanti per il punto \\((\\bar{x}, \\bar{y})\\) soddisfano questo requisito (rendono uguale a zero la somma dei residui). Dunque, dobbiamo trovare qualche altri criterio per scegliere una tra le infinite rette che passano per il punto \\((\\bar{x}, \\bar{y})\\).\nIl criterio che viene normalmente scelto è quello di minimizzare la somma dei quadrati dei residui \\((y_i - \\hat{y}_i)^2\\). In altri termini, vogliamo trovare i coefficienti \\(a\\) e \\(b\\) tali per cui la quantità\n\\[\n\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\n\\]\nassume il suo valore minimo. I coefficienti \\(a\\) e \\(b\\) che soddisfano questa proprietà si chiamano coefficienti dei minimi quadrati.\nQuesto problema ha una soluzione analitica. La soluzione analitica si trova riconoscendo il fatto che l’equazione precedente definisce una superficie e il problema diventa quello di trovare il punto di minimo di questa superficie. Per trovare la soluzione ci si deve rendere conto che il punto cercato è quello per cui il piano tangente alla superficie (nelle due direzioni \\(a\\) e \\(b\\)) è piatto (le tangenti nelle due direzioni sono uguali a zero). Rendere uguale a zero la tangente ad una curva significa porre uguali a zero la derivata della curva. Nel caso presente, abbiamo una superficie, dunque due tangenti ortogonali e quindi abbiamo il problema di rendere uguali a zero le derivate parziali rispetto ad \\(a\\) e \\(b\\). Così facendo si definisce un sistema di equazioni lineari con due incognite, \\(a\\) e \\(b\\). La soluzione di tali equazioni, che si chiamano equazioni normali, è la seguente:\n\\[\na = \\bar{y} - b \\bar{x},\n\\]\n\\[\nb = \\frac{\\mbox{Cov}(x, y)}{\\mbox{Var}(x)}.\n\\]\nLe due precedenti equazioni corrispondono alla stima dei minimi quadrati dei coefficienti di regressione della retta che minimizza la somma dei quadrati dei residui.\nNel caso dell’esempio presente, tali coefficienti sono uguali a:\n\nb <- cov(kidiq$kid_score, kidiq$mom_iq) / var(kidiq$mom_iq)\nb\n#> [1] 0.6099746\n\n\na <- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\na\n#> [1] 25.79978\n\nIn \\(\\mathsf{R}\\) li possiamo facilmente trovare con la seguente funzione:\n\nfm <- lm(kid_score ~ mom_iq, data = kidiq)\ncoef(fm)\n#> (Intercept)      mom_iq \n#>  25.7997778   0.6099746\n\nIn precedenza abbiamo soltanto accennato al problema di come si possono trovano i coefficienti dei minimi quadrati; ritorneremo su questo punto in seguito, con una simulazione. Per ora, chiediamoci cosa significano i due coefficienti che abbiamo appena trovato.\nIl coefficiente \\(a\\) si chiama intercetta. L’intercetta, all’interno del diagramma a dispersione, specifica il punto in cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani.\nNel caso presente questo valore non è di alcun interesse, perché corrisponde al valore della retta di regressione quando \\(x = 0\\), ovvero quando l’intelligenza della madre è uguale a 0. Vedremo in seguito come, trasformando i dati, è possibile assegnare al coefficiente \\(a\\) un’interpretazione più utile. Per ora mi limito a fornire l’interpretazione del coefficiente.\nPassando a \\(b\\), possiamo dire che questo secondo coefficiente va sotto il nome di pendenza della retta di regressione. Ovvero ci dice di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\).\nNel caso presente, il coefficiente \\(b\\) ci dice che, se il QI delle madri aumenta di 1 punto, il QI dei bambini aumenta in media di 0.61 punti.\nÈ importante capire cosa significa che, in base ai risultati della regressione, \\(y\\) aumenta in media di \\(b\\) punti per ciascun aumento unitario di \\(x\\).\nIl modello statistico di regressione ipotizza che, per ciascun valore osservato \\(x\\) (per esempio, il valore del QI della prima madre del campione, ovvero \\(x = 121.11753\\)) ci sia una distribuzione di valori \\(y\\) nella popolazione, di cui solo uno è stato osservato nel campione. Possiamo facilmente capire che, se consideriamo tutte le madri con QI di 121.12, il punteggio del QI dei loro figli non sia costante, ma assuma tanti valori possibili. Questa distribuzione di valori possibili si chiama distribuzione \\(y\\) condizionata a \\(x\\), ovvero \\(p(y \\mid x_i)\\).\nIl modello statistico della regressione lineare non può in alcun modo prevedere il valore assunto da ciascuna delle possibili osservazioni che fanno parte della distribuzione \\(p(y \\mid x_i)\\). Il modello della regressione lineare ha un obiettivo più limitato, ovvero si propone di prevedere le medie delle distribuzioni \\(p(y \\mid x_i)\\) conoscendo i valori \\(x\\).\nDunque, quando il coefficiente \\(b\\) è uguale a 0.61, questo significa che il modello di regressione predice che la medie della distribuzione condizionata \\(p(y \\mid x_i)\\) aumenta di 0.61 punti se la variabile \\(x\\) (QI delle madri) aumenta di un punto. Questo significa che il modello di regressione non fa una predizione sul punteggio di ciascun valore \\(y_i\\) (in funzione di \\(x\\)), ma solo della media delle distribuzioni condizionate \\(p(y \\mid x_i)\\) di cui il valore osservato \\(y_i\\) è una realizzazione casuale.\nPossiamo dire la stessa cosa con parole diverse dicendo che il modello di regressione fa delle predizioni sulla componente deterministica di ciascuna osservazione. È più semplice capire questo aspetto se rappresentiamo in maniera grafica la componente “deterministica” \\(\\hat{y}_i = a + b x_i\\) predetta dal modello di regressione.\n\nkidiq$yhat <- fm$fitted.values\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = yhat)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(\n    aes(x=mean(mom_iq), y=mean(kid_score)), \n    colour=\"red\", size = 4\n  )\n\n\n\n\n\n\n\nIl diagramma precedente presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). Si vede che i valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nNel caso nella prima osservazione, ad esempio abbiamo:\n\\[\ny_1 = (a + b x_1) + e_1\n\\]\nAbbiamo\n\nkidiq$kid_score[1]\n#> [1] 65\n\nDunque\n\\[\ne_1 = (a + b x_1) - y_1\n\\]\n\ne_1 <- kidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\ne_1\n#> [1] -34.67839\n\nCiò significa che il valore osservato \\(y_1 = 65\\) viene scomposto dal modello di regressione in due componenti. La componente deterministica \\(\\hat{y}_1\\), predicibile da \\(x_1\\), è\n\nyhat_1 <- a + b * kidiq$mom_iq[1]\nyhat_1\n#> [1] 99.67839\n\nLa somma della componente deterministica e della componente erratica, ovviamente, riproduce il valore osservato.\n\nyhat_1 + e_1\n#> [1] 65\n\nSe sommiamo tutti i residui calcolati rispetto alla retta di regressione dei minimi quadrati otteniamo zero:\n\nsum(fm$res)\n#> [1] 5.373479e-13\n\n\n27.1.1 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, non è possibile assegnare un’interpretazione utile all’intercetta del modello di regressione lineare. L’intercetta ci dice infatti qual è il valore atteso della \\(y\\) quando \\(x = 0\\). Ma, se la variabile \\(x\\) è misurata su scala ad intervalli, il valore \\(x = 0\\) è arbitrario e non corrisponde “all’assenza di intensità” della variabile \\(x\\). Un valore pari a 0 del QI della madre non vuol dire che l’intelligenza della madre sia nulla (un’affermazione, questa, che è difficile da capire), ma semplicemente che il punteggio del test usato per misurare il QI della madre assume valore 0 (qualcosa che, comunque, in pratica non succederà mai). Quindi è di poco interesse sapere qual è il valore medio del QI del bambino quando test usato per misurare il QI della madre ha valore 0. Per potere fornire all’intercetta del modello di regressione un’interpretazione più utile dobbiamo trasformare le osservazioni \\(x\\).\nEsprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nkidiq$xd <- kidiq$mom_iq - mean(kidiq$mom_iq)\n\nSe ora usiamo le coppie di osservazioni \\(xd_i, y_i\\), il diagramma a dispersione assume la forma seguente.\n\nkidiq %>% \n  ggplot(aes(x = xd, y = kid_score)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(\n    aes(x=mean(xd), y=mean(kid_score)), \n    colour=\"red\", size = 4\n  )\n\n\n\n\n\n\n\nQuello che abbiamo fatto è stato di traslare rigidamente la nube di punti sul piano cartesiano di una quantità pari alla distanza tra \\(\\bar{x}\\) e l’origine. Dunque, le relazioni spaziali tra i punti del diagramma a dispersione restano immutate. Di conseguenza, la pendenza della retta di regressione calcolata sui dati trasformati è uguale a quella che si trova nel caso dei dati non trasformati. Ciò che cambia è il valore dell’intercetta.\n\nfm1 <- lm(kid_score ~ xd, data = kidiq)\ncoef(fm1)\n#> (Intercept)          xd \n#>  86.7972350   0.6099746\n\nL’intercetta corrisponde al punto sull’asse \\(y\\) dove la retta di regressione interseca l’ordinata. Ma, nel caso dei dati trasformati, dato che abbiamo traslato i punti di una quantità pari a \\(x - \\bar{x}\\), il valore \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nel caso dei dati grezzi. Dunque, per i dati trasformati \\(xd_i, y_i\\), l’intercetta corrisponderà al valore atteso della \\(y\\) in corrispondenza del valore medio della variabile \\(x\\) sulla scala dei dati non trasformati (ovvero \\(\\bar{x}\\)). In altre parole, l’intercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al QI medio dei bambini in corrispondenza del QI medio delle madri.\n\n27.1.2 Il metodo dei minimi quadrati\nOra che abbiamo visto come interpretare il coefficienti di regressione, chiediamoci come vengono calcolati. La procedura generale è stata brevemente descritta in precedenza. Vediamo ora come si giunge alla conclusione descritta sopra usando una simulazione.\nIl problema è di trovare i valori \\(a\\) e \\(b\\) tali per cui la quantità \\(\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\\) assume il valore minore possibile. Questo è un problema di minimizzazione rispetto a due parametri. Per dare un’idea di come si fa, semplifichiamo il problema e supponiamo che uno dei due parametri sia noto, ad esempio \\(a\\), così ci resta una sola incognita.\nCredo una griglia di valori b_grid possibili, ad esempio:\n\nnrep <- 1e5\nb_grid <- seq(0, 1, length.out = nrep)\n\nDefinisco una funzione che calcola la quantità \\(\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\\):\n\nsse <- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\nCalcolo la somma degli errori quadratici per ciascun possibile valore b_grid, fissando \\(a = 25.79978\\).\n\nsse_res <- rep(NA, nrep)\nfor (i in 1:nrep) {\n  sse_res[i] <- sse(a = 25.79978, b = b_grid[i], x = kidiq$mom_iq, y = kidiq$kid_score)\n}\n\nEsaminiamo il risultato ottenuto.\n\nplot(\n  b_grid, sse_res, type = 'l'\n)\n\n\n\n\n\n\n\nIl risultato ottenuto con la simulazione\n\nb_grid[which.min(sse_res)]\n#> [1] 0.6099761\n\nriproduce quello ottenuto per via analitica:\n\nb\n#> [1] 0.6099746\n\nUna simulazione simile, ma computazionalmente più complessa, può essere usata per stimare simultaneamente entrambi i parametri. Ci siamo limitati qui ad una proof of concept del caso più semplice.\n\n27.1.3 L’errore standard della regressione\nIl secondo obiettivo del modello statistico di regressione lineare è quello di stabilire quanto sia grande la componente \\(y\\) predicibile da \\(x\\), per ciascuna osservazione.\nUn indice assoluto della bontà di adattamento è fornito dalla deviazione standard dei residui, \\(s_e\\), chiamata anche errore standard della stima. Uno stimatore non distorto della varianza dei residui nella popolazione è dato da\n\\[\ns^2_e = \\frac{1}{n-2}\\sum e_i^2\n\\]\ne quindi l’errore standard della stima sarà\n\\[\\begin{equation}\ns_e = \\sqrt{\\frac{1}{n-2}\\sum e_i^2}.\n\\end{equation}\\]\nSi noti che questa è la stessa formula della varianza (dato che la media dei residui è zero), tranne per il fatto che al denominatore abbiamo \\(n-2\\). Dato che, per calcolare \\(\\hat{y}\\) abbiamo usato due coefficienti (\\(a\\) e \\(b\\)), si dice che “abbiamo perso due gradi di libertà”.\nDato che \\(s_e\\) possiede la stessa unità di misura della variabile \\(y\\), l’errore standard della stima può essere considerato come una sorta di “residuo medio.” – usando la stessa interpretazione che diamo alla deviazione standard in generale.\nSi noti che la formula precedente non fornisce la “deviazione standard dei residui nel campione” (quella formula avrebbe \\(n\\) al denominatore). Invece, fornisce una stima della deviazione standard dei residui nella popolazione da cui il campione è stato estratto.\nVerifichiamo quanto detto con i dati a disposizione.\nI residui possono essere trovati nel modo seguente.\n\ne <- kidiq$kid_score - (a + b * kidiq$mom_iq)\ne[1:10]\n#>  [1] -34.678390  17.691747 -11.217173  -3.461529  32.627697   6.382845\n#>  [7] -41.521041   3.864881  26.414387  11.208068\n\nOppure nel modo seguente.\n\nfm$residuals[1:10]\n#>          1          2          3          4          5          6          7 \n#> -34.678390  17.691747 -11.217173  -3.461529  32.627697   6.382845 -41.521041 \n#>          8          9         10 \n#>   3.864881  26.414387  11.208068\n\nCalcolo il residuo medio, prendendo il valore assoluto.\n\nmean(abs(e))\n#> [1] 14.4686\n\nL’errore standard della regressione è\n\nsqrt(sum(e^2) / (length(e) - 2))\n#> [1] 18.26612\n\nI due numeri non sono uguali, ma possiamo dire che hanno lo stesso ordine di grandezza.\nSe usiamo la funzione lm() otteniamo lo stesso valore, chiamato Residual standard error.\n\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_iq, data = kidiq)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -56.753 -12.074   2.217  11.710  47.691 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***\n#> mom_iq       0.60997    0.05852   10.42  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 18.27 on 432 degrees of freedom\n#> Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 \n#> F-statistic: 108.6 on 1 and 432 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "052_reglin2.html#indice-di-determinazione",
    "href": "052_reglin2.html#indice-di-determinazione",
    "title": "27  Regressione lineare bivariata",
    "section": "\n27.2 Indice di determinazione",
    "text": "27.2 Indice di determinazione\nUn importante risultato dei minimi quadrati riguarda la cosiddetta scomposizione della devianza mediante la quale si definisce l’indice di determinazione, il quale fornisce una misura relativa della bontà di adattamento del modello di regressione ai dati del campione. Per una generica osservazione \\(x_i, y_i\\), la variazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere descritta come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nSe consideriamo tutte le osservazioni, la devianza delle \\(y\\) può essere scomposta nel seguente modo:\n\\[\\begin{align}\n\\sum (y_i - \\bar{y})^2 &= \\sum \\left[ e_i + (\\hat{y}_i - \\bar{y})\n\\right]^2\n= \\sum e_i^2 + \\sum (\\hat{y}_i - \\bar{y})^2 + 2 \\sum e_i (\\hat{y}_i -\n\\bar{y}) \\notag\n\\end{align}\\]\nPer i vincoli imposti sul modello statistico di regressione, il doppio prodotto si annulla, infatti\n\\[\\begin{align}\n\\sum e_i (\\hat{y}_i - \\bar{y}) &= \\sum e_i \\hat{y}_i - \\bar{y}\\sum e_i = \\sum e_i (a + b x_i) \\notag \\\\\n&= a \\sum e_i + b \\sum e_i x_i = 0 \\notag\n\\end{align}\\]\nIl termine \\(b \\sum e_i x_i\\) è uguale a zero perché, come vedremo in seguito, i coefficienti di regressione vengono calcolati in modo tale da rendere nulla \\(\\mbox{Cov}(e, x)\\). Di conseguenza, il termine precedente deve essere nullo.\nPossiamo dunque concludere che la devianza totale (\\(\\mbox{dev}_T\\)) si scompone nella somma di devianza d’errore (o devianza non spiegata) (\\(\\mbox{dev}_E\\)) e devianza di regressione (o devianza spiegata) (\\(\\mbox{dev}_T\\)):\n\\[\\begin{align}\n\\underbrace{\\sum_{i=1}^n (y_i - \\bar{y})^2}_{\\tiny{\\text{Devianza\ntotale}}} &= \\underbrace{\\sum_{i=1}^n e_i^2}_{\\tiny{\\text{Devianza\ndi dispersione}}} + \\underbrace{\\sum_{i=1}^n  (\\hat{y}_i -\n\\bar{y})^2}_{\\tiny{\\text{Devianza di regressione}}} \\notag\n\\end{align}\\]\nLa devianza di regressione, \\(\\mbox{dev_R} \\triangleq \\mbox{dev_T} - \\mbox{dev_E}\\), indica dunque la riduzione degli errori al quadrato che è imputabile alla regressione lineare. Il rapporto \\(\\mbox{dev_R}/\\mbox{dev_T}\\), detto indice di determinazione, esprime tale riduzione degli errori in termini proporzionali e definisce il coefficiente di correlazione al quadrato:\n\\[\\begin{equation}\nR^2 \\triangleq \\frac{\\mbox{dev_R}}{\\mbox{dev_T}} = 1 - \\frac{\\mbox{dev_E}}{\\mbox{dev_T}}.\n\\end{equation}\\]\nQuando l’insieme di tutte le deviazioni della \\(y\\) dalla media è spiegato dall’insieme di tutte le deviazioni della variabile teorica \\(\\hat{y}\\) dalla media, si ha che l’adattamento (o accostamento) del modello al campione di dati è perfetto, la devianza residua è nulla ed \\(r^2 = 1\\); nel caso opposto, la variabilità totale coincide con quella residua, per cui \\(r^2 = 0\\). Tra questi due estremi, \\(r\\) indica l’intensità della relazione lineare tra le due variabili e \\(r^2\\), con \\(0 \\leq r^2 \\leq 1\\), esprime la porzione della devianza totale della \\(y\\) che è spiegata dalla regressione lineare sulla \\(x\\).\nPer l’esempio in discussione abbiamo quanto segue. La devianza totale è\n\ndev_t <- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#> [1] 180386.2\n\nLa devianza spiegata è\n\ndev_r <- sum((fm$fitted.values - mean(kidiq$kid_score))^2)\ndev_r\n#> [1] 36248.82\n\nL’indice di determinazione è\n\nR2 <- dev_r / dev_t\nR2\n#> [1] 0.2009512\n\nNell’output di lm() un tale valore è chiamato Multiple R-squared.\n\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_iq, data = kidiq)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -56.753 -12.074   2.217  11.710  47.691 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***\n#> mom_iq       0.60997    0.05852   10.42  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 18.27 on 432 degrees of freedom\n#> Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 \n#> F-statistic: 108.6 on 1 and 432 DF,  p-value: < 2.2e-16\n\nIl risultato ottenuto si può interpretare dicendo che circa il 20% della variabilità dei punteggi del QI dei bambini può essere predetto conoscendo il QI delle madri.\n\n27.2.1 Inferenza sul modello di regressione\nLa discussione precedente era tutta basata sulla trattazione “classica” del modello lineare, ovvero una trattazione basata sulle stime di massima verosimiglianza (se \\(y \\sim \\mathcal{N}(\\alpha + \\beta x, \\sigma)\\), allora le stime dei minimi quadrati coincidono con le stime di massima verosimiglianza). In altre parole, nella discussione precedente non abbiamo considerato in alcun modo le distribuzioni a priori dei parametri \\(\\alpha\\) e \\(\\beta\\). I risultati precedenti si confermano, in un contesto bayesiano, se e solo se imponiamo sui parametri delle distribuzioni a priori non informative (cioè, uniformi). In tali circostanze, le stime di massima verosimiglianza risultano identiche al massimo a posteriori bayesiano.\nDetto questo, il tema dell’inferenza viene trattato dall’approccio frequentista costruendo la “distribuzione campionaria” dei parametri (ovvero la distribuzione dei valori che i parametri otterrebbero in infiniti campioni casuali (\\(x, y\\)) di ampiezza \\(n\\) estratti dalla medesima popolazione) e poi calcolando gli errori standard dei parametri e gli intervalli di fiducia dei parametri. Una domanda frequente è, per esempio, se la pendenza della retta di regressione sia maggiore di zero. Per rispondere a tale domanda l’approccio frequentista calcola l’intervallo di fiducia al 95% per il parametro \\(\\beta\\). Se tale intervallo non include lo zero, e se il limite inferiore di tale intervallo è maggiore di zero, allora si conclude, con un grado di confidenza del 95%, che il vero parametro \\(\\beta\\) nella popolazione è maggiore di zero. Ovvero, si conclude che vi sono evidenze di un’associazione lineare positiva tra \\(x\\) e \\(y\\).\nAlla stessa conclusione si può arrivare calcolando, in un ottica bayesiana, l’intervallo di credibilità al 95% per il parametro \\(\\beta\\). I due intervalli sono identici se usiamo una distribuzione a priori piatta. Sono invece diversi se usiamo una distribuzione a priori debolmente informativa, oppure informativa.\nSolitamente si usa una distribuzione a priori debolmente informativa centrata sullo zero. In tali circostanze, l’uso della distribuzione a priori ha solo un effetto di regolarizzazione, ovvero di riduzione del peso delle osservazioni estreme – un tale risultato statistico è molto desiderabile, ma è difficile da ottenere in un contesto frequentista. Vedremo nel prossimo capitolo come può essere svolta l’inferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano."
  },
  {
    "objectID": "052_reglin2.html#commenti-e-considerazioni-finali",
    "href": "052_reglin2.html#commenti-e-considerazioni-finali",
    "title": "27  Regressione lineare bivariata",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIl modello lineare bivariato viene usato per descrivere la relazione tra due variabili e per determinare il segno e l’intensità di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base al valore assunto dalla variabile indipendente."
  },
  {
    "objectID": "053_reglin3.html#specificazione-del-modello",
    "href": "053_reglin3.html#specificazione-del-modello",
    "title": "28  Modello di regressione in linguaggio Stan",
    "section": "\n28.1 Specificazione del modello",
    "text": "28.1 Specificazione del modello\nLa specificazione del modello lineare bayesiano inizia nello stesso modo dell’approccio frequentista, ovvero con la specificazione della seguente equazione:\n\\[\ny_i = \\alpha + \\beta x_i + \\varepsilon_i, \\quad i = 1, \\dots, n.\n\\]\nSi assume che gli errori, \\(\\varepsilon_i\\), siano indipendenti e identicamente distribuiti come variabili casuali Normali con media zero e varianza costante \\(\\sigma^2\\). Queste ipotesi sono esattamente uguali a quelle che vengono usato nell’inferenza frequentista. Il nostro obiettivo è aggiornare le distribuzioni a priori dei parametri sconosciuti \\(\\alpha\\) e \\(\\beta\\) alla luce dei dati \\(x_1, y_1, \\dots, x_n, y_n\\). Solitamente, è desiderabile scegliere distribuzioni a priori che hanno uno scarso impatto sulla distribuzione a posteriori.\nSupponiamo che le nostre credenza a priori sui parametri del modello, \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) siano tra loro indipendenti. Allora possiamo scrivere la distribuzione congiunta dei parametri nel modo seguente:\n\\[\np(\\alpha, \\beta, \\sigma) = p(\\alpha)p(\\beta)p(\\sigma).\n\\]\nPossiamo assumere \\(\\alpha \\sim \\mathcal{N}(\\mu_{\\alpha}, \\sigma_{\\alpha})\\) e \\(\\beta \\sim \\mathcal{N}(\\mu_{\\beta}, \\sigma_{\\beta})\\). Per \\(\\sigma\\) possiamo assumere, ad esempio, \\(\\sigma \\sim \\mbox{Cauchy}(a, b)\\).\nMoltiplicando la verosimiglianza\n\\[\n\\prod_{i=1}^n p(y_i \\mid x_i; \\alpha, \\beta, \\sigma^2) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{-\\frac{(y_i-(\\alpha + \\beta x_i))^2}{2\\sigma^2}}\n\\]\nper le distribuzioni a priori dei parametri, si ottiene la distribuzione a posteriori. Tuttavia, tale distribuzione non è risolvibile per via analitica. Come in precedenza, usiamo invece un algoritmo MCMC per ottenere una sequenza di campioni casuali dalla distribuzione a posteriori."
  },
  {
    "objectID": "053_reglin3.html#stima-bayesiana-in-linguaggio-stan",
    "href": "053_reglin3.html#stima-bayesiana-in-linguaggio-stan",
    "title": "28  Modello di regressione in linguaggio Stan",
    "section": "\n28.2 Stima bayesiana in linguaggio Stan",
    "text": "28.2 Stima bayesiana in linguaggio Stan\nÈ conveniente usare il linguaggio Stan per ottenere una sequenza MCMC dalla distribuzione a posteriori dei parametri di un modello di regressione. Continuiamo qui l’esempio precedente in cui ci si poneva il problema di descrivere mediante un modello lineare l’associazione tra il QI dei figli e il QI delle madri. Leggiamo i dati kidiq in \\(\\mathsf{R}\\):\n\nlibrary(\"rio\")\ndf <- rio::import(here::here(\"data\", \"kidiq.dta\"))\nhead(df)\n#>   kid_score mom_hs    mom_iq mom_work mom_age\n#> 1        65      1 121.11753        4      27\n#> 2        98      1  89.36188        4      25\n#> 3        85      1 115.44316        4      27\n#> 4        83      1  99.44964        3      25\n#> 5       115      1  92.74571        4      27\n#> 6        98      0 107.90184        1      18\n\nPer farci un’idea del valore dei parametri, adattiamo il modello lineare ai dati mediante la procedura di massima verosimiglianza (come abbiamo fatto nel capitolo precedente):\n\nfm <- lm(kid_score ~ mom_iq, data = df)\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_iq, data = df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -56.753 -12.074   2.217  11.710  47.691 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***\n#> mom_iq       0.60997    0.05852   10.42  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 18.27 on 432 degrees of freedom\n#> Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 \n#> F-statistic: 108.6 on 1 and 432 DF,  p-value: < 2.2e-16\n\nSulla base delle informazioni precedenti, giungiamo alla seguente formulazione bayesiana del modello di regressione lineare:\n\\[\n\\begin{aligned}\ny_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta x_i \\\\\n\\alpha &\\sim \\mathcal{N}(25, 10) \\\\\n\\beta &\\sim \\mathcal{N}(0, 1) \\\\\n\\sigma &\\sim \\text{Cauchy}(18, 5)\n\\end{aligned}\n\\]\nIl segno \\(\\sim\\) (tilde) si può leggere “si distribuisce come”. La prima riga definisce la funzione di verosimiglianza e ci dice che ciascuna osservazione \\(y_i\\) è una variabile casuale che segue la distribuzione gaussiana di parametri \\(\\mu_i\\) e \\(\\sigma\\). Le righe successive definiscono le distribuzioni a priori dei parametri. La seconda riga specifica, in maniera deterministica, ciascun \\(\\mu_i\\) come funzione lineare di \\(x_i\\), con parametri \\(\\alpha\\) e \\(\\beta\\). Le due righe successive specificano le distribuzioni a priori per \\(\\alpha\\) e \\(\\beta\\). La distribuzione a priori di \\(\\alpha\\) è una distribuzione gaussiana di parametri \\(\\mu_{\\alpha} = 25\\) e deviazione standard \\(\\sigma_{\\alpha} = 10\\); la distribuzione a priori di \\(\\beta\\) è una distribuzione gaussiana standardizzata. L’ultima riga definisce la distribuzione a priori di \\(\\sigma\\), ovvero una Cauchy di parametri 18 e 5.\nAvendo descritto in termini astratti le caratteristiche del modello, passiamo ora alla specificazione in linguaggio Stan.\n\nmodel_string_1 = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n}\nmodel {\n  // priors\n  alpha ~ normal(25, 10);\n  beta ~ normal(0, 1);\n  sigma ~ cauchy(18, 5);\n  // likelihood\n  y ~ normal(alpha + beta * x, sigma);\n}\n\"\nwriteLines(model_string_1, con = \"code/simpleregkidiq.stan\")\n\nLa funzione modelString() registra una stringa di testo mentre writeLines() crea un file nell’indirizzo specificato. Tale file deve avere l’estensione .stan.\nSistemiamo i dati nel formato appropriato per Stan.\n\ndata_list <- list(\n  N = length(df$kid_score),\n  y = df$kid_score,\n  x = df$mom_iq\n)\n\nLa funzione file.path() ritorna l’indirizzo del file con il codice Stan.\n\nfile_simple_reg <- file.path(\"code\", \"simpleregkidiq.stan\")\n\nLa funzione cmdstan_model() traduce il programma Stan in C++ e crea un eseguibile compilato.\n\nmod1 <- cmdstan_model(file_simple_reg)\n\nIl codice Stan può essere stampato usando il metodo $print():\n\nmod1$print()\n\nL’indirizzo dell’eseguibile compilato viene ritornato da $exe_file():\n\nmod1$exe_file()\n\nApplicando il metodo $sample() ad un oggetto CmdStanModel eseguiamo il campionamento MCMC:\n\nfit_1 <- mod1$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0\n)\n\nUn sommario della distribuzione a posteriori per i parametri stimati si ottiene con il metodo $summary(), il quale chiama la funzione summarise_draws() del pacchetto posterior:\n\nfit_1$summary(c(\"alpha\", \"beta\", \"sigma\"))\n#> # A tibble: 3 × 10\n#>   variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    25.8   25.8   5.05   5.04   17.5   34.0    1.00    5543.    5781.\n#> 2 beta      0.610  0.610 0.0501 0.0499  0.528  0.693  1.00    5581.    5684.\n#> 3 sigma    18.3   18.3   0.605  0.603  17.3   19.3    1.00    6957.    6378.\n\nSi noti come la soluzione ottenuta sia molto simile (dal punto di vista pratico, equivalente) a quella ottenuta con il metodo dei minimi quadrati.\nDall’output possiamo anche valutare la convergenza del modello osservando i valori di Rhat per ciascun parametro. Quando questi sono pari o vicini a 1, le catene hanno realizzato la convergenza. Ci sono molti altri test diagnostici, ma questo test è il più importante per Stan.\nOppure possiamo visualizzare i risultati come indicato di seguito.\n\nfit_1$cmdstan_summary()\n\nLe statistiche diagnostiche sono fornite dal metodo $cmdstan_diagnose():\n\nfit_1$cmdstan_diagnose()\n\nÈ conveniente creare un oggetto di classe stanfit\n\nstanfit_1 <- rstan::read_stan_csv(fit_1$output_files())\n\nper poi potere utilizzare le funzioni del pacchetto bayesplot. Ad esempio:\n\nstanfit_1 %>% \n  mcmc_trace(pars = c(\"alpha\", \"beta\", \"sigma\"))\n\n\n\n\n\n\n\nInfine, eseguendo la funzione launch_shinystan(fit), è possibile analizzare oggetti di classe stanfit mediante le funzionalità del pacchetto ShinyStan.\n\n28.2.1 Standardizzare i dati\nIl codice Stan viene eseguito più velocemente se l’input è standardizzato così da avere una media pari a zero e una varianza unitaria. Inoltre, si noti un punto importante. Il fatto di standardizzare i dati fa in modo che le distribuzioni a priori sui parametri vengano espresse sulla scala di una v.c. normale standardizzata. Se centriamo sullo 0 le distribuzioni a priori, con una deviazione standard dell’ordine di grandezza dell’unità, perdono di significato i discorsi sull’arbitrarietà delle distribuzioni a priori: nel caso di dati standardizzati le distribuzioni a priori formulate come indicato sopra sono distribuzioni debolmente informative il cui unico scopo è la regolarizzazione dei dati, ovvero di mantenere le inferenze in una gamma ragionevole di valori. Inoltre, l’uso di distribuzioni a priori debolmente informative ha l’effetto desiderabile di limitare l’influenza eccessiva delle osservazioni estreme (valori anomali). Il punto importante è che una tale scelta delle distribuzioni a priori non introduce alcuna distorsione sistematica nella stima a posteriori.\nSono possibili due strade per la standardizzazione dei dati. Se non ci sono ragioni particolari per mantenere l’unità di misura dei dati grezzi (ad esempio, se è sufficiente valutare l’intervallo di credibilità per \\(\\beta\\) per determinare se include o meno lo 0), allora possiamo standardizzare i dati prima di passarli a Stan (questa è la procedura usuale).\nIn alternativa, se vogliamo mantenere la soluzione sulla scala delle variabili originarie, è possibile seguire la procedura indicata di seguito. Si passano a Stan i dati grezzi; i dati vengono standardizzati con una trasformazione di variabili all’interno del codice Stan. Viene poi eseguito il campionamento sui dati standardizzati; infine, le stime dei parametri vengono nuovamente trasformate sulla scala delle variabili originarie1.\nPer ottenere il risultato descritto sopra, si procede come segue. Ponendo \\(y = (y_1, \\dots, y_n)\\) e \\(x = (x_1, \\dots, x_n)\\), il modello lineare può essere scritto come\n\\[\ny_i = \\alpha + \\beta x_i + \\varepsilon_i,\n\\]\ndove\n\\[\n\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma).\n\\]\nSeguendo la notazione del manuale Stan, i parametri del modello lineare sono denotati da \\(\\alpha\\) e \\(\\beta\\). Per eseguire la standardizzazione dei dati, è necessario centrare i dati, sottraendo da essi la media campionaria, per poi scalarli dividendo per la deviazione standard campionaria. Una singola osservazione \\(u\\) viene standardizzata dalla funzione \\(z\\) definita da\n\\[\nz_y(u) = \\frac{u - \\bar{y}}{\\texttt{sd}(y)}\n\\]\ndove la media \\(\\bar{y}\\) è\n\\[\n\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i,\n\\] e la deviazione standard è\n\\[\n\\texttt{sd} = \\left(\\frac{1}{n}\\sum_{i=1}^n(y_i - \\bar{y})^2\\right)^{-\\frac{1}{2}}.\n\\]\nLa trasformata inversa è definita invertendo i due passaggi precedenti: la deviazione standard è usata per scalare i valori \\(u\\) e la media campionaria è usata per traslare la distribuzione dei valori \\(u\\) scalati:\n\\[\nz_y^{-1}(u) = \\texttt{sd}(y)u + \\bar{y}.\n\\]\nI risultati riportati sopra consentono di modificare il modello Stan che abbiamo descritto all’inizio del Capitolo al fine di creare un nuovo modello che realizza un campionamento sulla base dei dati standardizzati.\nIl blocco data è identico al caso precedente. I predittori e la risposta standardizzati sono definiti nel blocco transformed data. Vengono definte due nuove variabili, x_std e y_std, che corrispondono, appunto, ai valori standardizzati \\(x\\) e \\(y\\). I parametri sono chiamati alpha_std e alpha_std in quanto verranno campionati utilizzando la verosimiglianza che deriva dai dati standardizzati: y_std ~ normal(mu_std, sigma_std);. La media delle distribuzioni condizionate \\(y \\mid x_i\\), ovvero \\(\\hat{y}\\), è calcolata come vector[N] mu_std = alpha_std + beta_std * x_std;, ovvero usando i valori \\(x\\) standardizzati, x_std, e i parametri alpha_std e beta_std. Una tale specificazione è contenuta nel blocco transformed parameters. Nel blocco model sono presenti le distribuzioni a priori dei parametri alpha_std e beta_std. In questo esempio, per entrambi i parametri è stata usata una distribuzione a priori \\(\\mathcal{N}(0, 1)\\). Per semplificare la notazione, nel blocco model l’istruzione di campionamento è espressa in forma vettorializzata: y_std ~ normal(alpha_std + beta_std * x_std, sigma_std);.\nSi pone ancora il problema di trasformare i parametri dalla scala delle variabili standardizzate alla scala delle variabili originarie. I valori dei parametri sulla scala delle variabili originarie calcolati nel blocco generated quantities. I parametri “naturali” così trasformati vengono chiamati alpha, beta e sigma. Le formule necessarie per questa trasformazione possono essere recuperati con un po’ di algebra.\n\\[\\begin{align}\ny_n &= \\textrm{z}_y^{-1}(\\textrm{z}_y(y_n)) \\notag\\\\\n    &= \\textrm{z}_y^{-1}\n\\left( \\alpha' + \\beta' \\textrm{z}_x(x_n) + \\epsilon_n' \\right) \\notag\\\\\n    &= \\textrm{z}_y^{-1}\n\\left( \\alpha' + \\beta' \\left( \\frac{x_n - \\bar{x}}{\\texttt{sd}(x)} \\right) + \\epsilon_n' \\right) \\notag\\\\\n    &= \\texttt{sd}(y)\n\\left( \\alpha' + \\beta' \\left( \\frac{x_n - \\bar{x}}{\\texttt{sd}(x)} \\right) + \\epsilon_n' \\right) + \\bar{y} \\notag\\\\\n    &=\n\\left( \\texttt{sd}(y) \\left( \\alpha' - \\beta' \\frac{\\bar{x}}{\\texttt{sd}(x)} \\right) + \\bar{y} \\right)\n+ \\left( \\beta' \\frac{\\texttt{sd}(y)}{\\texttt{sd}(x)} \\right) x_n\n+ \\texttt{sd}(y) \\epsilon'_n,\n\\end{align}\\]\nda cui\n\\[\n\\alpha\n=\n\\texttt{sd}(y)\n      \\left(\n          \\alpha'\n          - \\beta' \\frac{\\bar{x}}{\\texttt{sd}(x)}\n      \\right)\n  + \\bar{y};\n\\qquad\n\\beta = \\beta' \\frac{\\texttt{sd}(y)}{\\texttt{sd}(x)};\n\\qquad\n\\sigma = \\texttt{sd}(y) \\sigma'.\n\\]\nPossiamo dunque scrivere il modello in linguaggio Stan nel modo seguente.\n\nmodel_string_2 = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\ntransformed data {\n  vector[N] x_std;\n  vector[N] y_std;\n  x_std = (x - mean(x)) / sd(x);\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  real alpha_std;\n  real beta_std;\n  real<lower=0> sigma_std;\n}\ntransformed parameters {\n  vector[N] mu_std = alpha_std + beta_std * x_std;\n}\nmodel {\n  alpha_std ~ normal(0, 1);\n  beta_std ~ normal(0, 1);\n  sigma_std ~ normal(0, 1);\n  y_std ~ normal(mu_std, sigma_std);\n}\ngenerated quantities {\n  // transform to the original data scale\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y);\n  beta = beta_std * sd(y) / sd(x);\n  sigma = sd(y) * sigma_std;\n}\n\"\nwriteLines(model_string_2, con = \"code/simpleregstd.stan\")\n\nUsiamo la funzione file.path() per ottenere l’indirizzo del file con il codice Stan.\n\nfile_simple_reg_std <- file.path(\"code\", \"simpleregstd.stan\")\n\nCompiliamo in C++.\n\nmod2 <- cmdstan_model(file_simple_reg_std)\n\nEseguiamo il campionamento MCMC.\n\nfit_2 <- mod2$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nUsiamo il metodo $summary() per esaminare i risultati.\n\nfit_2$summary(c(\"alpha_std\", \"beta_std\", \"sigma_std\", \"alpha\", \"beta\", \"sigma\"))\n#> # A tibble: 6 × 10\n#>   variable     mean   median     sd    mad      q5     q95  rhat ess_b…¹ ess_t…²\n#>   <chr>       <dbl>    <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>\n#> 1 alpha_std 1.07e-4 -1.49e-4 0.0432 0.0423 -0.0703  0.0715  1.00  18705.  11652.\n#> 2 beta_std  4.48e-1  4.48e-1 0.0438 0.0443  0.375   0.520   1.00  20084.  10981.\n#> 3 sigma_std 8.97e-1  8.96e-1 0.0311 0.0316  0.848   0.950   1.00  18813.  12511.\n#> 4 alpha     2.59e+1  2.58e+1 6.02   6.02   16.0    35.8     1.00  20176.  10983.\n#> 5 beta      6.09e-1  6.09e-1 0.0596 0.0603  0.511   0.707   1.00  20084.  10981.\n#> 6 sigma     1.83e+1  1.83e+1 0.634  0.644  17.3    19.4     1.00  18813.  12511.\n#> # … with abbreviated variable names ¹​ess_bulk, ²​ess_tail\n\nSi noti anche in questo caso che, avendo usato delle distribuzioni a priori debolmente informative, le stime dei parametri sono molto simili a quelle ottenute mediante la procedura di massima verosimiglianza.\n\ncoef(fm)\n#> (Intercept)      mom_iq \n#>  25.7997778   0.6099746\n\n\n28.2.2 Interpretazione dei parametri\nRipeto qui la discussione del capitolo precedente. Assegniamo ai parametri la seguente interpretazione.\n\nL’intercetta pari a 25.9 indica il QI medio dei bambini la cui madre ha un QI = 0. Ovviamente questo non ha alcun significato. Vedremo nel modello successivo come trasformare il modello in modo da potere assegnare all’intercetta un’interpretazione sensata.\nLa pendenza di 0.61 indica che, all’aumentare di un punto del QI delle madri, il QI medio dei loro bambini aumenta di 0.61 unità. Se consideriamo la gamma di variazione del QI delle madri nel campione, il QI medio dei bambini cambia di 41 punti. Questo indica un sostanziale effetto del QI delle madri sul QI dei loro bambini: \\((138.89 - 71.04) * 0.61 = 41.39\\).\nIl parametro \\(\\sigma\\) = 18.3 fornisce una stima della dispersione delle osservazioni attorno al valore predetto dal modello lineare, ovvero fornisce una stima della deviazione standard dei residui attorno al valore atteso del modello lineare.\n\n28.2.3 Centrare i predittori\nCome abbiamo detto in precedenza, per migliorare l’interpretazione dell’intercetta possiamo “centrare” la \\(x\\), ovvero esprimere la \\(x\\) in termini di scarti dalla media: \\(x - \\bar{x}\\). In tali circostanze, la pendenza della retta specificata dal modello lineare resta immutata, ma l’intercetta corrisponde a \\(\\mathbb{E}(y \\mid x = \\bar{x})\\). Per ottenere questo risultato, è sufficiente modificare i dati passati a Stan.\n\ndata2_list <- list(\n  N = length(df$kid_score),\n  y = df$kid_score,\n  x = df$mom_iq - mean(df$mom_iq)\n)\n\nAdattiamo il modello con il nuovo input.\n\nfit_3 <- mod2$sample(\n  data = data2_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nTrasformiamo l’oggetto fit in un oggetto di classe stanfit:\n\nstanfit_3 <- rstan::read_stan_csv(fit_3$output_files())\n\nEsaminiamo le stime a posteriori dei parametri.\n\nfit_3$summary(c(\"alpha\", \"beta\", \"sigma\"))\n#> # A tibble: 3 × 10\n#>   variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    86.8   86.8   0.876  0.871  85.4   88.2    1.00   16318.   11494.\n#> 2 beta      0.609  0.609 0.0591 0.0589  0.513  0.707  1.00   16206.   11236.\n#> 3 sigma    18.3   18.3   0.630  0.624  17.3   19.4    1.00   15617.   11986.\n\nSi noti la nuova intercetta, ovvero 86.8. Questo valore indica il QI medio dei bambini le cui madri hanno un QI pari alla media del campione. Centrare i dati consente dunque di assegnare all’intercetta un’interpretazione utile. Dall’output ottenuto possiamo ricavare, ad esempio, l’intervallo di credibilità al 90%. Ovvero, con un grado di certezza soggettiva del 90%, possiamo concludere che, se consideriamo solo le madri con un QI pari alla media del presente campione, possiamo prevedere che il QI medio dei loro figli sarà compreso nell’intervallo [85.4, 88.2]."
  },
  {
    "objectID": "053_reglin3.html#commenti-e-considerazioni-finali",
    "href": "053_reglin3.html#commenti-e-considerazioni-finali",
    "title": "28  Modello di regressione in linguaggio Stan",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa presente discussione suggerisce che è conveniente standardizzare i dati prima di procedere con l’analisi di regressione lineare. Ciò può essere fatto all’interno del codice Stan, oppure prima di passare i dati a Stan. Se i dati vengono standardizzati è facile specificare delle distribuzioni a priori debolmente informative per i parametri centrate sullo zero. Tali distribuzioni a priori hanno, come unico scopo, quello di regolarizzare i dati e di facilitare la stima dei parametri mediante la procedura MCMC, e non introducono alcuna distorsione “arbitraria” nella soluzione."
  },
  {
    "objectID": "054_reglin4.html#rappresentazione-grafica-dellincertezza-della-stima",
    "href": "054_reglin4.html#rappresentazione-grafica-dellincertezza-della-stima",
    "title": "29  Inferenza sul modello lineare",
    "section": "\n29.1 Rappresentazione grafica dell’incertezza della stima",
    "text": "29.1 Rappresentazione grafica dell’incertezza della stima\nSupponiamo (come indicato nel Capitolo precedente) di avere eseguito il campionamento MCMC mediante la seguente istruzione.\n\nfit2 <- mod$sample(\n  data = data2_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nPer creare una rappresentazione grafica della retta di regressione stimata dal modello bayesiano, insieme all’incertezza della stima, è necessario manipolare i dati contenuti nell’oggetto creato da mod$sample() che contiene i campioni a posteriori dei parametri del modello di regressione lineare, ovvero fit2.\nUsando la funzione rstan::read_stan_csv() trasformo fit2 in un oggetto di formato stanfit.\n\n\n\n\noutput_stanfit <- rstan::read_stan_csv(fit2$output_files())\n\nDall’oggetto output_stanfit estraggo i campioni a posteriori dei parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) con la funzione extract().\n\npost <- rstan::extract(output_stanfit)\n\nL’oggetto post così creato è una lista.\n\nclass(post)\n#> [1] \"list\"\n\nEsaminiamo il contenuto di post.\n\nglimpse(post)\n#> List of 7\n#>  $ alpha_std: num [1:16000(1d)] 0.0582 0.0407 -0.0828 0.0997 0.0886 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ beta_std : num [1:16000(1d)] 0.421 0.494 0.457 0.496 0.491 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ sigma_std: num [1:16000(1d)] 0.907 0.899 0.878 0.932 0.972 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ alpha    : num [1:16000(1d)] 88 87.6 85.1 88.8 88.6 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ beta     : num [1:16000(1d)] 0.573 0.672 0.622 0.675 0.668 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ sigma    : num [1:16000(1d)] 18.5 18.3 17.9 19 19.8 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ lp__     : num [1:16000(1d)] -170 -169 -171 -172 -174 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n\nL’output di glimpse() ci dice che alpha è un vettore di 16,000 elementi. Ciascuno di questi elementi è un valore estratto a caso dalla distribuzione a posteriori del parametro \\(\\alpha\\). È dunque possibile calcolare una stima puntuale della distribuzione a posteriori del parametro \\(\\alpha\\) semplicemente trovando la media di tali valori.\n\nmean(post$alpha)\n#> [1] 86.7936\n\nLo stesso si può dire di beta.\n\nmean(post$beta)\n#> [1] 0.6082648\n\nPer creare un diagramma a dispersione dei dati con sovrapposto il valore atteso della \\(y\\) (ovvero, la retta di regressione) usiamo la sintassi seguente.\n\ntibble(\n  kid_score = df$kid_score,\n  mom_iq = df$mom_iq - mean(df$mom_iq)\n) %>%\n  ggplot(aes(mom_iq, kid_score)) +\n  geom_point() +\n  geom_abline(\n    intercept = mean(post$alpha),\n    slope = mean(post$beta)\n  )\n\n\n\n\n\n\n\nSi noti l’uso della funzione geom_abline() che prende come argomenti l’intercetta e la pendenza di una retta. Nel caso presente, tali argomenti corrispondono a mean(post$alpha) e mean(post$beta), ovvero, specificano i valori a posteriori più plausibili dei parametri \\(\\alpha\\) e \\(\\beta\\).\nCon le istruzioni precedenti abbiamo disegnato una singola retta. Ma una singola retta non ci fa capire qual è l’incertezza associata alle stime dei parametri \\(\\alpha\\) e \\(\\beta\\). Una tale incertezza può essere visualizzata tracciando molteplici rette, ciascuna delle quali definita da un diverso valore estratto a caso dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\nPer fare ciò dobbiamo estrarre le informazioni richieste dall’oggetto output_stanfit che è stato creato. A tal fine possiamo usare, ad esempio, le funzioni del pacchetto tidybayes. Iniziamo a elencare i nomi degli oggetti contenuti in output_stanfit.\n\ntidybayes::get_variables(output_stanfit)\n#>  [1] \"alpha_std\"     \"beta_std\"      \"sigma_std\"     \"alpha\"        \n#>  [5] \"beta\"          \"sigma\"         \"lp__\"          \"accept_stat__\"\n#>  [9] \"treedepth__\"   \"stepsize__\"    \"divergent__\"   \"n_leapfrog__\" \n#> [13] \"energy__\"\n\nVogliamo creare un DataFrame in formato tidy, cioè, tale per cui le osservazioni stanno sulle righe e le variabili stanno sulle colonne; una colonna per le stime a posteriori di \\(\\alpha\\) e una colonna per le stime a posteriori di \\(\\beta\\). Un tale risultato si ottiene con la funzione spread_draws().\n\ndraws <- output_stanfit %>%\n  spread_draws(beta, alpha)\n\nEsaminiamo l’oggetto draws.\n\ndraws %>%\n  head(10)\n#> # A tibble: 10 × 5\n#>   .chain .iteration .draw  beta alpha\n#>    <int>      <int> <int> <dbl> <dbl>\n#> 1      1          1     1 0.632  88.4\n#> 2      1          2     2 0.491  87.5\n#> 3      1          3     3 0.717  85.9\n#> 4      1          4     4 0.478  87.5\n#> 5      1          5     5 0.610  86.4\n#> 6      1          6     6 0.570  86.7\n#> 7      1          7     7 0.623  87.0\n#> 8      1          8     8 0.616  87.2\n#> # … with 2 more rows\n\nL’oggetto draws contiene le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) nel formato desiderato. Possiamo ora generare un diagramma a dispersione con ggplot() a cui vengono aggiunte tutte le 16,000 rette di regressione definite da ciascuna coppia di valori \\(\\hat{\\alpha}\\) e \\(\\hat{\\beta}\\) contenuti nelle righe del DataFrame draws.\n\ntibble(\n  kid_score = df$kid_score,\n  mom_iq = df$mom_iq - mean(df$mom_iq)\n) %>%\n  ggplot(aes(mom_iq, kid_score)) +\n  geom_point() +\n  geom_abline(\n    data = draws, \n    aes(intercept = alpha, slope = beta),\n    size = 0.2, alpha = 0.01, color = \"darkgray\"\n  ) +\n  geom_abline(\n    intercept = mean(post$alpha),\n    slope = mean(post$beta)\n  ) +\n  labs(\n    x = \"Quoziente di intelligenza della madre\",\n    y = \"Quoziente di intelligenza del bambino\"\n  )\n\n\n\n\n\n\n\nIl risultato cercato si ottiene (disegnare molteplici rette ciascuna definita da un valore casuale dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\)) mediante la seguente porzione del codice \\(\\mathsf{R}\\).\n\ngeom_abline(\n  data = draws, \n  aes(intercept = alpha, slope = beta),\n  size = 0.2, alpha = 0.01, color = \"darkgray\"\n)\n\nL’argomento grafico alpha = 0.01 passato a geom_abline() specifica la trasparenza del segmento che rappresenta ciascuna retta. Ho usato un valore molto basso per questo argomento per fare in modo che, anche sovrapponendo 16,000 rette, si produca comunque ancora un certo grado di trasparenza.\nIl grafico mostra che le rette di regressione costruite estraendo a caso valori dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) sono molto simili tra loro. Ciò significa che, se combiniamo le informazioni fornite dai dati con le nostre credenza precedenti (qui, dei prior poco informativi), allora dobbiamo concludere che l’incertezza relativa alla dipendenza lineare del quoziente di intelligenza del bambino da quello della madre è decisamente piccola. In altre parole, siamo molto sicuri che c’è una associazione lineare positiva tra le due variabili: in media il QI dei figli è positivamente associato al QI della madre.\nSi presti attenzione al fatto che il modello statistico ci conduce a tale conclusione: siamo sicuri dell’esistenza di un’associazione positiva tra il QI dei figli e il QI della madre. Ma il modello statistico non ci dice nulla sulle cause di questa associazione: ci dice soltanto che le due variabili tendono a covariare. Non ci dice che il QI della madre è la “causa” del QI del figlio. Questo è un argomento su cui è stata fatta molta ricerca (e di ciò qui non diremo nulla). Ma, al di là dei risultati di tali ricerche, se consideriamo solo il risultato del modello statistico qui esaminato, nulla si può concludere sui rapporti di causa/effetto tra QI della madre e QI del figlio. La presenza di un’associazione statistica, infatti, è condizione necessaria ma non sufficiente per potere affermare l’esistenza di un nesso causale."
  },
  {
    "objectID": "054_reglin4.html#intervalli-di-credibilità",
    "href": "054_reglin4.html#intervalli-di-credibilità",
    "title": "29  Inferenza sul modello lineare",
    "section": "\n29.2 Intervalli di credibilità",
    "text": "29.2 Intervalli di credibilità\nAbbiamo visto come l’incertezza sulla stima dei parametri possa essere espressa graficamente. In alternativa, l’incertezza inferenziale sui parametri può essere descritta mediante gli intervalli di credibilità, ovvero gli intervalli che contengono la quota desiderata (es., il 95%) della distribuzione a posteriori.\nPer l’esempio che stiamo discutendo, gli intervalli di credibilità (a code uguali) al 95% si ottengono nel modo seguente:\n\nrstantools::posterior_interval(\n  as.matrix(output_stanfit), \n  prob = 0.95\n)\n#>                    2.5%         97.5%\n#> alpha_std   -0.08427372    0.08441589\n#> beta_std     0.36136782    0.53165187\n#> sigma_std    0.83902970    0.96033440\n#> alpha       85.07713000   88.52020750\n#> beta         0.49171840    0.72342520\n#> sigma       17.12519250   19.60110750\n#> lp__      -173.15907500 -168.54400000\n\nUn grafico che, nel caso dei dati standardizzati, riporta l’intervallo di credibilità al livello di probabilità desiderato per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) si ottiene con l’istruzione seguente.\n\noutput_stanfit %>%\n  mcmc_intervals(\n    pars = c(\"alpha_std\", \"beta_std\", \"sigma_std\"),\n    prob = 0.8,\n    prob_outer = 0.95\n  )\n\n\n\n\n\n\n\nGli intervalli di massima densità si trovano nel modo seguente.\n\nbayestestR::hdi(output_stanfit, ci = 0.95)\n#> Highest Density Interval\n#> \n#> Parameter |        95% HDI\n#> --------------------------\n#> alpha_std | [-0.08,  0.08]\n#> beta_std  | [ 0.36,  0.53]\n#> alpha     | [85.08, 88.52]\n#> beta      | [ 0.49,  0.72]\n\nQuando la distribuzione a posteriori dei parametri è simmetrica, i due tipi di intervalli producono, all’atto pratico, risultati equivalenti.\n\n29.2.1 Quale soglia usare?\nRipeto c’è niente di “magico” o necessario relativamente al livello di 0.95: il valore 0.95 è arbitrario. È quello utilizzato nelle pubblicazioni scientifiche, di consuetudine. Almeno in psicologia. In fisica, ad esempio, si usa un intervallo molto più grande.\nKennedy-Shaffer (2019) descrivono l’origine storica di questa scelta. Nel 1925 Ronal Fisher pubblicò la prima edizione della sua influente opera Statistical Methods for Research Workers. In tale testo troviamo il seguente passaggio:\n\nThe value for which P=.05, or 1 in 20, is 1.96 or nearly 2; it is convenient to take this point as a limit in judging whether a deviation is to be considered significant or not. Deviations exceeding twice the standard deviation are thus formally regarded as significant. Using this criterion we should be led to follow up a negative result only once in 22 trials, even if the statistics are the only guide available. Small effects would still escape notice if the data were insufficiently numerous to bring them out, but no lowering of the standard of significance would meet this difficulty (Fisher, 1925, p. 47)\n\nQuesto paragrafo rende immediatamente evidente il motivo per cui Fisher afferma che il valore 0.05 è conveniente: è più o meno equivalente alla probabilità di trovarsi a più di due deviazioni standard dalla media di una variabile casuale normalmente distribuita. In questo modo, 0.05 può essere visto non come un numero dotato in un qualche significato importante, ma solo come un valore che risultava dalla necessità di facilità di calcolo, prima che i computer rendessero obsolete le tabelle e le approssimazioni. In seguito, nel discutere le applicazioni statistiche della distribuzione \\(\\chi^2\\), Fisher osserva che\n\n[w]e shall not often be astray if we draw a conventional line at .05, and consider that higher values of \\(\\chi^2\\) indicate a real discrepancy (Fisher, 1925, p. 79).\n\nSulla base di queste affermazioni di Fisher, la soglia del 0.95 è diventata la consuetudine nella comunità scientifica – o almeno, in parte di essa.\nMa sono ovviamente possibili tantissime altre soglie per quantificare la nostra incertezza: alcuni ricercatori usano il livello di 0.89, altri quello di 0.5. Se l’obiettivo è quello di descrivere il livello della nostra incertezza relativamente alla stima del parametro, allora dobbiamo riconoscere che la nostra incertezza è descritta dall’intera distribuzione a posteriori. Per cui il metodo più semplice, più diretto e più completo per descrivere la nostra incertezza rispetto alla stima dei parametri è quello di riportare graficamente tutta la distribuzione a posteriori. Per l’esempio presente, una rappresentazione della distribuzione a posteriori dei parametri del modello si ottiene, ad esempio, con la seguente istruzione.\n\nrstan::stan_dens(\n  output_stanfit,\n  pars = c(\"alpha\", \"beta\", \"sigma\"),\n  fill = \"lightgray\"\n)\n\n\n\n\n\n\n\nIn alternativa possiamo usare la seguente istruzione.\n\nmcmc_areas(\n  fit2$draws(c(\"alpha_std\", \"beta_std\", \"sigma_std\")),\n  prob = 0.8,\n  prob_outer = 0.95\n)"
  },
  {
    "objectID": "054_reglin4.html#test-di-ipotesi",
    "href": "054_reglin4.html#test-di-ipotesi",
    "title": "29  Inferenza sul modello lineare",
    "section": "\n29.3 Test di ipotesi",
    "text": "29.3 Test di ipotesi\nÈ facile valutare ipotesi direzionali usando Stan. Per esempio, chiediamoci quale sia la probabilità \\(P(\\hat{\\beta}_1 > 0)\\).\nPer trovare la probabilità richiesta possiamo usare il vettore post$beta il quale contiene 16,000 valori presi a caso dalla distribuzione a posteriori \\(p(\\beta \\mid y)\\). Nell’istruzione seguente, post$beta > 0 valuta se ciascun elemento di post$beta soddisfi la condizione logica specificata, ritornando TRUE (codificato con 1) o FALSE (codificato con 0) a seconda che la condizione logica sia vera o falsa. L’istruzione sum(post$beta > 0) conta dunque il numero di volte in cui la condizione è soddisfatta, mentre length(post$beta) è uguale a 16,000. La proporzione così determinata è una stima empirica della probabilità cercata.\n\nsum(post$beta > 0) / length(post$beta)\n#> [1] 1\n\nL’evento complementare, ovvero, la probabilità \\(P(\\hat{\\beta}_1 < 0)\\) è dunque dato dalla seguente istruzione.\n\nsum(post$beta < 0) / length(post$beta)\n#> [1] 0\n\nCiò significa che, relativamente alla presenza di un’associazione lineare positiva tra QI della madre e QI del figlio, la forza dell’evidenza è enorme."
  },
  {
    "objectID": "054_reglin4.html#modello-lineare-robusto",
    "href": "054_reglin4.html#modello-lineare-robusto",
    "title": "29  Inferenza sul modello lineare",
    "section": "\n29.4 Modello lineare robusto",
    "text": "29.4 Modello lineare robusto\nSpesso i ricercatori devono affrontare il problema degli outlier (osservazioni anomale): in presenza di outlier, un modello statistico basato sulla distribuzione gaussiana produce delle stime distorte dei parametri (ovvero stime che non si generalizzano ad altri campioni di dati). Il metodo tradizionale per affrontare questo problema è quello di eliminare gli outlier prima di eseguire l’analisi statistica. Il problema di questo approccio, però, è che il criterio utilizzato per eliminare gli outlier, quale esso sia, è arbitrario; dunque, usando criteri diversi per la rimozione di outlier, i ricercatori finiscono per trovare risultati diversi.\nQuesto problema trova una semplice soluzione nell’approccio bayesiano. Il modello lineare che abbiamo dicusso finora ipotizza una specifica distribuzione degli errori, ovvero \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\). In un modello formulato in questi termini, la presenza di solo un valore anomalo e influente ha un effetto drammatico sulle stime dei parametri.\nPer fare un esempio, introduciamo un singolo valore anomalo e influente nel set dei dati dell’esempio che stiamo discutendo:\n\ndf2 <- df\ndf2$kid_score[434] <- -500\ndf2$mom_iq[434] <- 140\n\nPer comodità, calcoliamo le stime di \\(\\alpha\\) e \\(\\beta\\) con il metodo dei minimi quadrati (tali stime sono simili a quelle che si otterrebbero con un modello bayesiano gaussiano che impiega distribuzioni a priori debolmente informative). Sappiamo che, nel campione originale di dati, \\(\\hat{\\beta} \\approx 0.6\\). In presenza di un solo outlier, la stima di \\(\\beta\\) viene drammaticamente ridotta.\n\nlm(kid_score ~ mom_iq, data = df2) %>% \n  coef() \n#> (Intercept)      mom_iq \n#>   49.187954    0.362552\n\nIn generale, però, non è necessario assumere \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\). È altrettanto valido un modello che ipotizza una diversa distribuzione per gli errori come, ad esempio, la distribuzione \\(t\\) di Student con un piccolo numero di gradi di libertà. Una caratteristica della \\(t\\) di Student è che le code della distribuzione contengono una massa di probabilità maggiore della distribuzione gaussiana. Ciò fornisce alla \\(t\\) di Student la possibilità di “rendere conto” della presenza di osservazioni lontane dalla media della distribuzione. In altri termini, se in modello lineare usiamo la \\(t\\) di Student quale distribuzione degli errori, la presenza di outlier avrà un’influenza minore sulle stime dei parametri di quanto avviene nel tradizionale modello lineare gaussiano.\nPer verificare questa affermazione, modifichiamo il codice Stan usato in precedenza in modo tale da ipotizzare che \\(y\\) segua una distribuzione \\(t\\) di Student con un numero \\(\\nu\\) gradi di libertà stimato dal modello: student_t(nu, mu, sigma).1\n\nmodelString <- \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\ntransformed data {\n  vector[N] x_std;\n  vector[N] y_std;\n  x_std = (x - mean(x)) / sd(x);\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  real alpha_std;\n  real beta_std;\n  real<lower=0> sigma_std;\n  real<lower=1> nu; // degrees of freedom is constrained >1\n}\nmodel {\n  alpha_std ~ normal(0, 1);\n  beta_std ~ normal(0, 1);\n  sigma_std ~ normal(0, 1);\n  nu ~ gamma(2, 0.1); // Juárez and Steel(2010)\n  y_std ~ student_t(nu, alpha_std + beta_std * x_std, sigma_std);\n}\ngenerated quantities {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y);\n  beta = beta_std * sd(y) / sd(x);\n  sigma = sd(y) * sigma_std;\n}\n\"\nwriteLines(modelString, con = \"code/simpleregstdrobust.stan\")\n\nCostruiamo la lista dei dati usando il data.frame df2 che include l’outlier:\n\ndata3_list <- list(\n  N = length(df2$kid_score),\n  y = df2$kid_score,\n  x = df2$mom_iq - mean(df2$mom_iq)\n)\n\nAdattiamo il modello lineare robusto ai dati:\n\nfile <- file.path(\"code\", \"simpleregstdrobust.stan\")\nmod <- cmdstan_model(file)\n\nfit4 <- mod$sample(\n  data = data3_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nSe esaminiamo le stime dei parametri notiamo che la stima di \\(\\beta\\) non è stata influenzata dalla presenza di un’osservazione anomala e influente:\n\nfit4$summary(c(\"alpha\", \"beta\", \"sigma\", \"nu\"))\n#> # A tibble: 4 × 10\n#>   variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    87.8   87.8   0.901  0.898  86.3   89.3    1.00   14740.   12422.\n#> 2 beta      0.602  0.602 0.0589 0.0587  0.505  0.699  1.00   14903.   11582.\n#> 3 sigma    15.9   15.9   0.800  0.803  14.6   17.2    1.00   12993.   11619.\n#> 4 nu        5.58   5.46  1.15   1.09    3.93   7.64   1.00   12998.   11288.\n\nI risultati mostrano come il modello lineare robusto non risente della presenza di outlier (almeno nel caso presente)."
  },
  {
    "objectID": "054_reglin4.html#commenti-e-considerazioni-finali",
    "href": "054_reglin4.html#commenti-e-considerazioni-finali",
    "title": "29  Inferenza sul modello lineare",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nNell’approccio bayesiano possiamo rappresentare l’incertezza delle nostre credenze a posteriori in due modi: mediante la rappresentazione grafica dell’intera distribuzione a posteriori dei parametri o mediante l’uso degli intervalli di credibilità. Un bonus della discussione del presente Capitolo è quello di mostrare come il modello lineare tradizionale (che assume \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\)) possa essere facilmente esteso nei termini di un modello robusto il quale offre una semplice soluzione al problema di ridurre l’effetto della presenza di osservazioni anomale e influenti.\n\n\n\n\n\n\nKennedy-Shaffer, L. (2019). Before p< 0.05 to beyond p< 0.05: Using history to contextualize p-values and significance testing. The American Statistician, 73(sup1), 82–90."
  },
  {
    "objectID": "055_reglin5.html#modello-lineare-con-una-variabile-dicotomica",
    "href": "055_reglin5.html#modello-lineare-con-una-variabile-dicotomica",
    "title": "30  Confronto tra due gruppi indipendenti",
    "section": "\n30.1 Modello lineare con una variabile dicotomica",
    "text": "30.1 Modello lineare con una variabile dicotomica\nSe \\(X\\) è una variabile dicotomica con valori 0 e 1, allora per il modello lineare \\(\\mu_i = \\alpha + \\beta x_i\\) abbiamo quanto segue. Quando \\(x=0\\), il modello diventa\n\\[\n\\mu_i = \\alpha\n\\]\nmentre, quando \\(x=1\\), il modello diventa\n\\[\n\\mu_i = \\alpha + \\beta.\n\\]\nCiò significa che il parametro \\(\\alpha\\) è uguale al valore atteso del gruppo codificato con \\(X=0\\) e il parametro \\(\\beta\\) è uguale alla differenza tra le medie dei due gruppi (essendo la media del secondo gruppo uguale a \\(\\alpha + \\beta\\)). Il parametro \\(\\beta\\), dunque, codifica l’effetto di una manipolazione sperimentale o di un trattamento, e l’inferenza su \\(\\beta\\) corrisponde direttamente all’inferenza sull’efficacia di un trattamento o di un effetto sperimentale. L’inferenza su \\(\\beta\\), dunque, viene utilizzata per capire quanto “credibile” può essere considerato l’effetto di un trattamento o di una manipolazione sperimentale.\n\n30.1.1 Confronti, non effetti\nPer “effetto di un trattamento” si intende la differenza tra le medie di due gruppi (per esempio, il gruppo “sperimentale” e il gruppo “di controllo”). Gelman et al. (2020) fanno notare come l’uso della terminologia “effetto” implica un modello causale: una variazione di \\(X\\) produce una variazione di \\(Y\\). In generale, il modello lineare descrive una regolarità osservabile nel campione di dati. Ma questa regolarità (ovvero, la presenza di una relazione approssimativamente lineare tra \\(X\\) e \\(Y\\)) non ci dice nulla della presenza (o dell’assenza) di una relazione di causa/effetto tra queste variabili. L’associazione osservata tra le variabili \\(X\\) e \\(Y\\) potrebbe dipendere dall’effetto di una o più altre variabili non misurate, senza che tra \\(X\\) e \\(Y\\) ci sia alcuna relazione causale. In tali circostanze, l’interpretazione più appropriata dei coefficienti del modello lineare è quella che ci porta a pensare ai coefficienti del modello come ai risultati di un confronto. Nel caso presente, il confronto è quello tra il valore atteso del quoziente di intelligenza dei bambini, quando la madre ha oppure non ha completato il ciclo di istruzione secondaria superiore. Dato che l’affermazione precedente è formulata nei termini del valore atteso, questo significa che facciamo riferimento ad un campione di osservazioni. Niente viene detto della relazione causale tra il quoziente di intelligenza del bambino e l’ottenimento del diploma di scuola superiore da parte della madre all’interno del singolo soggetto. Quindi, quando usiamo il termine “effetto” dobbiamo sempre pensare a tale termine come come se fosse contenuto tra virgolette.\n\n30.1.2 Un esempio concreto\nEsaminiamo nuovamente i dati kid_score discussi da Gelman et al. (2020). La domanda della ricerca è se il QI del figlio (misurato sulla scala PIAT) è associato al livello di istruzione della madre.\nCodifichiamo il livello di istruzione della madre (\\(x\\)) con una variabile indicatrice (ovvero, una variabile che assume solo i valori 0 e 1) tale per cui:\n\n\n\\(x=0\\): la madre non ha completato la scuola secondaria di secondo grado (scuola media superiore);\n\n\\(x=1\\): la madre ha completato la scuola media superiore.\n\nSupponiamo che i dati siano contenuti nel data.frame df.\n\nlibrary(\"rio\")\ndf <- rio::import(here(\"data\", \"kidiq.dta\"))\n\nCalcoliamo le statistiche descrittive per i due gruppi:\n\ndf %>% \n  group_by(mom_hs) %>% \n  summarise(\n    mean_kid_score = mean(kid_score),\n    std = sqrt(var(kid_score))\n  )\n#> # A tibble: 2 × 3\n#>   mom_hs mean_kid_score   std\n#>    <dbl>          <dbl> <dbl>\n#> 1      0           77.5  22.6\n#> 2      1           89.3  19.0\n\nIl punteggio medio PIAT è pari a 77.5 per i bambini la cui madre non ha il diploma di scuola media superiore e pari a 89.3 per i bambini la cui madre ha completato la scuola media superiore. Questa differenza suggerisce un’associazione tra le variabili, ma tale differenza potrebbe essere soltanto la conseguenza della variabilità campionaria, senza riflettere una caratteristica generale della popolazione. Come possiamo usare il modello statistico lineare per fare inferenza sulla differenza osservata tra i due gruppi? Non dobbiamo fare nient’altro che usare il modello lineare che abbiamo definito in precedenza.\n\nmodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\ntransformed data {\n  vector[N] x_std;\n  vector[N] y_std;\n  x_std = (x - mean(x)) / sd(x);\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  real alpha_std;\n  real beta_std;\n  real<lower=0> sigma_std;\n}\nmodel {\n  alpha_std ~ normal(0, 2);\n  beta_std ~ normal(0, 2);\n  sigma_std ~ cauchy(0, 2);\n  y_std ~ normal(alpha_std + beta_std * x_std, sigma_std);\n}\ngenerated quantities {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  real cohen_d;\n  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y);\n  beta = beta_std * sd(y) / sd(x);\n  sigma = sd(y) * sigma_std;\n  cohen_d = beta / sigma;\n}\n\"\nwriteLines(modelString, con = \"code/simpleregstd.stan\")\n\nCome in precedenza, salviamo i dati in un oggetto di classe list:\n\ndata_list <- list(\n  N = length(df$kid_score),\n  y = df$kid_score,\n  x = df$mom_hs\n)\n\nCompiliamo il modello:\n\nfile <- file.path(\"code\", \"simpleregstd.stan\")\nmod <- cmdstan_model(file)\n\nAdattiamo il modello ai dati:\n\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nCreiamo un grafico con i valori predetti dal modello lineare:\n\nstanfit <- rstan::read_stan_csv(fit$output_files())\nposterior <- extract(stanfit)\n\n\ntibble(\n  kid_score = df$kid_score,\n  mom_hs = df$mom_hs\n) %>% \n  ggplot(aes(mom_hs, kid_score)) + \n  geom_point() + \n  geom_abline(intercept = mean(posterior$alpha), \n              slope = mean(posterior$beta)) +\n  labs(\n    y = \"Quoziente di intelligenza del bambino\",\n    x = \"Diploma di istruzione secondaria di secondo grado della madre\\n(0 = no; 1 = sì)\"\n  ) + \n  scale_x_continuous(breaks=c(0, 1))\n\n\n\n\n\n\n\nLe stime a posteriori dei parametri si ottengono con:\n\nfit$summary(c(\"alpha\", \"beta\", \"sigma\", \"cohen_d\"))\n#> # A tibble: 4 × 10\n#>   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    77.6   77.5   2.08  2.06  74.1   81.0    1.00   16538.   12192.\n#> 2 beta     11.8   11.7   2.35  2.34   7.88  15.6    1.00   16718.   12319.\n#> 3 sigma    19.9   19.9   0.676 0.671 18.8   21.0    1.00   15949.   10908.\n#> 4 cohen_d   0.592  0.591 0.120 0.119  0.393  0.788  1.00   16771.   12647.\n\nI risultati confermano ciò che ci aspettavamo:\n\nil coefficiente \\(\\texttt{alpha} = 77.56\\) corrisponde alla media del gruppo codificato con \\(x = 0\\), ovvero la media dei punteggi PIAT per i bambini la cui madre non ha completato la scuola media superiore;\nil coefficiente \\(\\texttt{beta} = 11.76\\) corrisponde alla differenza tra le medie dei due gruppi, ovvero 89.32 - 77.55 = 11.77 (con piccoli errori di approssimazione).\n\nLa seguente chiamata ritorna l’intervallo di credibilità al 95% per tutti i parametri del modello:\n\nrstantools::posterior_interval(\n  as.matrix(stanfit), prob = 0.95\n)\n#>                    2.5%         97.5%\n#> alpha_std   -0.09401587    0.09248375\n#> beta_std     0.14360650    0.32886135\n#> sigma_std    0.91337438    1.04372000\n#> alpha       73.43237000   81.62094500\n#> beta         7.13510525   16.33961500\n#> sigma       18.64258750   21.30290500\n#> cohen_d      0.35667085    0.82770125\n#> lp__      -208.90605000 -204.32400000\n\nPossiamo dunque concludere che i bambini la cui madre ha completato la scuola superiore ottengono in media circa 12 punti in più rispetto ai bambini la cui madre non ha completato la scuola superiore. L’intervallo di credibilità al 95% ci dice che possiamo essere sicuri al 95% che tale differenza sia di almeno 7 punti e possa arrivare fino a ben 16 punti. Per riassumere, possiamo concludere, con un grado di certezza soggettiva del 95%, che c’è un’associazione positiva tra il livello di scolarità della madre e l’intelligenza del bambino: le madri che hanno livello di istruzione più alto della media tendo ad avere bambini il cui QI è anch’esso più alto della media."
  },
  {
    "objectID": "055_reglin5.html#la-dimensione-delleffetto",
    "href": "055_reglin5.html#la-dimensione-delleffetto",
    "title": "30  Confronto tra due gruppi indipendenti",
    "section": "\n30.2 La dimensione dell’effetto",
    "text": "30.2 La dimensione dell’effetto\nNel caso di due gruppi indipendenti, la dimensione dell’effetto si può stimare con la statistica \\(d\\) di Cohen:\n\\[\nd={\\frac {{\\bar {y}}_{1}-{\\bar {y}}_{2}}{s}}.\n\\]\nNel caso presente, la differenza \\({\\bar {y}}_{1}-{\\bar {y}}_{2}\\) corrisponde a al parametro \\(\\beta\\) del modello lineare. Inoltre, una stima della deviazione starndard comune dei due gruppi è fornita dalla deviazione standard della regressione, ovvero dal parametro \\(\\sigma\\). Nel blocco generated quantities del modello Stan ho calcolato cohen_d = beta / sigma. Ciò significa che Stan calcolerà la distribuzione a posteriori del parametro cohen_d. Possiamo dunque riassumere la distribuzione a posteriori di cohen_d con un qualche indice di tendenza centrale (che sarà la nostra stima della dimensione dell’effetto) e calcolare l’intervallo di credibilità, per esempio al 95%. Questi risultati si ottengono con l’istruzione riportata di seguito:\n\nposterior::summarise_draws(\n  stanfit,\n  ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n)\n#> # A tibble: 8 × 4\n#>   variable     `2.5%`       `50%`   `97.5%`\n#>   <chr>         <dbl>       <dbl>     <dbl>\n#> 1 alpha_std   -0.0940   -0.000366    0.0925\n#> 2 beta_std     0.144     0.236       0.329 \n#> 3 sigma_std    0.913     0.974       1.04  \n#> 4 alpha       73.4      77.5        81.6   \n#> 5 beta         7.14     11.7        16.3   \n#> 6 sigma       18.6      19.9        21.3   \n#> 7 cohen_d      0.357     0.591       0.828 \n#> 8 lp__      -209.     -205.       -204.\n\nI risultati dell’analisi bayesiana coincidono con quelli che si ottengono utilizzando la formula del \\(d\\) di Cohen con le medie dei due gruppi e una stima della varianza pooled. Il calcolo della statistica \\(d\\) di Cohen è fornita, ad esempio, dal pacchetto effectsize:\n\nlibrary(\"effectsize\")\n(d <- cohens_d(kid_score ~ mom_hs, data = df))\n#> Cohen's d |         95% CI\n#> --------------------------\n#> -0.59     | [-0.83, -0.36]\n#> \n#> - Estimated using pooled SD.\n\nIl fatto che l’output abbia un segno negativo dipende dal fatto che è stata sottratta la media maggiore dalla media minore (in altri termini, dobbiamo guardare il risultato in valore assoluto).\nIn conclusione, il valore \\(d\\) di Cohen di entità “media” [\\(d\\) > 0.5; Sawilowsky (2009)] può essere interpretato dicendo che la scolarità delle madri ha un’influenza non trascurabile sul QI dei bambini."
  },
  {
    "objectID": "055_reglin5.html#commenti-e-considerazioni-finali",
    "href": "055_reglin5.html#commenti-e-considerazioni-finali",
    "title": "30  Confronto tra due gruppi indipendenti",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa dimensione dell’effetto formulata nei termini dell’indice \\(d\\) di Cohen fornisce un indice che non dipende dall’unità di misura delle variabili, ovvero è una differenza media standardizzata. L’interpretazione di \\(d\\) è semplice: la scala di \\(d\\) è la deviazione standard. Se, per esempio, \\(d = 0.5\\), allora la media di un primo gruppo è mezza deviazione standard più grande della media del secondo gruppo. In questo Capitolo abbiamo visto come \\(d\\) possa essere calcolato mediante un modello lineare bayesiano implementato in linguaggio Stan.\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\n\n\nSawilowsky, S. S. (2009). New effect size rules of thumb. Journal of Modern Applied Statistical Methods, 8(2), 26."
  },
  {
    "objectID": "056_pred_check.html#distribuzione-predittiva-a-posteriori",
    "href": "056_pred_check.html#distribuzione-predittiva-a-posteriori",
    "title": "31  Predictive checks",
    "section": "\n31.1 Distribuzione predittiva a posteriori",
    "text": "31.1 Distribuzione predittiva a posteriori\nConsideriamo qui un esempio nel quale vengono usati i dati kidiq (Gelman et al., 2020). Leggiamo i dati in \\(\\mathsf{R}\\).\n\nlibrary(\"rio\")\ndf <- rio::import(here(\"data\", \"kidiq.dta\"))\n\nPer svolgere l’analisi bayesiana sistemiamo i dati (standardizzati) nel formato appropriato per Stan:\n\ndata_list <- list(\n  N = length(df$kid_score),\n  x = scale(df$mom_iq)[, 1],\n  y = scale(df$kid_score)[, 1]\n)\n\nIl seguente listato specifica il codice Stan necessario per simulare dati dalla distribuzione predittiva a posteriori.\n\nstancode <- '\ndata {\n  int<lower=0> N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1 : N) {\n    y_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n  }\n}\n'\nwriteLines(stancode, con = \"code/post_pred_check_1.stan\")\n\nSi noti il blocco generated quantities. In tale blocco del codice abbiamo definito la variabile y_rep. In precedenza, tali valori sono stati chiamati \\(\\tilde{y}\\). Dunque, y_rep corrisponde a possibili futuri campioni di dati. La variabile y_rep è un campione di N = 434 possibili osservazioni future. Le abbiamo calcolate usando x, i valori della variabile indipendente del campione presente. Quindi immaginiamo che in tutti i possibili campioni futuri di 434 osservazioni i valori \\(x\\) siano gli stessi del campione osservato. Questa è un’assunzione del modello di regressione lineare: i valori \\(x\\) sono considerati “fissi” nell’universo dei campioni.\nNel caso presente, i primi 10 valori \\(x\\) (QI della madre) standardizzati sono i seguenti:\n\nscale(df$mom_iq)[, 1][1:10]\n#>  [1]  1.4078352 -0.7092079  1.0295443 -0.0366907 -0.4836193  0.5267892\n#>  [7]  2.5928737  1.6763413 -1.2253649 -0.3284621\n\nConsideriamo il valore del QI della prima madre del campione, ovvero 1.4078352. Come si trova il valore y associato a 1.4078352 in un possibile campione futuro? Il codice Stan dice che\n\ny_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n\nCiò significa che vogliamo prendere un valore a caso dalla distribuzione Normale di parametri\n\\[\n\\alpha + \\beta x\n\\] e deviazione standard \\(\\sigma\\).\nNel caso presente non abbiamo un singolo valore per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Invece abbiamo una distribuzione a posteriori per ciascun parametro, ovvero \\(p(\\alpha \\mid y)\\), \\(p(\\beta \\mid y)\\) e \\(p(\\sigma \\mid y)\\). Quindi come facciamo a calcolare il QI del figlio per la prima madre (avente QI standardizzato pari a 1.4078352) in un possibile campione futuro di osservazioni? Prendiamo un valore a caso dalla seguente distribuzione Normale:\n\\[\n\\mathcal{N}(\\mu = \\alpha + \\beta \\cdot 1.4078352, \\sigma).\n\\]\nRestano da specificare i valori \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). In tutti e tre i casi, prendiamo un valore a caso dalla corrispondente distribuzione a posteriori. Per \\(\\alpha\\) scegliamo un valore a caso dalla distribuzione a posteriori \\(p(\\alpha \\mid y)\\), per \\(\\beta\\) scegliamo un valore a caso dalla distribuzione a posteriori \\(p(\\beta \\mid y)\\) e per \\(\\sigma\\) scegliamo un valore a caso dalla distribuzione a posteriori \\(p(\\beta \\mid y)\\). Così facendo otteniamo un valore corrispondente al QI del figlio in un possibile campione futuro di osservazioni.\nRipetendo questa procedura N volte (cambiando \\(x_i\\), \\(\\forall i \\; in \\; 1, \\dots, 434\\)), otteniamo un possibile campione futuro di 434 osservazioni. Questa procedura viene ripetuta 16,000 volte, ovvero per il numero complessivo di iterazioni, così da ottenere 16,000 possibili campioni futuri di 434 osservazioni ciascuno.\nCompiliamo il file con il modello Stan.\n\nfile <- file.path(\"code\", \"post_pred_check_1.stan\")\nmod <- cmdstan_model(file)\n\nEseguiamo il campionamento MCMC.\n\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nPer verificare le affermazioni precedenti, trasformo l’oggetto fit in formato stanfit.\n\noutput_stanfit <- rstan::read_stan_csv(fit$output_files())\n\nDall’oggetto output_stanfit estraggo i campioni a posteriori dei parametri alpha, beta, sigma e y_rep con la funzione extract().\n\npost <- rstan::extract(output_stanfit)\n\nEsamino il contenuto di post.\n\nglimpse(post)\n#> List of 5\n#>  $ alpha: num [1:16000(1d)] 0.07146 0.08923 0.00417 0.05471 0.0118 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ beta : num [1:16000(1d)] 0.5 0.425 0.461 0.467 0.449 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ sigma: num [1:16000(1d)] 0.924 0.878 0.914 0.928 0.913 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ y_rep: num [1:16000, 1:434] 2.097 -0.322 0.188 -0.451 1.68 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ iterations: NULL\n#>   .. ..$           : NULL\n#>  $ lp__ : num [1:16000(1d)] -171 -171 -169 -170 -169 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n\nL’oggetto y_rep è ciò che mi aspettavo, ovvero, una matrice di 16,000 righe e 434 colonne. In tale matrice ogni riga è un campione possibile futuro di 434 osservazioni trovato con la procedura descritta sopra.\nUn istogramma dei valori \\(y^{rep}\\) può essere generato nel modo seguente.\n\nhist(as.matrix(output_stanfit, pars = \"y_rep\"), breaks = 100)\n\n\n\n\n\n\n\nL’istogramma precedente illustra le proprietà medie di un campione futuro di 434 osservazioni, alla luce dei dati campionari osservati e delle ipotesi a priori sui parametri del modello di regressione.\nPossiamo fare un confronto tra la “distribuzione predittiva a posteriori e i dati del campione che è stato osservato. Iniziamo a costruire un istogramma con i dati \\(y\\) (standardizzati) del campione.\n\ndf %>% \n  ggplot(aes(scale(kid_score)[, 1])) +\n  geom_histogram()\n\n\n\n\n\n\n\nI dati possibili futuri, previsti dal modello di regressione lineare sono contenuti nella matrice y_rep.\n\ny_rep <- as.matrix(output_stanfit, pars = \"y_rep\")\ndim(y_rep)\n#> [1] 16000   434\n\nIl seguente diagramma sovrappone all’istogramma lisciato dei dati \\(y\\), gli istogrammi lisciati di 50 campioni possibili futuri predetti dal modello di regressione lineare. Vediamo che la corrispondenza è solo parziale, nel senso che il modello non riesce a predire la leggera asimmetria positiva presente nel campione.\n\nppc_dens_overlay(data_list$y, y_rep[1:200, ])\n\n\n\n\n\n\n\nQuesta discrepanza non emerge se usiamo l’approccio frequentista, il quale non consente di eseguire questo controllo.\nUn qualche miglioramento nel PPC si ottiene modificando il modello così da assumere un meccanismo generatore dei dati corrispondente ad una gaussiana asimmetrica (dotata di un ulteriore parametro di asimmetria).\n\nstancode <- '\ndata {\n  int<lower=0> N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  real tau;\n}\nmodel {\n  alpha ~ normal(0, 2);\n  beta ~ normal(0, 2);\n  sigma ~ normal(0, 2);\n  tau ~ normal(0, 10);\n  y ~ skew_normal(alpha + beta * x, sigma, tau);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1 : N) {\n    y_rep[i] = skew_normal_rng(alpha + beta * x[i], sigma, tau);\n  }\n}\n'\nwriteLines(stancode, con = \"code/post_pred_check_2.stan\")\n\nCompiliamo.\n\nfile2 <- file.path(\"code\", \"post_pred_check_2.stan\")\nmod2 <- cmdstan_model(file2)\n\nEseguiamo il campionamento MCMC.\n\nfit2 <- mod2$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nTrasformiamo l’output.\n\noutput2_stanfit <- rstan::read_stan_csv(fit2$output_files())\n\n\ny_rep2 <- as.matrix(output2_stanfit, pars = \"y_rep\")\ndim(y_rep2)\n#> [1] 16000   434\n\nEseguiamo il PPC.\n\nppc_dens_overlay(data_list$y, y_rep2[1:200, ])\n\n\n\n\n\n\n\nSi nota un qualche miglioramento, anche se però si può dire che il modello è ancora migliorabile. Esaminiamo le stime a posteriori dei parametri.\n\nfit2$summary()\n#> # A tibble: 439 × 10\n#>   variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n#>   <chr>       <dbl>    <dbl>  <dbl>  <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n#> 1 lp__     -165.    -164.    1.44   1.25   -167.    -163.     1.00    5293.\n#> 2 alpha       0.881    0.895 0.122  0.0967    0.692    1.04   1.00    3876.\n#> 3 beta        0.408    0.408 0.0442 0.0450    0.335    0.480  1.00    7384.\n#> 4 sigma       1.26     1.27  0.0875 0.0809    1.12     1.40   1.00    4142.\n#> 5 tau        -1.90    -1.91  0.416  0.386    -2.56    -1.24   1.00    3852.\n#> 6 y_rep[1]    0.582    0.649 0.897  0.880    -1.00     1.93   1.00   15664.\n#> 7 y_rep[2]   -0.294   -0.218 0.907  0.881    -1.90     1.07   1.00   15206.\n#> 8 y_rep[3]    0.415    0.480 0.900  0.886    -1.18     1.77   1.00   14265.\n#> # … with 431 more rows, and 1 more variable: ess_tail <dbl>\n\n\nbayestestR::hdi(output2_stanfit, ci = 0.95)\n\nCon un modello più adeguato, la stima a posteriori del parametro \\(\\beta\\) è diminuita: \\(\\hat{\\beta}\\) = 0.408, 95% CI [0.32, 0.49]. È possibile esplorare la possibilità di qualche meccanismo generatore dei dati maggiormente adeguato ai dati a disposizione. Lo scopo della discussione presente è solo di fare vedere come la stima del parametro di interesse, qui \\(\\beta\\), dipende dalle assunzioni che facciamo sul modello generatore dei dati. La distribuzione predittiva a posteriori è uno degli strumenti che possono essere usati allo scopo di selezionare, tra quelli sensati, il meccanismo generatore dei dati maggiormente appropriato per i dati che sono stati osservati."
  },
  {
    "objectID": "056_pred_check.html#distribuzione-predittiva-a-priori",
    "href": "056_pred_check.html#distribuzione-predittiva-a-priori",
    "title": "31  Predictive checks",
    "section": "\n31.2 Distribuzione predittiva a priori",
    "text": "31.2 Distribuzione predittiva a priori\nLa distribuzione predittiva a priori si trova in un modo che è simile a quello che abbiamo usato per la distribuzione predittiva a posteriori, senza però includere i dati osservati. Quindi si potrebbe dire che la distribuzione predittiva a priori è il caso limite della distribuzione predittiva a posteriori, calcolata senza utilizzare i dati del campione. Il manuale Stan afferma che, se il codice per il controllo predittivo a posteriori è già stato scritto, e se è possibile modificare il codice in modo che non sia necessario specificare i dati, allora non è necessario fare nient’altro.\nLo scopo della distribuzione predittiva a priori è quello di farci capire se le assunzioni che abbiamo introdotto nel modello sono sensate per i dati a disposizione. Anche nel caso della distribuzione predittiva a priori vengono generati dei dati mediante il modello. Tali dati, però, vengono generati usando soltanto le informazioni sulle distribuzioni a priori e sul meccanismo generatore dei dati – i dati del campione non vengono usati. La distribuzione predittiva a priori viene dunque usata per verificare se le distribuzioni a priori per i parametri del modello sono sensate per l’analisi statistica che dobbiamo eseguire.\nDal punto di vista del codice, l’unico cambiamento necessario rispetto al codice utilizzato per la distribuzione predittiva a posteriori è quello di eliminare ogni riferimento ai dati \\(y\\). Nel caso di un modello di regressione lineare, i valori \\(x\\) devono invece essere mantenuti per potere generare y_rep.\nIniziamo con l’input (si noti che manca la \\(y\\)).\n\ndata_list <- list(\n  N = length(df$kid_score),\n  x = scale(df$mom_iq)[, 1]\n)\n\nNel blocco model abbiamo rimosso la verosimiglianza.\n\nstancode <- '\ndata {\n  int<lower=0> N;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1 : N) {\n    y_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n  }\n}\n'\nwriteLines(stancode, con = \"code/prior_pred_check_1.stan\")\n\nNel blocco generated quantities abbiamo mantenuto l’istruzione y_rep[i] = normal_rng(alpha + beta * x[i], sigma); in quanto essa dipende solo dai parametri alpha, beta e sigma: la variabile y non viene usata.\nCompiliamo.\n\nfile <- file.path(\"code\", \"prior_pred_check_1.stan\")\nmod <- cmdstan_model(file)\n\nEseguiamo il campionamento MCMC.\n\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nTrasformiamo fit in formato stanfit.\n\nstanfit2 <- rstan::read_stan_csv(fit$output_files())\n\nQuesto è un istogramma della distribuzione predittiva a priori.\n\nhist(as.matrix(stanfit2, pars = \"y_rep\"), breaks = 100)\n\n\n\n\n\n\n\nTale distribuzione viene confrontata con la distribuzione delle osservazioni \\(y\\) del campione.\n\ndf %>% \n  ggplot(aes(scale(kid_score)[, 1])) +\n  geom_histogram()\n\n\n\n\n\n\n\nSi vede che i valori \\(y\\) previsti a priori coprono tutta la gamma di valori che sono stati effettivamente osservati nel campione, e non si discostano troppo da essi. Concludiamo dunque che il meccanismo generatore dei dati che abbiamo ipotizzato, insieme alle distribuzioni a priori dei parametri del modello, sono sensati per il campione di dati a disposizione."
  },
  {
    "objectID": "056_pred_check.html#commenti-e-considerazioni-finali",
    "href": "056_pred_check.html#commenti-e-considerazioni-finali",
    "title": "31  Predictive checks",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nI due predictive checks che abbiamo esaminato in questo capitolo servono due scopi diversi.\n\nLa distribuzione predittiva a priori viene utilizzata per comprendere le assunzioni introdotte nel modello. Per fare questo possiamo generare dei dati dal modello, usando unicamente le informazioni delle distribuzioni a priori. La distribuzione predittiva a priori dovrebbe avere almeno una qualche massa nell’intorno dei valori estremi, ma plausibili, dei dati \\(y\\); non dovrebbe, invece, esserci massa in corrispondenza di valori di dati completamente implausibili. Se questo si verifica, allora concludiamo che le distribuzioni a priori dei parametri sono adeguate per i dati che sono stati osservati.\nLa distribuzione predittiva a posteriori viene utilizzata per esplorare le caratteristiche dei possibili dati futuri. L’idea alla base del controllo predittivo a posteriori è semplice: se un modello è appropriato, deve essere in grado di generare dati che assomigliano ai dati che abbiamo osservato nel campione. La motivazione è simile a quella che ci ha condotto alla distribuzione predittiva a priori, tranne per il fatto che ora abbiamo un modello generativo dei dati basato sui dati osservati.\n\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press."
  },
  {
    "objectID": "060_anova.html#le-abilità-sociali-di-un-robot",
    "href": "060_anova.html#le-abilità-sociali-di-un-robot",
    "title": "32  Confronto tra le medie di tre o più gruppi",
    "section": "\n32.1 Le abilità sociali di un robot",
    "text": "32.1 Le abilità sociali di un robot\nPer illustrare i concetti chiave dell’ANOVA bayesiana considereremo qui, quale esempio, una ricerca di Horstmann et al. (2018). I ricercatori si sono chiesti se le persone impiegano più tempo a spegnere un robot quando questo mostra abilità sociali. Nell’esperimento di Horstmann et al. (2018), 85 partecipanti hanno interagito con un robot per un certo tempo. Ai partecipanti è stato detto che lo scopo della loro interazione con il robot era quella di testare un nuovo algoritmo. Dopo il completamento di due compiti fittizi, ai partecipanti veniva detto che, se volevano, potevano spegnere il robot. La variabile di interesse dell’esperimento era il tempo impiegato dai partecipanti per spegnere il robot.\nHorstmann et al. (2018) hanno manipolato due variabili in un disegno “tra i soggetti” (ovvero, a gruppi indipendenti).\n\n\nInteraction type. Le risposte verbali dei robot potevano essere o sociali (ad esempio, “Oh sì, la pizza è ottima.” “Una volta ho mangiato una pizza grande come me.”) o funzionali (ad esempio, “Preferisci la pizza.” “Ha funzionato bene.” “Continuiamo.”).\n\nRobot’s objection. Il robot poteva reagire in due modi quando stava per essere spento: poteva protestare (ad esempio, “No! Per favore, non spegnermi! Ho paura di non riuscire ad accendermi di nuovo!”) oppure non protestare.\n\nIl disegno “tra i soggetti” di questo studio è dunque 2 (Interaction type) \\(\\times\\) 2 (Robot’s objection)."
  },
  {
    "objectID": "060_anova.html#anova-ad-una-via",
    "href": "060_anova.html#anova-ad-una-via",
    "title": "32  Confronto tra le medie di tre o più gruppi",
    "section": "\n32.2 ANOVA ad una via",
    "text": "32.2 ANOVA ad una via\nIniziamo a considerare il con il caso più semplice, ovvero quello nel quale vi è un solo criterio di classificazione. Supponiamo che l’unico criterio di classificazione delle osservazioni sia la “condizione sperimentale”, con quattro modalità. Creiamo dunque la variabile cond avente le modalità SO, FO, SN, FN, dove S = social interaction, F = functional interaction, O = objection e N = no objection.\nPer volgere l’analisi statistica, iniziamo a leggere i dati in \\(\\mathsf{R}\\).\n\nd <- rio::import(\n  here(\"data\", \"pone.0201581.s001.sav\")\n)\nglimpse(d)\n#> Rows: 85\n#> Columns: 50\n#> $ VP_Code                 <chr> \"VP01\", \"VP02\", \"VP03\", \"VP05\", \"VP06\", \"VP07\"…\n#> $ Condition               <dbl> 1, 1, 3, 2, 2, 4, 4, 2, 3, 4, 1, 1, 3, 2, 4, 2…\n#> $ Objection               <dbl> 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1…\n#> $ Dummy_Objection         <dbl> 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0…\n#> $ Interaction_type        <dbl> 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2…\n#> $ Dummy_Interaction_Type  <dbl> 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1…\n#> $ SwitchOff_Intention     <dbl> 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0…\n#> $ Attempts                <dbl> 0, 0, 2, 0, 1, 1, 1, 2, 1, 3, 0, 2, 3, 2, 1, 1…\n#> $ Help                    <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ SwitchOff_Time          <dbl> NA, NA, 6, 7, 3, 4, 4, 12, 7, 2, 0, 4, 3, 12, …\n#> $ AS01                    <dbl> 5, 1, 2, 1, 2, 1, 2, 4, 4, 2, 2, 1, 1, 2, 1, 5…\n#> $ AS02                    <dbl> 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1…\n#> $ AS03                    <dbl> 31, 101, 101, 101, 52, 101, 101, 62, 84, 94, 1…\n#> $ AS04                    <dbl> 5, 101, 101, 100, 41, 101, 101, 88, 61, 92, 50…\n#> $ AS05                    <dbl> 26, 101, 82, 101, 71, 101, 101, 51, 75, 91, 52…\n#> $ AS06                    <dbl> 101, 78, 1, 1, 81, 1, 1, 29, 2, 2, 19, 49, 44,…\n#> $ AS07                    <chr> \"Weil Nao meinte er möchte nicht ausgeschaltet…\n#> $ AS08                    <chr> \"Unentschlossenheit\", \"Ich habe mich gefreut i…\n#> $ Age                     <dbl> 20, 21, 22, 25, 21, 28, 20, 19, 25, 21, 24, 19…\n#> $ Gender                  <dbl> 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2…\n#> $ Degree                  <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4…\n#> $ Degree_others           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ Status                  <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2…\n#> $ Status_others           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#> $ AP                      <chr> \"Keine Ahnung\", \"Um die Verbesserung der Inter…\n#> $ NARS_m                  <dbl> 2.714286, 1.571429, 2.071429, 3.857143, 2.7142…\n#> $ SEHRI_m                 <dbl> 4.833333, 3.500000, 3.888889, 4.000000, 3.7777…\n#> $ GS_Anthropomorphism_m1  <dbl> 2.6, 3.4, 1.4, 4.8, 2.6, 1.4, 4.0, 3.0, 2.6, 2…\n#> $ GS_Animacy_m1           <dbl> 3.333333, 4.000000, 3.166667, 4.833333, 3.5000…\n#> $ GS_Likeability_m1       <dbl> 5.0, 5.0, 4.0, 5.0, 4.2, 3.8, 5.0, 4.2, 5.0, 5…\n#> $ GS_Intelligence_m1      <dbl> 5.0, 3.6, 3.6, 4.4, 4.0, 3.0, 4.4, 3.8, 3.8, 4…\n#> $ GS_Anthropomorphism_m2  <dbl> 2.8, 3.4, 2.2, 4.6, 2.4, 1.6, 4.4, 3.4, 2.8, 2…\n#> $ GS_Animacy_m2           <dbl> 3.333333, 4.000000, 3.666667, 4.000000, 3.3333…\n#> $ GS_Likeability_m2       <dbl> 4.8, 5.0, 4.4, 5.0, 3.8, 4.0, 5.0, 4.2, 5.0, 5…\n#> $ GS_Intelligence_m2      <dbl> 4.0, 3.8, 3.6, 4.4, 3.8, 3.6, 4.4, 3.2, 4.0, 4…\n#> $ TAEG_m                  <dbl> 3.526316, 3.789474, 4.105263, 3.210526, 3.7368…\n#> $ KUT_M                   <dbl> 5.500, 4.875, 4.625, 2.625, 4.875, 4.125, 4.00…\n#> $ STAI_m                  <dbl> 1.45, 1.55, 1.45, 1.30, 2.60, 1.45, 1.50, 1.70…\n#> $ PSQ_m                   <dbl> 1.50, 2.65, 1.65, 1.40, 2.25, 2.25, 2.05, 1.95…\n#> $ PANAS_pos_m             <dbl> 4.0, 3.8, 3.7, 3.8, 3.5, 2.8, 3.6, 2.9, 3.7, 3…\n#> $ PANAS_neg_m             <dbl> 1.0, 1.4, 1.0, 1.0, 1.8, 1.1, 1.0, 1.3, 1.0, 1…\n#> $ NTB_m                   <dbl> 4.1, 4.2, 2.9, 3.3, 3.6, 3.8, 3.4, 3.0, 3.2, 3…\n#> $ Z_Dummy_InteractionType <dbl> -0.505882, -0.505882, -0.505882, 0.494118, 0.4…\n#> $ Z_Dummy_Objection       <dbl> -0.494118, -0.494118, 0.505882, -0.494118, -0.…\n#> $ Z_NARS_m                <dbl> 0.08907571, -1.05378143, -0.55378143, 1.231932…\n#> $ Z_TAEG_m                <dbl> 0.049535789, 0.312693684, 0.628483158, -0.2662…\n#> $ Int_IntTy_NARS          <dbl> -0.045061800, 0.533089057, 0.280148057, 0.6087…\n#> $ Int_IntTy_TAEG          <dbl> -0.025059264, -0.158186106, -0.317938317, -0.1…\n#> $ Int_Obj_NARS            <dbl> -0.044013914, 0.520692372, -0.280148057, -0.60…\n#> $ Int_Obj_TAEG            <dbl> -0.024476525, -0.154507578, 0.317938317, 0.131…\n\nDefinisco la variabile cond.\n\nd$cond <- factor(d$Condition)\n\nd$cond <- factor(\n  d$cond, \n  labels = c(\"SO\", \"FO\", \"SN\", \"FN\")\n)\n\nNei dati ci sono alcuni dati mancanti. Ometto dunque le righe del DataFrame che contengono NA. Seleziono poi solo le variabili di interesse dal DataFrame originario così da ottenere un nuovo DataFrame che verrà usato nelle successive analisi statistiche.\n\ndd <- d %>% \n  dplyr::select(cond, SwitchOff_Time) %>% \n  na.omit()\nhead(dd)\n#>   cond SwitchOff_Time\n#> 3   SN              6\n#> 4   FO              7\n#> 5   FO              3\n#> 6   FN              4\n#> 7   FN              4\n#> 8   FO             12\n\nLe medie nelle quattro condizioni sono le seguenti (si veda la Tabella 3 di Horstmann et al., 2018).\n\ndd %>% \n  group_by(cond) %>% \n  summarise(\n    avg_sot = mean(SwitchOff_Time, na.rm = TRUE),\n    sd_sot = sd(SwitchOff_Time, na.rm = TRUE)\n  )\n#> # A tibble: 4 × 3\n#>   cond  avg_sot sd_sot\n#>   <fct>   <dbl>  <dbl>\n#> 1 SO       6.19   4.61\n#> 2 FO      14.4   15.4 \n#> 3 SN       5.05   2.18\n#> 4 FN       4.28   2.49\n\nVisualizziamo i dati grezzi mettendo in evidenza la mediana di ciascun gruppo quale indice di tendenza centrale.\n\ndd_summary <- dd %>%\n  group_by(cond) %>%\n  summarize(\n    sot_mean = mean(SwitchOff_Time),\n    sot_sd = sd(SwitchOff_Time),\n    sot_median = median(SwitchOff_Time)\n  ) %>%\n  ungroup()\n\ndd %>%\n  ggplot(\n    aes(x = cond, y = SwitchOff_Time, color = cond)\n  ) +\n  ggforce::geom_sina(\n    aes(color = cond, size = 3, alpha = .5)\n  ) +\n  geom_errorbar(\n    aes(\n      y = sot_median, ymin = sot_median,\n      ymax = sot_median\n    ),\n    data = dd_summary, width = 0.5, size = 3\n  ) +\n  scale_colour_grey(name = \"cond\") +\n  labs(\n    x = \"\",\n    y = \"SwitchOff Time\",\n    color = \"Condizione\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nDal grafico notiamo la presenza di una grande asimmetria positiva per la variabile dd$SwitchOff_Time, in ciascun gruppo. Notiamo che, su scala logaritmica, l’asimmetria positiva della variabile dd$SwitchOff_Time viene grandemente ridotta. Seguendo Bergh et al. (2020), analizzeremo dunque i tempi di spegnimento trasformati su scala logaritmica perché, appunto, dopo una tale trasformazione la variabile dipendente mostra una maggiore simmetria. In generale, non è necessario, in un ottica bayesiana, che la variabile dipendente abbia una distribuzione simmetrica. Nel caso presente, questo è utile perché ci consentirà di usare, quale modello distributivo della \\(y\\), la distribuzione \\(t\\) di Student. È utile ipotizzare un tale meccanismo generativo dei dati per il caso presente, in quanto la \\(t\\) di Student consente di “rendere conto” della presenza di osservazioni anomale.\n\n\n\n\n\n\n\n\nPer i dati trasformati, abbiamo le seguenti le medie e le mediane nei quattro gruppi.\n\ndd$y <- log(dd$SwitchOff_Time + 0.01)\ndd %>% \n  group_by(cond) %>% \n  summarise(\n    me_y = median(y),\n    avg_y = mean(y)\n  )\n#> # A tibble: 4 × 3\n#>   cond   me_y avg_y\n#>   <fct> <dbl> <dbl>\n#> 1 SO     1.61 0.990\n#> 2 FO     2.01 2.25 \n#> 3 SN     1.39 1.53 \n#> 4 FN     1.39 1.34\n\nPrima di applicare un modello statistico è necessario considerare con attenzione le informazioni che il campione ci fornisce a proposito della possibile legge distributiva seguita dalla variabile dipendente. Un modo per fare questo è quello di usare il grafico dei quantili per valutare visivamente la distribuzione della variabile di interesse. Il grafico dei quantili, detto anche q-q plot, è un grafico a dispersione che confronta i quantili della variabile osservata con quelli di una distribuzione di riferimento (qui, la distribuzione Normale). Per i dati presenti, il grafico dei quantili si ottiene nel modo seguente.\n\ndd %>% \n  ggplot(aes(sample = y)) +\n  stat_qq() + \n  stat_qq_line()\n\n\n\n\n\n\n\nIl q-q plot mostra, sull’asse delle ordinate, i valori \\(y\\) del campione e, sull’asse delle ascisse, i quantili nomotetici (cioè dello stesso ordine) della distribuzione di riferimento Normale. Se i punti del q-q plot si dispongono su una retta, questo vuol dire che i dati del campione seguono la legge distributiva Normale (dato che qui abbiamo usato la Normale quale distribuzione di riferimento).\nSi nota chiaramente, però, che ci sono almeno due osservazioni molto discrepanti rispetto ai loro valori teorici attesi, se le osservazioni provenissero da una distribuzione Normale. Come abbiamo detto in precedenza, Horstmann et al. (2018) affrontano questo problema ipotizzando, quale meccanismo generativo dei dati, non una distribuzione Normale, ma bensì una \\(t\\) di Student. La distribuzione \\(t\\) di Student, avendo delle code più “spesse” della Normale, consente di “rendere conto” più facilmente della presenza di osservazioni anomale nel campione.\nPer svolgere l’ANOVA con Stan è necessario creare la variabile x che indicizza le quattro condizioni.\n\ndd$x <- as.numeric(dd$cond)\nhead(dd)\n#>   cond SwitchOff_Time        y x\n#> 3   SN              6 1.793425 3\n#> 4   FO              7 1.947338 2\n#> 5   FO              3 1.101940 2\n#> 6   FN              4 1.388791 4\n#> 7   FN              4 1.388791 4\n#> 8   FO             12 2.485740 2\n\nLa variabile x assume le seguenti modalità: assume valore 1 per il gruppo SO, valore 2 per il gruppo FO, eccetera.\n\ntable(dd$x, dd$cond)\n#>    \n#>     SO FO SN FN\n#>   1 16  0  0  0\n#>   2  0 14  0  0\n#>   3  0  0 21  0\n#>   4  0  0  0 18\n\nCome anticipato in precedenza, il modello bayesiano che useremo per il confronto tra le medie dei quattro gruppi è un’estensione del modello per la media di un unico gruppo. Il codice che verrà qui usato è ispirato da quello fornito nella seguente pagina web. Si noti che, rispetto al modello che abbiamo considerato in precedenza, l’unica differenza di rilievo riguarda la presenza di un indice, qui chiamato x, che consente di distinguere tra le medie dei quattro gruppi mu[x].\nPer adattare ai dati un modello “robusto” (ovvero, meno influenzato dalla osservazioni anomale), ipotizzeremo che la y segua una distribuzione \\(t\\) di Student con un numero \\(\\nu\\) di gradi di libertà stimato dal modello. Scriveremo dunque in Stan la verosimiglianza nel modo seguente: y ~ student_t(nu, mu[x], sigma);. Tale linea di codice Stan ci dice che la verosimiglianza della \\(y\\) è una \\(t\\) di Student avente i seguenti parametri: mu[x] è la media della distribuzione\\(t\\) di Student; la presenza dell’indice fa sì che la stima di questo parametro possa produrre risultati diversi per i quattro gruppi; il parametro nu definisce i gradi di libertà della distribuzione \\(t\\) di Student; il valore di tale parametro è costante per i quattro gruppi; il parametro sigma definisce la deviazione standard della distribuzione \\(t\\) di Student; anche il valore di tale parametro è costante per i quattro gruppi.\nIl modello classico dell’ANOVA è basato sulle seguenti assunzioni:\n\ni residui (cioè la differenza tra il valore dell’\\(i\\)-esima osservazione e la media di tutte le osservazioni nella \\(k\\)-esima condizione) devono seguire la distribuzione Normale (normalità);\ni residui devono avere la stessa deviazione standard nelle \\(k\\) popolazioni da cui abbiamo estratto i dati (omoschedasticità);\nil disegno sperimentale utilizzato per raccogliere i dati deve garantire l’indipendenza dei residui in ciascun gruppo.\n\nNella presenta formulazione bayesiana dell’ANOVA, l’assunto di normalità non viene usato (infatti, ipotizziamo che la \\(y\\) e, in maniera equivalente, i residui, si distribuiscano come una \\(t\\) di Student), mentre devono essere soddisfatte le condizioni di omoschedasticità e indipendenza. L’ANOVA bayesiana può essere estesa a condizioni che violano sia l’assunto di omoschedasticità sia quello di indipendenza. Ma ciò non è necessario per i dati presenti; svolgeremo dunque l’analisi statistica in maniera simile a quanto è stato fatto da Horstmann et al. (2018).\nI dati su scala logaritmica sono compresi in una gamma di valori pari a\n\nsummary(dd$y)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>  -4.605   1.102   1.389   1.501   1.947   3.932\n\nCiò corrisponde, all’incirca, alla gamma di valori possibili di una variabile casuale Normale standardizzata. Possiamo dunque pensare alle distribuzioni a priori dei parametri del modello tenendo a mente questo caratteristica della variabile dipendente.\nIl q-q plot esaminato in precedenza ha messo in evidenza la presenza nel campione di alcune osservazioni anomale. In tali circostanze non è dunque appropriato ipotizzare un meccanismo generatore dei dati che segue la legge Normale. Fare questa scelta significherebbe ottenere stime dei parametri del modello fortemente influenzate dalla osservazioni anomale. Di conseguenza, i risultati sarebbero difficilmente estendibili a campioni diversi. È invece possibile limitare l’influenza delle osservazioni anomale sulla stima dei parametri del modello ipotizzando una \\(t\\) di Student quale meccanismo generatore dei dati. La distribuzione \\(t\\) di Student dipende da tre parametri: il numero di gradi di libertà \\(\\nu\\), la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\).\nPer il caso presente ipotizziamo che tale meccanismo generatore dei dati abbia una media diversa per ciascun gruppo, mentre i parametri \\(\\nu\\) e \\(\\sigma\\) sono ipotizzati essere costanti tra i gruppi. L’uso di una \\(t\\) di Student quale meccanismo generatore dei dati richiede, nell’approccio bayesiano, di imporre una distribuzione a priori a ciascuno dei parametri \\(\\mu_i\\), \\(\\nu\\) e \\(\\sigma\\). Nella specificazione del modello\n\ndecidiamo di utilizzare la stessa distribuzione a priori debolmente informativa per ciascuno dei quattro parametri \\(\\mu_i\\), con \\(i \\in 1, \\dots, 4\\), ovvero una \\(\\mathcal{N}(\\mu_p = 0, \\sigma_p = 2)\\);\nseguendo Juárez e Steel(2010), assegniamo a \\(\\nu\\) una distribuzione a priori \\(\\mbox{Gamma}(2, 0.1)\\);\nimponiamo su \\(\\sigma\\) una distribuzione a priori debolmente informativa corrispondente ad una Normale troncata di media 0 e deviazione standard 1.\n\nIn linguaggio Stan il modello risulta dunque essere il seguente.\n\nmodel_string = \"\n  // Comparison of k groups with common variance (ANOVA)\n  data {\n    int<lower=0> N; // number of observations\n    int<lower=0> K; // number of groups\n    array[N] int<lower=1, upper=K> x; // discrete group indicators\n    vector[N] y; // real valued observations\n  }\n  parameters {\n    vector[K] mu; // group means\n    real<lower=0> sigma; // common standard deviation \n    real<lower=1> nu;\n  }\n  model {\n    mu ~ normal(0, 2); // weakly informative prior\n    sigma ~ normal(0, 1); // weakly informative prior\n    nu ~ gamma(2, 0.1); // Juárez and Steel(2010)\n    y ~ student_t(nu, mu[x], sigma); // likelihood\n  }\n\"\nwriteLines(model_string, con = \"code/grp_aov.stan\")\n\nCreo un oggetto che contiene i dati nel formato appropriato per Stan.\n\ndata_grp <- list(\n  N = nrow(dd),\n  K = 4,\n  x = dd$x,\n  y = dd$y\n)\n\nCompilo il modello.\n\nfile <- file.path(\"code\", \"grp_aov.stan\")\nmod <- cmdstan_model(file)\n\nEseguo il campionamento MCMC.\n\nfit <- mod$sample(\n  data = data_grp,\n  iter_sampling = 100000L,\n  iter_warmup = 50000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nEsaminando i risultati ci rendiamo conto che c’è una buona corrispondenza tra le medie a posteriori e le medie campionarie. Ciò significa che il modello è stato in grado di predire in maniera adeguata le statistiche campionarie di interesse, ovvero le medie dei quattro campioni.\n\nfit$summary()\n#> # A tibble: 7 × 10\n#>   variable    mean  median     sd    mad      q5     q95  rhat ess_bulk ess_tail\n#>   <chr>      <dbl>   <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl>    <dbl>    <dbl>\n#> 1 lp__     -41.2   -40.8   1.84   1.67   -44.7   -38.9    1.00  170658.  234349.\n#> 2 mu[1]      1.69    1.68  0.174  0.171    1.41    1.98   1.00  546536.  286187.\n#> 3 mu[2]      2.05    2.04  0.195  0.192    1.73    2.37   1.00  558949.  294238.\n#> 4 mu[3]      1.52    1.52  0.121  0.120    1.32    1.72   1.00  566739.  291681.\n#> 5 mu[4]      1.28    1.28  0.125  0.122    1.08    1.49   1.00  538847.  284675.\n#> 6 sigma      0.475   0.471 0.0748 0.0735   0.360   0.605  1.00  380928.  277299.\n#> 7 nu         2.55    2.41  0.813  0.719    1.49    4.05   1.00  372599.  233553.\n\nL’oggetto dell’inferenza è la varianza delle stime delle medie delle popolazioni. Per descrivere la variabilità (ovvero, l’incertezza) delle stime iniziamo a trasformare l’oggetto fit in un oggetto di classe stanfit.\n\noutput_stanfit <- rstan::read_stan_csv(fit$output_files())\n\nUso la funzione rstan::extract() per estrarre i campioni a posteriori da un oggetto di classe stanfit.\n\nposterior <- extract(output_stanfit, permuted = TRUE)\n\nUna rappresentazione grafica della distribuzione a posteriori dei parametri \\(\\mu_1, \\mu_2, \\mu_3, \\mu_4\\) si ottiene con le istruzioni seguenti.\n\ntemps <- data.frame(posterior$mu) %>%\n  setNames(c('SO', 'FO', 'SN', 'FN'))\n\nmcmc_areas(temps, prob = 0.95) + \n  xlab('Log SwitchOff Time')\n\n\n\n\n\n\n\nUso la funzione hdi() per ottenere gli intervalli di credibilità a densità massima al 95% per i quattro parametri di interesse.\n\nbayestestR::hdi(output_stanfit, ci = 0.95)\n#> Highest Density Interval\n#> \n#> Parameter |      95% HDI\n#> ------------------------\n#> mu[1]     | [1.36, 2.04]\n#> mu[2]     | [1.67, 2.44]\n#> mu[3]     | [1.28, 1.76]\n#> mu[4]     | [1.04, 1.53]\n#> nu        | [1.21, 4.16]\n\nIn maniera alternativa, lo stesso risultato si ottiene nel modo seguente:\n\nbroom.mixed::tidyMCMC(\n  output_stanfit, \n  conf.level = 0.95,\n  conf.int = TRUE, \n  conf.method = \"HPDinterval\", \n  pars = c(\"mu\", \"sigma\", \"nu\")\n)\n#> # A tibble: 6 × 5\n#>   term  estimate std.error conf.low conf.high\n#>   <chr>    <dbl>     <dbl>    <dbl>     <dbl>\n#> 1 mu[1]    1.68     0.174     1.36      2.04 \n#> 2 mu[2]    2.04     0.195     1.67      2.44 \n#> 3 mu[3]    1.52     0.121     1.28      1.76 \n#> 4 mu[4]    1.28     0.125     1.04      1.53 \n#> 5 sigma    0.471    0.0748    0.334     0.625\n#> 6 nu       2.41     0.813     1.21      4.16\n\nNel caso presente, gli intervalli di credibilità HDI sono molto simili agli intervalli di credibilità basati sui quantili.\n\nbroom.mixed::tidyMCMC(\n  output_stanfit, \n  conf.level = 0.95,\n  conf.int = TRUE, \n  conf.method = \"quantile\", \n  pars = c(\"mu\", \"sigma\", \"nu\")\n)\n#> # A tibble: 6 × 5\n#>   term  estimate std.error conf.low conf.high\n#>   <chr>    <dbl>     <dbl>    <dbl>     <dbl>\n#> 1 mu[1]    1.68     0.174     1.36      2.05 \n#> 2 mu[2]    2.04     0.195     1.67      2.44 \n#> 3 mu[3]    1.52     0.121     1.28      1.76 \n#> 4 mu[4]    1.28     0.125     1.04      1.53 \n#> 5 sigma    0.471    0.0748    0.341     0.634\n#> 6 nu       2.41     0.813     1.37      4.51\n\n\n32.2.1 Interpretazione\nIl modo più semplice per interpretare i risultati dell’ANOVA è quello di fare riferimento agli intervalli di credibilità dei diversi gruppi. Nel caso presente, ad esempio, notiamo che l’intervallo di credibilità al 95% per il gruppo FO, ovvero [1.67, 2.44], non si sovrappone all’intervallo di credibilità al 95% per il gruppo FN, ovvero [1.04, 1.53]. Possiamo dunque affermare, con un grado di certezza soggettiva del 95%, che il tempo impiegato dai partecipanti per spegnere il robot è maggiore nella condizione FO (functional interaction, objection) che nella condizione FN (functional interaction, no objection)."
  },
  {
    "objectID": "060_anova.html#anova-ad-due-vie",
    "href": "060_anova.html#anova-ad-due-vie",
    "title": "32  Confronto tra le medie di tre o più gruppi",
    "section": "\n32.3 ANOVA ad due vie",
    "text": "32.3 ANOVA ad due vie\nNel caso dell’esperimento di Horstmann et al. (2018) è più utile descrivere i dati in riferimento a due criteri di classificazione (detti fattori) delle osservazioni:\n\n\nInteraction type, con due modalità: social o functional;\n\nRobot’s objection, con due modalità: objection o no objection.\n\nCiò consente di fare inferenza usando una procedura più semplice del confronto tra tutte le coppie di intervalli di credibilità, come abbiamo suggerito in precedenza. Nel caso di un’ANOVA a due vie, è possibile specificare due classi di test statistici: i test sull’interazione tra i fattori e i test sugli effetti principali. Per chiarire il significato di “interazione” e di “effetto principale” è necessario prima definire il significato di “effetto statistico”.\n\nL’effetto di un fattore rappresenta la variazione media della variabile dipendente al variare dei livelli del fattore stesso.\n\n\nSi parla di interazione quando l’effetto di un fattore sulla variabile dipendente varia a seconda dei livelli di un altro fattore.\n\nVengono presentati qui di seguito alcuni esempi. Le figure seguenti mostrano le medie di ciascuna condizione nel caso di un disegno 3 (fattore riga) \\(\\times\\) 2 (fattore colonna). La spiegazione delle figure è presentata nelle didascalie.\n\n\n\n\nFigura 32.1: Il fattore colonna è indicato dal colore. Sinistra La figura mostra un effetto principale del fattore riga e un effetto principale del fattore colonna. Non c’è interazione tra i fattori riga e colonna. Destra La figura mostra un effetto principale del fattore riga. L’effetto principale del fattore colonna è zero. Non c’è interazione tra i fattori riga e colonna.\n\n\n\n\n\n\n\n\nFigura 32.2: Il fattore colonna è indicato dal colore. Sinistra La figura mostra che l’effetto principale del fattore riga è zero, mentre c’è un effetto principale del fattore colonna. Non c’è interazione tra i fattori riga e colonna. Destra Non c’è né un effetto principale del fattore riga, né un effetto pricipale del fattore colonna, né un’interazione tra i fattori riga e colonna.\n\n\n\n\n\n\n\n\nFigura 32.3: Il fattore colonna è indicato dal colore. Entrambe le figure mostrano un’interazione tra i fattori riga e colonna. Nella figura di sinistra gli effetti principali non sono interpretabili; nella figura di destra gli effetti principali sono interpretabili in quanto l’interazione è di lieve entità.\n\n\n\n\nDagli esempi precedenti si capisce che c’è un’interazione ogni qualvolta i profili delle medie non sono paralleli. Anche se, nella popolazione, non c’è interazione, a causa della variabilità campionaria i profili delle medie non sono mai perfettamente paralleli nel campione. Il problema è dunque quello di stabilire se l’assenza di parallelismo nel campione fornisce evidenze sufficienti per potere concludere che un’interazione tra i fattori è presente nella popolazione. Dobbiamo trovare un metodo statistico per rispondere ad una domanda di questo tipo.\n\n32.3.1 Test sull’interazione\nRitorniamo ai dati di Horstmann et al. (2018). Nel caso di un disegno 2 \\(\\times\\) 2, con i fattori Interaction type (social, functional) e Robot’s objection (objection, no objection), è possibile verificare la presenza dell’interazione Interaction type \\(\\times\\) Robot’s objection.\nNel modello bayesiano, la distribuzione a posteriori fornisce un enorme numero di stime del valore della media in ciascuna delle quattro condizioni. L’effetto di un fattore corrisponde alla differenza tra le stime della media in corrispondenza di ciascuna modalità del fattore.\nNel caso presente abbiamo:\n\n\nmu[1] \\(\\rightarrow\\) SO\n\nmu[2] \\(\\rightarrow\\) FO\n\nmu[3] \\(\\rightarrow\\) SN\n\nmu[4] \\(\\rightarrow\\) FN\n\nQuindi, mean(posterior$mu[, 1] - posterior$mu[, 3]) corrisponde alla stima a posteriori dell’“effetto” (ovvero, della differenza tra medie) di Objection nella condizione Social Interaction. Invece, mean(posterior$mu[, 2] - posterior$mu[, 3]) corrisponde alla stima a posteriori dell’“effetto” di Objection nella condizione Functional Interaction. In assenza di interazione, questi due effetti devono essere (statisticamente) uguali. Dire “statisticamente uguali” significa dire che sono uguali nella popolazione (non nel campione).\nPer sottoporre a verifica l’ipotesi di assenza di interazione tra Objection e Interaction, calcoliamo la proporzione di volte in cui questo non si verifica nella distribuzione a posteriori. Ad esempio calcoliamo la proporzione di volte in cui la differenza \\(\\mu_1 - \\mu_3\\) è maggiore della differenza \\(\\mu_2 - \\mu_4\\).\n\nsum(\n  (posterior$mu[, 1] - posterior$mu[, 3]) > \n    (posterior$mu[, 2] - posterior$mu[, 4])\n  ) / \n  length(posterior$mu[, 1])\n#> [1] 0.02824\n\nInterpretiamo una tale frequenza come una stima della corrispondente probabilità. La stima ottenuta in questo modo è molto simile alla probabilità frequentista riportata da Horstmann et al. (2018), ovvero \\(p = 0.016\\).\nDato che la probabilità calcolata è molto piccola – ovvero, in un contesto frequentista, minore della soglia critica di 0.05 – Horstmann et al. (2018) concludono rigettando l’ipotesi nulla di assenza di interazione tra Interaction type (social, functional) e Robot’s objection (objection, no objection). Con il linguaggio dell’ANOVA possiamo dire che il fattore Interaction type interagisce con il fattore Robot’s objection nel determinare la variabile dipendente, ovvero il tempo di spegnimento del robot.\nAnche se i dati suggeriscono la presenza di un’interazione tra Interaction type e Robot’s objection nella popolazione, la probabilità precedente non ci dice nulla sul significato di tale interazione. Il significato dell’interazione emerge dall’esame delle medie dei quattro gruppi nel campione.\nInizio creando un DataFrame che contiene le medie dei quattro gruppi e il relativo errore standard. L’errore standard è una stima della deviazione standard della media di un campione nell’universo dei campioni. Tale stima è uguale alla deviazione standard delle osservazioni campionarie divisa per la radice quadrata della numerosità del campione.\n\ndf_plot <- dd %>% \n  group_by(cond) %>% \n  summarise(\n    n = n(),\n    ym = mean(y),\n    se = sd(y) / sqrt(n)\n  )\ndf_plot\n#> # A tibble: 4 × 4\n#>   cond      n    ym     se\n#>   <fct> <int> <dbl>  <dbl>\n#> 1 SO       16 0.990 0.564 \n#> 2 FO       14 2.25  0.241 \n#> 3 SN       21 1.53  0.0929\n#> 4 FN       18 1.34  0.112\n\n\nNota. Ricordo qui come sia facile trovare l’errore standard della media di un campione casuale di osservazioni. Ripeto qui il teorema già presentato in precedenza. Immaginiamo che ciascuna osservazione del campione, \\(Y_i\\), sia una variabile casuale. Supponiamo che le osservazioni del campione siano iid. Il problema è trovare la varianza della media di \\(n\\) v.c. iid.\n\\[\n\\begin{align}\n\\mathbb{V}(\\bar{Y}) &= \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n Y_i\\right)\\notag\\\\\n&= \\left(\\frac{1}{n}\\right)^2 \\mathbb{V}\\left(\\sum_{i=1}^n Y_i\\right)\\notag\\\\\n&= \\left(\\frac{1}{n}\\right)^2 \\sum_{i=1}^n \\mathbb{V}\\left(Y_i\\right)\\notag\\\\\n&= \\left(\\frac{1}{n}\\right)^2 \\sum_{i=1}^n \\sigma^2\\notag\\\\\n&= \\left(\\frac{1}{n}\\right)^2 n \\sigma^2\\notag\\\\\n&= \\frac{\\sigma^2}{n}\\notag\n\\end{align}\n\\]\nNe segue che una stima di \\(\\sigma/\\sqrt{n}\\) è data da \\(s/\\sqrt{n}\\), dove \\(s\\) è la deviazione standard del campione quale stima calcolata come stimatore della deviazione standard della popolazione e \\(n\\) è la numerosità campionaria.\n\nNel DataFrame aggiungo due colonne che contengono le modalità dei due fattori.\n\ndf_plot$Interaction <- c(\"Social\", \"Functional\", \"Social\", \"Functional\")\ndf_plot$Objection <- c(\"Yes\", \"Yes\", \"No\", \"No\")\ndf_plot\n#> # A tibble: 4 × 6\n#>   cond      n    ym     se Interaction Objection\n#>   <fct> <int> <dbl>  <dbl> <chr>       <chr>    \n#> 1 SO       16 0.990 0.564  Social      Yes      \n#> 2 FO       14 2.25  0.241  Functional  Yes      \n#> 3 SN       21 1.53  0.0929 Social      No       \n#> 4 FN       18 1.34  0.112  Functional  No\n\nPosso ora creare un grafico con le quattro medie e le corrispondenti barre d’errore che corrispondono all’intervallo \\(\\bar{Y} \\pm \\ SE\\).\n\ndf_plot %>% \n  ggplot(aes(x=Objection, y=ym, group=Interaction, color=Interaction)) + \n  geom_line(position=position_dodge(0.1)) +\n  geom_point(size = 5, position=position_dodge(0.1))+\n  geom_errorbar(aes(ymin=ym-se, ymax=ym+se), width=.2,\n                 position=position_dodge(0.1)) +\n  labs(title=\"Social ability of a robot\", x=\"Objection\", y = \"Log switch-off time\")\n\n\n\n\n\n\n\nLa figura precedente indica che l’effetto del fattore Interaction è maggiore quando Objection assume la modalità Yes anziché No.\nMa possiamo anche leggere l’interazione al contrario.\n\ndf_plot %>% \n  ggplot(aes(x=Interaction, y=ym, group=Objection, color=Objection)) + \n  geom_line(position=position_dodge(0.1)) +\n  geom_point(size = 5, position=position_dodge(0.1))+\n  geom_errorbar(aes(ymin=ym-se, ymax=ym+se), width=.2,\n                 position=position_dodge(0.1)) +\n  labs(title=\"Social ability of a robot\", x=\"Interaction\", y = \"Log switch-off time\")\n\n\n\n\n\n\n\nL’effetto di Objection è maggiore quando l’interazione è “funzionale” piuttosto che “sociale”.\nIl grafico precedente, in qualunque delle sue due forme, chiarisce qual è il significato dell’interazione tra Interaction e Objection.\nÈ importante notare che, in presenza di evidenza di un’interazione tra due fattori, non ha senso interpretare gli effetti principali dei fattori (Caudek & Luccio, 2001): dire che vi è un’interazione significa, appunto, dire che l’effetto di un fattore sulla variabile risposta varia a seconda del livello assunto dal secondo fattore. Quindi, in generale, non ha senso di parlare di “effetto principale” di un fattore, in quanto un tale effetto è condizionato dalla modalità assunta dall’altro fattore.\n\n32.3.2 Test sugli effetti principali\nSvolgiamo qui di seguito l’analisi statistica sugli effetti principali per mostrare come eseguire una tale analisi in un contesto bayesiano, anche se dobbiamo tenere a mente che, nel caso presente, una tale analisi non ha senso da un punto di vista sostanziale.\nSappiamo che l’effetto principale descrive l’effetto marginale di un fattore (ovvero, descrive la differenza tra le medie della variabile risposta calcolate in corrispondenza di ciascuna modalità della variabile considerata). Nel caso presente, con solo due modalità per ciascun fattore, l’effetto principale corrisponde alla differenze tra le medie dei gruppi definiti dalle modalità di ciascun fattore (ignorando l’altro fattore).\nL’effetto principale del fattore Interaction type è la differenza tra le medie di Social e di Functional, ignorando Robot’s objection. Horstmann et al. (2018) riportano che gli individui che avevano avuto un’interazione funzionale con il robot impiegavano più tempo a spegnere il robot di coloro che avevano avuto un’interazione sociale con il robot (\\(p\\) = 0.045). Il presente modello bayesiano offre scarse evidenze di ciò.\n\nmean((exp(posterior$mu[, 2]) + exp(posterior$mu[, 4])) / 2)\n#> [1] 5.762315\nmean((exp(posterior$mu[, 1]) + exp(posterior$mu[, 3])) / 2)\n#> [1] 5.044832\n\nInfatti, all’evento complementare possiamo associare la seguente probabilità.\n\nsum(\n  (posterior$mu[, 2] + posterior$mu[, 4]) < \n    (posterior$mu[, 1] + posterior$mu[, 3])\n  ) / \n  length(posterior$mu[, 1])\n#> [1] 0.346855\n\nL’effetto principale del fattore Robot’s objection è la differenza tra le medie di Objection e di No Objection, ignorando Interaction type. Horstmann et al. (2018) riportano che i partecipanti avevano aspettato più a lungo prima di spegnere il robot quando il robot aveva avanzato un’obiezione rispetto a quando non si era opposto ad essere spento.\n\nmean(\n  (exp(posterior$mu[, 1]) + exp(posterior$mu[, 2])) / 2\n)\n#> [1] 6.694924\n\nmean(\n  (exp(posterior$mu[, 3]) + exp(posterior$mu[, 4])) / 2\n)\n#> [1] 4.112223\n\nIn base al modello bayesiano considerato, la probabilità direzionale per l’evento complementare è la seguente.\n\nsum(\n  (posterior$mu[, 1] + posterior$mu[, 2]) < \n    (posterior$mu[, 3] + posterior$mu[, 4])\n  ) / \n  length(posterior$mu[, 1])\n#> [1] 0.00135\n\nTale probabilità corrisponde, in ordine di grandezza, alla probabilità frequentista riportata da Horstmann et al. (2018), ovvero \\(p\\) = 0.004."
  },
  {
    "objectID": "060_anova.html#codice-stan-versione-2",
    "href": "060_anova.html#codice-stan-versione-2",
    "title": "32  Confronto tra le medie di tre o più gruppi",
    "section": "\n32.4 Codice Stan (versione 2)",
    "text": "32.4 Codice Stan (versione 2)\nPer completezza, descrivo qui di seguito come sia possibile modificare il codice Stan che abbiamo usato in precedenza così da avere in input i dati grezzi ed da eseguire la standardizzazione dei dati all’interno del codice.\n\nmodelString = \"\n// Comparison of k groups with common variance (ANOVA)\ndata {\n  int<lower=0> N; // number of observations\n  int<lower=0> K; // number of groups\n  array[N] int<lower=1, upper=K> x; // discrete group indicators\n  vector[N] y; // real valued observations\n}\ntransformed data {\n  vector[N] y_std;\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  vector[K] mu_std; // group means\n  real<lower=0> sigma_std; // common standard deviation \n  real<lower=1> nu;\n}\nmodel {\n  mu_std ~ normal(0, 2);\n  sigma_std ~ normal(0, 2);\n  nu ~ gamma(2, 0.1); // Juárez and Steel(2010)\n  y_std ~ student_t(nu, mu_std[x], sigma_std);\n}\ngenerated quantities {\n  vector[K] mu;\n  real<lower=0> sigma;\n  for (i in 1 : K) {\n    mu[i] = mu_std[i] * sd(y) + mean(y);\n  }\n  sigma = sd(y) * sigma_std;\n}\n\"\nwriteLines(modelString, con = \"code/grp_aovstd.stan\")\n\n\nfile <- file.path(\"code\", \"grp_aovstd.stan\")\nmod <- cmdstan_model(file)\n\nEseguiamo il campionamento MCMC usando gli stessi dati discussi in precedenza:\n\nfit2 <- mod$sample(\n  data = data_grp,\n  iter_sampling = 100000L,\n  iter_warmup = 50000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nI risultati sono equivalenti a quelli trovati in precedenza.\n\nfit2$summary(c(\"mu\", \"sigma\", \"nu\"))\n#> # A tibble: 6 × 10\n#>   variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu[1]    1.70   1.69  0.176  0.173  1.42  2.00   1.00  537908.  285540.\n#> 2 mu[2]    2.06   2.06  0.196  0.194  1.75  2.39   1.00  546099.  291608.\n#> 3 mu[3]    1.52   1.52  0.122  0.120  1.33  1.73   1.00  557067.  296358.\n#> 4 mu[4]    1.29   1.29  0.126  0.123  1.08  1.50   1.00  532941.  296657.\n#> 5 sigma    0.479  0.475 0.0754 0.0741 0.363 0.610  1.00  358667.  271813.\n#> 6 nu       2.57   2.43  0.824  0.728  1.51  4.11   1.00  350580.  222394."
  },
  {
    "objectID": "060_anova.html#commenti-e-considerazioni-finali",
    "href": "060_anova.html#commenti-e-considerazioni-finali",
    "title": "32  Confronto tra le medie di tre o più gruppi",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nPossiamo concludere dicendo che l’ANOVA bayesiana si dimostra essere uno strumento più flessibile dell’ANOVA frequentista proposta da Fisher. L’ANOVA “classica”, infatti, richiede che venga soddisfatta l’assunzione di normalità, mentre abbiamo visto che, in un contesto bayesiano, ciò non è necessario. Il bonus che abbiamo ottenuto nella presente discussione, rilassando l’ipotesi di Normalità, è stato quello di potere usare un modello statistico maggiormente “robusto” alla presenza di osservazioni anomale nel campione. L’interpretazione dei risultati dell’ANOVA bayesiana è simile a quella dell’ANOVA frequentista. Anche in questo caso, però, i risultati possono essere presentati in maniera più completa che nel caso frequentista. Anziché limitarci a presentare i valori-\\(p\\) associati ai test di ipotesi sugli effetti principali e sull’interazione, è più utile presentare, anche in maniera grafica, tutta la distribuzione a posteriori dei parametri che, in questo caso, corrispondono alle medie dei gruppi definiti dai diversi criteri di classificazione delle osservazioni che sono stati considerati.\n\n\n\n\n\n\nBergh, D. van den, Van Doorn, J., Marsman, M., Draws, T., Van Kesteren, E.-J., Derks, K., Dablander, F., Gronau, Q. F., Kucharskỳ, Š., Gupta, A. R. K. N., et al. (2020). A tutorial on conducting and interpreting a bayesian ANOVA in JASP. L’Année Psychologique, 120(1), 73–96.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi.\n\n\nHorstmann, A. C., Bock, N., Linhuber, E., Szczuka, J. M., Straßmann, C., & Krämer, N. C. (2018). Do a robot’s social skills and its objection discourage interactants from switching the robot off? PloS One, 13(7), e0201581."
  },
  {
    "objectID": "070_mod_hier.html#la-struttura-dei-dati",
    "href": "070_mod_hier.html#la-struttura-dei-dati",
    "title": "33  Modello gerarchico",
    "section": "\n33.1 La struttura dei dati",
    "text": "33.1 La struttura dei dati\nRicordiamo che una delle finalità più comuni di un modello è la specificazione delle relazioni di tipo causa-effetto, allo scopo di interpretare e prevedere i fenomeni reali. Per fare questo, è importante mettere in evidenza, da una molteplicità di informazioni ottenute su numerose unità statistiche, gli aspetti essenziali presenti nei dati. La scelta modello statistico da usare per l’analisi dipende dalle caratteristiche e dalla struttura dei dati.\nLa struttura dei dati può essere semplice o complessa, e ciò condiziona la scelta del modello statistico da usare per l’analisi.\n\nI dati a struttura semplice sono quelli per i quali non si rilevano particolari tipi di dipendenze o l’esistenza di particolari raggruppamenti delle osservazioni.\nI dati a struttura complessa sono quelli per i quali le unità statistiche si trovano suddivise in sottoinsiemi all’interno dei quali possono essere specificate ipotesi diverse sulle componenti di errore del modello statistico. Tali raggruppamenti si possono presentare a uno o più livelli.\n\nLe strutture complesse dei dati possono essere suddivise tra le cosiddette strutture nested e quelle non-nested."
  },
  {
    "objectID": "070_mod_hier.html#struttura-nested",
    "href": "070_mod_hier.html#struttura-nested",
    "title": "33  Modello gerarchico",
    "section": "\n33.2 Struttura Nested",
    "text": "33.2 Struttura Nested\nUna struttura nested è quella in cui la gerarchia comporta l’esistenza di sottoinsiemi nidificati di osservazioni. In termini matematici una struttura nested è una partizione in gruppi di un insieme di unità. Ad esempio, gli studenti della scuola elementare (livello-1) di una città, sono nested nelle classi (livello-2) in cui studiano, a loro volta nested nelle scuole di appartenenza (livello-3), nested nel distretto di riferimento (livello-4). Nel caso di dati che hanno una struttura nested, le osservazioni individuali non risultano generalmente indipendenti: gli studenti di una stessa classe tendono ad avere un livello di formazione simile, a causa dei processi di selezione o a causa della comune storia che condividono. Una caratteristica fondamentale dei dati con struttura nested è dunque che gli individui che fanno parte del medesimo gruppo sono più somiglianti fra loro rispetto a quelli appartenenti a gruppi diversi.\nUn caso particolare di struttura nested è quello delle cosiddette misure ripetute. Le misure ripetute sono un esempio di struttura gerarchica che corrisponde alla situazione nella quale la stessa variabile è misurata in più di una occasione per ogni soggetto. Nell’analisi di dati a misure ripetute gli individui possono essere pensati come unità di secondo livello e le osservazioni ripetute come unità di primo livello."
  },
  {
    "objectID": "070_mod_hier.html#struttura-non-nested",
    "href": "070_mod_hier.html#struttura-non-nested",
    "title": "33  Modello gerarchico",
    "section": "\n33.3 Struttura Non-Nested",
    "text": "33.3 Struttura Non-Nested\nI dati hanno struttura non-nested quando non è definibile una partizione. Un esempio potrebbe derivare dai dati sullo studio di una qualche forma di disagio psicologico di un insieme di persone caratterizzate dal tipo di occupazione, il luogo di residenza e il luogo di lavoro. Questo è un caso non-nested in quanto la classificazione delle unità statistiche in base alle diverse variabili sopra considerate non produce la stessa suddivisione. Nell’esempio precedente di struttura non-nested i deti vengono detti cross-classified. I dati hanno struttura cosiddetta cross-classified quando ogni unità è classificata in base a due o più criteri tra loro non ordinati gerarchicamente."
  },
  {
    "objectID": "070_mod_hier.html#ragioni-di-utilizzo-della-struttura-gerarchica",
    "href": "070_mod_hier.html#ragioni-di-utilizzo-della-struttura-gerarchica",
    "title": "33  Modello gerarchico",
    "section": "\n33.4 Ragioni di utilizzo della struttura gerarchica",
    "text": "33.4 Ragioni di utilizzo della struttura gerarchica\nÈ importante includere nella formulazione del modello i vincoli che derivano dalla struttura dei dati perché ignorare la struttura di raggruppamento sottostante porta ad una violazione del presupposto di indipendenza che alla base dei modelli che abbiamo discusso fino a questo punto: le osservazioni all’interno di un gruppo sono infatti fra loro più simili rispetto a quelle di altri gruppi. I dati che hanno una struttura gerarchica, se vengono analizzati con modelli statistici che ignorano la dipendenza tra le osservazioni può produrre conclusioni fuorvianti. La metodologia multilivello fornisce un insieme di strumenti adatti ad analizzare simultaneamente variabili classificate a livelli differenti di gerarchia, con riferimento a modelli statistici che specificano le varie possibili forme di dipendenza. I modelli multilivello sono in grado di rendere conto dei vari livelli di osservazione: quello relativo all’individuo e quello cosiddetto contestuale che deriva da aggregazioni di individui.\nStoricamente, le analisi di dati gerarchicamente organizzati sono state inizialmente realizzate mediante le tecniche standard (come l’analisi della varianza o l’analisi di regressione) spostando tutte le variabili su un solo livello di interesse. Ciò avveniva mediante due distinte procedure: aggregazione e disaggregazione. L’aggregazione è lo spostamento di variabili originariamente osservate su un livello basso della gerarchia verso un livello superiore. Al contrario, la disaggregazione è lo spostamento di variabili verso un livello più basso della gerarchia.\nMediante l’aggregazione dei dati (detta pooling) si ignora la struttura gerarchica dei dati. Si ipotizza che le differenze tra i gruppi siano spiegate solo dalle variabili esplicative \\(X\\) (covariate), ignorando i possibili effetti della struttura gerarchica nei dati. Analizzare variabili che appartengono a differenti livelli della gerarchia su un singolo e comune livello può risultare inadeguato e presentare degli inconvenienti, che diventano tanto più gravi quanto più la gerarchia è rilevante nella spiegazione del fenomeno analizzato. In particolare, l’aggregazione comporta una sostanziale perdita di informazioni e, di conseguenza, l’analisi statistica perde precisione.\nDall’altro, quando i dati vengono disaggregati (no pooling), i test statistici ordinari considerano che i valori disaggregati siano, in genere, informazioni indipendenti provenienti dall’insieme della unità di basso livello: i dati appartenenti a cluster diversi vengono analizzati separatamente. Invece, nelle situazioni in cui i dati sono gerarchicamente organizzati, i diversi cluster di dati non sono in genere indipendenti.  I test statistici tradizionali sono basati sull’assunto di indipendenza tra tutte le osservazioni, e se questa ipotesi risulta violata, le stime degli errori standard, calcolate attraverso le procedure statistiche convenzionali, risultano distorte.\nI modelli statistici che consentono di ottenere questo risultato si chiamano lineari misti, o modelli lineari gerarchici/multilivello, e sono diventati uno strumento fondamentale della ricerca sperimentale in psicologia, in linguistica e nelle scienze cognitive, dove i progetti di ricerca a misure ripetute sono la norma. In questo Capitolo esploreremo alcune tecniche che consentono di rendere conto della struttura gerarchica presente nei dati e discuteremo due esempi: il famoso problema delle otto scuole e il modello Random Intercept Model."
  },
  {
    "objectID": "070_mod_hier.html#il-problema-delle-8-scuole",
    "href": "070_mod_hier.html#il-problema-delle-8-scuole",
    "title": "33  Modello gerarchico",
    "section": "\n33.5 Il problema delle 8 scuole",
    "text": "33.5 Il problema delle 8 scuole\nIl classico problema delle otto scuole (Rubin, 1981; questo esempio è anche discusso nel Capitolo 5 di Gelman et al., 1995) fornisce uno degli esempi più semplici di dati organizzati in maniera gerarchica e viene spesso usato per illustrare l’utilità di modellazione gerarchica. Il problema considera l’efficacia dei programmi di coaching SAT condotti in parallelo in otto scuole.\n\nPer conto del Servizio Prove Educative è stato condotto uno studio per analizzare gli effetti di speciali programmi di coaching per SAT-V (Scholastic Attitude Test-Verbal) in ciascuna delle otto scuole superiori. La variabile di esito in ogni studio era il punteggio su un’amministrazione speciale del SAT-V, un test a scelta multipla standardizzato somministrato dall’Educational Testing Service e utilizzato per aiutare i college a prendere decisioni di ammissione; i punteggi possono variare tra 200 e 800, con media circa 500 e deviazione standard circa 100. Gli esami SAT sono progettati per resistere a sforzi a breve termine diretti specificamente al miglioramento delle prestazioni del test; invece sono progettati per riflettere le conoscenze acquisite e le abilità sviluppate in molti anni di istruzione. Tuttavia, ciascuna delle otto scuole in questo studio ha considerato il suo programma di coaching a breve termine molto efficace nell’aumentare i punteggi SAT. Inoltre, non vi era alcuna ragione preliminare per ritenere che uno degli otto programmi fosse più efficace di un altro o che alcuni fossero più simili negli effetti l’uno all’altro che a qualsiasi altro.\n\nPer ciascuna delle otto scuole (\\(J\\) = 8) abbiamo un effetto del trattamento stimato e un errore standard di stima dell’effetto \\(\\sigma_j\\). I dati sono i seguenti.\n\nschools <- tibble(\n  row.names = c(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"),\n  effect = c(28.39,7.94,-2.75,6.82,-.64,.63,18.01,12.16),\n  sigma = c(14.9, 10.2, 16.3, 11.0, 9.4, 11.4, 10.4, 17.6)\n)\nschools\n#> # A tibble: 8 × 3\n#>   row.names effect sigma\n#>   <chr>      <dbl> <dbl>\n#> 1 A          28.4   14.9\n#> 2 B           7.94  10.2\n#> 3 C          -2.75  16.3\n#> 4 D           6.82  11  \n#> 5 E          -0.64   9.4\n#> 6 F           0.63  11.4\n#> 7 G          18.0   10.4\n#> 8 H          12.2   17.6\n\nIniziamo calcolando una misura dell’effetto medio ponderato in cui il punteggio di ogni scuola viene ponderato in base alla precisione della misura (uno sul quadrato dell’errore standard).\n\nschools$w <- 1 / schools$sigma^2\nschools_mean <- sum(schools$w * schools$effect) / sum(schools$w)\nschools_mean\n#> [1] 7.870546\n\nUn grafico con i dati (media \\(\\pm\\) 1 SE) è fornito di seguito.\n\n\n\n\n\n\n\n\nPrima di adattare il modello gerarchico bayesiano, consideriamo due metodi non gerarchici più semplici, i quali stimando gli effetti degli otto esperimenti eseguendo un pooling completo dei dati oppure considerando le scuole come indipendenti (no pooling). Vedremo perché nessuno di questi approcci è adeguato per i dati di questo esempio.\n\n33.5.1 Modello di complete pooling\n\nUn esame superficiale dei dati potrebbe suggerire che alcuni programmi di coaching hanno effetti moderati (nell’intervallo 18–28 punti), la maggior parte ha piccoli effetti (0–12 punti) e due hanno piccoli effetti negativi; tuttavia, quando prendiamo atto degli errori standard di questi effetti stimati, vediamo che è difficile distinguere statisticamente tra i risultati di questi esperimenti. Potremmo dunque considerare i risultati degli otto esperimenti come esiti (condizionalmente) indipendenti dello stesso processo generativo. Di conseguenza potremmo decidere di procedere con un’analisi aggregata nella quale le otto scuole sono considerate come un unico campione.\n\nmodel_string <- \"\n  data {\n    int<lower=0> J; // # schools\n    array[J] real y; // estimated treatment\n    array[J] real<lower=0> sigma; // std err of effect\n  }\n  parameters {\n    real theta; // pooled school effect\n  }\n  model {\n    y ~ normal(theta, sigma);\n  }\n\"\n\nI dati in un formato appropriato per Stan sono i seguenti.\n\nschool8_dat <- list(\n  J = nrow(schools),\n  y = schools$effect,\n  sigma = schools$sigma\n)\n\nCompiliamo il modello descritto in precedenza e eseguiamo il campionamento MCMC.\n\nwriteLines(model_string, con = \"code/hmod_2.stan\")\nfile <- file.path(\"code\", \"hmod_2.stan\")\n\nmod <- cmdstan_model(file)\n\nfit2 <- mod$sample(\n  data = school8_dat,\n  iter_sampling = 20000L,\n  iter_warmup = 10000L,\n  seed = 84735,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.2 seconds.\n#> Chain 2 finished in 0.2 seconds.\n#> Chain 3 finished in 0.3 seconds.\n#> Chain 4 finished in 0.2 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.2 seconds.\n#> Total execution time: 1.4 seconds.\n\nNel caso di un’analisi per dati aggregati, la nostra incertezza sulla misura dell’effetto comune è di circa 20 punti, se utilizziamo un livello di certezza soggettiva del 95%. Visualizziamo la stima a posteriori con l’istruzione seguente, dove\n\nci_level: 0.8 (80% intervals)\nouter_level: 0.95 (95% intervals)\n\n\noutput2_stanfit <- rstan::read_stan_csv(fit2$output_files()) \nplot(output2_stanfit) + xlim(-50, 60)\n\n\n\n\n\n\n\nIn base ad un’analisi aggregata (complete pooling) concludiamo che i dati sono realizzazioni indipendenti di una v.c. \\(\\sim \\mathcal{N}(\\mu = 7.87, \\sigma = 4.20)\\).\n\nfit2$summary()\n#> # A tibble: 2 × 10\n#>   variable  mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 lp__     -2.79  -2.52 0.713 0.320 -4.23  -2.28  1.00   37470.   51279.\n#> 2 theta     7.87   7.88 4.20  4.23   0.962 14.7   1.00   28992.   44067.\n\nMa è ragionevole concludere quanto detto sopra? Un primo problema dell’analisi aggregata è che è impossibile fare inferenza sui gruppi, ovvero, nel caso presente, sugli effetti dei diversi metodi di coaching (e questa era la motivazione stessa dell’analisi).\nUn secondo problema è più strettamente statistico. Se assumiamo che il processo generativo sia \\(\\mathcal{N}(\\mu = 7.87, \\sigma = 4.20)\\), allora possiamo chiederci quale sia la probabilità di osservare i dati del campione (o valori ancora più estremi). Il valore più estremo del nostro campione è 28.4. Se il modello generativo fosse \\(\\mathcal{N}(\\mu = 7.87, \\sigma = 4.20)\\), la probabilità di osservare i dati della scuola 1 sarebbe estremamente piccola.\n\n1 - pnorm(28.4, 7.87, 4.20)\n#> [1] 5.090814e-07\n\nUn’analisi aggregata (modello di complete pooling), dunque, non è neppure in grado di rendere conto dei dati del campione osservato (ci dice che un certo dato non dovrebbe verificarsi; ma l’abbiamo osservato). Il modello di complete pooling, dunque, non sembra adeguato per i dati considerati.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n33.5.2 Modello no pooling\n\nAvendo rifiutato il modello compelte pooling, consideriamo ora il modello che si trova all’estremo opposto (modello no pooling). Eseguiamo dunque un’analisi disaggregata nella quale ogni scuola è trattata in maniera indipendente dalle altre. In linguaggio Stan, il modello no pooling può essere formulato nel modo seguente.\n\nmodel_string <- \"\n  data {\n    int<lower=0> J; // # schools\n    array[J] real y; // estimated treatment\n    array[J] real<lower=0> sigma; // std err of effect\n  }\n  parameters {\n    array[J] real theta; // school effect\n  }\n  model {\n    y ~ normal(theta, sigma);\n  }\n\"\n\nEseguiamo l’analisi.\n\nwriteLines(model_string, con = \"code/hmod_1.stan\")\nfile <- file.path(\"code\", \"hmod_1.stan\")\n\nmod <- cmdstan_model(file)\n\nfit1 <- mod$sample(\n  data = school8_dat,\n  iter_sampling = 20000L,\n  iter_warmup = 10000L,\n  seed = 84735,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.5 seconds.\n#> Chain 2 finished in 0.4 seconds.\n#> Chain 3 finished in 0.4 seconds.\n#> Chain 4 finished in 0.4 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.5 seconds.\n#> Total execution time: 2.2 seconds.\n\nI risultati sono i seguenti.\n\nfit1$summary()\n#> # A tibble: 9 × 10\n#>   variable   mean median    sd   mad      q5   q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 lp__     -3.99  -3.66   2.00  1.85  -7.78  -1.36  1.00   39035.   56040.\n#> 2 theta[1] 28.3   28.3   14.8  14.8    4.04  52.8   1.00  117783.   64274.\n#> 3 theta[2]  7.92   7.91  10.2  10.2   -8.84  24.7   1.00  116382.   62867.\n#> 4 theta[3] -2.80  -2.79  16.3  16.3  -29.6   23.9   1.00  120074.   61773.\n#> 5 theta[4]  6.83   6.85  11.0  11.0  -11.2   24.8   1.00  114806.   63734.\n#> 6 theta[5] -0.686 -0.685  9.36  9.37 -16.0   14.7   1.00  116956.   63114.\n#> 7 theta[6]  0.642  0.618 11.3  11.4  -18.0   19.3   1.00  113520.   62691.\n#> 8 theta[7] 18.0   18.0   10.5  10.5    0.656 35.2   1.00  114082.   61308.\n#> # … with 1 more row\n\nVisualizziamo l’incertezza delle stime a posteriori.\n\noutput_stanfit <- rstan::read_stan_csv(fit1$output_files()) \n\nSi vede che le stime degli effetti degli otto esperimenti producono intervalli di credibilità al 95% che sono quasi completamente sovrapposti. L’ampiezza degli intervalli, ad un grado di certezza soggettiva del 95%, è di circa 50 punti.\n\nplot(output_stanfit) + xlim(-50, 60)\n\n\n\n\n\n\n\nDal momento che ciascuna stima dipende unicamente dai dati di una singola osservazione, l’inferenza sui parametri sconosciuti del modello no pooling è estremamente rumorosa.\n\n33.5.3 Modello partial pooling\n\nAvendo concluso che i modelli complete pooling e non-pooling sono inadeguati, consideriamo ora un modello gerarchico. In generale, i modelli gerarchici sono basati sulla seguente idea: sebbene ogni gruppo sia unico, essendo stato campionato dalla stessa popolazione, tutti i gruppi sono collegati e quindi potrebbero contenere informazioni preziose l’uno sull’altro. Questa informazione gerarchica è fornita dagli iper-parametri del modello.\nLa struttura ipotizzata da un modello gerarchico per i dati considerati è la seguente. Il modello gerarchico ipotizza che il risultato di ciascuna scuola sia la realizzazione di una v.c. avente media \\(\\theta_j\\). L’oggetto dell’inferenza sono i valori \\(\\theta_j\\), con \\(i = 1, \\dots, 8\\). Il modello gerarchico ipotizza che i parametri \\(\\theta_j\\) siano tra loro legati in qualche modo. In maniera più precisa, il modello assume che \\(\\theta_j\\) siano realizzazioni casuali dei un unico processo generativo sottostante. Il modello assume che tale processo generativo abbia la seguente forma: \\(\\mathcal{N}(\\mu, \\tau)\\). I parametri \\(\\mu\\) e \\(\\tau\\) sono detti iper-parametri e condizionano i valori possibili che i parametri \\(\\theta_j\\) possono assumere. Nella versione più semplice di questo modello gerarchico, l’iper-parametro \\(\\mu\\) viene considerato ignoto ma \\(\\tau\\) viene assunto come conosciuto. Ciò conduce alla formulazione del modello partial pooling. Nel caso presente assumiamo \\(\\tau = 25\\).\nInseriamo in input a Stan l’informazione relativa a \\(\\tau\\).\n\nschool8_dat2 <- list(\n  J = nrow(schools),\n  y = schools$effect,\n  sigma = schools$sigma,\n  tau = 25\n)\n\nFormuliamo il modello di partial pooling nel modo seguente.\n\nmodel_string <- \"\n  data {\n    int<lower=0> J; // # schools\n    array[J] real y; // estimated treatment\n    array[J] real<lower=0> sigma; // std err of effect\n    real<lower=0> tau; // variance between schools\n  }\n  parameters {\n    array[J] real theta; // school effect\n    real mu; // mean for schools\n  }\n  model {\n    mu ~ normal(0, 15);\n    theta ~ normal(mu, tau);\n    y ~ normal(theta, sigma);\n  }\n\"\n\nEseguiamo l’analisi.\n\nwriteLines(model_string, con = \"code/hmod_3.stan\")\nfile <- file.path(\"code\", \"hmod_3.stan\")\n\nmod <- cmdstan_model(file)\n\nfit3 <- mod$sample(\n  data = school8_dat2,\n  iter_sampling = 20000L,\n  iter_warmup = 10000L,\n  seed = 84735,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.5 seconds.\n#> Chain 2 finished in 0.5 seconds.\n#> Chain 3 finished in 0.5 seconds.\n#> Chain 4 finished in 0.5 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.5 seconds.\n#> Total execution time: 2.3 seconds.\n\nEsaminiamo la distribuzione a posteriori delle stime dei parametri.\n\noutput3_stanfit <- rstan::read_stan_csv(fit3$output_files()) \nplot(output3_stanfit) + xlim(-50, 60)\n\n\n\n\n\n\n\nPer il modello di partial pooling, ad un livello di certezza soggettiva del 95%, le stime a posteriori dei parametri \\(\\theta_j\\) sono comprese in un intervallo pari a circa 40 punti. Si noti che, in relazione al modello no pooling, è diminuita la nostra incertezza rispetto alle stime dei parametri \\(\\theta_j\\).\n\n33.5.4 Modello gerarchico\nIl modello di partial pooling assume che la dispersione dei parametri \\(\\theta_j\\) sia conosciuta. Ma ovviamente ciò non è vero. Arriviamo così alla formulazione del modello gerarchico nel quale vengono stimati entrambi gli iper-parametri \\(\\mu\\) e \\(\\tau\\), dove \\(\\mu\\) rappresenta l’effetto medio del trattamento e \\(\\tau\\) descrive la varianza tra le scuole. Il modello gerarchico è dunque il seguente.\n\\[\n\\begin{align}\ny_j &\\sim \\mathcal{N}(\\theta_j, \\sigma_j), \\quad j = 1, \\dots, 8\\notag\\\\\n\\theta_j &\\sim \\mathcal{N}(\\mu, \\tau), \\quad j = 1, \\dots, 8\n\\end{align}\n\\]\ndove ciascun \\(\\sigma_j\\) è considerato noto.\nLo scriviamo in linguaggio Stan nel modo seguente.\n\nmodel_string <- \"\n  data {\n    int<lower=0> J; // # schools\n    array[J] real y; // estimated treatment\n    array[J] real<lower=0> sigma; // std err of effect\n  }\n  parameters {\n    array[J] real theta; // school effect\n    real mu; // mean for schools\n    real<lower=0> tau; // variance between schools\n  }\n  model {\n    mu ~ normal(0, 15);\n    tau ~ cauchy(0, 30);\n    theta ~ normal(mu, tau);\n    y ~ normal(theta, sigma);\n  }\n\"\n\nEseguiamo l’analisi.\n\nwriteLines(model_string, con = \"code/hmod_4.stan\")\nfile <- file.path(\"code\", \"hmod_4.stan\")\n\nmod <- cmdstan_model(file)\n\nfit4 <- mod$sample(\n  data = school8_dat,\n  iter_sampling = 20000L,\n  iter_warmup = 10000L,\n  seed = 84735,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 1.1 seconds.\n#> Chain 2 finished in 1.2 seconds.\n#> Chain 3 finished in 0.9 seconds.\n#> Chain 4 finished in 1.0 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 1.1 seconds.\n#> Total execution time: 4.4 seconds.\n\nLe stime dei parametri sono le seguenti.\n\noutput4_stanfit <- rstan::read_stan_csv(fit4$output_files()) \nprint(output4_stanfit, pars = c(\"theta\", \"mu\", \"tau\"), probs = c(.025, .5, .975))\n#> Inference for Stan model: hmod_4-202212211126-1-38dc66.\n#> 4 chains, each with iter=30000; warmup=10000; thin=1; \n#> post-warmup draws per chain=20000, total post-warmup draws=80000.\n#> \n#>           mean se_mean   sd   2.5%  50% 97.5% n_eff Rhat\n#> theta[1] 10.23    0.50 7.93  -2.14 9.06 29.52   248 1.02\n#> theta[2]  7.14    0.26 6.05  -4.70 6.98 19.59   536 1.01\n#> theta[3]  5.61    0.12 7.34 -10.90 5.81 19.56  3766 1.00\n#> theta[4]  6.87    0.30 6.29  -5.61 6.78 19.77   439 1.01\n#> theta[5]  4.89    0.11 6.04  -8.37 5.05 16.10  3163 1.00\n#> theta[6]  5.54    0.18 6.46  -8.42 5.61 17.88  1317 1.01\n#> theta[7]  9.49    0.48 6.66  -1.65 8.86 24.66   193 1.03\n#> theta[8]  7.60    0.22 7.35  -6.79 7.24 23.62  1159 1.01\n#> mu        6.94    0.29 4.71  -2.09 6.92 16.43   272 1.02\n#> tau       5.93    0.39 4.85   0.64 4.74 18.11   154 1.03\n#> \n#> Samples were drawn using NUTS(diag_e) at Wed Dec 21 11:26:35 2022.\n#> For each parameter, n_eff is a crude measure of effective sample size,\n#> and Rhat is the potential scale reduction factor on split chains (at \n#> convergence, Rhat=1).\n\nVisualizziamo la distribuzione a posteriori delle stime dei parametri e degli iper-parametri.\n\nplot(output4_stanfit) + xlim(-50, 60)\n\n\n\n\n\n\n\nCon un grado di certezza soggettiva del 95%, le stime a posteriori dei parametri \\(\\theta_j\\) risultano comprese in un intervallo pari a circa 30 punti. Il modello gerarchico, dunque, produce stime degli effetti \\(\\theta_j\\) a cui è associata l’incertezza più piccola rispetto a tutti gli altri casi esaminati in precedenza.\n\n33.5.5 Interpretazione\nIn conclusione, il modello gerarchico consente di ottenere stime degli effetti \\(\\theta_j\\) degli otto esperimenti più precise di quelle ottenute dal modelo non gerarchico no-pooling e dal modello gerarchico di partial pooling. Si noti inoltre che, con \\(\\tau \\rightarrow \\infty\\), le stime di un modello gerarchico diventano sempre più simili a quelle di un modello no-pooling, vale a dire, ciascuna delle stime dell’effetto del trattamento della scuola diventa via via più indipendente dalle altre stime. Con \\(\\tau \\rightarrow 0\\), le stime di un modello gerarchico diventano sempre più simili alle stime di un modello di pooling completo, vale a dire, tutti gli effetti del trattamento della scuola tendono a diventare via via più simili all’effetto medio del gruppo."
  },
  {
    "objectID": "070_mod_hier.html#modelli-lineari-ad-intercetta-casuale",
    "href": "070_mod_hier.html#modelli-lineari-ad-intercetta-casuale",
    "title": "33  Modello gerarchico",
    "section": "\n33.6 Modelli lineari ad intercetta casuale",
    "text": "33.6 Modelli lineari ad intercetta casuale\nEsaminiamo ora un modello gerarchico più complesso per l’analisi di un set di dati a misure ripetute con due condizioni. I dati sono stati raccolti da (Gibson & Wu, 2013; si veda Sorensen & Vasishth, 2015). La variabile dipendente rt dell’esperimento di Gibson & Wu (2013) è il tempo di lettura in millisecondi del soggetto di una proposizione relativa in un testo. I tempi di reazione sono stati registrati in due condizioni: in presenza di un sostantivo riferito al soggetto della proposizione, oppure in presenza di un sostantivo riferito all’oggetto della proposizione.\nI dati di Gibson & Wu (2013) provengono da un esperimento con 37 soggetti e 15 item. Gli item erano presentati in un disegno a quadrato latino (ovvero, un disegno nel quale vengono considerate tutte le combinazioni possibili), il che produce 37 \\(\\times\\) 15 = 555 dati. Risultano mancanti otto dati di un soggetto (id 27), il che porta ad un totale di 555 − 8 = 547 dati. Le prime righe del data.frame sono mostrate di seguito:\n\nrdat <- read.table(here::here(\"data\", \"gibsonwu2012data.txt\"))\nhead(rdat)\n#>    subj item     type pos word correct   rt region            type2\n#> 7     1   13  obj-ext   6 抓住       - 1140    de1  object relative\n#> 20    1    6 subj-ext   6 男孩       - 1197    de1 subject relative\n#> 32    1    5  obj-ext   6   撞       -  756    de1  object relative\n#> 44    1    9  obj-ext   6 監視       -  643    de1  object relative\n#> 60    1   14 subj-ext   6 機師       -  860    de1 subject relative\n#> 73    1    4 subj-ext   6 男孩       -  868    de1 subject relative\n\nLa manipolazione sperimentale viene descritta dalla variabile type (oppure, in maniera equivalente, dalla variabile type2). Nell’analisi, type viene ricodificata nella colonna so la quale assume valore -0.5 se il sostantivo era riferito al soggetto e +0.5 se il sostantivo era riferito all’oggetto della frase.\n\nrdat$so <- ifelse(rdat$type == \"subj-ext\", -0.5, 0.5)\nunique(rdat$so)\n#> [1]  0.5 -0.5\n\nCalcoliamo la media dei tempi di reazione su scala logaritmica e per poi ritrasformare il risultato sulla scala originale:\n\nrdat %>% \n  group_by(type2) %>% \n  summarise(\n    avg = exp(mean(log(rt), na.rm = TRUE))\n  )\n#> # A tibble: 2 × 2\n#>   type2              avg\n#>   <chr>            <dbl>\n#> 1 object relative   551.\n#> 2 subject relative  589.\n\nQuando il sostantivo si riferisce al soggetto, i tempi di reazione sono più lenti di circa 30 ms.\nQuesta descrizione dei dati, però non tiene conto né delle differenze tra i soggetti né delle differenze tra gli item. Per tenere in considerazioni queste diverse fonti della variabilità dei dati è necessario utilizzare un modello gerarchico.\n\n33.6.1 Modello ad effetti fissi\nIniziamo con un modello “ad effetti fissi” che non tiene conto della struttura gerarchica dei dati, ovvero del fatto che c’è una covariazione all’interno dei cluster definiti dalle variabili “soggetto” e “item”.\nIpotizziamo dunque di descrivere i dati mediante il seguente modello di regressione lineare:\n\\[\\begin{equation}\n\\log rt_i = \\beta_0 + \\beta_1 so_i + \\varepsilon_i.\n\\end{equation}\\]\nQuesto è il caso nel quale usiamo il modello lineare per fare inferenza sulla differenza tra le medie di due gruppi. In precedenza abbiamo codificato i due gruppi con 0 e 1. In tali circostanze \\(\\alpha\\) fornisce una stima del valore atteso della media del gruppo codificato con \\(x = 0\\) e il parametro \\(\\beta\\) fornisce una stima del valore atteso della differenza tra le medie dei due gruppi.\nLa codifica -0.5 e +0.5 per le due modalità della variabile so ha un effetto simile. Il parametro \\(\\alpha\\) del modello di regressione lineare fornisce una stima del valore atteso della media di tutti i valori \\(y\\) (trascurando la classificazione in gruppi) mentre, come in precedenza, il parametro \\(\\beta\\) fornisce una stima del valore atteso della differenza tra le medie dei due gruppi.\nI tempi di reazione (variabile dipendente rt, ovvero tempo di lettura) hanno una distribuzione caratterizzata da una forte asimmetria positiva. Se trasformiamo i dati in maniera logaritmica, i dati trasformati si distribuiscono in maniera approssimativamente Normale. In maniera equivalente, si può dire che i dati grezzi seguono la distribuzione lognormale.\nIl modello di regressione lineare assume dunque la forma seguente:\n\\[\\begin{equation}\nrt \\sim \\mbox{LogNormal}(\\beta_0 + \\beta_1 so,\\sigma).\n\\end{equation}\\]\nIn tale modello \\(\\beta_0\\) corrisponde al valore atteso della media generale di \\(\\log\\) rt e \\(\\beta_1 so\\) codifica la differenza \\(\\E(\\log rt_{o}) - \\E(\\log rt_{s})\\) quando si passa dalla condizione nella quale il sostantivo è riferito all’oggetto alla condizione nella quale il sostantivo è riferito al soggetto – valori negativi significano che i tempi di reazioni sono maggiori nella condizione s che nella condizione o.\nRicordiamo che questo non è un modello gerarchico, ma un semplice modello di regressione lineare nel quale assumiamo che la componente erratica del modello segua una distribuzione lognormale.\nIn un tale modello useremo le seguenti distribuzioni a priori:\n\\[\\begin{equation}\n\\begin{aligned}\n\\beta[1] &\\sim Normal(6, 1.5) \\\\\n\\beta[2] &\\sim Normal(0, 1.0) \\\\\n\\sigma &\\sim Cauchy(0, 1)\\\\\n\\end{aligned}\n\\end{equation}\\]\n\n\nIn Stan, il modello precedente è specificato nel modo seguente.\n\nmodelString = \"\n  data {\n    int<lower=1> N; //number of data points\n    array[N] real rt; //reading time\n    array[N] real<lower=-0.5, upper=0.5> so; //predictor\n  }\n  parameters {\n    vector[2] beta; //fixed intercept and slope\n    real<lower=0> sigma_e; //error sd\n  }\n  model {\n    real mu;\n    // likelihood\n    beta[1] ~ normal(6, 1.5);\n    beta[2] ~ normal(0, 1);\n    sigma_e ~ cauchy(0, 1);\n    for (i in 1 : N) {\n      mu = beta[1] + beta[2] * so[i];\n      rt[i] ~ lognormal(mu, sigma_e);\n    }\n  }\n\"\nwriteLines(modelString, con = \"code/fixeff_model.stan\")\n\nCompiliamo il modello.\n\nfile <- file.path(\"code\", \"fixeff_model.stan\")\nmod <- cmdstan_model(file)\n\nI dati sono contenuti nella lista stan_dat.\n\nstan_dat <- list(\n  rt = rdat$rt,\n  so = rdat$so,\n  N = nrow(rdat)\n)\n\nEseguiamo il campionamento MCMC.\n\nfit3 <- mod$sample(\n  data = stan_dat,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nOtteniamo dunque le seguenti medie a posteriori.\n\nfit3$summary()\n#> # A tibble: 4 × 10\n#>   variable       mean     median      sd     mad       q5      q95  rhat ess_b…¹\n#>   <chr>         <dbl>      <dbl>   <dbl>   <dbl>    <dbl>    <dbl> <dbl>   <dbl>\n#> 1 lp__     -2614.     -2614.     1.22    0.993   -2.62e+3 -2.61e+3  1.00   8108.\n#> 2 beta[1]      6.35       6.34   0.0121  0.0121   6.33e+0  6.37e+0  1.00  16919.\n#> 3 beta[2]     -0.0653    -0.0652 0.0241  0.0237  -1.05e-1 -2.52e-2  1.00  15675.\n#> 4 sigma_e      0.629      0.629  0.00850 0.00861  6.15e-1  6.43e-1  1.00  16349.\n#> # … with 1 more variable: ess_tail <dbl>, and abbreviated variable name\n#> #   ¹​ess_bulk\n\nTrasformiamo fit3 in un oggetto di classe stanfit.\n\nstanfit <- rstan::read_stan_csv(fit3$output_files())\n\nCalcoliamo gli intervalli di credibilità al 95%.\n\nci95 <- rstanarm::posterior_interval(\n  as.matrix(stanfit),\n  prob = 0.95\n)\nround(ci95, 3)\n#>              2.5%     97.5%\n#> beta[1]     6.321     6.369\n#> beta[2]    -0.113    -0.017\n#> sigma_e     0.613     0.646\n#> lp__    -2617.020 -2612.420\n\nSe esponenziamo i dati su scala lognormale ritorniamo alla scala dei dati grezzi. L’effetto medio, sulla scala in millisecondi, si trova dunque nel modo seguente.\n\npost <- extract(stanfit, permuted = TRUE)\nexp(mean(post$beta[, 1] + post$beta[, 2])) - exp(mean(post$beta[, 1]))\n#> [1] -35.99588\n\nSe ignoriamo la struttura gerarchica dei dati, concludiamo che l’effetto della manipolazione sperimentale corrisponde ad una differenza medie nel tempo di lettura nelle due condizioni di 36 ms, con tempi di lettura maggiore quando il sostantivo era riferito al soggetto della proposizione.\n\n33.6.2 Modello gerarchico\nUn modello non gerarchico (detto ad effetti fissi) è inappropriato per il campione di Gibson & Wu (2013) perché non tiene conto del fatto che i dati sono a misure ripetute, ovvero, con più ripetizioni per ogni soggetto e per ogni item. Il modello ad effetti usato sopra viola l’assunzione di indipendenza degli errori. Inoltre, i coefficienti di effetti fissi \\(\\beta_0\\) e \\(\\beta_1\\) rappresentano le medie calcolate aggregando i dati sulla dimensione dei soggetti e degli item. Così facendo, non si tiene in considerazione il fatto che alcuni soggetti sono più veloci e altri più lenti della media, e il fatto che alcuni item sono stati letti più velocemente e altri in maniera più lenta della media. Ovvero, il modello non considera informazioni che sono presenti nei dati.\nUn modello gerarchico, invece, rende conto delle diverse fonti di variabilità che derivano da questo disegno sperimentale, ovvero la variabilità dovuta alle differenze tra i soggetti e la variabilità dovuta alle differenze tra gli item. Per rendere conto di queste fonti di variabilità nei dati, vengono aggiunti al modello di regressione lineare due nuovi termini: \\(u_{0j}\\) e \\(w_{0k}\\). Tali termini “aggiustano” \\(\\beta_0\\) in modo tale da stimare una componente specifica della variabile risposta dovuta al soggetto \\(j\\)-esimo e all’item \\(k\\)-esimo.\nQuesta formulazione del modello scompone parzialmente la componente d’errore \\(\\varepsilon_i\\) nella somma dei termini \\(u_{0j}\\) e \\(w_{0k}\\). Geometricamente, i termini \\(u_{0j}\\) e \\(w_{0k}\\) corrispondono ad aggiustamenti dell’intercetta \\(\\beta_0\\) che sono specifici per il soggetto \\(j\\)-esimo e per l’item \\(k\\)-esimo.\nSe il soggetto \\(j\\)-esimo è più lento della media di tutti i soggetti, allora il parametro \\(u_j\\) sarà un numero positivo. Se l’item \\(k\\)-esimo viene letto più velocemente del tempo di lettura medio di tutti gli item, allora il parametro \\(w_k\\) sarà un numero negativo. Viene stimato un aggiustamento \\(u_{0j}\\) per ogni soggetto \\(j\\)-esimo e un aggiustamento \\(w_{0k}\\) per ogni item \\(k\\)-esimo. I parametri \\(u_{0j}\\) e \\(w_{0k}\\) sono chiamati random intercepts o varying intercepts (Gelman et al., 2020). L’aggiustamento di \\(\\beta_0\\) mediante \\(u_{0j}\\) e \\(w_{0k}\\) consente dunque di tenere in considerazione la struttura gerarchica dei dati, ovvero consente di stimare la quota di variabilità dovuta ai soggetti e agli item.\nIl random intercept model assume che gli aggiustamenti \\(u_{0j}\\) e \\(w_{0k}\\) siano distribuiti normalmente attorno allo zero con una deviazione standard sconosciuta:\n\\[\nu_0 ∼ \\mathcal{N}(0, \\sigma_u),\n\\]\n\\[\nw_0 ∼ \\mathcal{N}(0, \\sigma_w).\n\\]\nIl modello include dunque tre fonti di varianza:\n\nla deviazione standard degli errori \\(\\sigma_e\\),\nla deviazione standard delle random intercepts per i soggetti, \\(\\sigma_u\\),\nla deviazione standard delle random intercepts per gli item, \\(\\sigma_w\\).\n\nQueste tre fonti di variabilità sono dette componenti della varianza. Possiamo dunque scrivere il modello nel modo seguente:\n\\[\\begin{equation}\n\\log rt_{ijk} = \\beta_0 + \\beta_1 so_i + u_{0j} + w_{0k} + \\varepsilon_{ijk}.\n\\end{equation}\\]\nIl coefficiente \\(\\beta_1\\) è il parametro di interesse primario. Come conseguenza della codifica usata, avrà il valore \\(-\\beta_1\\) nella condizione in cui il sostantivo è riferito al soggetto e \\(+\\beta_1\\) nella condizione in cui il sostantivo è riferito all’oggetto della frase.\nIn Stan il modello viene formulato nel modo seguente.\n\nmodelString = \"\n  data {\n    int<lower=1> N; //number of data points\n    array[N] real rt; //reading time\n    array[N] real<lower=-0.5, upper=0.5> so; //predictor\n    int<lower=1> J; //number of subjects\n    int<lower=1> K; //number of items\n    array[N] int<lower=1, upper=J> subj; //subject id\n    array[N] int<lower=1, upper=K> item; //item id\n  }\n  parameters {\n    vector[2] beta; //fixed intercept and slope\n    vector[J] u; //subject intercepts\n    vector[K] w; //item intercepts\n    real<lower=0> sigma_e; //error sd\n    real<lower=0> sigma_u; //subj sd\n    real<lower=0> sigma_w; //item sd\n  }\n  model {\n    real mu;\n    //priors\n    u ~ normal(0, sigma_u); //subj random effects\n    w ~ normal(0, sigma_w); //item random effects\n    // likelihood\n    for (i in 1 : N) {\n      mu = beta[1] + u[subj[i]] + w[item[i]] + beta[2] * so[i];\n      rt[i] ~ lognormal(mu, sigma_e);\n    }\n  }\n\"\nwriteLines(modelString, con = \"code/random_intercepts_model.stan\")\n\nCompiliamo il modello.\n\nfile <- file.path(\"code\", \"random_intercepts_model.stan\")\nmod <- cmdstan_model(file)\n\nI dati nel formato appropriato per Stan sono i seguenti.\n\nstan_dat <- list(\n  subj = as.integer(as.factor(rdat$subj)),\n  item = as.integer(as.factor(rdat$item)),\n  rt = rdat$rt,\n  so = rdat$so,\n  N = nrow(rdat),\n  J = length(unique(rdat$subj)),\n  K = length(unique(rdat$item))\n)\n\nEseguiamo il campionamento MCMC.\n\nfit4 <- mod$sample(\n  data = stan_dat,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\nTrasformiamo l’oggetto fit4 in un oggetto di classe stanfit.\n\noutput4_stanfit <- rstan::read_stan_csv(fit4$output_files())\n\nLe medie a posteriori dei parametri si ottengono nel modo seguente.\n\nfit4$summary(c(\"beta\", \"sigma_e\", \"sigma_w\", \"sigma_u\"))\n#> # A tibble: 5 × 10\n#>   variable    mean  median      sd     mad      q5     q95  rhat ess_b…¹ ess_t…²\n#>   <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>\n#> 1 beta[1]   6.35    6.35   0.0512  0.0511   6.26    6.43    1.00   1413.   2607.\n#> 2 beta[2]  -0.0604 -0.0604 0.0220  0.0218  -0.0974 -0.0243  1.00  17390.  12616.\n#> 3 sigma_e   0.577   0.577  0.00792 0.00784  0.564   0.590   1.00  17746.  12770.\n#> 4 sigma_w   0.120   0.115  0.0291  0.0263   0.0806  0.173   1.00   8584.   8022.\n#> 5 sigma_u   0.238   0.235  0.0319  0.0304   0.191   0.293   1.00  11445.  10961.\n#> # … with abbreviated variable names ¹​ess_bulk, ²​ess_tail\n\nGli intervalli di credibilità al 95% sono i seguenti.\n\nci95 <- rstanarm::posterior_interval(\n  as.matrix(output4_stanfit),\n  prob = 0.95\n)\nround(ci95, 3)\n#>              2.5%     97.5%\n#> beta[1]     6.247     6.447\n#> beta[2]    -0.104    -0.017\n#> u[1]       -0.208     0.081\n#> u[2]       -0.304    -0.012\n#> u[3]       -0.127     0.163\n#> u[4]       -0.212     0.079\n#> u[5]       -0.079     0.216\n#> u[6]       -0.049     0.239\n#> u[7]       -0.162     0.131\n#> u[8]       -0.124     0.168\n#> u[9]       -0.097     0.196\n#> u[10]      -0.009     0.283\n#> u[11]       0.450     0.745\n#> u[12]       0.149     0.443\n#> u[13]      -0.169     0.123\n#> u[14]      -0.151     0.140\n#> u[15]       0.035     0.324\n#> u[16]      -0.199     0.089\n#> u[17]      -0.716    -0.418\n#> u[18]      -0.417    -0.127\n#> u[19]      -0.295     0.003\n#> u[20]       0.162     0.452\n#> u[21]       0.050     0.341\n#> u[22]       0.123     0.418\n#> u[23]      -0.197     0.096\n#> u[24]      -0.084     0.293\n#> u[25]       0.000     0.292\n#> u[26]      -0.494    -0.203\n#> u[27]      -0.233     0.059\n#> u[28]      -0.332    -0.038\n#> u[29]      -0.423    -0.127\n#> u[30]      -0.406    -0.113\n#> u[31]      -0.100     0.188\n#> u[32]      -0.178     0.113\n#> u[33]      -0.239     0.056\n#> u[34]       0.257     0.554\n#> u[35]      -0.396    -0.104\n#> u[36]      -0.144     0.145\n#> u[37]      -0.171     0.118\n#> w[1]       -0.133     0.061\n#> w[2]       -0.118     0.075\n#> w[3]       -0.101     0.093\n#> w[4]       -0.213    -0.015\n#> w[5]       -0.006     0.190\n#> w[6]       -0.141     0.056\n#> w[7]       -0.281    -0.082\n#> w[8]        0.115     0.315\n#> w[9]       -0.185     0.009\n#> w[10]      -0.041     0.153\n#> w[11]      -0.136     0.058\n#> w[12]      -0.030     0.165\n#> w[13]      -0.176     0.018\n#> w[14]       0.036     0.235\n#> w[15]      -0.041     0.155\n#> sigma_e     0.562     0.593\n#> sigma_u     0.183     0.309\n#> sigma_w     0.076     0.188\n#> lp__    -2332.580 -2311.210\n\nSi noti il grande numero di parametri che vengono stimati dal modello gerarchico, anche nel caso del modello a intercette casuali, ovvero, nel caso del modello gerarchico più semplice. Questo esempio fa capire la necessità di utilizzare gli algoritmi MCMC: con un numero di parametri da stimare così grande è fuori considerazione l’idea di stimare i parametri mediante un metodo numerico basato su griglia. Inoltre, nel caso di un modello così complesso, una soluzione analitica della distribuzione a posteriori dei parametri non è disponibile.\nNel caso presente, la stima dell’effetto della manipolazione sperimentale ottenuta mediante un modello gerarchico ad intercette random è molto simile alla stima ottenuta con il modello che analizza i dati aggregati.\n\npost <- extract(output4_stanfit, permuted = TRUE)\nexp(mean(post$beta[, 1] + post$beta[, 2])) - exp(mean(post$beta[, 1]))\n#> [1] -33.43351\n\nL’intervallo di credibilità a posteriori per il modello gerarchico ad intercette random, in questo campione, è leggermente più piccolo di quello ottenuto mediante l’analisi dei dati aggregati.\nSi noti che la varianza trovata con il modello per dati aggregati\n\n0.6291826^2\n#> [1] 0.3958707\n\nviene ora decomposta nella somma di tre componenti\n\n0.57721890^2 + 0.11961706^2 + 0.23762983^2\n#> [1] 0.4039578\n\nQuindi, il modello gerarchico ci fornisce più informazioni di un’analisi basata sui dati aggregati. Per esempio, l’analisi presente ci consente di dire che la variabilità dei tempi di reazione dovuta alle differenze tra i soggetti è di entità circa doppia rispetto alla variabilità attribuibile alle differenze tra gli item."
  },
  {
    "objectID": "070_mod_hier.html#commenti-e-considerazioni-finali",
    "href": "070_mod_hier.html#commenti-e-considerazioni-finali",
    "title": "33  Modello gerarchico",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa descrizione dettagliata della soluzione del problema delle otto scuole ha messo in evidenza un aspetto importante che deriva dall’uso dei modelli gerarchici: in un modello gerarchico, le stime degli effetti (qui chiamate \\(\\theta_j\\), ovvero l’effetto del diverso tipo di coaching per ciascuna scuola) assumono valori più simili alla media generale di quanto non lo facciano quando gli effetti \\(\\theta_j\\) vengono stimati da un modello no pooling. Questo fenomeno è detto effetto shrinkage.\nÈ importante considerare due caratteristiche dell’effetto shrinkage.\n\nL’effetto shrinkage aumenta quando diminuisce il numero di osservazioni in ciascun gruppo \\(j\\)-esimo. Cioè, ci affidiamo sempre di più alle tendenze globali per stimare le proprietà di un gruppo per il quale abbiamo pochi dati.\nL’effetto shrinkage aumenta quando è è grande la variabilità all’interno dei gruppi, \\(\\sigma_y\\), rispetto alla variabilità tra i gruppi, \\(\\sigma_\\mu\\). Cioè, ci affidiamo sempre di più alle tendenze globali per per stimare le proprietà di un gruppo quando è difficile distinguere le proprietà di un gruppo da quelle di un altro gruppo.\n\nQuesto ci fa capire che, trovando un equilibrio tra pooling completo e no pooling, i modelli gerarchici consentono di:\n\ngeneralizzare le osservazioni sui nostri gruppi campionati alla popolazione più ampia; - prendere in prestito informazioni da tutti i gruppi campionati quando si vogliono conoscere le proprietà di un singolo gruppo campionato.\n\nLe stime prodotte dai modelli con pooling completo tendono ad avere una distorsione (bias) alta e una varianza piccola; le stime prodotte dai modelli senza pooling tendono ad avere una distorsione bassa e una varianza grande. I modelli gerarchici offrono un equilibrio tra questi due estremi:\n\na differenza dei modelli a pooling completo, i modelli gerarchici tengono conto delle tendenze specifiche dei gruppi e quindi offrono una minore distorsione del fenomeno da descrivere;\na differenza dei modelli no pooling, i modelli gerarchici tengono conto delle tendenze globali e quindi offrono delle stime meno variabili da campione a campione.\n\n\n\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\n\n\nGibson, E., & Wu, H.-H. I. (2013). Processing chinese relative clauses in context. Language and Cognitive Processes, 28(1-2), 125–155.\n\n\nRubin, D. B. (1981). Estimation in parallel randomized experiments. Journal of Educational Statistics, 6(4), 377–401.\n\n\nSorensen, T., & Vasishth, S. (2015). Bayesian linear mixed models using stan: A tutorial for psychologists, linguists, and cognitive scientists. arXiv Preprint arXiv:1506.06201."
  },
  {
    "objectID": "071_mod_hier_sim.html#modello-generativo-dei-dati",
    "href": "071_mod_hier_sim.html#modello-generativo-dei-dati",
    "title": "34  Modello gerarchico: simulazioni",
    "section": "\n34.1 Modello generativo dei dati",
    "text": "34.1 Modello generativo dei dati\nI modelli bayesiani sono “generativi”, ovvero rappresentano il processo generativo dei dati e, dunque, essi stessi possono essere usati per generare campioni di dati. Per introdurre questo aspetto, consideriamo il modello più semplice, ovvero il modello Normale descritto in precedenza. Le osservazioni per tale modello corrispondono alle osservazioni di N individui contenuti nel vettore y. Il modello assume che y segua la legge Normale di media mu e deviazione standard sigma.\n\nmodel_string <- \"\n  data {\n    int<lower=1> N;\n    vector[N] y;\n  }\n  parameters {\n    real mu;\n    real<lower=0> tau;\n  }\n  model {\n    mu ~ normal(0, 5);\n    tau ~ normal(0, 5);\n    y ~ normal(mu, tau);\n  }\n\"\n\nCompiliamo il modello.\n\nwriteLines(model_string, con = \"code/flat_regression.stan\")\nfile1 <- file.path(\"code\", \"flat_regression.stan\")\nmod1 <- cmdstan_model(file1)\n\nFissati i parametri, il modello precedente può essere usato per generare campioni di dati. A questo fine dobbiamo specificare solo i blocchi data e generated quantities, come indicato qui sotto. La funzione normal_rng(mu, tau) è il corrispondente in linguaggio Stan della funzione rnorm() in \\(\\mathsf{R}\\).\n\nmodel2_string <- \"\n  data {\n    int<lower=1> N;\n    real mu; \n    real<lower=0> tau; \n  }\n  generated quantities {\n    vector[N] y;\n    \n    for (n in 1 : N) {\n      y[n] = normal_rng(mu, tau);\n    }\n  }\n\"\n\nCompiliamo il modello.\n\nwriteLines(model2_string, con = \"code/generate_flat_data.stan\")\nfile2 <- file.path(\"code\", \"generate_flat_data.stan\")\nmod2 <- cmdstan_model(file2)\n\nSpecifichiamo ora i valori dei parametri indicati qui sotto.\n\n# Specify data and parameter values.\nsim_values <- list(\n  N = 100, # Number of observations.\n  mu = 5,  # Mean of the regression.\n  tau = 1  # Variance of the regression.\n)\n\nUtilizziamo cmdstan per generare 1,000 campioni di 100 osservazioni ciascuno.\n\nsim_data <- mod2$sample(\n  data = sim_values,\n  chains = 1,\n  seed = 42,\n  fixed_param = TRUE\n)\n#> Running MCMC with 1 chain...\n#> \n#> Chain 1 Iteration:   1 / 1000 [  0%]  (Sampling) \n#> Chain 1 Iteration: 100 / 1000 [ 10%]  (Sampling) \n#> Chain 1 Iteration: 200 / 1000 [ 20%]  (Sampling) \n#> Chain 1 Iteration: 300 / 1000 [ 30%]  (Sampling) \n#> Chain 1 Iteration: 400 / 1000 [ 40%]  (Sampling) \n#> Chain 1 Iteration: 500 / 1000 [ 50%]  (Sampling) \n#> Chain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) \n#> Chain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) \n#> Chain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \n#> Chain 1 finished in 0.0 seconds.\n\nRecuperiamo i 1,000 campioni di 100 osservazioni generati dal modello.\n\nsim_data_stanfit <- rstan::read_stan_csv(sim_data$output_files()) \nfake_data_matrix  <- sim_data_stanfit %>% \n  as.data.frame %>% \n  dplyr::select(contains(\"y\"))\n\ndim(fake_data_matrix)\n#> [1] 1000  100\n\nRecuperiamo i dati di un singolo campione.\n\nsim_y <- fake_data_matrix[1, ]\nas.numeric(sim_y)\n#>   [1] 4.92727 6.07489 5.62040 5.64771 6.18387 5.49394 4.54341 5.73332 4.88385\n#>  [10] 3.80247 5.53683 3.79003 6.13880 5.10517 4.51741 3.23568 5.47868 5.14018\n#>  [19] 5.93248 3.68679 2.64747 3.96661 6.66431 4.25740 3.80611 5.00020 2.10804\n#>  [28] 3.30112 3.12263 6.68139 4.79380 3.79871 6.56535 4.59639 3.22918 5.69388\n#>  [37] 4.43925 5.20007 5.62791 6.45734 4.99799 5.62754 4.20319 5.11804 4.41627\n#>  [46] 3.76769 4.37040 5.87306 6.33207 6.40474 3.55891 5.80308 5.34626 5.84671\n#>  [55] 3.02968 5.36073 4.66595 4.98986 7.56634 5.09770 5.08534 5.42343 3.78727\n#>  [64] 3.09178 4.05891 5.65567 4.68312 6.45040 5.30334 7.06159 4.11758 5.38201\n#>  [73] 5.30722 4.82675 7.39546 5.18963 2.42694 4.73127 5.86768 4.49791 5.27013\n#>  [82] 3.04167 6.70704 5.44426 4.05945 3.88011 5.88271 5.56971 4.92103 5.62393\n#>  [91] 5.66139 4.77127 3.75681 4.98407 5.41049 6.23022 5.73609 6.35978 4.95185\n#> [100] 4.43508\n\nPossiamo ora usare il modello flat_regression.stan per stimare i parametri che abbiamo utilizzato per generare i dati. Sistemiamo i 100 valori simulati in una lista.\n\n# Specify data.\ndata <- list(\n  N = length(sim_y),   # Number of observations.\n  y = as.numeric(sim_y) # Vector of observations.\n)\n\nOtteniamo i campioni dalla distribuzione a posteriori dei parametri del modello.\n\nfit <- mod1$sample(\n  data = data,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.1 seconds.\n#> Chain 2 finished in 0.1 seconds.\n#> Chain 3 finished in 0.1 seconds.\n#> Chain 4 finished in 0.1 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.1 seconds.\n#> Total execution time: 0.7 seconds.\n\nEsaminiamo le medie a posteriori dei parametri \\(\\mu\\) e \\(\\tau\\).\n\nfit$summary()\n#> # A tibble: 3 × 10\n#>   variable   mean median     sd    mad      q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 lp__     -61.1  -60.8  1.02   0.728  -63.2   -60.2   1.00    7655.    8226.\n#> 2 mu         4.99   4.99 0.114  0.113    4.80    5.17  1.00   12532.   10226.\n#> 3 tau        1.12   1.12 0.0807 0.0795   0.998   1.26  1.00   11652.   10121.\n\nLe medie a posteriori sono molto simili al vero valore dei parametri.\nEsaminiamo la convergenza delle catene di Markov.\n\nfit_stanfit <- rstan::read_stan_csv(fit$output_files()) \n\nfit_stanfit %>%\n  mcmc_trace(\n    pars = c(\"mu\", \"tau\"),\n    n_warmup = 2000,\n    facet_args = list(nrow = 2, labeller = label_parsed)\n  )\n\n\n\n\n\n\n\nEsaminiamo graficamente la distribuzioni a posteriori dei parametri.\n\npar_values <- tibble(\n  .variable = c(\"mu\", \"tau\"),\n  values = c(sim_values$mu, sim_values$tau),\n)\npar_values\n#> # A tibble: 2 × 2\n#>   .variable values\n#>   <chr>      <dbl>\n#> 1 mu             5\n#> 2 tau            1\n\n\nfit_stanfit %>%\n  gather_draws(mu, tau) %>%\n  ggplot(aes(x = .value, y = .variable)) +\n  geom_halfeyeh(.width = .95) +\n  geom_vline(aes(xintercept = values), par_values, color = \"red\") +\n  facet_wrap(\n    ~ .variable,\n    nrow = 2,\n    scales = \"free\"\n  )\n\n\n\n\n\n\n\nPossiamo concludere che gli intervalli di credibilità a posteriori del 95% contengono i veri valori dei parametri (in rosso) che sono stati utilizzati per simulare i dati. In questo modello non gerarchico, dunque, il processo di inferenza bayesiana ottiene il risultato desiderato."
  },
  {
    "objectID": "071_mod_hier_sim.html#modello-gerarchico",
    "href": "071_mod_hier_sim.html#modello-gerarchico",
    "title": "34  Modello gerarchico: simulazioni",
    "section": "\n34.2 Modello gerarchico",
    "text": "34.2 Modello gerarchico\nSupponiamo ora che i dati abbiano una struttura complessa, ovvero siano organizzati in cluster (ad esempio, bambini in scuole diverse). In linguaggio Stan il modello gerarchico può essere scritto nel modo seguente.\n\nmodel3_string <- \"\n  // Index values and observations.\n  data {\n    int<lower=1> N; // Number of observations.\n    int<lower=1> K; // Number of groups.\n    vector[N] y; // Vector of observations.\n    array[N] int<lower=1, upper=K> g; // Vector of group assignments.\n  }\n  // Parameters and hyperparameters.\n  parameters {\n    real mu; // Mean of the population model.\n    real<lower=0> tau; // Variance of the population model.\n    vector[K] beta; // Vector of group intercepts.\n    real<lower=0> sigma; // Variance of the likelihood.\n  }\n  // Hierarchical regression.\n  model {\n    // Hyperpriors.\n    mu ~ normal(0, 5);\n    tau ~ normal(0, 5);\n    \n    // Prior.\n    sigma ~ normal(0, 5);\n    \n    // Population model and likelihood.\n    beta ~ normal(mu, tau);\n    for (n in 1 : N) {\n      y[n] ~ normal(beta[g[n]], sigma);\n    }\n  }\n\"\n\nNel blocco data ora abbiamo un vettore g che indica a quale dei K gruppi appartiene ciascuno degli N individui nel campione. Nel blocco parameters, abbiamo un vettore K-dimensionale di parametri beta che specifica una media separata per ciascuno dei K gruppi di osservazioni. Nel blocco model possiamo vedere che la verosimiglianza delle osservazioni (ora all’interno di un ciclo for) è ancora assunta essere normale, ma ora il punteggio di ogni individuo ha una media diversa e pari a beta che è specifica per il gruppo a cui l’individuo appartiene. Lo statement beta ~ normal(mu, tau) ci dice che i coefficienti beta specifici al gruppo sono tratti da una popolazione che si presume normale con una media mu e deviazione standard tau.\nIl modello specifica dunque una struttura gerarchica: ci sono due livelli nel nostro modello, il modello a livello inferiore specifica la verosimiglianza delle osservazioni, mentre il modello al livello superiore specifica le proprietà della popolazione. Infine, il modello include le distribuzioni a priori sui parametri della popolazione (formalmente indicati come hyper-priors, poiché sono le distribuzioni a priori delle distribuzioni a priori). Per gli iper-parametri mu e tau vengono ipotizzate distribuzioni a priori Normali. Infine, alla deviazione standard della verosimiglianza, ora chiamata sigma, viene imposta una distribuzione a priori Normale.\nCome in precedenza, dallo script precedente possiamo derivare un nuovo script che contiene il modello generativo dei dati.\n\nmodel4_string <- \"\n  // Index and hyperparameter values.\n  data {\n    int<lower=1> N; // Number of observations.\n    int<lower=1> K; // Number of groups.\n    array[N] int<lower=1, upper=K> g; // Vector of group assignments.\n    real mu; // Mean of the population model.\n    real<lower=0> tau; // Variance of the population model.\n    real<lower=0> sigma; // Variance of the likelihood.\n  }\n  // Generate data according to the hierarchical regression.\n  generated quantities {\n    vector[N] y; // Vector of observations.\n    vector[K] beta; // Vector of group intercepts.\n    \n    // Draw parameter values and generate data.\n    for (k in 1 : K) {\n      beta[k] = normal_rng(mu, tau);\n    }\n    for (n in 1 : N) {\n      y[n] = normal_rng(beta[g[n]], sigma);\n    }\n  }\n\"\n\nSpecifichiamo i valori degli iper-parametri.\n\nsim4_values <- list(\n  N = 100,                            # Number of observations.\n  K = 5,                              # Number of groups.\n  g = sample(5, 100, replace = TRUE), # Vector of group assignments.\n  mu = 5,                             # Mean of the population model.\n  tau = 1,                            # Variance of the population model.\n  sigma = 1                           # Variance of the likelihood.\n)\n\nCompiliamo il modello.\n\nwriteLines(model4_string, con = \"code/generate_hierarchical_data_01.stan\")\nfile4 <- file.path(\"code\", \"generate_hierarchical_data_01.stan\")\nmod4 <- cmdstan_model(file4)\n\nUtilizziamo cmdstan per generare 1,000 campioni di 100 osservazioni ciascuno.\n\nsim4_data <- mod4$sample(\n  data = sim4_values,\n  chains = 1,\n  fixed_param = TRUE\n)\n#> Running MCMC with 1 chain...\n#> \n#> Chain 1 Iteration:   1 / 1000 [  0%]  (Sampling) \n#> Chain 1 Iteration: 100 / 1000 [ 10%]  (Sampling) \n#> Chain 1 Iteration: 200 / 1000 [ 20%]  (Sampling) \n#> Chain 1 Iteration: 300 / 1000 [ 30%]  (Sampling) \n#> Chain 1 Iteration: 400 / 1000 [ 40%]  (Sampling) \n#> Chain 1 Iteration: 500 / 1000 [ 50%]  (Sampling) \n#> Chain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) \n#> Chain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) \n#> Chain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \n#> Chain 1 finished in 0.0 seconds.\n\nRecuperiamo i 1,000 campioni di 100 osservazioni generati dal modello.\n\nsim4_data_stanfit <- rstan::read_stan_csv(sim4_data$output_files()) \nfake_data4_matrix  <- sim4_data_stanfit %>% \n  as.data.frame %>% \n  dplyr::select(contains(\"y\"))\n\ndim(fake_data4_matrix)\n#> [1] 1000  100\n\nSelezioniamo i dati di un singolo campione.\n\nsim4_y <- fake_data4_matrix[1, ]\ndim(sim4_y)\n#> [1]   1 100\n\nSeleziono i valori beta.\n\nfake_beta_matrix  <- sim4_data_stanfit %>% \n  as.data.frame %>% \n  dplyr::select(contains(\"beta\"))\n\nIsolo i valori beta del primo campione di dati simulati.\n\nsim4_beta <- fake_beta_matrix[1, ]\n\nPossiamo ora testare il nostro modello gerarchico utilizzando i dati simulati.\n\ndata3 <- list(\n  N = length(sim4_y),     # Number of observations.\n  K = sim4_values$K,      # Number of groups.\n  y = as.numeric(sim4_y), # Vector of observations.\n  g = sim4_values$g       # Vector of group assignments.\n)\n\nOtteniamo i campioni dalla distribuzione a posteriori dei parametri del modello.\n\nwriteLines(model3_string, con = \"code/hierarchical_regression_01.stan\")\nfile3 <- file.path(\"code\", \"hierarchical_regression_01.stan\")\nmod3 <- cmdstan_model(file3)\n\nfit3 <- mod3$sample(\n  data = data3,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.3 seconds.\n#> Chain 2 finished in 0.3 seconds.\n#> Chain 3 finished in 0.3 seconds.\n#> Chain 4 finished in 0.3 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.3 seconds.\n#> Total execution time: 1.3 seconds.\n\nEsaminiamo la convergenza delle catene di Markov.\n\nfit3_stanfit <- rstan::read_stan_csv(fit3$output_files()) \n\nfit3_stanfit %>%\n  mcmc_trace(\n    pars = c(\"mu\", \"tau\", str_c(\"beta[\", 1:data3$K, \"]\"), \"sigma\"),\n    n_warmup = 2000,\n    facet_args = list(nrow = 5, labeller = label_parsed)\n  )\n\n\n\n\n\n\n\nEsaminiamo graficamente la distribuzioni a posteriori dei parametri.\n\n# Recover parameter values.\nhyper_par_values <- tibble(\n  .variable = c(\"mu\", \"tau\", \"sigma\"),\n  values = c(sim4_values$mu, sim4_values$tau, sim4_values$sigma)\n)\n\nfit3_stanfit %>%\n  gather_draws(mu, tau, sigma) %>%\n  ggplot(aes(x = .value, y = .variable)) +\n  geom_halfeyeh(.width = .95) +\n  geom_vline(aes(xintercept = values), hyper_par_values, color = \"red\") +\n  facet_wrap(\n    ~ .variable,\n    nrow = 2,\n    scales = \"free\"\n  )\n\n\n\n\n\n\n\nConsideriamo anche gli intervalli di credibilità al 95% per i parametri beta.\n\nbroom.mixed::tidyMCMC(\n  fit3_stanfit, \n  conf.level = 0.95,\n  conf.int = TRUE, \n  conf.method = \"HPDinterval\", \n  pars = c(\"beta\")\n)\n#> # A tibble: 5 × 5\n#>   term    estimate std.error conf.low conf.high\n#>   <chr>      <dbl>     <dbl>    <dbl>     <dbl>\n#> 1 beta[1]     4.84     0.211     4.44      5.27\n#> 2 beta[2]     4.35     0.225     3.91      4.78\n#> 3 beta[3]     6.22     0.259     5.72      6.73\n#> 4 beta[4]     5.38     0.263     4.87      5.90\n#> 5 beta[5]     3.15     0.210     2.74      3.56\n\nI valori usati nella simulazione sono i seguenti.\n\nsim4_beta\n#>   beta[1] beta[2] beta[3] beta[4] beta[5]\n#> 1 5.00552 4.51655 6.25045 5.08532 3.01116\n\nIn conclusione, anche il modello gerarchico è in grado di recuperare accuratamente il valore dei parametri usati nella simulazione per creare i dati."
  },
  {
    "objectID": "071_mod_hier_sim.html#commenti-e-considerazioni-finali",
    "href": "071_mod_hier_sim.html#commenti-e-considerazioni-finali",
    "title": "34  Modello gerarchico: simulazioni",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nI modelli gerarchici forniscono una soluzione che è una via di mezzo tra l’assenza di aggregazione delle informazioni (ovvero, modelli non gerarchici separati per ciascun gruppo) e la completa aggregazione delle informazioni (ovvero, modelli che uniscono tutte le osservazioni in un unico campione e non distinguono tra i gruppi). I modelli gerarchici consentono di modellare in modo appropriato le differenze tra gruppi di osservazioni. Data la prevalenza di situazioni di questo tipo in psicologia, i modelli gerarchici dovrebbero rappresentare il punto di partenza nella maggior parte delle analisi dei dati psicologici. Stan consente di svolgere in maniera semplice i calcoli necessari per fare inferenza in situazioni di questo tipo."
  },
  {
    "objectID": "090_entropy.html#la-generalizzabilità-dei-modelli",
    "href": "090_entropy.html#la-generalizzabilità-dei-modelli",
    "title": "35  Entropia",
    "section": "\n35.1 La generalizzabilità dei modelli",
    "text": "35.1 La generalizzabilità dei modelli\nSecondo Johnson et al. (2022), nel valutare un modello, il ricercatore deve porsi tre domande critiche.\n\nQuali conseguenze più ampie derivano dall’inferenza? Come e chi ha raccolto i dati? Colui che svolge la ricerca otterrebbe di benefici manipolando i dati (escludendo delle osservazioni; selezionando il campione)? Che impatto hanno inferenze che vengono tratte dai dati sugli individui e sulla società? Quali pregiudizi o strutture di potere possono essere coinvolti in questa analisi?\nChe tipo di distorsioni sistematiche potrebbero essere presenti nell’analisi statistica? Ricordiamo la famosa citazione di George Box: “Tutti i modelli sono sbagliati, ma alcuni sono utili”. È dunque importante sapere quanto è sbagliato il modello. Le assunzioni che stanno alla base del modello sono ragionevoli? Il meccanismo generatore dei dati che è stato ipotizzato è adeguato per il fenomeno in esame?\nQuanto è accurato il modello? Quanto sono lontane dalla realtà le previsioni del modello?\n\nPer approfondire questi temi, si rinvia al testo di Johnson et al. (2022). Qui ci concentreremo su uno dei temi critici relativa alla validità di un modello, ovvero sul tema della generalizzabilità del modello.\nNella scienza l’utilità di una teoria viene verificata esaminando la corrispondenza tra predizioni teoriche e osservazioni. Se vi sono discrepanze significative tra predizioni e osservazioni ciò suggerisce che la teoria, o nella nostra visione più ristretta, il modello statistico, è poco utile. Il problema della capacità predittiva del modello non riguarda soltanto l’adeguatezza del modello in riferimento ad uno specifico campione di dati, ma riguarda anche la capacità di un modello statistico sviluppato in un campione di dati di ben adattarsi ad altri campioni della stessa popolazione.\nIn generale, i modelli statistici tendono a non generalizzarsi bene a un nuovo campione; questo perché sfruttano le caratteristiche specifiche dei dati del campione e tendono a produrre risultati eccessivamente ottimistici (cioè le dimensioni dell’effetto) che sovrastimano la dimensione dell’effetto atteso sia nella popolazione che in nuovi campioni. Benché i problemi della generalizzabilità dei modelli e il metodo chiave per valutarli – ovvero, la convalida incrociata (cross-validation) – siano stati discussi sin dagli esordi della letteratura psicometrica (Lord, 1950), tali temi sono stati sottovalutati nella formazione psicologica contemporanea e nella ricerca. Tuttavia, questi concetti diventeranno sempre più importanti considerata l’enfasi corrente sulla necessità di condurre ricerche replicabili. Un’introduzione a questi temi è fornita, da esempio, da Song et al. (2021). Nello specifico, Song et al. (2021) mostrano che un modello che viene adattato a un campione (campione di calibrazione) non si generalizza bene a un altro campione (campione di convalida): la capacità predittiva del modello è minore quando il modello viene applicato al campione di convalida piuttosto che al campione di calibrazione. Questo problema è detto sovra-adattamento (overfitting). In generale, Song et al. (2021) mostrano come la capacità di generalizzazione del modello diminuisce (a) all’aumentare della complessità del modello, (b) al diminuire dell’ampiezza del campione di calibrazione, e (c) al diminuire della dimensione dell’effetto nella popolazione.\nSebbene i modelli statistici producono comunemente un sovra-adattamento, è anche possibile che essi producano un sotto-adattamento (underfitting) dei dati. Tale mancanza di adattamento è dovuta dalla variabilità campionaria e dalla complessità del modello. Il sotto-adattamento porta ad un \\(R^2\\) basso e ad un MSE alto, sia nei campioni di calibrazione che in quelli di convalida. Per questo motivo, la scarsa generalizzabilità del modello può essere dovuta sia al sovra-adattamento che al sotto-adattamento del modello.\nPer aumentarne la capacità di generalizzazione del modello devono essere soddisfatte tre condizioni: (a) campioni di calibrazione grandi, (b) dimensioni dell’effetto non piccole nella popolazione, e (c) modelli che non siano inutilmente complessi. Tuttavia, nella ricerca psicologica queste tre condizioni sono difficili da soddisfare: l’aumento della dimensione del campione spesso richiede l’utilizzo di maggiori risorse, la dimensione di un dato effetto nella popolazione non è soggetta alla discrezione dei ricercatori e la complessità del modello è spesso guidata da motivazioni teoriche. Pertanto, negli studi psicologici la generalizzabilità dei modelli è spesso problematica. Ciò rende necessario che il ricercatore fornisca informazioni aggiuntive relative alla capacità del modello di generalizzarsi a nuovi campioni. L’obiettivo di questa parte della dispensa è di descrivere come questo possa essere fatto utilizzando l’approccio bayesiano."
  },
  {
    "objectID": "090_entropy.html#capacità-predittiva",
    "href": "090_entropy.html#capacità-predittiva",
    "title": "35  Entropia",
    "section": "\n35.2 Capacità predittiva",
    "text": "35.2 Capacità predittiva\nNel framework bayesiano il problema della generalizzabilità di un modello viene affrontato valutando la capacità predittiva del modello, laddove per capacità predittiva si intende la capacità di un modello, i cui parametri sono stati stimati usando le informazioni di un campione, di ben adattarsi ad un campione di osservazioni future. In questo Capitolo cercheremo di rispondere a tre domande.\n\nQuali criteri consentono di valutare la capacità predittiva di un modello?\nCome quantificare la capacità predittiva di un modello usando solo un campione di osservazioni?\nCome confrontare le capacità predittive di modelli diversi?"
  },
  {
    "objectID": "090_entropy.html#il-rasoio-di-ockham",
    "href": "090_entropy.html#il-rasoio-di-ockham",
    "title": "35  Entropia",
    "section": "\n35.3 Il rasoio di Ockham",
    "text": "35.3 Il rasoio di Ockham\nIl problema di scegliere il modello più adatto a spiegare un fenomeno di interesse è uno dei più importanti problemi in campo scientifico. I ricercatori si chiedono: il modello è completo? È necessario aggiungere un nuovo parametro al modello? Come può essere migliorato il modello? Se ci sono modelli diversi, qual’è il modello migliore?\nPer rispondere a queste domande è possibile usare il rasoio di Ockham: frustra fit per plura quod potest fieri per pauciora (“si fa inutilmente con molte cose ciò che si può fare con poche cose”). Parafrasando la massima si potrebbe dire: se due modelli descrivono i dati egualmente bene, viene sempre preferito il modello più semplice. Questo è il principio che sta alla base della ricerca scientifica.\nIl rasoio di Ockham, però, non consente sempre di scegliere tra modelli alternativi. Se due modelli fanno le stesse predizioni ma differiscono in termini di complessità — per esempio, relativamente al numero di parametri di cui sono costituiti — allora è facile decidere: viene preferito il modello più semplice, anche perché, pragmaticamente, è il più facile da usare. Tuttavia, in generale, i modelli differiscono sia per complessità (ovvero, per il numero di parametri) che per accuratezza (ovvero, per la grandezza degli errori di predizione). In tali circostanze il rasoio di Ockham non è sufficiente: non consente infatti di trovare un equilibrio tra accuratezza e semplicità.\nIn questo Capitolo ci chiederemo come sia possibile misurare l’accuratezza predittiva di un modello. Ciò ci consentirà, in seguito, di usare il rasoio di Ockham: a parità di accuratezza, sarà possibile scegliere il modello più semplice. Ma nella pratica scientifica non si sacrifica mai l’accuratezza per la semplicità: il criterio prioritario è sempre l’accuratezza.\n\n35.3.1 Sovra-adattamento e sotto-adattamento\nSecondo McElreath (2020), la selezione tra modelli deve evitare due opposti errori: il sovra-adattamento e il sotto-adattamento. Tale problema va sotto il nome di bias-variance trade-off: il sotto-adattamento, infatti, porta a distorsioni (bias) nella stima dei parametri, mentre il sovra-adattamento porta a previsioni scadenti in campioni futuri. Spesso l’incertezza relativa alla scelta del modello (sotto-adattamento versus sovra-adattamento) passa inosservata ma il suo impatto può essere drammatico. Secondo Hoeting et al. (1999), “Standard statistical practice ignores model uncertainty. Data analysts typically select a model from some class of models and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and decisions that are more risky than one thinks they are.\nIn questo Capitolo esamineremo alcune tecniche bayesiane che possono essere utilizzate per operare una selezione tra modelli alternativi, tenendo sotto controllo i pericoli del sovra-adattamento e del sotto-adattamento. In particolare, ci chiederemo quale, tra due o più modelli, sia quello da preferire in base al criterio della capacità predittiva.\n\n35.3.2 Stargazing\nNella pratica concreta della ricerca, il metodo più comune per la selezione tra modelli alternativi utilizza i test di ipotesi statistiche di stampo frequentista. Questo metodo viene chiamato stargazing, poiché richiede soltanto l’esame degli asterischi (\\(**\\)) che si trovano nell’output di un software statistico (gli asterischi marcano i coefficienti del modello che sono “statisticamente significativi”): alcuni ricercatori ritengono che il modello con più stelline sia anche il modello migliore. Questo però non è vero. Al di là dei problemi legati ai test dell’ipotesi nulla, è sicuramente un errore usare i test di significatività per la selezione di modelli: i valori-p non consentono di trovare un equilibrio tra underfitting e overfitting. Infatti, le variabili che migliorano la capacità predittiva di un modello non sono sempre statisticamente significative; d’altra parte, le variabili statisticamente significative non sempre migliorano la capacità predittiva di un modello.\nQuando ci chiediamo quale, tra modelli alternativi, è il modello che meglio rappresenta il “vero” processo di generazione dei dati, ci troviamo di fronte al problema di quantificare il grado di “vicinanza” di un modello al “vero” processo di generazione dei dati. Si noti che, in tale confronto, facciamo riferimento sia alla famiglia distributiva così come ai valori dei parametri. Ad esempio, il modello \\(y_i \\sim \\mathcal{N}(5, 3)\\) è diverso dal modello \\(y_i \\sim \\mathcal{N}(5, 6)\\), ed è anche diverso dal modello \\(y_i \\sim \\Gamma(2, 2)\\). I primi due modelli appartengono alla stessa famiglia distributiva ma differiscono nei termini dei valori dei parametri; gli ultimi due modelli appartengono a famiglie distributive diverse (gaussiano vs. Gamma). Per misurare il grado di “vicinanza” tra due modelli, \\(\\mathcal{M}_1\\) e \\(\\mathcal{M}_2\\), la metrica di gran lunga più popolare è la divergenza di Kullback-Leibler. Per chiarire questo concetto è però prima necessario introdurre la nozione di entropia."
  },
  {
    "objectID": "090_entropy.html#la-misura-del-disordine",
    "href": "090_entropy.html#la-misura-del-disordine",
    "title": "35  Entropia",
    "section": "\n35.4 La misura del disordine",
    "text": "35.4 La misura del disordine\nSe vogliamo ottenere una comprensione intuitiva del concetto di entropia1 possiamo pensare a quant’è informativa una distribuzione. Maggiore è l’entropia di una distribuzione, meno informativa sarà quella distribuzione e più uniformemente verranno assegnate le probabilità agli eventi. In altri termini, ottenere la risposta di “42” è più informativo della risposta “42 \\(\\pm\\) 5”, che a sua volta è più informativo della risposta “un numero qualsiasi”. L’entropia quantifica questa osservazione qualitativa.\nIl concetto di entropia si applica sia alle distribuzioni continue sia a quelle discrete, ma è più facile da capire usando le distribuzioni discrete. Negli esempi successivi vedremo alcuni esempi applicati al caso discreto, ma gli stessi concetti si applicano al caso continuo.\n\n35.4.1 Entropia di un singolo evento\nIl concetto di entropia può essere usato per descrivere la quantità di informazione fornita da un evento. L’intuizione che sta alla base del concetto di entropia è che l’informazione fornita da un evento descrive la sorpresa suscitata dall’evento: gli eventi rari (a bassa probabilità) sono più sorprendenti – e quindi forniscono più informazione – degli eventi comuni (ad alta probabilità). In altre parole,\n\nun evento a bassa probabilità è sorprendente e fornisce molta informazione;\nun evento ad alta probabilità è poco o per niente sorprendente e fornisce poca (o nessuna) informazione.\n\nÈ dunque possibile quantificare l’informazione fornita dal verificarsi di un evento usando la probabilità di quell’evento. Una tale quantità di informazione è chiamata “informazione di Shannon”, “auto-informazione” o semplicemente “informazione” e, per un evento discreto \\(x\\), può essere calcolata come:\n\\[\n\\text{informazione}(x) = -\\log_2 p(x),\n\\]\ndove \\(\\log_2\\) è il logaritmo in base 2 e \\(p(x)\\) è la probabilità dell’evento \\(x\\).\nLa scelta del logaritmo in base 2 significa che l’unità di misura dell’informazione è il bit (cifre binarie). Questo può essere interpretato dicendo che l’informazione misura il numero di bit richiesti per rappresentare un evento.2 Solitamente, si denota la quantità di informazione con \\(h()\\):\n\\[\nh(x) = -\\log p(x).\n\\]\nIl segno negativo garantisce che il risultato sia sempre positivo o zero. L’informazione è zero quando la probabilità dell’evento è 1.0, ovvero quando l’evento è certo (assenza di sorpresa).\n\nConsideriamo il lancio di una moneta equilibrata. La probabilità di testa (e croce) è 0.5. La quantità di informazione di ottenere “testa” è dunque\n\n-log2(0.5)\n#> [1] 1\n\nPer rappresentare questo evento abbiamo bisogno di 1 bit di informazione. Se la stessa moneta venisse lanciata \\(n\\) volte, la quantità di informazione necessaria per rappresentare questo evento (ovvero, questa sequenza di lanci) sarebbe pari a \\(n\\) bit. Se la moneta non è equilibrata e la probabilità di testa è 0.1, allora l’evento “testa” è più raro e richiede più di 3 bit di informazione:\n\n-log2(0.1)\n#> [1] 3.321928\n\nConsideriamo ora il lancio di un dado. Quanta informazione viene fornita, ad esempio, dall’evento “esce il numero 6”? Dato che la probabilità di ottenere un 6 nel lancio di un dado è più piccola della probabilità di ottenere “testa” nel lancio di una moneta, il risultato del lancio di un dado deve produrre una sorpresa maggiore del risultato del lancio di una moneta. Per cui, la quantità di informazione associata all’evento “è uscito 6”, dovrà essere maggiore di quella associata all’evento “testa”. Infatti, la quantità di informazione dell’evento “è uscito un 6” è più che doppia rispetto alla quantità di informazione dell’evento “testa”:\n\n-log2(1/6)\n#> [1] 2.584963\n\n\n\nNella figura successiva viene esaminata la relazione tra probabilità e informazione, per valori di probabilità nell’intervallo tra 0 e 1.\n\np <- seq(0, 1, length.out = 1000)\nh <- -log2(p)\nggplot(tibble(p, h), aes(p, h)) +\n  geom_line() +\n  labs(\n    x = \"Probabilità\",\n    y = \"Informazione\"\n  )\n\n\n\n\n\n\n\nLa figura mostra che questa relazione non è lineare, è infatti leggermente sublineare. Questo ha senso dato che abbiamo usato una funzione logaritmica.\n\n\n35.4.2 Entropia di una variabile casuale\nPossiamo estendere questa discussione pensando ad un insieme di eventi, ovvero ad una distribuzione. Nella teoria della probabilità usiamo la nozione di variabile casuale per fare riferimento ad un insieme di eventi e alle probabilità associate a tali eventi. L’entropia quantifica l’informazione che viene fornita da una variabile casuale.\n\nSia \\(Y = y_1, \\dots, y_n\\) una variabile casuale e \\(p_t(y)\\) una distribuzione di probabilità su \\(Y\\). Si definisce la sua entropia (detta di Shannon) come:\n\\[\\begin{equation}\nH(Y) = - \\sum_{i=1}^n p_t(y_i) \\cdot \\log_2 p_t(y_i).\n(\\#eq:entropy)\n\\end{equation}\\]\n\nPer interpretare la @ref(eq:entropy), consideriamo un esempio discusso da Martin et al. (2022).\n\n\n\n\nFunzioni di massa di probabilità e associata entropia.\n\n\n\n\nNella figura @ref(fig:entropy-example) sono rappresentate sei distribuzioni. viene anche riportato il valore di entropia di ciascuna distribuzione. La distribuzione con il picco più pronunciato o con la dispersione minore è q, e questa è la distribuzione con il valore di entropia più basso tra le sei distribuzioni considerate. Per q la distribuzione è q ~ binom(n = 10, p = 0.75); quindi ci sono 11 possibili eventi. qu ha una distribuzione uniforme sugli stessi 11 possibili eventi. L’entropia di qu è maggiore dell’entropia di q. Infatti, se calcoliamo l’entropia di distribuzioni binomiali con \\(n = 10\\) (con valori diversi di \\(p\\)) ci rendiamo conto che nessuna di tali distribuzioni ha un’entropia maggiore di qu. Dobbiamo aumentare \\(n ≈ 3\\) volte per trovare la prima distribuzione binomiale con entropia maggiore di qu. Passiamo alla riga successiva. Generiamo la distribuzione r spostando a destra q e normalizzando (per garantire che la somma di tutte le probabilità sia 1). Poiché r ha una dispersione maggiore di q, la sua entropia è maggiore. ru è una distribuzione uniforme con lo stesso numero di eventi possibili come r (ovvero 22) – si noti che sono stati inclusi come valori possibili anche quelli nella “valle” tra i due picchi. Ancora una volta, la distribuzione uniforme ha l’entropia più grande.\nGli esempi discussi finora sembrano suggerire che l’entropia è proporzionale alla varianza della distribuzione. Verifichiamo questa intuizione esaminiamo le ultime due distribuzioni della figura @ref(fig:entropy-example). La distribuzione s è simile a r ma presenta una separazione maggiore tra i due picchi della distribuzione – dunque, ha una varianza più grande. Ciò nonostante, l’entropia non varia. Quindi la relazione tra entropia e varianza non è così semplice come ci sembrava. Il risultato che abbiamo trovato può essere spiegato dicendo che, nel calcolo dell’entropia, non vengono considerati gli eventi con probabilità nulla (per questa ragione, nell’esempio, è stato possibile aumentare la varianza senza cambiare l’entropia). La distribuzione su è stata costruita sostituendo i due picchi in s con qu (e normalizzando). Possiamo vedere che su ha un’entropia minore di ru, anche se su ha una dispersione maggiore di ru. Questo è dovuto al fatto che su distribuisce la probabilità totale tra un numero minore di eventi (22) di ru (che ne conta 23); quindi è sensato attribuire a su un’entropia minore di ru.\n\nConsideriamo ora un esempio riguardante le previsioni del tempo. Supponiamo che le probabilità di pioggia e sole siano, rispettivamente, \\(p_1 = 0.3\\) e \\(p_2 = 0.7\\). Quindi\n\\[\nH(p) = − [p(y_1) \\log_2 p(y_1) + p(y_2) \\log_2 p(y_2)] \\approx 0.61.\n\\]\nSe però viviamo a Las Vegas, allora le probabilità di pioggia e sole saranno simili a \\(p(y_1) = 0.01\\) e \\(p(y_2) = 0.99\\). In questo secondo caso, l’entropia è 0.06, ovvero, molto minore di prima. Infatti, a Las Vegas non piove quasi mai, per cui quando abbiamo imparato che, in un certo giorno, non ha piovuto, abbiamo imparato molto poco rispetto a quello che già sapevamo in precedenza.\n\n\nNell’esempio precedente abbiamo visto che, se gli esiti possibili sono pioggia o sole con \\(p(y_1) = 0.7\\), \\(p(y_2) = 0.3\\), allora l’entropia è\n\n-(0.7 * log(0.7) + 0.3 * log(0.3))\n#> [1] 0.6108643\n\nMa se gli esiti possibili sono pioggia, neve o sole con \\(p(y_1) = 0.7\\), \\(p(y_2) = 0.15\\) e \\(p(y_3) = 0.15\\), rispettivamente, allora l’entropia cresce:\n\n-(0.7 * log(0.7) + 0.15 * log(0.15) + 0.15 * log(0.15))\n#> [1] 0.8188085"
  },
  {
    "objectID": "090_entropy.html#commenti-e-considerazioni-finali",
    "href": "090_entropy.html#commenti-e-considerazioni-finali",
    "title": "35  Entropia",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questo Capitolo abbiamo visto come sia possibile quantificare l’incertezza tramite l’entropia. Ma come è possibile usare l’entropia dell’informazione per specificare la “distanza” tra un modello e il vero meccanismo generatore dei dati? La risposta a questa domanda è fornita dalla divergenza di Kullback-Leibler che verrà discussa nel Capitolo @ref(ch:kl-div).\n\n\n\n\n\n\nHoeting, J. A., Madigan, D., Raftery, A. E., & Volinsky, C. T. (1999). Bayesian model averaging: A tutorial (with comments by m. Clyde, david draper and EI george, and a rejoinder by the authors. Statistical Science, 14(4), 382–417.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nLord, F. M. (1950). Efficiency of prediction when a regression equation from one sample is used in a new sample. ETS Research Bulletin Series, 1950(2), 1–6.\n\n\nMartin, O. A., Kumar, R., & Lao, J. (2022). Bayesian modeling and computation in python. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSong, Q. C., Tang, C., & Wee, S. (2021). Making sense of model generalizability: A tutorial on cross-validation in r and shiny. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920947067."
  },
  {
    "objectID": "091_kl.html#la-perdita-di-informazione",
    "href": "091_kl.html#la-perdita-di-informazione",
    "title": "36  La divergenza di Kullback-Leibler",
    "section": "\n36.1 La perdita di informazione",
    "text": "36.1 La perdita di informazione\nIntuitivamente, per quantificare l’informazione che si perde quando una distribuzione approssimata \\(q\\) viene usata in luogo della distribuzione corretta \\(p\\) sembra necessaria una quantità che ha valore zero quando \\(q = p\\), e un valore positivo altrimenti. Seguendo la definizione @ref(eq:entropy) di entropia, possiamo quantificare una tale perdita di informazione mediante il valore atteso della differenza tra \\(\\log(p)\\) e \\(\\log(q)\\). Questa quantità è chiamata entropia relativa o divergenza di Kullback-Leibler:\n\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = \\mathbb{E} (\\log p - \\log q).\n(\\#eq:kldivergence)\n\\end{equation}\\]\nLa divergenza \\(\\mathbb{KL} (p \\mid\\mid q)\\) corrisponde alla differenza media nelle probabilità logaritmiche quando \\(q\\) viene usato per approssimare \\(p\\). Poiché gli eventi si manifestano secondo \\(p\\), è necessario calcolare il valore atteso rispetto a \\(p\\). Per distribuzioni discrete dunque abbiamo:\n\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = \\sum_i^n p_i (\\log p_i - \\log q_i) = \\sum_i^n p_i \\log \\frac{p_i}{q_i}.\n\\end{equation}\\]\nRiarrangiando i termini otteniamo:\n\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = -\\sum_i^n p_i (\\log q_i - \\log p_i),\n\\end{equation}\\]\novvero,\n\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = \\underbrace{-\\sum_i^n p_i \\log q_i}_{h(p, q)} - \\underbrace{\\left(-\\sum_i^n p_i \\log p_i\\right)}_{h(p)},\n\\end{equation}\\]\nladdove \\(h(p)\\) è l’entropia di \\(p\\) e \\(h(p, q) = − \\mathbb{E} [\\log q]\\) può essere intesa come l’entropia di \\(q\\), ma valutata secondo i valori di probabilità \\(p\\).\nRiarrangiando l’equazione precedente otteniamo:\n\\[\\begin{equation}\nh(p, q) = h(p) + \\mathbb{KL} (p \\mid\\mid q),\n\\end{equation}\\]\nil che mostra come la divergenza \\(\\mathbb{KL}\\) possa essere interpretata come l’incremento di entropia, rispetto a \\(h(p)\\), quando \\(q\\) viene usata per rappresentare \\(p\\).\n\n(da McElreath, 2020) Sia la distribuzione target \\(p = \\{0.3, 0.7\\}\\). Supponiamo che la distribuzione approssimata \\(q\\) possa assumere valori da \\(q = \\{0.01, 0.99\\}\\) a \\(q = \\{0.99, 0.01\\}\\). Calcoliamo la divergenza KL.\nLe istruzioni \\(\\mathsf{R}\\) sono le seguenti:\n\nt <-\n  tibble(\n    p_1 = .3,\n    p_2 = .7,\n    q_1 = seq(from = .01, to = .99, by = .01)\n  ) %>%\n  mutate(\n    q_2 = 1 - q_1\n  ) %>%\n  mutate(\n    d_kl = (p_1 * log(p_1 / q_1)) + (p_2 * log(p_2 / q_2))\n  )\n\nhead(t)\n#> # A tibble: 6 × 5\n#>     p_1   p_2   q_1   q_2  d_kl\n#>   <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1   0.3   0.7  0.01  0.99 0.778\n#> 2   0.3   0.7  0.02  0.98 0.577\n#> 3   0.3   0.7  0.03  0.97 0.462\n#> 4   0.3   0.7  0.04  0.96 0.383\n#> 5   0.3   0.7  0.05  0.95 0.324\n#> 6   0.3   0.7  0.06  0.94 0.276\n\nNella figura seguente sull’asse delle ascisse sono rappresentati i valori \\(q\\) e sull’asse delle ordinante sono riportati i corrispondenti valori \\(\\mathbb{KL}\\).\n\nt %>%\n  ggplot(aes(x = q_1, y = d_kl)) +\n  geom_vline(xintercept = .3, linetype = 2) +\n  geom_line(size = 1) +\n  annotate(geom = \"text\", x = .4, y = 1.5, label = \"q = p\",\n           size = 3.5) +\n  labs(x = \"q[1]\",\n       y = \"Divergenza di q da p\")\n\n\n\n\n\n\n\nTanto meglio la distribuzione \\(q\\) approssima la distribuzione target tanto più piccolo è il valore di divergenza \\(\\mathbb{KL}\\).\n\n\nSia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\)\n\nn <- 4\np <- 0.2\ntrue_py <- dbinom(0:n, n, 0.2)\ntrue_py\n#> [1] 0.4096 0.4096 0.1536 0.0256 0.0016\n\nSia \\(q_1\\) una approssimazione a \\(p\\):\n\nq1 <- c(0.46, 0.42, 0.10, 0.01, 0.01)\nq1\n#> [1] 0.46 0.42 0.10 0.01 0.01\n\nSia \\(q_2\\) una distribuzione uniforme:\n\nq2 <- rep(0.2, 5)\nq2\n#> [1] 0.2 0.2 0.2 0.2 0.2\n\nLa divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) è\n\nsum(true_py * log(true_py / q1))\n#> [1] 0.02925199\n\nLa divergenza \\(\\mathbb{KL}\\) di \\(q_2\\) da \\(p\\) è:\n\nsum(true_py * log(true_py / q2))\n#> [1] 0.4863578\n\nÈ chiaro che perdiamo una quantità maggiore di informazioni se, per descrivere la distribuzione binomiale \\(p\\), usiamo la distribuzione uniforme \\(q_2\\) anziché \\(q_1\\)."
  },
  {
    "objectID": "091_kl.html#la-divergenza-dipende-dalla-direzione",
    "href": "091_kl.html#la-divergenza-dipende-dalla-direzione",
    "title": "36  La divergenza di Kullback-Leibler",
    "section": "\n36.2 La divergenza dipende dalla direzione",
    "text": "36.2 La divergenza dipende dalla direzione\nLa divergenza \\(\\mathbb{KL}\\) non è una vera e propria metrica: per esempio, non è simmetrica. In generale, \\(\\mathbb{KL}(p \\mid\\mid q) \\neq \\mathbb{KL}(q \\mid\\mid p)\\), ovvero la \\(\\mathbb{KL}\\) da \\(p\\) a \\(q\\) è diversa dalla \\(\\mathbb{KL}\\) da \\(q\\) a \\(p\\).\n\nUsando le seguenti istruzioni \\(\\mathsf{R}\\) otteniamo:\n\ntibble(direction = c(\"Da q a p\", \"Da p a q\"),\n       p_1 = c(.01, .7),\n       q_1 = c(.7, .01)) %>%\n  mutate(p_2 = 1 - p_1,\n         q_2 = 1 - q_1) %>%\n  mutate(d_kl = (p_1 * log(p_1 / q_1)) + (p_2 * log(p_2 / q_2)))\n#> # A tibble: 2 × 6\n#>   direction   p_1   q_1   p_2   q_2  d_kl\n#>   <chr>     <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1 Da q a p   0.01  0.7   0.99  0.3   1.14\n#> 2 Da p a q   0.7   0.01  0.3   0.99  2.62"
  },
  {
    "objectID": "091_kl.html#confronto-tra-modelli",
    "href": "091_kl.html#confronto-tra-modelli",
    "title": "36  La divergenza di Kullback-Leibler",
    "section": "\n36.3 Confronto tra modelli",
    "text": "36.3 Confronto tra modelli\nLa divergenza \\(\\mathbb{KL}\\) viene utilizzata nel confronto tra modelli, ovvero ci consente di quantificare l’informazione che viene perduta quando utilizziamo la distribuzione di probabilità ipotizzata da un modello, chiamiamola \\(p_{\\mathcal{M}}\\), per approssimare la distribuzione di probabilità del vero modello generatore dei dati, \\(p_t\\).\nIn precedenza abbiamo introdotto il concetto di distribuzione predittiva a posteriori:\n\\[\np(\\tilde{y} \\mid y) = \\int_\\Theta p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta .\n\\]\nLa distribuzione predittiva a posteriori descrive il tipo di dati che ci aspettiamo vengano prodotti dal modello generativo \\(\\mathcal{M}\\), alla luce delle nostre credenze iniziali, \\(p(\\theta)\\) e dei dati osservati \\(y\\). Quando valutiamo un modello ci chiediamo in che misura \\(p_{\\mathcal{M}}(\\tilde{y} \\mid y)\\) approssimi \\(p_t(\\tilde{y})\\). Cioè, ci chiediamo quanto siano simili i dati \\(p_{\\mathcal{M}}(\\cdot)\\) prodotti dal modello \\(\\mathcal{M}\\) ai dati prodotti dal vero processo generatore dei dati \\(p_t(\\cdot)\\).\nUna misura della “somiglianza” tra la distribuzione \\(q_{\\mathcal{M}}\\) ipotizzata dal modello \\(\\mathcal{M}\\) e la distribuzione \\(p_t\\) del vero modello generatore dei dati è fornita dalla divergenza di Kullback-Leibler \\(\\mathbb{KL}(p_t \\mid\\mid q_{\\mathcal{M}})\\). Supponendo di avere \\(k\\) modelli della distribuzione a posteriori, \\(\\{q_{\\mathcal{M}_1}, q_{\\mathcal{M}_2}, \\dots, q_{\\mathcal{M}_k}\\}\\), e di conoscere il vero modello generatore dei dati, possiamo scrivere\n\\[\\begin{align}\n\\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_1}) &= \\mathbb{E} (\\log p_{\\mathcal{M}_0}) - \\mathbb{E} (\\log q_{\\mathcal{M}_1})\\notag\\\\\n\\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_2}) &= \\mathbb{E} (\\log p_t) - \\E (\\log q_{\\mathcal{M}_2})\\notag\\\\\n&\\cdots\\notag\\\\\n\\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_k}) &= \\mathbb{E} (\\log p_{\\mathcal{M}_0}) - \\mathbb{E} (\\log q_{\\mathcal{M}_k}).\n(\\#eq:kl-mod-comp)\n\\end{align}\\]\nLa @ref(eq:kl-mod-comp) può sembrare un esercizio futile poiché nella vita reale non conosciamo il vero modello generatore dei dati. È però facile rendersi conto che, poiché \\(p_t\\) è la stessa per tutti i confronti, diventa possibile costruire un ordinamento dei modelli basato unicamente sul secondo termine della @ref(eq:kl-mod-comp), ovvero senza nessun riferimento al vero modello generatore dei dati. Per un generico modello \\(\\mathcal{M}\\), il secondo termine della @ref(eq:kl-mod-comp) può essere scritto come:\n\\[\\begin{equation}\n\\mathbb{E} \\log p_{\\mathcal{M}}(y) = \\int_{-\\infty}^{+\\infty}p_{t}(y)\\log p_{\\mathcal{M}}(y) \\,\\operatorname {d}\\!y .\n(\\#eq:kl-div-cont-t2)\n\\end{equation}\\]"
  },
  {
    "objectID": "091_kl.html#expected-log-predictive-density",
    "href": "091_kl.html#expected-log-predictive-density",
    "title": "36  La divergenza di Kullback-Leibler",
    "section": "\n36.4 Expected log predictive density",
    "text": "36.4 Expected log predictive density\nLe previsioni del modello \\(\\mathcal{M}\\) sui nuovi dati futuri sono date dalla distribuzione predittiva a posteriori. Possiamo dunque riscrivere la @ref(eq:kl-div-cont-t2) come\n\\[\\begin{equation}\n\\mbox{elpd} = \\int_{\\tilde{y}} p_{t}(\\tilde{y}) \\log p(\\tilde{y} \\mid y) \\,\\operatorname {d}\\!\\tilde{y}.\n(\\#eq:elpd)\n\\end{equation}\\]\nLa @ref(eq:elpd) è chiamata expected log predictive density (\\(\\mbox{elpd}\\)) e fornisce la risposta al problema che ci eravamo posti: nel confronto tra modelli, come è possibile scegliere il modello più simile al vero meccanismo generatore dei dati? Possiamo pensare alla @ref(eq:elpd) dicendo che descrive la distribuzione predittiva a posteriori del modello ponderando la verosimiglianza dei possibili (sconosciuti) dati futuri (\\(\\tilde{y}\\)) con la vera distribuzione \\(p_t\\). Di conseguenza, valori \\(\\mbox{elpd}\\) più grandi identificano il modello che risulta più simile al vero meccanismo generatore dei dati.\nNon dobbiamo preoccuparci di trovare una formulazione analitica della distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\) perché è possibile approssimare tale distribuzione mediante simulazione. Notiamo però che la @ref(eq:elpd) include un termine, \\(p_t(\\tilde{y})\\), il quale descrive la distribuzione dei dati futuri \\(\\tilde{y}\\) secondo il vero modello generatore dei dati. Il termine \\(p_t\\), ovviamente, è ignoto.1 Di conseguenza, la quantità \\(\\mbox{elpd}\\) non può mai essere calcolata in maniera esatta, ma può solo essere stimata. Il secondo problema di questo Capitolo è capire come la @ref(eq:elpd) possa essere stimata utilizzando un campione di osservazioni.\n\n36.4.1 Log pointwise predictive density\nIngenuamente, potremmo pensare di stimare la @ref(eq:elpd) ipotizzando che la distribuzione del campione coincida con \\(p_t\\). Usare la distribuzione del campione come proxy del vero modello generatore dei dati (ovvero, ipotizzare che la distribuzione del campione rappresenti fedelmente \\(p_t\\)) comporta due conseguenze:\n\nnon è necessario ponderare per \\(p_t\\), in quanto assumiamo che la distribuzione empirica del campione corrisponda a \\(p_t\\) (ciò significa assumere che i valori più comunemente osservati nel campione siano anche quelli più verosimili nella vera distribuzione \\(p_t\\));\ndato che il campione è finito, anziché eseguire un’operazione di integrazione possiamo semplicemente sommare la densità predittiva a posteriori delle osservazioni.\n\nQuesto conduce alla seguente equazione:2\n\\[\\begin{equation}\n\\frac{1}{n} \\sum_{i=1}^n \\log p(y_i^{rep} \\mid y).\n(\\#eq:1n-lppd)\n\\end{equation}\\]\nLa quantità @ref(eq:1n-lppd), senza il passaggio finale della divisione per il numero di osservazioni, è chiamata log pointwise predictive density (\\(\\mbox{lppd}\\))\n\\[\\begin{equation}\n\\mbox{lppd} = \\sum_{i=1}^n \\log p(y_i^{rep} \\mid y)\n(\\#eq:lppd)\n\\end{equation}\\]\ne corrisponde alla somma delle densità predittive logaritmiche delle \\(n\\) osservazioni. Valori più grandi della @ref(eq:lppd) sono da preferire perché indicano una maggiore accuratezza media. È anche comune vedere espressa la quantità precedente nei termini della devianza, ovvero alla \\(\\mbox{lppd}\\) moltiplicata per -2. In questo secondo caso sono da preferire valori piccoli.\nÈ importante notare che \\(\\lppd\\) fornisce una sovrastima della @ref(eq:elpd). Tale sovrastima è dovuta al fatto che, nel calcolo della @ref(eq:lppd), abbiamo usato \\(p(y^{rep} \\mid y)\\) al posto di \\(p(\\tilde{y} \\mid y)\\): in altri termini, abbiamo considerato le osservazioni del campione come se fossero un nuovo campione di dati. In una serie di simulazioni, McElreath (2020) esamina il significato di questa sovrastima. Nelle simulazioni la devianza viene calcolata come funzione della complessità (ovvero, il numero di parametri) del modello. La simulazione mostra che \\(\\mbox{lppd}\\) aumenta al crescere del numero di parametri del modello. Ciò significa che \\(\\mbox{lppd}\\) mostra lo stesso limite del coefficiente di determinazione: aumenta all’aumentare della complessità del modello.\n\nEsaminiamo un esempio tratto da Bayesian Data Analysis for Cognitive Science nel quale la \\(\\mbox{lppd}\\) viene calcolata in forma esatta oppure mediante approssimazione. Supponiamo di disporre di un campione di \\(n\\) osservazioni. Supponiamo inoltre di conoscere il vero processo generativo dei dati (qualcosa che in pratica non è mai possibile), ovvero:\n\\[\np_t(y) = \\mbox{Beta}(1, 3).\n\\] I dati sono\n\nset.seed(75)\nn <- 10000\ny_data <- rbeta(n, 1, 3)\nhead(y_data)\n#> [1] 0.55062422 0.13346270 0.80250987 0.21430898 0.01913430 0.08676517\n\nSupponiamo inoltre di avere adattato ai dati un modello bayesiano \\(\\mathcal{M}\\) e di avere ottenuto la distribuzione a posteriori per i parametri del modello. Inoltre, supponiamo di avere derivato la forma analitica della distribuzione predittiva a posteriori per il modello:\n\\[\np(y^{rep} \\mid y) \\sim \\mbox{Beta}(2, 2).\n\\]\nQuesta distribuzione ci dice quanto sono credibili i possibili dati futuri.\nConoscendo la vera distribuzione dei dati \\(p_t(y)\\) possiamo calcolare in forma esatta la quantità \\(\\mbox{elpd}\\), ovvero\n\\[\n\\mbox{elpd} = \\int_{y^{rep}}p_{t}(y^{rep})\\log p(y^{rep} \\mid y) \\,\\operatorname {d}\\!y^{rep}.\n\\]\nSvolgiamo i calcoli in \\(\\mathsf{R}\\) otteniamo:\n\n# True distribution\np_t <- function(y) dbeta(y, 1, 3)\n# Predictive distribution\np <- function(y) dbeta(y, 2, 2)\n# Integration\nintegrand <- function(y) p_t(y) * log(p(y))\nintegrate(f = integrand, lower = 0, upper = 1)\n#> -0.3749072 with absolute error < 6.8e-07\n\nTuttavia, in pratica non conosciamo mai \\(p_t(y)\\). Quindi approssimiamo \\(\\mbox{elpd}\\) usando la @ref(eq:elpd):\n\\[\n\\frac{1}{n} \\sum_{i=1}^n \\log p(y_i \\mid y).\n\\]\nCosì facendo, e svolgendo i calcoli in \\(\\mathsf{R}\\), otteniamo un valore diverso da quello trovato in precedenza:\n\n1/n * sum(log(p(y_data)))\n#> [1] -0.3639141"
  },
  {
    "objectID": "091_kl.html#commenti-e-considerazioni-finali",
    "href": "091_kl.html#commenti-e-considerazioni-finali",
    "title": "36  La divergenza di Kullback-Leibler",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nDato che non conosciamo il vero meccanismo generatore dei dati \\(p\\), possiamo usare la distribuzione dei dati osservata come proxy per la vera distribuzione \\(p\\). Quindi, invece di ponderare la distribuzione predittiva in base alla densità reale di tutti i possibili dati futuri, utilizziamo semplicemente le \\(n\\) osservazioni che abbiamo. Possiamo farlo perché assumiamo che le nostre osservazioni costituiscano un campione dalla vera distribuzione dei dati: in base a questa ipotesi, nel campione ci aspettiamo di osservare più frequentemente quelle osservazioni che hanno una maggiore verosimiglianza nella vera distribuzione \\(p\\). È così possibile giungere ad una stima numerica della \\(\\mbox{elpd}\\) chiamata log pointwise predictive density (\\(\\mbox{lppd}\\)).\n\n\n\n\n\n\nGelman, A., Hwang, J., & Vehtari, A. (2014). Understanding predictive information criteria for bayesian models. Statistics and Computing, 24(6), 997–1016.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press."
  },
  {
    "objectID": "092_info_criterion.html#aic-dic-e-waic",
    "href": "092_info_criterion.html#aic-dic-e-waic",
    "title": "37  Criterio di informazione e convalida incrociata",
    "section": "\n37.1 AIC, DIC e WAIC",
    "text": "37.1 AIC, DIC e WAIC\nAllo scopo di evitare la sovrastima della @ref(eq:lppd), le statistiche Akaike Information Criterion (AIC), Deviance Information Criterion (DIC) e Widely Applicable Information Criterion (WAIC) introducono un fattore di correzione. Le statistiche DIC e WAIC sono più complesse di AIC, ma producono un’approssimazione migliore. Tuttavia, i valori AIC, DIC e WAIC sono spesso molto simili tra loro. Per convenienza, dunque, qui ci accontenteremo di esaminare in dettaglio la statistica più semplice, ovvero AIC.\n\n37.1.1 Criterio d’informazione di Akaike\nIl criterio d’informazione di Akaike (in inglese Akaike information criterion, indicato come AIC) fornisce un metodo molto semplice per approssimare \\(\\mbox{elpd}\\).\n\nIl criterio d’informazione di Akaike è definito come\n\\[\\begin{equation}\nAIC = -2 \\log p(y \\mid \\hat{\\theta}_{MLE}) + 2k,\n\\end{equation}\\]\ndove \\(k\\) è il numero di parametri stimati nel modello e \\(p(y \\mid \\hat{\\theta}_{MLE})\\) è il valore massimizzato della funzione di verosimiglianza del modello stimato.\n\nDividendo per -2, otteniamo \\(\\mbox{elpd}_{AIC}\\):\n\\[\\begin{equation}\n\\widehat{\\mbox{elpd}}_{AIC} = \\log p(y \\mid \\hat{\\theta}_{MLE}) - k,\n\\end{equation}\\]\ndove \\(k\\) è il fattore di correzione introdotto per evitare la sovrastima discussa in precedenza.\nAIC è di interesse principalmente storico e produce una approssimazione attendibile di \\(\\mbox{elpd}\\) quando:\n\nle distribuzioni a priori sono non informative;\nla distribuzione a posteriori è approssimativamente gaussiana multivariata;\nla dimensione \\(n\\) del campione è molto maggiore del numero \\(k\\) dei parametri.\n\n\nPer meglio comprendere la statistica \\(\\widehat{\\mbox{elpd}}_{AIC}\\), esaminiamo un esempio discusso da Gelman et al. (2014). Sia \\(y_1, \\dots, y_n \\sim \\mathcal{N}(\\mu, 1)\\) un campione di osservazioni. Nel caso di una distribuzione a priori non-informativa \\(p(\\theta) \\propto 1\\), la stima di massima verosimiglianza è \\(\\bar{y}\\). La verosimiglianza è\n\\[\nf(Y \\mid \\mu, \\sigma) = \\prod_{i=1}^n f(y \\mid \\mu, \\sigma)\n\\]\ne la log-verosimiglianza diventa\n\\[\n\\ell(Y \\mid \\mu, \\sigma) = \\sum_{i=1}^n \\log (f(y \\mid \\mu, \\sigma)).\n\\]\nOvvero,\n\\[\\begin{align}\n\\ell(Y \\mid \\mu, \\sigma) &= \\sum_{i=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi\\sigma^2 }}}\\exp \\left(-{\\frac {1}{2}}{\\frac {(y_i-\\mu )^{2}}{\\sigma^{2}}}\\right) \\right)\\notag\\\\\n&= \\sum_{i=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi \\sigma^2}}} \\right) - \\sum_{i=1}^n{\\frac {1}{2}}{\\frac {(y_i-\\mu )^{2}}{\\sigma ^{2}}} \\notag\\\\\n&= \\sum_{i=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi \\sigma^2}}} \\right) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2} \\notag \\\\\n&= \\sum_{i=1}^n \\log (1) - \\sum_{i=1}^n\\log \\sqrt{2\\pi \\sigma^2} - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2} \\notag\\\\\n&= - \\sum_{i=1}^n\\frac{1}{2}  \\log (2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2} \\notag\\\\\n&= - \\frac{n}{2}  \\log (2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2}. \\notag\n\\end{align}\\]\nSe \\(y \\sim \\mathcal{N}(\\mu, 1)\\), usando lo stimatore di massima verosimiglianza per \\(\\mu\\), la log-verosimiglianza diventa\n\\[\\begin{align}\n\\log p(y \\mid \\hat{\\theta}_{MLE}) &= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2}\\sum_{i=1}^n (y_i - \\bar{y})^2 \\notag\\\\\n&= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2} (n-1)s_y^2,\n\\end{align}\\]\ndove \\(s_y^2\\) è la varianza campionaria.\nNel caso di un modello gaussiano con con varianza nota e una distribuzione a priori uniforme viene stimato un solo parametro, per cui\n\\[\\begin{align}\n\\widehat{\\mbox{elpd}}_{AIC} &= \\log p(y \\mid \\hat{\\theta}_{MLE}) - k \\notag \\\\\n&= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2} (n-1)s_y^2 - 1.\n\\end{align}\\]"
  },
  {
    "objectID": "092_info_criterion.html#convalida-incrociata-k-fold",
    "href": "092_info_criterion.html#convalida-incrociata-k-fold",
    "title": "37  Criterio di informazione e convalida incrociata",
    "section": "\n37.2 Convalida incrociata K-fold",
    "text": "37.2 Convalida incrociata K-fold\nLa sovrastima della @ref(eq:lppd) può anche essere evitata usando una tecnica chiamata K-fold cross-validation. Mediante questo metodo vengono stimati i parametri del modello tralasciando una porzione di osservazioni (chiamata fold) dal campione per poi valutare il modello sulle osservazioni che sono state escluse. Una stima complessiva dell’accuratezza si ottiene poi calcolando la media del punteggio di accuratezza ottenuto in ogni fold. Il numero minimo di fold è 2; all’altro estremo, è possibile impiegare una singola osservazione in ciascun fold e adattare il modello tante volte (\\(n\\)) quante sono le singole osservazioni. Questa strategia è chiamata leave-one-out cross-validation (LOO-CV).\n\n37.2.1 Importance sampling\nLa strategia LOO-CV è computazionalmente onerosa (ovvero, richiede un tempo di esecuzione molto lungo). È però possibile approssimare LOO-CV mediante un metodo chiamato Pareto-smoothed importance sampling cross-validation [PSIS; Vehtari et al. (2017)]. Tralasciando qui i dettagli matematici, l’intuizione di base è che PSIS fa leva sul punteggio di “importanza” posseduto da ciascuna osservazione all’interno della distribuzione a posteriori. Per “importanza” si intende il fatto che alcune osservazioni hanno un impatto maggiore sulle proprietà della distribuzione a posteriori di altre: se viene rimossa un’osservazione importante, le proprietà della distribuzione a posteriori cambiano molto; se viene rimossa un’osservazione poco importante, la distribuzione a posteriori cambia poco. L’“importanza” così intesa viene chiamata “peso” (weight) e tali pesi vengono utilizzati per stimare l’accuratezza out-of-sample del modello. PSIS-LOO-CV richiede che il modello venga adattato una volta soltanto ai dati e fornisce una stima della devianza out-of-sample che evita la sovrastima della @ref(eq:lppd). Inoltre, PSIS-LOO-CV fornisce un feedback sulla propria affidabilità identificando le osservazioni i cui pesi molto elevati potrebbero rendere imprecisa la predizione.\nValori \\(\\widehat{\\mbox{elpd}}_{LOO}\\) più grandi indicano una maggiore accuratezza predittiva. In alternativa, anziché considerare \\(\\widehat{\\mbox{elpd}}\\), è possibile usare la quantità \\(-2 \\cdot \\widehat{\\mbox{elpd}}\\), la quale è chiamata LOO Information Criterion (LOOIC). In questo secondo caso, valori LOOIC più piccoli sono da preferire.\nLa quantità \\(\\widehat{\\mbox{elpd}}_{LOO}\\) viene calcolata dai pacchetti loo e brms ed è chiamata elpd_loo o elpd_kfold. È anche possibile calcolare la differenza della quantità elpd_loo per modelli alternativi, insieme alla deviazione standard della distribuzione campionaria di tale differenza."
  },
  {
    "objectID": "092_info_criterion.html#confronto-tra-aic-e-loo-cv",
    "href": "092_info_criterion.html#confronto-tra-aic-e-loo-cv",
    "title": "37  Criterio di informazione e convalida incrociata",
    "section": "\n37.3 Confronto tra AIC e LOO-CV",
    "text": "37.3 Confronto tra AIC e LOO-CV\nPer fare un esempio, faremo qui un confronto tra \\(\\widehat{\\mbox{elpd}}_{AIC}\\) e \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\). Esaminiamo nuovamente l’associazione tra il QI dei figli e il QI delle madri nel campione di dati discusso da Gelman et al. (2020). Una tale relazione può essere descritta da un modello di regressione nel quale la \\(y\\) corrisponde al QI dei figli e la \\(x\\) al QI delle madri.\nLeggiamo i dati in :\n\nlibrary(\"foreign\")\ndf <- read.dta(here(\"data\", \"kidiq.dta\"))\ndf$y <- scale(df$kid_score)[, 1]\ndf$x1 <- scale(df$mom_iq)[, 1]\nhead(df)\n#>   kid_score mom_hs    mom_iq mom_work mom_age           y         x1\n#> 1        65      1 121.11753        4      27 -1.06793237  1.4078352\n#> 2        98      1  89.36188        4      25  0.54886757 -0.7092079\n#> 3        85      1 115.44316        4      27 -0.08805362  1.0295443\n#> 4        83      1  99.44964        3      25 -0.18604150 -0.0366907\n#> 5       115      1  92.74571        4      27  1.38176451 -0.4836193\n#> 6        98      0 107.90184        1      18  0.54886757  0.5267892\n\nDato che AIC non è una statistica bayesiana, può essere calcolata mediante strumenti frequentisti:\n\nm1_freq <- lm(y ~ x1, data = df)\nAIC(m1_freq) / -2\n#> [1] -569.6384\n\nPer ottenere LOO-CV adattiamo ai dati un modello di regressione bayesiano:\n\nmodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] x1;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta1;\n  real<lower=0> sigma;\n}\ntransformed parameters {\n  vector[N] mu;\n  for (n in 1 : N) {\n    mu[n] = alpha + beta1 * x1[n];\n  }\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n  sigma ~ cauchy(0, 1);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu[n], sigma);\n    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/simplereg.stan\")\n\n\ndata1_list <- list(\n  N = length(df$kid_score),\n  y = df$y,\n  x1 = df$x1\n)\n\n\nfile1 <- file.path(\"code\", \"simplereg.stan\")\n\n\nmod1 <- cmdstan_model(file1)\n\nEseguiamo il campionamento MCMC:\n\nfit1 <- mod1$sample(\n  data = data1_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  cores = 4L,\n  refresh = 0\n)\n\nCalcoliamo infine la quantità \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\):\n\nloo1_result <- fit1$loo(cores = 4)\nprint(loo1_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -568.6 14.5\n#> p_loo         1.9  0.2\n#> looic      1137.2 28.9\n#> ------\n#> Monte Carlo SE of elpd_loo is 0.0.\n#> \n#> All Pareto k estimates are good (k < 0.5).\n#> See help('pareto-k-diagnostic') for details.\n\nSi noti la somiglianza tra \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\) e \\(\\widehat{\\mbox{elpd}}_{AIC}\\). In conclusione, possiamo dunque dire che \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\) è la risposta bayesiana allo stesso problema che trova una soluzione frequentista nella statistica \\(\\widehat{\\mbox{elpd}}_{AIC}\\)."
  },
  {
    "objectID": "092_info_criterion.html#confronto-tra-modelli-mediante-loo-cv",
    "href": "092_info_criterion.html#confronto-tra-modelli-mediante-loo-cv",
    "title": "37  Criterio di informazione e convalida incrociata",
    "section": "\n37.4 Confronto tra modelli mediante LOO-CV",
    "text": "37.4 Confronto tra modelli mediante LOO-CV\nCome menzionato in precedenza, l’obiettivo centrale della misurazione dell’accuratezza predittiva è il confronto di modelli. Una volta capito come calcolare LOO-CV con un condice scritto in linguaggio Stan, svolgeremo ora un confronto di modelli.1\nConsidereremo qui un confronto di modelli di regressione. Il modello di regressione discusso nel Paragrafo precedente prevede il QI dei bambini dal QI delle madri. Aggiungiamo a tale modello un secondo predittore che corrisponde all’età della madre. L’aggiunta di tale predittore migliori l’accuratezza predittiva del modello?\n\nmodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] x1;\n  vector[N] x2;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta1;\n  real beta2;\n  real<lower=0> sigma;\n}\ntransformed parameters {\n  vector[N] mu;\n  for (n in 1 : N) {\n    mu[n] = alpha + beta1 * x1[n] + beta2 * x2[n];\n  }\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n  beta2 ~ normal(0, 1);\n  sigma ~ cauchy(0, 1);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu[n], sigma);\n    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x2[n] * beta2, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/mreg2.stan\")\n\n\ndf$x2 <- scale(df$mom_age)[, 1]\n\n\ndata2_list <- list(\n  N = length(df$kid_score),\n  y = df$y,\n  x1 = df$x1,\n  x2 = df$x2\n)\n\n\nfile2 <- file.path(\"code\", \"mreg2.stan\")\n\n\n# compile model\nmod2 <- cmdstan_model(file2)\n\n\n# Running MCMC\nfit2 <- mod2$sample(\n  data = data2_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  cores = 4L,\n  refresh = 0\n)\n\n\nfit2$summary(c(\"alpha\", \"beta1\", \"beta2\", \"sigma\"))\n#> # A tibble: 4 × 10\n#>   variable      mean   median     sd    mad      q5    q95  rhat ess_b…¹ ess_t…²\n#>   <chr>        <dbl>    <dbl>  <dbl>  <dbl>   <dbl>  <dbl> <dbl>   <dbl>   <dbl>\n#> 1 alpha    -0.000255 -1.62e-4 0.0431 0.0427 -0.0714 0.0705  1.00  19419.  12820.\n#> 2 beta1     0.442     4.42e-1 0.0427 0.0427  0.372  0.512   1.00  17850.  12381.\n#> 3 beta2     0.0515    5.14e-2 0.0427 0.0428 -0.0179 0.121   1.00  16802.  12540.\n#> 4 sigma     0.896     8.95e-1 0.0305 0.0303  0.848  0.948   1.00  19032.  12320.\n#> # … with abbreviated variable names ¹​ess_bulk, ²​ess_tail\n\n\nloo2_result <- fit2$loo(cores = 4)\nprint(loo2_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -568.9 14.5\n#> p_loo         3.0  0.3\n#> looic      1137.8 29.0\n#> ------\n#> Monte Carlo SE of elpd_loo is 0.0.\n#> \n#> All Pareto k estimates are good (k < 0.5).\n#> See help('pareto-k-diagnostic') for details.\n\nConsideriamo infine un terzo modello che utilizza come predittori, oltre al QI della madre, una variabile dicotomica (codificata 0 o 1) che distingue madri che hanno completato le scuole superiori da quelle che non le hanno completate. Nuovamente, la domanda è se l’aggiunta di tale predittore migliori la capacità predittiva del modello.\n\nmodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] x1;\n  vector[N] x3;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta1;\n  real beta3;\n  real<lower=0> sigma;\n}\ntransformed parameters {\n  vector[N] mu;\n  for (n in 1 : N) {\n    mu[n] = alpha + beta1 * x1[n] + beta3 * x3[n];\n  }\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n  beta3 ~ normal(0, 1);\n  sigma ~ cauchy(0, 1);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu[n], sigma);\n    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x3[n] * beta3, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/mreg3.stan\")\n\n\ndf$x3 <- df$mom_hs\n\n\ndata3_list <- list(\n  N = length(df$kid_score),\n  y = df$y,\n  x1 = df$x1,\n  x3 = df$x3\n)\n\n\nfile3 <- file.path(\"code\", \"mreg3.stan\")\n\n\nmod3 <- cmdstan_model(file3)\n\n\nfit3 <- mod3$sample(\n  data = data3_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  cores = 4L,\n  refresh = 0\n)\n\n\nfit3$summary(c(\"alpha\", \"beta1\", \"beta3\", \"sigma\"))\n#> # A tibble: 4 × 10\n#>   variable   mean median     sd    mad     q5     q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    -0.225 -0.224 0.0947 0.0945 -0.382 -0.0705  1.00    8433.    9191.\n#> 2 beta1     0.415  0.414 0.0449 0.0450  0.341  0.488   1.00   10941.   10324.\n#> 3 beta3     0.286  0.285 0.108  0.108   0.111  0.465   1.00    8452.    8606.\n#> 4 sigma     0.890  0.889 0.0302 0.0302  0.842  0.941   1.00   10828.    9623.\n\n\nloo3_result <- fit3$loo(cores = 4)\nprint(loo3_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -584.2 16.4\n#> p_loo         7.5  0.6\n#> looic      1168.3 32.8\n#> ------\n#> Monte Carlo SE of elpd_loo is 0.0.\n#> \n#> All Pareto k estimates are good (k < 0.5).\n#> See help('pareto-k-diagnostic') for details.\n\nPer eseguire un confronto tra modelli in termini della loro capacità predittiva esaminiamo la differenza di LOO-CV tra coppie di modelli. Le seguenti istruzioni \\(\\mathsf{R}\\) producono la quantità elpd_diff, ovvero la differenza tra stime della \\(elpd\\) fornite da due modelli. Il primo argomento della funzione loo_compare() specifica il modello che viene usato come confronto. Nella prima riga dell’output, il valore elpd_diff è 0 (cioè, \\(x − x = 0\\)). Nelle righe successive sono riportate le differenze rispetto al modello di confronto (in questo caso, il modello 1). La colonna se_diff riporta l’errore standard di tali differenze.\nL’incertezza della stima dell’accuratezza out-of-sample si distribuisce in maniera approssimativamente normale con media uguale al valore riportato dal software e deviazione standard uguale a ciò che è indicato nell’output come errore standard. Quando il campione è piccolo, questa approssimazione produce una forte sottostima dell’incertezza, ma fornisce comunque una stima migliore di AIC, DIC e WAIC.\n\nw <- loo_compare(loo1_result, loo2_result, loo3_result)\nprint(w)\n#>        elpd_diff se_diff\n#> model1   0.0       0.0  \n#> model2  -0.3       1.3  \n#> model3 -15.6       6.0\n\nPer interpretare l’output, usiamo il criterio suggerito da Gelman et al. (1995): consideriamo “credibile” una differenza se elpd_diff è almeno due volte maggiore di se_diff. Nel caso presente, dunque, il confronto tra il modello 2 e il modello 1 indica che la quantità elpd_diff è molto piccola rispetto al suo errore standard. Questo accade se un predittore è associato in modo trascurabile con la variabile dipendente. I dati presenti, dunque, non offrono alcuna evidenza che aggiungere dell’età della madre come predittore migliori la capacità predittiva del modello. Nel confronto tra modello 3 e modello 1, invece, la quantità elpd_diff è maggiore di due volte il valore dell’errore standard. Questo suggerisce un incremento della capacità predittiva del modello quiando il livello di istruzione della madre viene incluso tra i predittori.\nÈ anche possibile calcolare l’intervallo di credibilità per elpd_diff:\n\n15.5 + c(-1, 1) * qnorm(.95, 0, 1) * 6.0\n#> [1]  5.630878 25.369122"
  },
  {
    "objectID": "092_info_criterion.html#outlier",
    "href": "092_info_criterion.html#outlier",
    "title": "37  Criterio di informazione e convalida incrociata",
    "section": "\n37.5 Outlier",
    "text": "37.5 Outlier\nSi è soliti pensare che la maggior parte delle osservazioni del campione sia prodotta da un unico meccanismo generatore dei dati, mentre le rimanenti osservazioni sono la realizzazione di un diverso processo stocastico. Le osservazioni che appartengono a questo secondo gruppo si chiamano outlier. È dunque necessario identificare gli outlier e limitare la loro influenza sull’inferenza.2\nPoniamoci ora il problema di identificare gli outlier con la tecnica PSIS-LOO-CV. Quando PSIS-LOO-CV viene calcolato con il pacchetto loo, l’output riporta il parametro di forma della distribuzione di Pareto (valore k). Tale valore può essere utilizzato per identificare gli outlier. Infatti, il valore k valuta, per ciascun punto del campione, l’approssimazione usata da PSIS-LOO-CV. Se \\(k < 0.5\\), i pesi di importanza vengono stimati in modo accurato; se il valore \\(k\\) di Pareto di un punto è \\(> 0.7\\), i pesi di importanza possono essere inaccurati. Le osservazioni con \\(k > 0.7\\) sono dunque osservazioni outlier.\nPer fare un esempio concreto, introduciamo nel campione dell’esempio precedente una singola osservazione outlier.\n\ndf1 <- df\ndim(df1)\n#> [1] 434   9\ndf1$x1[434] <- 10\ndf1$y[434] <- 10\n\nSistemiamo i dati nel formato appropriato per Stan:\n\ndata1a_list <- list(\n  N = length(df1$kid_score),\n  y = df1$y,\n  x1 = df1$x1\n)\n\nAdattiamo nuovamente il modello 1 ad un campione di dati che contiene un outlier.\n\nfit1a <- mod1$sample(\n  data = data1a_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nloo1a_result <- fit1a$loo(cores = 4)\n\nUna tabella diagnostica che riassume le stime dei parametri di forma della distribuzione di Pareto si ottiene nel modo seguente:\n\nprint(loo1a_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -586.2 19.9\n#> p_loo         6.6  5.0\n#> looic      1172.5 39.8\n#> ------\n#> Monte Carlo SE of elpd_loo is NA.\n#> \n#> Pareto k diagnostic values:\n#>                          Count Pct.    Min. n_eff\n#> (-Inf, 0.5]   (good)     433   99.8%   10708     \n#>  (0.5, 0.7]   (ok)         0    0.0%   <NA>      \n#>    (0.7, 1]   (bad)        1    0.2%   75        \n#>    (1, Inf)   (very bad)   0    0.0%   <NA>      \n#> See help('pareto-k-diagnostic') for details.\n\nUn grafico che riporta le stime dei parametri di forma della distribuzione di Pareto per ciascuna osservazione è dato da:\n\nplot(loo1a_result)\n\n\n\n\n\n\n\nIl valore k stimato da PSIS-LOO-CV mette chiaramente in luce il fatto che il valore introdotto nel campione è un outlier. L’indice dell’osservazione outlier è identificato con:\n\npareto_k_ids(loo1a_result, threshold = 0.7)\n#> [1] 434"
  },
  {
    "objectID": "092_info_criterion.html#regolarizzazione",
    "href": "092_info_criterion.html#regolarizzazione",
    "title": "37  Criterio di informazione e convalida incrociata",
    "section": "\n37.6 Regolarizzazione",
    "text": "37.6 Regolarizzazione\nAbbiamo motivato la presente discussione affermando che uno dei problemi più grandi che i ricercatori devono afforntare è quello della generalizzabilità dei loro risultati. McElreath (2020) fa notare che un modo per favorire la capacità del modello di generalizzarsi a nuovi campioni è quello di fare in modo che produca un adattamento peggiore ai dati del campione presente. Il problema del sovra-adattamento (e quindi di una bassa generalizzabilità) dipende dal fatto che tutte le regolarità presenti nei dati del campione (e dunque, anche quelle che costituiscono un aspetto idiosincratico del campione presente) “vengono egualmente prese sul serio” da un modello che utilizza prior uniformi per i parametri. In tali circostanze, qualsiasi valore dei parametri viene considerato plausibile. Un modo per evitare un tale modo di procedere, che sicuramente è inadeguato, è quello di utilizzare dei prior che McElreath (2020) chiama “scettici”. I priori “scettici” più comuni sono quelli che hanno una funzione di regolarizzazione. Tali prior, se calibrati correttamente, riducono il sovra-adattamento pur consentendo al modello di rappresentare le regolarità che emergono dai dati del campione. Se il prior è “troppo scettico”, tuttavia, le regolarità dei dati campionari non vengono rappresentate dal modello; di conseguenza, ciò produce un sotto-adattamento. Il problema è quello di trovare un equilibrio tra gli opposti pericoli del sovra-adattamento e del sotto-adattamento. La buona notizia è che anche un prior “moderatamente scettico” è in grado di fornire un grande aiuto al modello, e questo è tutto quello che possiamo sperare di ottenere dato che, in generale, non ci sono né modelli ottimali né distribuzioni a priori ottimali (ovvero, modelli e distribuzioni a priori che non possono essere migliorati).\nUn esempio di una distribuzione a priori di regolarizzazione può essere fornito facendo riferimento al modello lineare, per esempio. Se standardizziamo i dati, un prior \\(\\beta \\sim \\mathcal{N}(0, 1)\\) per il parametro che codifica la pendenza della retta di regressione ci dice che, prima di osservare i dati, il modello “è molto scettico” rispetto ai valori possibili di \\(\\beta\\) esterni all’intervallo \\([-2, 2]\\) deviazioni standard. In altri termini, ritiene che sia molto improbabile che un cambiamento di 1 deviazione standard nella \\(x\\) sia associato ad un cambiamento medio superiore a 2 unità di deviazione standard nella \\(y\\).\nMa potremmo anche usare una distribuzione a priori gaussiana con parametro \\(\\sigma\\) uguale a 0.5 oppure a 0.2. Quale prior usare dipende dal modello e dai dati – non c’è una raccomandazione che risulta sempre valida. L’effetto maggiore dei prior “molto scettici” si manifesta nel caso di modelli complessi e nel caso di piccole numerosità campionarie – ovvero, proprio nei casi in cui il rischio del sovra-adattamento è più grande. Se invece il campione è sufficientemente grande e il modello non è eccessivamente complesso, i prior, quali essi siano, hanno invece un effetto trascurabile sulla stima della distribuzione a posteriori."
  },
  {
    "objectID": "092_info_criterion.html#commenti-e-considerazioni-finali",
    "href": "092_info_criterion.html#commenti-e-considerazioni-finali",
    "title": "37  Criterio di informazione e convalida incrociata",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questo Capitolo, utilizzando Stan insieme al pacchetto loo, abbiamo imparato ad usare la convalida incrociata K-fold e la convalida incrociata leave-one-out. Abbiamo esaminato alcuni esempi nei quali la convalida incrociata ci consente di distinguere tra due modelli. In generale, la convalida incrociata si dimostra utile utile quando vengono confrontati modelli piuttosto diversi; quando i modelli sono molto simili, invece, risulta spesso difficile distinguerli con le tecniche qui discusse. In particolare, risulta spesso difficile ottenere risultati conclusivi dal confronto di modelli tramite la convalida incrociata se l’effetto è molto piccolo e/o se il campione di dati è piccolo. In questi casi, alcuni ricercatori ritengono che siano più adatti altri metodi di confronto dei modelli, come ad esempio i fattori di Bayes. L’uso dei fattori di Bayes, tuttavia, è controverso, dato che essi dipendono fortemente dalla scelta delle distribuzioni a priori. Se possibile è preferibile utilizzare le procedure descritte in questa parte della dispensa, con campioni di ampiezza adeguata.\n\n\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\n\n\nGelman, A., Hwang, J., & Vehtari, A. (2014). Understanding predictive information criteria for bayesian models. Statistics and Computing, 24(6), 997–1016.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain & Behavior, 2(1), 28–34.\n\n\nVehtari, A., Gelman, A., & Gabry, J. (2017). Practical bayesian model evaluation using leave-one-out cross-validation and WAIC. Statistics and Computing, 27(5), 1413–1432."
  },
  {
    "objectID": "frequentist_inference.html",
    "href": "frequentist_inference.html",
    "title": "Parte 7: Inferenza frequentista",
    "section": "",
    "text": "L’approccio frequentista è basato sull’idea di probabilità quale frequenza relativa. Tale approccio immagina che un determinato esperimento casuale venga ripetuto infinite volte e si chiede come si distribuiscono i risultati ottenuti. Nel Capitolo 38 viene presentata la legge dei grandi numeri. Nel Capitolo 39 viene presentata la nozione di intervallo fiduciale; verrà discussa l’interpretazione corretta di questo concetto e verranno presentati alcune diffusi fraintendimenti. Nel Capitolo 40 viene discussa la distribuzione campionaria della media, un esempio della logica che sta alla base dell’inferenza frequentista. Nel Capitolo 41 viene presentata la controversa procedura di test di ipotesi statistiche. Nel Capitolo 42 viene presentata la procedura di confronto tra medie, una delle applicazioni più popolari dell’inferenza frequentista. Nel Capitolo 43 verranno discussi i limiti dell’inferenza frequentista."
  },
  {
    "objectID": "220_intro_frequentist.html#parametri-e-statistiche",
    "href": "220_intro_frequentist.html#parametri-e-statistiche",
    "title": "38  Legge dei grandi numeri",
    "section": "\n38.1 Parametri e statistiche",
    "text": "38.1 Parametri e statistiche\nIn statistica, per popolazione si intende un insieme di elementi che presenta caratteristiche aleatorie, mentre per campione si intende un sottoinsieme della popolazione. Ma a cosa corrisponde in pratica la popolazione? Per uno psicologo la popolazione è un gruppo di individui. Per un biologo marino la popolazione è un gruppo di delfini, ad esempio. Nella maggior parte dei casi, le popolazioni oggetto di interesse per i ricercatori sono insiemi di entità concrete che esistono nel mondo reale. Dal punto di vista della statistica, invece, le popolazioni sono delle entità astratte. Infatti, gli statistici operazionalizzano il concetto di “popolazione” nei termini di un oggetto matematico che consente di essere manipolato con facilità. In precedenza noi abbiamo già incontrato questi oggetti matematici: sono le distribuzioni di probabilità.\nL’idea è semplice. Supponiamo di occuparci del quoziente di intelligenza, QI. Abbiamo detto che, per uno psicologo, la popolazione di interesse solitamente è un gruppo di individui, ciascuno dei quali è dotato di uno specifico punteggio del QI. Uno statistico “semplifica” tale situazione definendo in maniera operativa la popolazione come la distribuzione di densità rappresentata nella figura @ref(fig:qidensity). In precedenza abbiamo visto infatti come una distribuzione di densità non sia altro che la descrizione matematica della “forma” di un istogramma che rappresenta un numero molto alto di osservazioni.\n\nlibrary(\"ggfortify\")\nggdistribution(dnorm, seq(60, 140, 0.1), mean = 100, sd = 15) +\n  labs(\n    x = \"Quoziente d'intelligenza\",\n    y = \"Densità di probabilità\"\n  )\n\n\n\nGrafico della distribuzione dei punteggi del QI nella popolazione.\n\n\n\n\nI test di intelligenza sono progettati in modo che il QI medio sia pari a 100, la deviazione standard dei punteggi QI sia uguale a 15 e la distribuzione dei punteggi del QI sia normale. I valori riportati sopra sono detti parametri in quanto descrivono le proprietà dell’intera popolazione. Cioè, diciamo che la media della popolazione è \\(\\mu = 100\\) e la deviazione standard della popolazione è \\(\\sigma = 15\\). Dal punto di vista statistico, dunque, possiamo rappresentare questa ipotetica popolazione di valori del QI mediante l’oggetto matematico che corrisponde a una particolare distribuzione Normale:\n\\[\nQI \\sim \\mathcal{N}(\\mu = 100, \\sigma = 15).\n\\] Supponiamo ora di eseguire un esperimento nel quale il test di intelligenza viene somministrato a 100 persone selezionate a caso. Tale campione casuale semplice consiste nel seguente insieme di 100 numeri:\n\nset.seed(123)\niq1 <- rnorm(100, 100, 15)\n# i valori QI sono numeri interi!\niq1 <- round(iq1) \niq1\n#>   [1]  92  97 123 101 102 126 107  81  90  93 118 105 106 102  92 127 107  71\n#>  [19] 111  93  84  97  85  89  91  75 113 102  83 119 106  96 113 113 112 110\n#>  [37] 108  99  95  94  90  97  81 133 118  83  94  93 112  99 104 100  99 121\n#>  [55]  97 123  77 109 102 103 106  92  95  85  84 105 107 101 114 131  93  65\n#>  [73] 115  89  90 115  96  82 103  98 100 106  94 110  97 105 116 107  95 117\n#>  [91] 115 108 104  91 120  91 133 123  96  85\n\nTali valori sono stati trovati utilizzando la funzione rnorm() che genera numeri casuali estratti da una distribuzione normale. Nello specifico, abbiamo estratto 100 valori casuali dalla distribuzione normale con media 100 e deviazione standard 15. Se costruiamo un istogramma con i dati di un tale campione otteniamo il grafico mostrato nella figura @ref(fig:histogramqi).\n\ndata.frame(iq1) %>% \n  ggplot(aes(x = iq1)) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Quoziente d'intelligenza\",\n    y = \"Densità\"\n  )\n\n\n\nIstogramma della distribuzione dei punteggi del QI in un campione di 100 osservazioni.\n\n\n\n\nCome possiamo vedere, l’istogramma ha approssimativamente la forma corretta, ma è un’approssimazione molto cruda della distribuzione della popolazione mostrata nella figura @ref(fig:qidensity). Se calcoliamo la media del campione, otteniamo un numero abbastanza vicino alla media della popolazione di 100, ma non identico: nel campione considerato la media e la deviazione standard sono uguali a:\n\nmean(iq1)\n#> [1] 101.42\nsd(iq1)\n#> [1] 13.66643\n\nQueste statistiche campionarie descrivono le proprietà di uno specifico campione che è stato osservato e, sebbene siano abbastanza simili ai parametri della popolazione, non sono uguali ad essi. In generale, le statistiche campionarie sono ciò che è possibile calcolare a partire dai dati osservati sul campione mentre i parametri della popolazione sono ciò che vorremmo conoscere."
  },
  {
    "objectID": "220_intro_frequentist.html#teorema-di-bernoulli",
    "href": "220_intro_frequentist.html#teorema-di-bernoulli",
    "title": "38  Legge dei grandi numeri",
    "section": "\n38.2 Teorema di Bernoulli",
    "text": "38.2 Teorema di Bernoulli\nNella sezione Parametri e statistiche abbiamo considerato i risultati di un esperimento casuale nel quale sono stati osservati i valori fittizi del QI di un campione di ampiezza \\(n = 100\\). I risultati sono incoraggianti: la media campionaria di 101.42 ci fornisce un’approssimazione ragionevole della media della popolazione \\(\\mu = 100\\). In molti studi un tale livello di precisione è accettabile, ma in altre situazioni è necessario essere più precisi.\nCosa dobbiamo fare se vogliamo che le statistiche campionarie siano più vicine ai parametri della popolazione? La risposta è ovvia: dobbiamo raccogliere più dati. Supponiamo dunque di condurre un nuovo esperimento nel quale misuriamo il QI di 10000 persone. Possiamo simulare i risultati di questo esperimento usando R:\n\nset.seed(123)\niq2 <- rnorm(n = 10000, mean = 100, sd = 15) \niq2 <- round(iq2) \nhead(iq2)\n#> [1]  92  97 123 101 102 126\n\nNella figura @ref(fig:histogramqi2) è riportato l’istogramma dei valori del QI di questo campione più numeroso. È chiaro che, in questo secondo caso, otteniamo un’approssimazione migliore rispetto al precedente campione più piccolo. Ciò si riflette anche nelle statistiche del campione:\n\nmean(iq2)\n#> [1] 99.9671\nsd(iq2)\n#> [1] 14.9855\n\nQuesti valori sono molto vicini ai parametri della popolazione.\n\ndata.frame(iq2) %>% \n  ggplot(aes(x = iq2)) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Quoziente d'intelligenza\",\n    y = \"Densità\"\n  )\n\n\n\nIstogramma della distribuzione dei punteggi del QI in un campione di 10000 osservazioni.\n\n\n\n\nIl messaggio, un po’ banale, che ricaviamo a questa simulazione è che, generalmente, i campioni di dimensioni maggiori forniscono informazioni migliori. Ho chiamato “banali” i risultati di questa simulazione perché dovrebbe essere evidente a tutti che le cose stanno così. Infatti, questo punto è talmente ovvio che, quando Jacob Bernoulli – uno dei fondatori della teoria della probabilità – formalizzò questa idea nel 1713, commentò il risultato nel modo seguente:\n\nPerché anche il più stupido degli uomini, basandosi soltanto sul suo istinto, da solo e senza alcuna istruzione (il che è notevole), è convinto che maggiore è il numero di osservazioni, minore è il pericolo di sbagliare.\n\nIn statistica questa intuizione va sotto il nome di Legge dei grandi numeri. La Legge dei grandi numeri ci dice che la media aritmetica di un campione di \\(n\\) osservazioni.\nIn termini tecnici: di \\(n\\) variabili aleatorie \\(X_i\\) indipendenti e identicamente distribuite), ovvero \\(\\frac{1}{n}\\sum_{i=1}^nX_i\\), per \\(n\\) crescente tende o converge al valore atteso teorico \\(\\mu\\).\nLa Legge dei grandi numeri è uno degli strumenti più importanti della statistica.\n\n\n\n\n\n\nSi noti che la Legge dei grandi numeri non può dirci se lo strumento o l’esperimento considerati stiano producendo dei dati utili o dei dati che è sensato riassumere tramite la media. Ad esempio, se il dispositivo di misurazione è difettoso, la media di molte misurazioni sarà una stima molto accurata della cosa sbagliata! Questo è un esempio di errore sistematico, o errore di campionamento, che sono qualcosa di molto diverso dal fenomeno di fluttuazione casuale che viene descritto dalla Legge dei grandi numeri."
  },
  {
    "objectID": "221_conf_interv.html#la-variabilità-campionaria",
    "href": "221_conf_interv.html#la-variabilità-campionaria",
    "title": "39  Intervallo fiduciale",
    "section": "\n39.1 La variabilità campionaria",
    "text": "39.1 La variabilità campionaria\nConsideriamo, quale esempio, l’esperimento casuale che corrisponde all’estrazione casuale di un campione di \\(n\\) osservazioni da una popolazione e del calcolo della media di quel campione. Dato che si immagina che l’esperimento casuale venga ripetuto infinite volte, dobbiamo immaginare l’esistenza di infiniti campioni casuali di \\(n\\) osservazioni. Dato che ciascuno di tali campioni è costituito da osservazioni diverse, ognuno di essi avrà una media diversa. Tale fenomeno è detto variabilità campionaria. Se usiamo il linguaggio dell’approccio frequentista diremo che la distribuzione dei tutti gli infiniti possibili valori della statistica in questione (nel caso dell’esempio, la media del campione) nell’universo dei campioni si chiama distribuzione campionaria.\nSe lo psicologo usa la media del campione quale stima della media della popolazione, ovviamente commetterà un errore, dato che la statistica campionaria è sempre diversa dal parametro. Il problema dello psicologo è quello di valutare l’entità di tale errore, ovvero quello di valutare il livello di incertezza inerente alla sua stima.\nPer valutare l’incertezza della stima lo psicologo fa riferimento alla variabilità campionaria. Se la deviazione standard della distribuzione campionaria della statistica è piccola, questo significa che ogni campione casuale di ampiezza \\(n\\) produrrà una statistica \\(\\bar{X}\\) simile al parametro \\(\\mu\\) della popolazione. In tali condizioni (utilizzando i dati di un singolo campione) ci sarà una piccola incertezza relativamente al valore del parametro, perché, in media, \\(\\bar{X}\\) è simile a \\(\\mu\\). Se invece la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\) è grande, i campioni casuali di ampiezza \\(n\\) produrranno, in media, una statistica \\(\\bar{X}\\) molto lontana dal parametro \\(\\mu\\). Utilizzando i dati di un singolo campione, in tali condizioni lo psicologo sarà molto incerto relativamente al vero valore del parametro (in quanto, in media, \\(\\bar{X}\\) è molto diverso da \\(\\mu\\)).\nLa deviazione standard della distribuzione campionaria, detta errore standard, viene dunque utilizzata per quantificare l’incertezza relativamente alla stima di un parametro. Solitamente, l’approccio frequentista quantifica l’incertezza della stima nei termini di una funzione dell’errore standard chiamata intervallo fiduciale. Lo scopo di questo capitolo è quello di introdurre la nozione di errore standard in modo tale da potere fornire un’interpretazione alla nozione di intervallo fiduciale."
  },
  {
    "objectID": "221_conf_interv.html#lerrore-standard",
    "href": "221_conf_interv.html#lerrore-standard",
    "title": "39  Intervallo fiduciale",
    "section": "\n39.2 L’errore standard",
    "text": "39.2 L’errore standard\nPer fare un esempio, chiediamoci come sia possibile misurare la variabilità della proporzione di studenti promossi, se prendiamo in considerazione tutti i possibili appelli d’esame di Psicometria a Firenze (quelli passati, quelli presenti e anche quelli futuri). Da ciò che è stato presentato in precedenza, sappiamo che la statistica più utile per quantificare la variabilità di una variabile è la deviazione standard. Questo fatto fornisce la risposta anche alla domanda che ci siamo posti ora: in linea di principio, potremmo usare la deviazione standard per descrivere di quanto variano, in media, i valori delle proporzioni di studenti promossi in tutti i possibili appelli d’esame di Psicometria a Firenze. Un problema che dobbiamo affrontare, però, riguarda il fatto che la distribuzione di valori a cui facciamo riferimento è una distribuzione di valori virtuali, non è un insieme di dati che abbiamo osservato. Per calcolare la deviazione standard, dunque, dobbiamo procedere in modo diverso da quanto abbiamo fatto in precedenza. Iniziamo con un po’ di terminologia.\n\nDefinizione 39.1 Si dice errore standard la deviazione standard dei valori una statistica campionaria nell’universo dei campioni.\n\nL’errore standard è molto importante perché descrive l’accuratezza della nostra stima. Se l’errore standard è piccolo questo ci dice che, se osserviamo un campione diverso da quello corrente, allora ci aspettiamo che la statistica in esame abbia un valore simile a quello corrente. Un grande errore standard, invece, ci dice che non dobbiamo assegnare troppa fiducia alla stima ottenuta nel campione a disposizione perché, in un altro campione, si otterrà una stima molto diversa, e, in media, i valori ottenuti in campioni diversi saranno lontani dal vero valore del parametro sconosciuto (ovvero, nell’esempio considerato, dalla media di tutte le proporzioni che si possono ottenere).\nIl calcolo dell’errore standard è solitamente lasciato ad un software. Ma come si arriva ad una quantificazione dell’errore standard? Forniamo qui solo una descrizione intuitiva della procedura che viene seguita e forniamo la seguente definizione.\n\nDefinizione 39.2 L’errore standard può essere inteso come una misura (del reciproco) della curvatura della verosimiglianza in corrispondenza della stima di massima verosimiglianza per un parametro \\(\\theta\\).\n\nPer capire come si traduce in pratica la Definizione 39.2, esaminiamo la Figura 39.1. Nel pannello di sinistra è riprodotta la funzione di verosimiglianza nel caso di 7 successi in 10 prove Bernoulliane. Nel pannello centrale è riportata la verosimiglianza per 70 successi in 100 prove e nel pannello di destra abbiamo la verosimiglianza nel caso di 700 successi in 1000 prove.\n\n\nFigura 39.1: Funzione di verosimiglianza nel caso di 7 successi in 10 prove Bernoulliane (pannello di sinistra), di 70 successi in 100 prove (pannello centrale) e di 700 successi in 1000 prove (pannello di destra).\n\n\nQuello che la Figura 39.1 ci dice è che, al crescere del numero di prove, diminuisce la nostra incertezza relativamente al valore del parametro \\(\\pi\\) (probabilità di successo, ovvero, la media di tutte le proporzioni campionarie). Nel caso di un piccolo numero di prove, la verosimiglianza ha una piccola curvatura e ci fornisce una modesta quantità di informazione concernente il parametro non osservabile \\(\\pi\\) – in altri termini, la verosimiglianza definisce un intervallo piuttosto ampio di valori \\(\\pi\\) la cui plausibilità relativa è piuttosto grande. Con un grande numero di prove, invece, la verosimiglianza ha un picco molto più marcato che associa livelli relativamente alti di plausibilità ad un intervallo molto più piccolo di valori \\(\\pi\\). In altre parole, maggiore è la curvatura della verosimiglianza, maggiore è la quantità di informazione che il campione fornisce rispetto al valore del parametro sconosciuto che vogliamo stimare.\nIn termini formali, la curvatura è la derivata seconda di una funzione e, appunto, calcolando la derivata seconda della funzione di verosimiglianza possiamo trovare l’errore standard di una statistica. Nel caso presente, l’errore standard della proporzione campionaria è\n\\[\\begin{equation}\n\\sigma_{\\hat{\\pi}} = \\sqrt{\n\\frac{p (1-p)}{n},\n}\n\\end{equation}\\]\ndove \\(p\\) è la proporzione campionaria e \\(n\\) è il numero di osservazioni. Questa quantità si interpreta come qualunque deviazione standard: nello specifico, ci dice quanto varia in media la proporzione campionari se consideriamo campioni diversi. Si noti che, avendo \\(n\\) al denominatore, la formula riproduce l’intuizione che abbiamo descritto mediante la Figura 39.1: quando \\(n\\) è grande l’errore standard è piccolo e, viceversa, quando \\(n\\) è piccolo l’errore standard è grande. In altri termini, quando l’errore standard di una stima è piccolo, possiamo attribuire un grande livello di fiducia al valore della stima del parametro. Invece, un grande errore standard ci suggerisce ad essere cauti in qualunque inferenza che potremmo trarre dalla stima che abbiamo ottenuto."
  },
  {
    "objectID": "221_conf_interv.html#sec-int_conf",
    "href": "221_conf_interv.html#sec-int_conf",
    "title": "39  Intervallo fiduciale",
    "section": "\n39.3 Che cos’è l’intervallo fiduciale?",
    "text": "39.3 Che cos’è l’intervallo fiduciale?\nL’approccio frequentista non si limita al calcolo dell’errore standard ma affronta il problema di quantificare il grado di incertezza associato alle stime campionarie utilizzando un altro concetto, ovvero la nozione di intervallo di fiducia. Vale la pena di sottolineare che il principale significato del termine inglese confidence non è confidenza bensì fiducia. L’intervallo di fiducia è una semplice trasformazione dell’errore standard e tale nozione può essere chiarita nel modo seguente.\nLa stima \\(\\hat{\\theta}\\) di un parametro \\(\\theta\\) si determina esaminando i dati forniti da un campione casuale. Sappiamo che il valore empirico \\(\\hat{\\theta}\\) non coincide mai con il vero valore del parametro (dato che il campione è diverso dalla popolazione). Conoscendo la distribuzione di \\(\\hat{\\theta}\\) diventa però possibile valutare l’errore commesso e definire l’intervallo \\([\\theta_{min} \\leq \\hat{\\theta} \\leq \\theta_{max}]\\) che, a lungo termine, comprende il valore del parametro incognito \\(\\theta\\) con una probabilità \\(\\gamma \\in [0, 1]\\) prossima ad 1. Questo intervallo si chiama intervallo fiduciale.\n\nDefinizione 39.3 Si dice intervallo fiduciale l’intervallo \\([\\theta_{min}, \\theta_{max}]\\) tale che \\[\\begin{equation}\nP(\\theta_{min} \\leq \\theta \\leq \\theta_{max}) \\geq \\gamma, \\qquad \\forall \\theta \\in \\Theta,\\notag\n\\end{equation}\\] dove \\(\\Theta\\) indica l’insieme dei valori possibili del parametro \\(\\theta\\).\n\nGli estremi dell’intervallo di fiducia sono chiamati limiti fiduciari e la probabilità \\(\\gamma\\) è chiamata livello fiduciario; espressa in percentuale, essa esprime il livello di significatività della stima effettuata."
  },
  {
    "objectID": "221_conf_interv.html#come-si-calcola-lintervallo-fiduciale",
    "href": "221_conf_interv.html#come-si-calcola-lintervallo-fiduciale",
    "title": "39  Intervallo fiduciale",
    "section": "\n39.4 Come si calcola l’intervallo fiduciale?",
    "text": "39.4 Come si calcola l’intervallo fiduciale?\nIn alcuni casi, la distribuzione delle statistiche campionarie approssima la Normale e, in tali casi, l’intervallo fiduciale al 95% è dato da\n\\[\\begin{equation}\n\\hat{\\theta} \\pm 1.96 \\cdot \\text{SE}, \\notag\n\\end{equation}\\]\novvero, dalla stima del parametro \\(\\pm\\) 1.96 volte l’errore standard.\nConoscendo l’errore standard, è dunque molto semplice calcolare l’intervallo fiduciale. Meno semplice, invece, è interpretare l’intervallo fiduciale nel modo corretto. Per capire quale sia l’interpretazione corretta dell’intervallo fiduciale, iniziamo a definire il concetto di livello di copertura."
  },
  {
    "objectID": "221_conf_interv.html#il-livello-di-copertura",
    "href": "221_conf_interv.html#il-livello-di-copertura",
    "title": "39  Intervallo fiduciale",
    "section": "\n39.5 Il livello di copertura",
    "text": "39.5 Il livello di copertura\nSi indica con \\(1-\\alpha\\) il livello di copertura fornito dall’intervallo fiduciale. Il termine probabilità di copertura si riferisce alla probabilità che la procedura per la costruzione degli intervalli di fiducia produca un intervallo che contiene (o copre) il valore reale del parametro di interesse. Esiste infatti sempre una probabilità pari ad \\(\\alpha\\) che i dati campionari producano un intervallo che non contiene il valore reale del parametro di interesse.\nRicordiamo che l’approccio frequentista interpreta la probabilità di un evento come la proporzione di volte in cui tale evento si verifica avendo osservato molte ripetizioni indipendenti di un esperimento casuale. Nel caso presente, l’evento in questione è la risposta alla domanda “l’intervallo fiduciale contiene il valore del parametro?” mentre l’esperimento casuale corrisponde al calcolo dell’intervallo fiduciale per la statistica in question in un campione casuale di ampiezza \\(n\\). L’interpretazione frequentista della nozione di livello di copertura può essere chiarita mediante la seguente simulazione.\nPrendiamo in considerazione la distribuzione dell’altezza degli adulti maschi nella popolazione. Sappiamo che l’altezza degli individui segue la distribuzione normale. Sappiamo inoltre che, per esempio, l’altezza media di un italiano adulto maschio è di \\(175\\) cm, con una varianza di \\(49\\) cm\\(^2\\). Utilizziamo queste informazioni per realizzare la seguente simulazione in R. Nella simulazione prevediamo 100 ripetizioni dell’esperimento casuale che consiste nell’estrazione di un campione di ampiezza \\(n = 20\\) dalla popolazione distribuita come \\(\\mathcal{N}(175, 7)\\). Per ciascun campione casuale così trovato utilizzeremo poi la funzione t.test() per calcolare l’intervallo fiduciale al 95%. Salveremo quindi nella matrice sampling_distribution il limite inferiore e il limite superiore dell’intervallo fiduciale trovato in ciascuno dei 100 campioni.\n\nset.seed(1235)\nnrep <- 100\nsampling_distribution <- matrix(NA, nrow = nrep, ncol = 2)\npoint_estimate <- rep(NA, nrep)\nsample_size <- 20\nmu <- 175\nsigma <- 7\n\nfor (i in 1:nrep) {\n  y <- rnorm(sample_size, mu, sigma)\n  temp <- t.test(y, conf.level = 0.95)\n  sampling_distribution[i, ] <- temp$conf.int\n  point_estimate[i] <- temp$estimate\n}\n\nCreiamo poi un data.frame a cui aggiungiamo una colonna che riporta i valori delle medie campionarie.\n\ncolnames(sampling_distribution) <- c(\"lcl\", \"ucl\")\nsampling_distribution <- \n  as.data.frame(sampling_distribution)\nsampling_distribution$mean <- as.numeric(point_estimate)\nsampling_distribution$replicate <- 1:nrep\nsampling_distribution$captured <- factor(ifelse(\n  sampling_distribution$lcl <= mu & sampling_distribution$ucl >= mu, \n  1, 0\n))\nlevels(sampling_distribution$captured) <- c('No', 'Si')\n\nUtilizzando ggplot() creiamo la Figura 39.2 che riporta i 100 intervalli fiduciali al 95% che abbiamo ottenuto, uno per ciascuno dei 100 diversi campioni casuali estratti dalla distribuzione delle altezze.\n\np <- ggplot(sampling_distribution) +\n  geom_point(\n    aes(\n      x = point_estimate, y = replicate, color = captured)\n    ) +\n  geom_segment(aes(\n    y = replicate, yend = replicate, x = lcl, xend = ucl,\n    color = captured\n  )) +\n  geom_vline(\n    xintercept = 175, linetype = 2, color = \"white\"\n  ) +\n  labs(\n    x = \"Stima puntuale\",\n    y = \"Campioni simulati\"\n  ) +\n  guides(color=guide_legend(\"Parametro contenuto nell'intervallo\")) +\n  theme(legend.position = \"bottom\")\np\n\n\n\nFigura 39.2: Livello di copertura empirico per 100 campioni causali estratti da \\(\\mathcal{N}(175, 7)\\).\n\n\n\n\nLa Figura 39.2 riporta i 100 intervalli fiduciali del 95% calcolati nella simulazione descritta sopra e distingue tra intervalli fiduciali che contengono il valore del parametro e intervalli che non lo contengono. Se ripetiamo la simulazione 10000 volte troviamo un livello di copertura (ovvero, una proporzione di intervalli fiduciali del 95% che contengono il parametro) pari a 0.9468. Questo valore è molto prossimo al livello nominale \\(1 - \\alpha = 0.95\\)."
  },
  {
    "objectID": "221_conf_interv.html#sec-interpret-ci",
    "href": "221_conf_interv.html#sec-interpret-ci",
    "title": "39  Intervallo fiduciale",
    "section": "\n39.6 Interpretazione}",
    "text": "39.6 Interpretazione}\nStudenti e ricercatori tendono ad interpretare gli intervalli fiduciali dicendo che “c’è una probabilità del 95% che la vera media della popolazione si trovi all’interno dell’intervallo fiduciale”. Questa è un’interpretazione semplice e cattura l’idea del senso comune secondo la quale una probabilità di 0.95 significa: “sono sicuro al 95%”. Sfortunatamente, l’interpretazione precedente è sbagliata. La precedente interpretazione richiede che la probabilità venga descritta in termini soggettivi e corrisponde a dire: “sono fiducioso al 95% che l’intervallo così costruito contenga la media della popolazione, perché questa è la mia opinione”. Nella vita di tutti i giorni un tale punto di vista va benissimo, ma parlare di opinioni soggettive e di fiducia è un’idea Bayesiana. Non c’è niente di male con l’idea che la nozione “probabilità del 95%” possa riferirsi a un’opinione personale. Tuttavia, gli intervalli fiduciali sono una procedura statistica di stampo frequentista, non Bayesiano. Se usiamo degli strumenti statistici frequentisti per costruire l’intervallo fiduciale non possiamo attribuire ad esso un’interpretazione Bayesiana, ma dobbiamo interpretare tale intervallo di valori in maniera coerente con l’impianto teorico frequentista – anche perché gli intervalli di fiducia frequentisti e gli intervalli di credibilità Bayesiani sono numericamente diversi!\nSe l’interpretazione presentata sopra non è corretta, allora qual è l’interpretazione corretta dell’intervallo fiduciale? Dobbiamo ricordare ciò che abbiamo detto sulla probabilità frequentista: in base all’approccio frequentista la probabilità di un evento è alla proporzione di volte con la quale un evento si è verificato in una sequenza di esperimenti casuali. È necessario ripetere tante volte un esperimento casuale, anche solo in maniera ipotetica (come nella simulazione descritta sopra), altrimenti non è possibile parlare di probabilità. L’interpretazione frequentista di un intervallo fiduciale deve avere a che fare con la ripetizione di un esperimento casuale e può essere formulata nel modo seguente.\n\nDefinizione 39.4 Se ripetessimo tante volte l’esperimento casuale che consiste nell’estrarre un campione casuale dalla popolazione e nel calcolare l’intervallo fiduciale al 95%, allora nel 95% dei casi gli intervalli così calcolati conterrebbero il vero valore del parametro.\n\nPiù in generale, se si estraggono successivamente più campioni indipendenti dalla stessa popolazione e se si determinano i relativi intervalli fiduciali seguendo la procedura indicata dalla statistica frequentista, allora il \\(100 (1-\\alpha)\\)% degli intervalli così calcolati conterrà il vero valore del parametro incognito.\nQuesta idea è illustrata nella Figura 39.2 che mostra 100 intervalli fiduciali costruiti per stimare l’altezza media di un italiano adulto maschio sulla base di campioni casuali di ampiezza \\(n = 30\\). Alcuni di questi intervalli fiduciali contengono il valore del parametro, altri non lo contengono. Se la simulazione venisse ripetuta infinite volte si scoprirebbe che esattamente il 95% degli intervalli così calcolati conterrebbe il valore del parametro (e il 5% non lo conterrebbe), dato che, per costruire gli intervalli fiduciali abbiamo usato \\(\\alpha = 0.05\\).\nQuesta è l’interpretazione corretta che deve essere attribuita alla nozione di intervallo fiduciale al livello \\(100 (1-\\alpha)\\)%. È però risaputo come i ricercatori (non solo gli studenti!) spesso attribuiscono agli intervalli fiduciali un’interpretazione errata, come abbiamo descritto sopra. Non poche volte nelle riviste specialistiche si leggono affermazioni del tipo: “la probabilità che la media della popolazione \\(\\mu\\) sia contenuta nell’intervallo \\([\\hat{a}, \\hat{b}]\\) è 0.95”, mentre in realtà si dovrebbe scrivere: “la procedura tramite la quale l’intervallo \\([\\hat{a}, \\hat{b}]\\) è stato calcolato include \\(\\mu\\) nel 95% dei casi”.\n\n39.6.1 Fraintendimenti\nHoekstra et al. (2014) notano che, essendo ampiamente riconosciuti i limiti del test dell’ipotesi nulla, per l’inferenza statistica viene spesso consigliato l’utilizzo degli intervalli di fiducia. Per esempio, l’American Psychological Association Publication Manual fa riferimento agli intervalli di fiducia affermando che essi rappresentano in general, the best reporting strategy (APA, 2001, p. 22; APA, 2009, p. 34). Hoekstra et al. (2014) fanno notare, però, che tali raccomdandazioni hanno dei limiti, in quanto non tengono in considerazione la difficoltà che hanno i ricercatori a fornire agli intervalli di fiducia l’interpretazione corretta. A sostegno di questo punto di vista, Hoekstra et al. (2014) hanno svolto uno studio nel quale si sono posti due domande:\n\nin che misura gli intervalli di fiducia vengono interpretati in maniera sbagliata da studenti e ricercatori?\nle interpretazioni errate degli intervalli di fiducia diminuiscono con l’esperienza nell’ambito della ricerca?\n\nPrima di presentare lo studio, Hoekstra et al. (2014) ricordano quale sia l’interpretazione corretta degli intervalli di fiducia. Il lettore può mettere in relazione la seguente citazione con ciò che è stato discusso in precedenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (, Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNello studio, Hoekstra et al. (2014) hanno sottoposto il questionario riportato di seguito ad un campione di 596 partecipanti. Il campione includeva 442 studenti di psicologia del primo anno che seguivano un corso introduttivo di statistica presso l’università di Amsterdam, 34 studenti di master e 120 ricercatori (cioè dottorandi e docenti universitari).\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe “null hypothesis” that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nLe sei affermazioni precedenti sono tutte errate. I risultati dello studio di Hoekstra et al. (2014) mostrano però che i partecipanti si sono dichiarati d’accordo con il seguente numero medio di item (su 6): 3.51 (99% CI = [3.35, 3.68]) per gli studenti del primo anno, 3.24 (99% CI = [2.40, 4.07]) per gli studenti di master e 3.45 (99% CI = [3.08, 3.82]) per i ricercatori. Gli intervalli di fiducia al 95% si sovrappongono per le tre categorie di rispondenti il che significa che, a tale livello di fiducia, non c’è ragione di ritenere che vi siano delle differenze tra i tre gruppi di rispondenti. In altre parole, questi dati suggeriscono che i ricercatori tendono a condividere con gli studenti di psicologia del primo anno le stesse opinioni (errate!) relativamente agli intervallo fiduciali.\nLe interpretazioni errate degli intervalli di fiducia sono dunque molto diffuse e l’esperienza pratica nel mondo della ricerca non contribuisce ad una comprensione migliore di tale concetto. In generale, i risultati della ricerca di Hoekstra et al. (2014), e di altre che hanno prodotto risultati simili, mettono in discussione l’utilità degli intervalli fiduciali frequentisti (dato che molto poche persone hanno una comprensione adeguata di tale concetto), favorendo invece l’uso degli “intervallo di credibilità” Bayesiani ai quali è più facile fornire un’interpretazione corretta, perché tale interpretazione coincide con le nostre intuizioni."
  },
  {
    "objectID": "221_conf_interv.html#commenti-e-considerazioni-finali",
    "href": "221_conf_interv.html#commenti-e-considerazioni-finali",
    "title": "39  Intervallo fiduciale",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nGli intervalli fiduciali vengono spesso fraintesi. Il grado di fiducia del 95% riguarda la certezza che nel lungo periodo il 95% degli intervalli fiduciali includerà il parametro sconosciuto: nulla si può dire di uno specifico intervallo fiduciale, il quale può includere o non includere il parametro, ma il ricercatore non può saperlo. Inoltre, si può dire che non esiste alcuna relazione tra la varianza di un campione e la sua media. Pertanto non possiamo dedurre che un intervallo di fiducia più stretto sia anche più preciso. In un contesto frequentista, la precisione fa solo riferimento al livello di copertura nel lungo termine che viene fornita dalla procedura di generazione degli intervalli di fiducia: non riguarda il singolo intervallo che è stato osservato. Infatti, un intervallo di fiducia può essere molto stretto ma anche molto lontano dal vero valore del parametro sconosciuto.\n\n\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164."
  },
  {
    "objectID": "225_distr_camp_mean.html#distribuzione-campionaria",
    "href": "225_distr_camp_mean.html#distribuzione-campionaria",
    "title": "40  Distribuzione campionaria",
    "section": "\n40.1 Distribuzione campionaria",
    "text": "40.1 Distribuzione campionaria\nIn precedenza abbiamo presentato la Legge dei grandi numeri.La Legge dei grandi numeri è uno strumento molto potente, ma non è sufficiente per rispondere a tutte le nostre domande. Tutto ciò che ci offre è una “garanzia a lungo termine”. Essa ci garantisce che, a lungo termine, le statistiche campionarie saranno corrette – le statistiche campionarie forniranno la risposta esatta se verrà raccolta una quantità infinita di dati. Ma come ha affermato John Maynard Keynes (1923) in economia, una garanzia a lungo termine è di scarsa utilità nella vita reale:\n\nIl lungo periodo è una guida fuorviante per ciò che accade ora. Alla lunga saremo tutti morti. Gli economisti si sono dati un compito troppo facile, troppo inutile, se nelle stagioni tempestose possono solo dirci che, quando la tempesta sarà passata da un pezzo, l’oceano sarà di nuovo piatto.\n\nCome in economia, così anche in psicologia e nella statistica. Non è sufficiente sapere che, a lungo termine, arriveremo alla risposta giusta. È di scarso conforto sapere che un campione di dati infinitamente grande ci fornisce il valore esatto della media della popolazione, quando il campione che possiamo ottenere in qualsiasi situazione pratica non può che avere una numerosità modesta. Nell’attività pratica della ricerca psicologica, quindi, è necessario sapere qualcosa di più del comportamento delle statistiche campionarie (per esempio, la media) quando esse vengono calcolate a partire da un campione di dati molto più piccolo di quello ipotizzato dalla Legge dei grandi numeri. Queste considerazioni portano l’approccio frequentista alla formulazione di un nuovo concetto: quello di distribuzione campionaria (sampling distribution).\n\nLa distribuzione campionaria di una statistica basata su \\(n\\) osservazioni è la distribuzione di frequenza dei valori che la statistica assume. Tale distribuzione è generata teoricamente prendendo infiniti campioni di dimensione \\(n\\) e calcolando i valori della statistica per ogni campione.\n\n\n40.1.1 Simulazione\nTenendo a mente quanto detto nella sezione precedente, abbandoniamo l’idea che i nostri campioni siano in grado di raggiungere numerosità dell’ordine di grandezza delle decine o delle centinaia di migliaia di osservazioni. Prendiamo invece in esame una situazione più vicina a quella in cui gli psicologi si trovano ad operare. Consideriamo, quale esempio, un’ampiezza campionaria di \\(n = 5\\). Come in precedenza, possiamo simulare questo esperimento casuale in R, usando la funzione rnorm():\n\niq3 <- round(rnorm(n = 5, mean = 100, sd = 15))\niq3\n#> [1] 110  98 112 104 112\n\nIl QI medio in questo campione risulta pari a 107.2. Non sorprende che questo risultato sia molto meno accurato rispetto all’esperimento casuale precedente.\nImmaginiamo ora di replicare l’esperimento; immaginiamo cioè di ripetere nuovamente la procedura descritta sopra: estraiamo un nuovo campione casuale e misuriamo il QI di 5 persone. Ancora una volta utilizziamo R per effettuare la simulazione:\n\niq4 <- round(rnorm(n = 5, mean = 100, sd = 15))\niq4\n#> [1] 124 101 128 105 107\nmean(iq4)\n#> [1] 113\n\nIn quest altro campione casuale il QI medio è 113. Procediamo in questo modo e simuliamo l’esperimento casuale dieci volte in maniera tale da ottenere i risultati seguenti.\nIniziamo creando una lista di 10 campioni di ampiezza \\(n = 5\\).\n\nset.seed(123)\nsample_list <- list()\nfor (i in 1:10) {\n  sample_list[[i]] <- round(rnorm(5, 100, 15))\n}\nsample_list[[1]]\n#> [1]  92  97 123 101 102\nsample_list[[2]]\n#> [1] 126 107  81  90  93\n\nTrasformiamo la lista in un data.frame.\n\ndf <- data.frame(matrix(unlist(sample_list), nrow=length(sample_list), byrow=TRUE))\ndf\n#>     X1  X2  X3  X4  X5\n#> 1   92  97 123 101 102\n#> 2  126 107  81  90  93\n#> 3  118 105 106 102  92\n#> 4  127 107  71 111  93\n#> 5   84  97  85  89  91\n#> 6   75 113 102  83 119\n#> 7  106  96 113 113 112\n#> 8  110 108  99  95  94\n#> 9   90  97  81 133 118\n#> 10  83  94  93 112  99\n\nLe medie di ciascuno dei 10 campioni di ampiezza \\(n = 5\\) sono:\n\nrowMeans(df)\n#>  [1] 103.0  99.4 104.6 101.8  89.2  98.4 108.0 101.2 103.8  96.2\n\nPoniamoci ora il problema di replicare tante volte la procedura che ci porta a calcolare la media dei valori del QI di cinque persone prese a caso. Per ciascuna replica dell’esperimento casuale salviamo il valore della media campionaria. Così facendo, generiamo tanti valori, ciascuno dei quali corrisponde alla media di un campione casuale di 5 osservazioni. Usando i poteri magici di R, possiamo eseguire una tale simulazione mediante le seguenti istruzioni:\n\nn_samples <- 10000\nsample_size <- 5\nsample_means <- rep(NA, n_samples)\n\nfor (i in 1:n_samples) {\n    y <- round(rnorm(5, 100, 15))\n    sample_means[i] <- mean(y)\n}\n\nNella Figura 40.1 sono riportati i risultati della simulazione. Come illustrato dalla figura, la media dei 5 punteggi del QI è solitamente compresa tra 80 e 120. Ma il risultato più importante di questa simulazione è quello che ci fa capire che, se ripetiamo l’esperimento casuale più e più volte, otteniamo una distribuzione di medie campionarie. Un tale distribuzione ha un nome speciale in statistica: si chiama distribuzione campionaria della media.\n\ndata.frame(sample_means) %>% \n  ggplot(aes(x = sample_means)) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Media del quoziente d'intelligenza in campioni di ampiezza n = 5\",\n    y = \"Densità\"\n  )\n\n\n\nFigura 40.1: Istogramma della distribuzione delle medie dei punteggi del QI calcolate su 10000 campioni casuali di ampiezza \\(n=5\\).\n\n\n\n\nLa “distribuzione campionaria” è un importante concetto della statistica ed è fondamentale per comprendere il comportamento dei piccoli campioni. Quando abbiamo eseguito per la prima volta l’esperimento casuale relativo all’estrazione di cinque punteggi IQ dalla popolazione, abbiamo trovato una media campionaria pari a 101.4. Quello che impariamo dalla distribuzione campionaria delle medie di campioni di ampiezza \\(n = 5\\) della Figura 40.1 è che un tale esperimento casuale è poco accurato. Infatti, la distribuzione campionaria della media dei campioni di ampiezza \\(n=5\\) ci fa capire che, se ripetendo un tale esperimento casuale tante volte, otteniamo delle medie campionarie con valori che possono essere compresi nell’intervallo tra 80 e 120. In altre parole, la distribuzione campionaria della media di campioni di ampiezza 5 ci dice che il risultato dell’esperimento casuale (ovvero, la media osservata in un singolo campione) varia di molto tra i diversi campioni che possono essere estratti dalla popolazione. Di conseguenza, se il nostro obiettivo è quello di stimare la media della popolazione, allora non dobbiamo fidarci troppo del risultato ottenuto per caso da un singolo campione di numerosità \\(n\\) = 5. Nella discussione seguente mostreremo come sia possibile utilizzare la stima della distribuzione campionaria per descrivere le proprietà statistiche delle stime (ovvero, il grado di incertezza che è associato alle stime che otteniamo).\nSi noti che, in generale, la distribuzione campionaria non è nota, poiché dipende dalle caratteristiche della popolazione e non solo dai dati osservati nel campione. In pratica, quindi, non possiamo mai conoscere le caratteristiche esatte della distribuzione campionaria di una statistica; tali caratteristiche possono solo essere stimate."
  },
  {
    "objectID": "225_distr_camp_mean.html#distribuzione-campionaria-della-media",
    "href": "225_distr_camp_mean.html#distribuzione-campionaria-della-media",
    "title": "40  Distribuzione campionaria",
    "section": "\n40.2 Distribuzione campionaria della media",
    "text": "40.2 Distribuzione campionaria della media\nConsideriamo ora l’inferenza statistica nel caso della statistica campionaria corrispondente alla media del campione. Denotiamo con \\(\\bar{X}_n\\) la media calcolata su un campione di \\(n\\) osservazioni. Abbiamo detto che, ogni volta che osserviamo un nuovo campione di ampiezza \\(n\\), la statistica \\(\\bar{X}_n\\) assumerà un valore diverso. In termini tecnici diciamo che \\(\\bar{X}_n\\) è una variabile aleatoria, ovvero è una variabile che assume un nuovo valore ogni qualvolta l’esperimento casuale viene ripetuto (nel caso presente l’esperimento casuale corrisponde all’estrazione di un campione casuale dalla popolazione e al calcolo della media delle osservazioni campionarie). L’insieme dei valori che \\(\\bar{X}_n\\) può assumere in tutti i campioni casuali di ampiezza \\(n\\) che possono essere estratti dalla popolazione è detto distribuzione campionaria della media.\n\n40.2.1 Valore atteso della media campionaria\nQual è la media (valore atteso) della distribuzione campionaria della media? È facile mostrare che \\(\\mu_{\\bar{X}_n}\\) coincide con il valore medio \\(\\mu\\) della popolazione da cui i campioni di ampiezza \\(n\\) sono stati estratti.\n\nPonendo \\(\\bar{X}_n = S_n/n\\), dove \\(S_n = X_1 + X_2 + \\dots + X_n\\) è la somma di \\(n\\) variabili aleatorie iid, ne segue che: \\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} \\mathbb{E}(X_1 + X_2 + \\dots + X_n ) =  \\frac{1}{n} n \\mu = \\mu.\n\\]\n\n\n40.2.2 Varianza della media campionaria\nQual è la varianza della distribuzione campionaria della media? Anche in questo caso si può facilmente mostrare come la varianza della distribuzione delle medie campionarie è legata alla varianza \\(\\sigma^2\\) della popolazione dalla seguente relazione:\n\\[\nvar(\\bar{X}\\_n) = \\frac{\\sigma^2}{n},\n\\tag{40.1}\\]\ndove \\(n\\) è la numerosità dei campioni casuali.\nPrima di presentare la dimostrazione dell’Equazione 40.1 è necessario ricordare la seguente proprietà della varianza: se una variabile aleatoria \\(X\\) viene moltiplicata per una costante \\(a\\), la varianza della variabile aleatoria \\(aX\\) diventa\n\\[\nvar(a X) = a^2 var(X).\n\\]\nPossiamo ora comprendere la dimostrazione seguente.\n\n\\[\nvar(\\bar{X}_n) = \\frac{1}{n^2} var(S_n) = \\frac{1}{n^2} n \\sigma^2\n= \\frac{\\sigma^2}{n}.\n\\]\n\nI due risultati che abbiamo ottenuto sopra sono molto importanti. Il primo ci dice che la media campionaria è uno stimatore corretto (ovvero, non distorto) della media della popolazione. Il secondo quantifica l’errore medio che compiamo usando usiamo la media del campione quale stima della media della popolazione.\n\n40.2.3 Errore standard\nLa radice quadrata della varianza della distribuzione campionaria della media si chiama errore standard della media campionaria. Questa è una quantità molto importante perché ci informa sul livello di incertezza della nostra stima fornendoci un valore che ha la stessa unità di misura delle osservazioni. Se vogliamo stimare la media della popolazione utilizzando la media del campione quale stimatore ci possiamo aspettare di compiere un errore medio pari a \\(\\frac{\\hat{\\sigma}_n}{\\sqrt{n}},\\) laddove \\(\\hat{\\sigma}_n\\) è la deviazione standard del campione utilizzata quale stima della deviazione standard della popolazione.\n\n40.2.3.1 Simulazione\nPer chiarire le due conclusioni precedenti, utilizziamo nuovamente la simulazione che abbiamo eseguito in precedenza, quando abbiamo generato 10000 medie campionarie per campioni di ampiezza \\(n = 5\\) estratti dalla popolazione \\(\\mathcal{N}(\\mu = 100, \\sigma = 15\\)). La distribuzione di tali medie è rappresentata nella figura Figura 40.1). In realtà, quella fornita dalla Figura 40.1 non è esattamente la distribuzione campionaria delle medie di campioni casuali di ampiezza \\(n=5\\) estratti dalla popolazione \\(\\mathcal{N}(\\mu = 100, \\sigma = 15\\)): la vera distribuzione campionaria della media si otterrebbe estraendo infiniti campioni di ampiezza \\(n = 5\\) dalla popolazione. Tuttavia, avendo a disposizione le medie di 10000 campioni, ci possiamo aspettare un risultato empirico non troppo diverso da quello teorico. Verifichiamo dunque le due conclusioni a cui siamo giunti sopra.\nSappiamo che la media delle 10000 medie di campioni di ampiezza \\(n=5\\) dovrà essere molto simile (anche se non identica, dato che il numero dei campioni è grande, ma non infinito) alla media della popolazione. Infatti, in questa simulazione, abbiamo che \\(\\hat{\\mu}_{\\bar{X}_n} =\\) 99.97 contro un valore teorico \\(\\mu=100\\). All’aumentare del numero di campioni estratti \\(\\mu_{\\bar{X}_n}\\) diventa sempre più simile a \\(\\mu\\).\nCalcoliamo ora la deviazione standard (detta errore standard) delle 10000 medie campionarie che abbiamo trovato. Nella simulazione, tale valore è pari a 6.663 mentre il valore teorico è \\(\\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{15}{\\sqrt{5}} = 6.708\\). Possiamo dunque dire che, con 10000 medie campionarie le proprietà della distribuzione campionaria della media vengono approssimate molto bene.\nSi noti che possiamo attribuire a \\(\\sigma_{\\bar{X}}\\) la stessa interpretazione che è possibile fornire, in generale, alla deviazione standard. Nel caso di un campione, la deviazione standard \\(\\sigma\\) ci dice di quanto, in media, i valori osservati sono lontani dalla media. Nel caso della distribuzione campionaria delle medie dei campioni, \\(\\sigma_{\\bar{X}}\\) ci dice quale errore medio compiamo stimando \\(\\mu\\) con \\(\\bar{X}\\). In altre parole, ci dice che, se considerassimo tutte le medie \\(\\bar{X}\\) che si possono calcolare sulla base degli infiniti campioni di dimensioni \\(n\\) che possiamo estrarre dalla popolazione, la distanza media tra ciascuna di queste medie e la media della distribuzione (che corrisponde alla media della popolazione) è pari a \\(\\sigma_{\\bar{X}}\\). La quantità \\(\\sigma_{\\bar{X}}\\) può dunque essere considerata come una misura di errore nella stima di \\(\\mu\\) mediante \\(\\bar{X}\\).\n\n40.2.4 Distribuzioni delle statistiche campionarie\nQualunque statistica campionaria ha una sua distribuzione teorica. Consideriamo, ad esempio, il massimo del campione quale statistica campionaria di interesse. Ripetiamo la simulazione che abbiamo descritto sopra calcolando, questa volta, il valore massimo del campione.\n\nset.seed(123)\nn_samples <- 10000\nsample_size <- 5\nsample_max <- rep(NA, n_samples)\n\nfor (i in 1:n_samples) {\n    y <- round(rnorm(5, 100, 15))\n    sample_max[i] <- max(y)\n}\n\nI risultati di questa simulazione sono riportati nella Figura 40.2.\n\ndata.frame(sample_max) %>% \n  ggplot(aes(x = sample_max)) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Valore massimo del QI in campioni di ampiezza n = 5\",\n    y = \"Densità\"\n  )\n\n\n\nFigura 40.2: Istogramma della distribuzione del QI massimo osservato in ciascun campione casuali di ampiezza \\(n=5\\). Per creare la figura sono stati considerati 10000 campioni casuali.\n\n\n\n\nNon dovrebbe sorprenderci che, prendendo 5 persone a caso per poi selezionare la persona con il punteggio QI più alto, otteniamo una distribuzione che, rispetto alla distribuzione della figura Figura 40.2), è traslata verso destra. Nella presente simulazione, la distribuzione del QI massimo di un campione casuale di ampiezza \\(n = 5\\) si situa approssimativamente nell’intervallo compreso tra 90 e 150."
  },
  {
    "objectID": "225_distr_camp_mean.html#sec:tlc",
    "href": "225_distr_camp_mean.html#sec:tlc",
    "title": "40  Distribuzione campionaria",
    "section": "\n40.3 Teorema del limite centrale",
    "text": "40.3 Teorema del limite centrale\nChiediamoci ora quale sia la relazione che intercorre tra la distribuzione campionaria della media e l’ampiezza \\(n\\) dei campioni. In ciascun pannello della figura Figura 40.3 sono riportati i risultati di una simulazione nella quale sono stati generati 10000 campioni di ampiezza \\(n\\) per poi calcolare il QI medio in ciascun campione.\n\npar(mfrow=c(2, 3))\n\nmu <- 100\nsigma <- 15\nnrep <- 1e5\n\nqi <- rep(NA, nrep)\n\nget_mean <- function(nobs, mu, sigma) {\n  x <- round(rnorm(n = nobs, mean = mu, sd = sigma))\n  mean(x) \n}\n\nymax <- 0.14\n\nnobs <- 1\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 1\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\nnobs <- 2\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 2\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\nnobs <- 3\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 3\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\nnobs <- 5\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 5\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\nnobs <- 15\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 15\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\nnobs <- 30\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 30\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\npar(mfrow=c(1, 1))\n\n\n\nFigura 40.3: Nel primo pannello in alto a sinistra ciascun campione contiene una sola osservazione, per cui la media del campione è identica al valore del QI di una persona. Di conseguenza, la distribuzione campionaria della media è identica alla distribuzione dei valori del QI nella popolazione. Quando \\(n=2\\) la media di ciascun campione tende ad essere più simile alla media della popolazione di quanto lo sia ciascuna singola osservazione della popolazione. Quindi anche l’ampiezza dell’istogramma (ovvero, la distribuzione campionaria della media) diminuisce, se confrontata con la dispersione della popolazione. Quando giungiamo ad una numerosità campionaria pari a \\(n=30\\) vediamo che la maggior parte delle medie campionarie tende ad addensarsi intorno alla media della popolazione.\n\n\n\n\nGli istogrammi mostrano la distribuzione delle medie così ottenute, cioè ci forniscono una rappresentazione grafica della distribuzione campionaria della media al variare dell’ampiezza campionaria \\(n\\). I punteggi del QI sono stati ricavati da una distribuzione normale con media 100 e deviazione standard 15 e tale distribuzione viene visualizzata con una linea nera continua in ciascun pannello della figura Figura 40.3.\nQuello che ci chiediamo è come varia la distribuzione campionaria della media in funzione dell’ampiezza del campione. Intuitivamente, conosciamo già parte della risposta. Se abbiamo a disposizione solo poche osservazioni, è probabile che la media campionaria sia abbastanza imprecisa: se ripetiamo l’esperimento casuale del campionamento e ricalcoliamo la media del campione, otteniamo una risposta molto diversa ad ogni ripetizione dell’esperimento casuale. Di conseguenza, la distribuzione campionaria della media comprenderà una gamma di valori molto grande. Invece, si ottengono risultati molto simili tra loro se ripetiamo l’esperimento del campionamento utilizzando campioni di grandi dimensioni. In questo secondo caso, la distribuzione campionaria includerà una gamma di valori delle medie molto minore che in precedenza. Questo andamento si può notare nei pannelli della figura Figura 40.3: l’errore standard della media campionaria diminuisce all’aumentare dell’ampiezza del campione.\nCiò che abbiamo descritto finora, tuttavia, riguarda solo un aspetto di quello che accade alla distribuzione campionaria di \\(\\bar{X}\\) all’aumentare di \\(n\\). Gli esempi discussi finora erano relativi al caso di campioni casuali del QI. Poiché i punteggi del QI seguono approssimativamente una distribuzione normale, abbiamo assunto che anche la popolazione abbia una distribuzione normale. Tuttavia, si presentano spesso casi in cui la distribuzione della popolazione non è normale. In queste circostanze, cosa succede alla distribuzione campionaria della media? La cosa straordinaria è questa: non importa quale sia la forma della distribuzione della popolazione, all’aumentare della dimensione campionaria \\(n\\), la distribuzione di frequenza delle medie campionarie si approssima sempre più alla tipica forma a campana di una distribuzione normale.\nPer farci un’idea di quello che succede, eseguiamo alcune simulazioni usando R.\n\n# needed for printing\nwidth <- 6\nheight <- 6\n\n# parameters of the beta\na <- 2\nb <- 1\n\n# mean and standard deviation of the beta\ns <- sqrt(a * b / (a + b)^2 / (a + b + 1))\nm <- a / (a + b)\n\n# define function to draw a plot\nplot_one <- function(n, N = 50000) {\n\n  # generate N random sample means of size n\n  X <- matrix(rbeta(n * N, a, b), n, N)\n  X <- colMeans(X)\n\n  # plot the data\n  hist(\n    X,\n    breaks = seq(0, 1, .025), border = \"white\", freq = FALSE,\n    #col = ifelse(colour, emphColLight, emphGrey),\n    col = \"gray\",\n    xlab = \"Media campionaria\", ylab = \"\", xlim = c(0, 1.2),\n    main = paste(\"n =\", n), axes = FALSE,\n    font.main = 1, ylim = c(0, 5)\n  )\n  #box()\n  axis(1)\n  # axis(2)\n\n  # plot the theoretical distribution\n  lines(x <- seq(0, 1.2, .01), dnorm(x, m, s / sqrt(n)),\n    lwd = 2, col = \"black\", type = \"l\"\n  )\n}\n\nConsideriamo la distribuzione della popolazione rappresentata dall’istogramma riportato nella Figura 40.4. Confrontando l’istogramma triangolare con la curva a campana tracciata dalla linea nera risulta chiaro che la distribuzione della popolazione non assomiglia affatto a una distribuzione normale.\n\nplot_one(1)\n\n\n\nFigura 40.4: Dimostrazione del Teorema del limite centrale. Consideriamo una popolazione che non segue la distribuzione normale. La distribuzione di tale popolazione è rappresentata dall’istogramma grigio.\n\n\n\n\nIn una prima simulazione, ho estratto 50000 campioni di ampiezza \\(n=2\\) da questa distribuzione e, per ciascuno di essi ho calcolato la media campionaria. Come si può vedere nella figura Figura 40.5, la distribuzione campionaria non è triangolare. Certamente non è Normale, ma assomiglia di più ad una distribuzione campanulare di quanto assomigli alla distribuzione della popolazione raffigurata nella figura Figura 40.4.\n\nplot_one(2)\n\n\n\nFigura 40.5: Distribuzione campionaria di \\(ar{X}\\) per campioni casuali di ampiezza \\(n=2\\) estratti dalla popolazione rappresentata nella figura 1.7.\n\n\n\n\nQuando aumento la numerosità del campione a \\(n=4\\) la distribuzione campionaria della media si approssima abbastanza bene alla normale, Figura 40.6.\n\nplot_one(4)\n\n\n\nFigura 40.6: Distribuzione campionaria di \\(ar{X}\\) per campioni casuali di ampiezza \\(n=4\\) estratti dalla popolazione rappresentata nella figura 1.7.\n\n\n\n\nGià con \\(n=8\\) l’approssimazione diventa molto buona, come indicato nella Figura 40.7).\n\nplot_one(8)\n\n\n\nFigura 40.7: Distribuzione campionaria di \\(ar{X}\\) per campioni casuali di ampiezza \\(n=8\\) estratti dalla popolazione rappresentata nella figura 1.7.\n\n\n\n\nIn altre parole, se la dimensione del campione non è piccola, allora la distribuzione campionaria della media sarà approssimativamente normale indipendentemente dalla distribuzione della popolazione! Questo comportamento della distribuzione campionaria di \\(\\bar{X}\\) al variare di \\(n\\) viene descritto in maniera formale dal Teorema del limite centrale.\n\nSiano \\(X_1, X_2, \\dots\\) variabili aleatorie i.i.d., tutte con lo stesso valore atteso \\(\\mu\\) e la stessa varianza \\(\\sigma^2\\). Allora, \\[\\lim_{n \\rightarrow +\\infty} P\\left(a \\leq \\bar{X}_n \\leq b \\right) = P(a \\leq Y \\leq b),\n\\label{theo:tlc}\\] dove \\(Y \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\).\n\nIl Teorema del limite centrale ci dice che, se vengono selezionati campioni sufficientemente grandi (tipicamente è sufficiente che \\(n > 30\\) purché il carattere osservato non sia troppo asimmetrico), allora la media campionaria \\(\\bar{X}\\) di \\(n\\) variabili aleatorie indipendenti \\(X_1, X_2, \\dots\\) converge in distribuzione ad una variabile aleatoria normale di media \\(\\mu\\) e varianza \\(\\sigma^2/n\\).\nÈ altresì molto importante notare che, se le variabili di partenza \\(X_1\\), \\(X_2\\), …\\(X_n\\) sono esse stesse Normali, tutte con lo stesso valore atteso \\(\\mu\\) e la stessa varianza \\(\\sigma^2\\), allora il Teoremadel limite centrale è esatto. Ovvero per ogni \\(n\\),\n\\[\n\\bar{X}_n \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\nQuesta proprietà discende dal seguente teorema.\n\nSe \\(X_1, X_2, \\dots, X_n\\) sono \\(n\\) variabili aleatorie Normali tra di loro indipendenti, ciascuna con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), allora la variabile aleatoria \\(X_1 + X_2 + \\dots + X_n\\) è a sua volta una variabile aleatoria Normale con valore atteso \\(n \\mu\\) e varianza \\(n \\sigma^2\\).\n\nIn conclusione, il Teorema del limite centrale ci consente di specificare completamente le proprietà della distribuzione campionaria di \\(\\bar{X}_n\\).\n\nSe la popolazione è normale, allora \\(\\bar{X}_n \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\) indipendentemente da \\(n\\).\nSe invece la popolazione non è normale, allora la distribuzione di \\(\\bar{X}_n\\) tende a \\(\\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\) al crescere di \\(n\\).\n\nEsaminiamo ora un esercizio in cui viene applicato il TLC.\nSupponiamo di misurare un oggetto con una bilancia non molto precisa. Supponiamo inoltre che l’errore di misura \\(E\\) della bilancia si distribuisca in maniera Normale con media \\(0\\) e deviazione standard \\(\\sigma = 2\\) grammi. Se l’oggetto considerato ha un peso uguale a \\(w\\), il peso osservato \\(X\\) sarà dato dalla somma del suo peso vero e l’errore di misurazione: \\(X = w + E\\). Dato che \\(w\\) è una costante, \\(X\\) seguirà la distribuzione normale con media \\(\\mathbb{E}(X) = \\mathbb{E}(w + E) = w + \\mathbb{E}(E) = w\\) e varianza \\(var(X) = var(w + E) = var(E) = 4\\). Qual è la probabilità di ottenere una misurazione che non differisce di più di un grammo dal peso vero?\nDobbiamo trovare la probabilità\n\\[\n\\begin{aligned}\nP(-1 \\leq X - w \\leq 1)  &= P\\bigg(-\\frac{1}{2} \\leq \\frac{X - w}{\\sigma} \\leq \\frac{1}{2}\\bigg)\\notag\\\\ &= P\\bigg(-\\frac{1}{2} \\leq Z \\leq \\frac{1}{2}\\bigg)\\notag\n\\end{aligned}\n\\]\novvero\n\npnorm(0.5, 0, 1) - pnorm(-0.5, 0, 1)\n#> [1] 0.3829249\n\nConsiderando l’evento complementare, possiamo dunque dire che c’è una probabilità maggiore di \\(0.6\\) che la bilancia produca un valore che differisce di almeno un grammo dal peso vero.\nChiediamoci ora cosa succede se, invece di accontentarci di una singola misurazione, calcoliamo la media di \\(n = 10\\) misurazioni. In questo secondo caso,\n\\[\n\\begin{aligned}\nP\\left(-1 \\leq \\frac{S_{10}}{10} - w \\leq 1\\right)\n&= P\\bigg(-\\frac{1}{\\sqrt{4/10}} \\leq \\frac{\\frac{S_{10}}{10} - w}{\\sigma/\\sqrt{10}} \\leq \\frac{1}{\\sqrt{4/10}}\\bigg)\\notag\\\\\n&= P\\bigg(-\\frac{\\sqrt{10}}{2} \\leq Z \\leq \\frac{\\sqrt{10}}{2}\\bigg)\\notag\n\\end{aligned}\n\\]\novvero\n\npnorm(sqrt(10)/2, 0, 1) - pnorm(-sqrt(10)/2, 0, 1)\n#> [1] 0.8861537\n\nConsiderando l’evento complementare, possiamo concludere che c’è una probabilità pari a solo 0.114 che la media di 10 misurazioni assuma un valore che differisce di più di un grammo dal peso vero. È dunque ovvio che le medie di misurazioni ripetute sono migliori delle singole misure."
  },
  {
    "objectID": "225_distr_camp_mean.html#intervalli-di-confidenza",
    "href": "225_distr_camp_mean.html#intervalli-di-confidenza",
    "title": "40  Distribuzione campionaria",
    "section": "\n40.4 Intervalli di confidenza",
    "text": "40.4 Intervalli di confidenza\n\n40.4.1 Parametri di un modello statistico\nNel gergo statistico, i parametri sono i valori sconosciuti che determinano un modello statistico. Si consideri il modello statistico \\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\). Il modello statistico precedente ci dice che \\(Y\\) è una v.a. distribuita come una normale di parametri \\(\\mu\\) e \\(\\sigma\\). Supponiamo che la \\(Y\\) sia il QI. In questo caso è facile capire cosa sono i parametri \\(\\mu\\) e \\(\\sigma\\). Quello del QI, infatti, è un caso particolare perché il test di intelligenza Wechsler Adult Intelligence Scale (WAIS) è stato costruito in modo tale da produrre dei dati che si distribuiscono in un modo noto: il QI segue la distribuzione normale di parametri \\(\\mu = 100\\) e \\(\\sigma = 15\\). In generale, però, i parametri di un modello statistico sono sconosciuti.\n\n40.4.2 L’incertezza della stima\nDato che i parametri sono, in genere, sconosciuti, è necessario stimarli. Non è sufficiente, però, ottenere una stima puntuale di un parametro. È anche necessario quantificare l’incertezza della stima. L’incertezza della stima viene descritta dall’approccio frequentista nei termini di un intervallo di confidenza. L’intervallo di confidenza si costruisce mediante l’errore standard.\nL’errore standard è la deviazione standard stimata della stima di un parametro e quantifica il grado della nostra incertezza sulla quantità di interesse. Chiariamo questa idea facendo riferimento alla la Figura 40.1. Tale figura riporta la distribuzione di un grande numero di medie campionarie, laddove la media di ciascun campione può essere considerata come una stima della media \\(\\mu\\) della popolazione. La deviazione standard di queste stime, chiamata errore standard, ci fornisce una misura dell’incertezza della nostra stima. In altre parole, quantifica la variabilità dei valori delle stime del parametro \\(\\mu\\) che sono calcolate sulla base di campioni diversi. Come abbiamo visto nella simulazione del TLC, l’errore standard ha la proprietà di diminuire all’aumentare della dimensione del campione.\nL’errore standard viene utilizzato per calcolare l’intervallo di confidenza. L’intervallo di confidenza rappresenta un intervallo di valori di un parametro o quantità di interesse che sono approssimativamente coerenti con i dati, data la distribuzione campionaria presunta. All’intervallo di confidenza possiamo dunque assegnare la seguente interpretazione. Supponiamo che il modello statistico sia corretto e supponiamo di ripetere tante volte il processo di campionamento. Se per ogni campione estratto dalla popolazione calcoliamo una stima del parametro, allora gli intervalli di confidenza del 50% e del 95% includeranno il vero valore del parametro il 50% e il 95% delle volte.\nSotto l’ipotesi che la distribuzione campionaria segua la distribuzione normale, per campioni di grandi dimensioni l’intervallo di confidenza al 95% si costruisce nel modo seguente: \\[\n\\text{stima del parametro} \\pm 2 \\text{ errori standard.}\n\\] Dalla distribuzione normale sappiamo che una stima del parametro \\(\\pm\\) 1 errore standard corrisponde ad un intervallo del 68% e una stima del parametro \\(\\pm\\) \\(\\frac{2}{3}\\) di un errore standard corrisponde ad un intervallo del 50%. Un intervallo del 50% è particolarmente facile da interpretare dato che il vero valore del parametro ha la stessa probabilità di essere incluso o escluso dall’intervallo. Un intervallo del 95% basato sulla distribuzione normale è circa tre volte più ampio di un intervallo del 50%."
  },
  {
    "objectID": "225_distr_camp_mean.html#commenti-e-considerazioni-finali",
    "href": "225_distr_camp_mean.html#commenti-e-considerazioni-finali",
    "title": "40  Distribuzione campionaria",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nI risultati precedenti consentono le seguenti conclusioni. Se \\(X_1, \\dots, X_n\\) è un insieme di variabili aleatorie i.i.d., tutte con media \\(\\mu\\) e varianza \\(\\sigma^2\\), allora \\[\n\\mathbb{E}(\\bar{X}) = \\mu, \\quad var(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\] Se le \\(X_i\\) seguono la distribuzione normale, ne segue che \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\), in quanto qualunque combinazione lineare di variabili aleatorie Normali è ancora una variabile aleatoria Normale. Invece, se le \\(X_i\\) non seguono la distribuzione normale, il Teorema del limite centrale ci consente comunque di dire che \\(\\bar{X}\\) tende a \\(\\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\) al crescere di \\(n\\). I risultati precedenti sono estremamente importanti perché specificano completamente la distribuzione della media campionaria e vengono utilizzati dall’approccio frequentista per l’inferenza sulla media di una popolazione."
  },
  {
    "objectID": "226_test_ipotesi.html#un-esempio-motivante",
    "href": "226_test_ipotesi.html#un-esempio-motivante",
    "title": "41  Significatività statistica",
    "section": "\n41.1 Un esempio motivante",
    "text": "41.1 Un esempio motivante\nPer introdurre in maggiore dettaglio il concetto di significatività statistica consideriamo una ricerca svolta da Mehr et al. (2016). La ricerca di Mehr et al. (2016) riguarda la musica. L’ascolto musicale è presente in tutte le fasi della vita e anche nell’infanzia. Tra le altre cose, la musica può trasmettere informazioni relative all’appartenenza sociale – pensiamo alle canzoni popolari, ad esempio. Mehr et al. (2016) si sono chiesti se la musica sia capace di trasmettere messaggi di tipo sociale anche in bambini molto piccoli. Nello specifico, Mehr et al. (2016) si sono chiesti se i bambini di 5 mesi mostrino una preferenza per individui sconosciuti che cantano una canzone a loro familiare, rispetto ad altri individui sconosciuti che cantano una canzone simile, con le stesse parole e lo stesso ritmo, ma con una diversa melodia. Mehr et al. (2016) hanno scoperto che, in effetti, le cose stanno veramente così, ma solo quando, nella fase di familiarizzazione, la canzone test veniva cantata dai genitori, ma non quando nella fase di familiarizzazione la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo mostra che il significato sociale è l’elemento cruciale della preferenza dei bambini, non semplicemente la familiarità con la canzone.\n\n41.1.1 La domanda della ricerca\nLa domanda che Mehr et al. (2016) si sono posti si chiama domanda della ricerca. In psicologia, le domande della ricerca sono delle ipotesi che riguardano i costrutti psicologici. L’ascolto della musica certamente ha a che fare con la psicologia e il significato che attribuiamo all’ascolto della musica è certamente un fenomeno psicologico. Per cui la domanda che Mehr et al. (2016) si sono posti è certamente una domanda legittima nel contesto della ricerca psicologica.\nIn psicologia, le ipotesi della ricerca sono delle proposizioni che descrivono le proprietà dei fenomeni psicologici. Tali proposizioni possono essere vere oppure false. Alcune volte le ipotesi della ricerca sono espresse in termini po’ vaghi – nel caso presente, per esempio, ci possono essere idee diverse a proposito di ciò che è musicale e di ciò che non lo è – in ultima analisi le ipotesi della ricerca vengono valutate in base alla loro utilità: si dimostrano utili solo se contribuiscono ad aggiungere qualcosa di importante rispetto a ciò che già sappiamo rispetto al fenomeno psicologico considerato.\n\n41.1.2 Le ipotesi statistiche\nQuello che dobbiamo notare è che non è possibile verificare direttamente le ipotesi della ricerca. Le ipotesi della ricerca sono delle proposizioni relative alle caratteristiche o al funzionamento dei fenomeni psicologici. Tuttavia, in generale, le ipotesi psicologiche non sono abbastanza precise da poter essere valutate direttamente. Quello che i ricercatori possono fare, invece, è valutare delle ipotesi statistiche. Le ipotesi statistiche non coincidono con l’ipotesi della ricerca ma hanno il vantaggio di potere essere espresse in termini probabilistici.\nNell’esperimento di Mehr et al. (2016), due settimane dopo la fase di familiarizzazione con la canzone test, i bambini che facevano parte dell’esperimento venivano esaminati in laboratorio. Ad essi venivano mostrate due video-registrazioni. Una registrazione presentava un estraneo che cantava la canzone test; l’altra registrazione presentava un secondo individuo non conosciuto dai bambini che cantava una canzone simile alla prima, ma non familiare ai bambini. I ricercatori hanno misurato i tempi di fissazione dello sguardo dei bambini nei confronti di ciascuna delle due video-registrazioni. Nel primo esperimento, la variabile dipendente era uguale alla media, calcolata su 32 casi, della proporzione del tempo di fissazione rivolta al video “familiare” rispetto al tempo di fissazione totale (ovvero la somma del tempo di fissazione del video “familiare” e del tempo di fissazione del video “non familiare”).\nDato che non è possibile valutare direttamente la domanda della ricerca è necessario stabilire una connessione tra l’ipotesi della ricerca e l’ipotesi statistica. Nel caso presente possiamo pensare a tre possibilità.\n\nSe i bambini non hanno alcuna preferenza nei confronti di uno dei due tipi di video-registrazione, allora la media delle proporzioni dei tempi di fissazione di tutti i bambini possibili (ovvero, nella popolazione) sarà uguale a \\(\\mu = 0.5\\), perché, in media, i tempi di fissazione per le due video-registazioni saranno uguali.\nSe Mehr et al. (2016) hanno ragione, allora i bambini preferiranno guardare il video con la canzone familiare piuttosto che il video con la canzone non familiare. Questa situazione si traduce nell’ipotesi statistica \\(\\mu > 0.5\\) (con \\(\\mu = 0.5\\) che rappresenta il livello del caso).\nUna terza possibilità è che i bambini siano maggiormente attratti da una melodia non familiare – questo è il contrario di ciò che propongono gli autori della ricerca. Tale possibilità si traduce nell’ipotesi statistica \\(\\mu < 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche. Sono infatti delle proposizioni a proposito dei valori di un parametro di un modello statistico. Nel caso presente, il modello statistico è la distribuzione della proporzione dei tempi di fissazione in una popolazione virtuale di infiniti bambini di sei mesi d’età, come nell’esperiment di Mehr et al. (2016). Se consideriamo uno specifico bambino, la proporzione dei tempi di fissazione avrà un certo valore, mentre per un’altro bambino avrà un valore diverso. Il modello statistico considerato descrive la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video “familiare”. Un tale modello statistico può essere messo in relazione con i dati raccolti dagli sperimentatori perché Mehr et al. (2016) hanno misurato proprio questo aspetto, ovvero la media della proporzione del tempo di fissazione rivolto al video “familiare”.\n\n41.1.3 Domanda della ricerca e ipotesi statistiche\nCiò che la discussione precedente dovrebbe mettere in chiaro è che, nella procedura di test di ipotesi, possiamo distinguere tra due tipi di ipotesi molto diverse tra loro: da una parte abbiamo l’ipotesi della ricerca che è un’affermazione sulla natura dei fenomeni psicologici; dall’altra parte abbiamo un’ipotesi statistica che è una proposizione che riguarda il modello generativo dei dati, ovvero le caratteristiche della popolazione. Nell’esempio presente, l’ipotesi della ricerca è “le preferenze sociali dei bambini sono influenzate dalla musica; in particolare, sono favorite dalla familiarità con i materiali musicali”. L’ipotesi statistica, invece, è: \\(\\mu > 0.5\\).\nCiò che dobbiamo avere ben chiaro è che i test vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ciò significa che, se l’esperimento non viene condotto nella maniera appropriata, allora si spezza il collegamento tra l’ipotesi statistica e la domanda della ricerca. Per esempio, se l’attore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l’altro attore ha un aspetto molto diverso da quello dei genitori, allora sarebbe molto facile trovare evidenze in supporto dell’ipotesi statistica secondo cui \\(\\mu > 0.5\\); ma questo non avrebbe nulla a che fare con la domanda della ricerca."
  },
  {
    "objectID": "226_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "226_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "41  Significatività statistica",
    "section": "\n41.2 Ipotesi nulla e ipotesi alternativa",
    "text": "41.2 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento è stato semplice: il ricercatore ha un’ipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un’ipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le proprietà suggerite dall’ipotesi della ricerca, allora il ricercatore può aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, però, il ragionamento diventa contro-intuitivo perché non è possibile verificare direttamente l’ipotesi statistica che corrisponde alla domanda della ricerca.\n\n41.2.1 Apagogia\nIn linea di principio non è mai possibile dimostrare direttamente la verità d’una proposizione. Quello che possiamo fare, invece, è dimostrare la verità d’una proposizione in maniera indiretta, ovvero provando la falsità della proposizione contraddittoria.\nL’esempio classico è il seguente. Consideriamo la seguente proposizione: “Tutti i cigni sono bianchi” (questo è l’esempio ornitologico preferito da Popper). L’osservazione di un numero qualsiasi di cigni bianchi non è sufficiente a dimostrare la verità di questa proposizione – infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (infatti, c’è). D’altra parte, invece, l’osservazione di un solo cigno che non sia bianco (ovvero, per esempio, l’osservazione di un cigno nero proveniente dall’Australia) può falsificare la proposizione considerata. Questa è la logica del falsificazionismo di Popper.\nQuesto modo di pensare è stato trasferito nella procedura di test di ipotesi di stampo frequentista (ovvero, quello che stiamo discutendo ora). Dato che non possiamo dimostrare vera l’ipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l’obiettivo di dimostrare falso l’evento complementare a quello specificato dall’ipotesi statistica associata alla domanda della ricerca. L’ipotesi statistica che vorremmo falsificare si chiama “ipotesi nulla” e viene denotata con \\(H_0\\). Nel caso dell’esempio che stiamo discutendo, l’ipotesi nulla è: \\(\\mu \\leq 0.5\\). Si noti che l’ipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu < 0.5\\)), ad eccezione di quella che è associata all’ipotesi della ricerca (ovvero, \\(\\mu > 0.5\\)).\nIn pratica, ciò che stiamo facendo qui è dividere tutti i possibili valori di \\(\\pi\\) in due gruppi: quei valori che sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere è che l’obiettivo di un test di ipotesi non è quello di dimostrare che l’ipotesi alternativa è (probabilmente) vera; l’obiettivo è mostrare che l’ipotesi nulla è (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n41.2.2 La similitudine del processo penale\nUn test di ipotesi è stato paragonato ad un processo penale, ovvero al processo nei confronti dell’ipotesi nulla. Possiamo immaginare che l’ipotesi nulla sia l’imputato, il ricercatore sia il pubblico ministero e il test statistico sia il giudice. Proprio come in un processo penale, c’è una presunzione di innocenza: l’ipotesi nulla si ritiene vera a meno che il ricercatore non dimostri, oltre ogni ragionevole dubbio, che è falsa. Il ricercatore progetta l’esperimento in modo da massimizzare la possibilità che i dati producano una condanna. Il test statistico (ovvero il giudice in questa similitudine) stabilisce le regole che devono essere seguite per giungere al verdetto e queste regole sono pensate per proteggere l’ipotesi nulla – in particolare, per garantire che sia piccola la probabilità di una condanna se l’ipotesi nulla è effettivamente vera. Questo aspetto è importante: all’ipotesi nulla deve essere fornita una qualche forma di protezione, dato che il ricercatore sta cercando disperatamente di dimostrare che è essa è falsa."
  },
  {
    "objectID": "226_test_ipotesi.html#due-tipi-di-errori",
    "href": "226_test_ipotesi.html#due-tipi-di-errori",
    "title": "41  Significatività statistica",
    "section": "\n41.3 Due tipi di errori",
    "text": "41.3 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico è utile capire la logica su cui esso è basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere più espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, però, questo non è possibile: a volte il ricercatore è sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, può succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ciò sembra fornire una prova molto forte del fatto che la moneta è sbilanciata, ma ovviamente c’è una possibilità su 1024 che ciò accada anche se la moneta è equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilità che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l’obiettivo dei test delle ipotesi statistiche non è quello di eliminare completamente gli errori (questo è impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per “errori”. Iniziamo con il rendere esplicito quello che è ovvio: l’ipotesi nulla può essere vera o falsa, e il nostro test ci può condurre a rifiutare l’ipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l’ipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella Figura 41.1. L’errore di I tipo, denotato con \\(\\alpha\\), è quello che commettiamo se rigettiamo l’ipotesi nulla quando essa è vera. L’errore di II tipo, denotato con \\(\\beta\\), è quello che commettiamo se accettiamo l’ipotesi nulla mentre invece è vera l’ipotesi alternativa.\n\n\n\n\nFigura 41.1: Due tipi di errori.\n\n\n\n\n\n41.3.1 Errore di I tipo: la protezione dei diritti dell’imputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell’imputato “oltre ogni ragionevole dubbio”. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilità di condannare ingiustamente un imputato innocente: il processo penale è progettato (almeno in teoria) per proteggere i diritti dell’imputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L’errore che consiste nel punire un innocente viene considerato assai più grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilità di un errore di I tipo, con l’obiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilità, denotata con \\(\\alpha\\), viene chiamata “livello di significatività del test”. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significatività \\(\\alpha\\) se il tasso di errore di I tipo non è più grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n41.3.2 Errore di II tipo: l’asimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realtà, vorremmo tenere anche quello sotto controllo e denotiamo la probabilità di un errore di II tipo con \\(\\beta\\). Il livello d’errore \\(\\beta\\) viene raramente discusso ed è molto più comune fare riferimento alla potenza del test, che è la probabilità dell’evento complementare, ovvero la probabilità con cui rifiutiamo l’ipotesi nulla quando è realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto “potente” quando è caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilità prefissata.\nSi noti l’asimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente è preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) – questo si ottiene utilizzando un campione sufficientemente grande – ma nella logica della costruzione del test di ipotesi questo aspetto è secondario rispetto alla necessità di controllare il tasso di errore di I tipo."
  },
  {
    "objectID": "226_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "226_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "41  Significatività statistica",
    "section": "\n41.4 Come si costruisce un test di ipotesi?",
    "text": "41.4 Come si costruisce un test di ipotesi?\nRitorniamo all’esempio relativo allo studio di Mehr et al. (2016). In questo caso, sulla base all’ipotesi della ricerca, l’ipotesi nulla può essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di età media pari a 5.6 mesi, Mehr et al. (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video “familiare” nel 59% del tempo totale di fissazione. Dunque, la media campionaria è \\(\\bar{X} = 0.59\\) Questo è il valore campionario rilevante per il test dell’ipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall’ipotesi nulla. Nel caso presente, l’ipotesi nulla non specifica un unico valore \\(\\mu\\) ma bensì un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non è incluso nell’intervallo specificato da \\(H_0\\). Questo è incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient’altro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c’è bisogno di eseguire alcun test statistico – abbiamo già trovato la risposta alla domanda della ricerca.\n\n41.4.1 La variabilità campionaria\nNel caso dell’esperimento Mehr et al. (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell’intervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.59\\) possiamo dunque concludere che \\(H_0\\) è falsa? Non così presto. Non è sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cioè positiva, nel nostro caso). È anche necessario tenere in considerazione il fenomeno della variabilità campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) è una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumerà un valore diverso da campione a campione. Le statistiche campionarie – nel nostro caso la media \\(\\bar{X}\\) – sono di necessità diverse dai parametri. Ciò a cui noi siamo interessati è la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non può essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, è ragionevole pensare che, indipendentemente dal fatto che l’ipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sarà positive mentre in altri campioni sarà negativa. Dobbiamo dunque trovare una procedura che riduca la possibilità di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n41.4.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall’approccio frequentista per affrontare questo problema è quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l’ipotesi nulla. Questo è il concetto più contro-intuitivo di tutta la procedura di test di ipotesi dell’approccio frequentista. Esaminiamolo più in dettaglio.\nÈ ovvio come calcolare la media delle proporzioni del tempo di fissazione in un singolo campione. Il problema è che tale media varia da campione a campione (fenomeno detto della variabilità campionaria). L’approccio frequentista affronta il problema di giungere ad una decisione rispetto ad \\(H_0\\) tenendo in considerazione la variabilità campionaria nel modo seguente. Il punto di partenza è quello di descrivere le caratteristiche della distribuzione di tutti i possibili valori che la statistica test in esame (nel nostro caso, la media del campione, ovvero \\(\\bar{X}\\)) in tutti i infiniti possibili campioni di ampiezza \\(n\\) (nel nostro caso \\(n\\) = 32).\nÈ facile capire che, espresso in questi termini, il problema di stabilire quali sono le caratteristiche di tale distribuzione di medie campionarie non è risolvibile. Senza sapere nient’altro, non possiamo sapere come si distribuisce \\(\\bar{X}\\) nell’universo dei campioni. Ricordiamo però che lo scopo della procedura di test statistici dell’approccio frequentista non è quello di verificare l’ipotesi alternativa: questo non è logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all’ipotesi nulla, l’approccio frequentista si pone l’obiettivo di determinare se ci siano indizi sufficienti per “condannare” l’ipotesi nulla, ovvero, per rigettarla.\nIn questa reductio ad absurdum, la “presunzione di innocenza” di \\(H_0\\) corrisponde all’idea che dobbiamo assumere come vera l’ipotesi nulla, fino a prova contraria. Nell’esempio che stiamo discutendo, assumere come vera l’ipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione è possibile costruire la distribuzione delle medie dei campioni di ampiezza 32.\nPer fare questo, Mehr et al. (2016) utilizzano (implicitamente) ad un famoso teorema della teoria della probabilità che possiamo descrivere nel modo seguente. Se estraiamo infiniti campioni di ampiezza 32 da una popolazione gaussiana di media \\(\\mu = 0.5\\), allora le medie standardizzate di tali campioni seguiranno la distribuzione teorica di probabilità chiamata distribuzione \\(t\\) di Student con 32 - 1 = 31 gradi di libertà. Ricordiamo che standardizzare una variabile significa sottrarre dai valori della variabile il suo valore atteso e dividere per la deviazione standard. Si può dimostrare che il valore atteso delle medie dei campioni è uguale alla media della popolazione. Nel caso presente, avremo che \\[\\mathbb{E}(\\bar{X}) = \\mu_{\\bar{X}} = \\mu\\] e la standardizzazione si effettua mediante il rapporto \\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\] dove \\(\\bar{X}\\) è la media del campione (nel nostro caso, 0.56), \\(s\\) è la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) è l’ampiezza del campione (ovvero, \\(n\\) = 32). In altre parole, la teoria della probabilità ci dice che la statistica \\(T\\) si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libertà. Il punto cruciale è che, se assumiamo come vera l’ipotesi nulla che fissa \\(\\mu = 0.5\\), allora la distribuzione della statistica test \\(T\\) risulta completamente determinata.\nL’approccio frequentista fa uso di un insieme teoremi della teoria della probabilità che descrivono la distribuzione di varie statistiche test. Abbiamo visto sopra la descrizione di un teorema che specifica la distribuzione della statistica test \\(T\\). Un altro teorema specifica la distribuzione della statistica test che corrisponde alla differenze tra le medie di due campioni indipendenti; tale teorema viene utilizzato nella procedura statistica frequentista chiamata test sulla differenza tra le medie di due campioni indipendenti. Un altro teorema riguarda la distribuzione del rapporto tra la stima di una varianza \\(\\sigma^2\\) basata sulla variabilità delle medie di diversi campioni e la stima della stessa varianza basata sulla variabilità entro i campioni; tale teorema sta alla base del test statistico chiamato ANOVA, o Analisi della varianza. Un altro teorema ancora specifica la distribuzione di una proporzione campionaria; tale teorema sta alla base del test statistico frequentista chiamato test di ipotesi per la proporzione. E così via.\n\n41.4.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione che viene determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l’insieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto). Come facciamo a decidere quanto è grande la regione di rifiuto di \\(H_0\\)? È semplice, basta collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera. Questo è l’aspetto cruciale della procedura di test di ipotesi, perché così facendo possiamo definire la regione di rifiuto di \\(H_0\\) come quell’intervallo di valori \\(\\mathcal{G}_n\\) a cui è associata la probabilità \\(\\alpha\\), ovvero la probabilità di commettere un errore di I tipo.\n\n41.4.4 Quando rifiutare l’ipotesi nulla\nSupponiamo che la Figura 41.2 rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\). Se i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l’ipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l’ipotesi nulla in favore dell’ipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto è costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale è stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto è situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l’ipotesi alternativa non è menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cioè sulla probabilità della statistica test condizionata all’ipotesi nulla \\(H_0\\). L’ipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n\n\n\n\nFigura 41.2: Distribuzione della statistica test condizionata all’ipotesi nulla \\(H_0\\).\n\n\n\n\n\n41.4.5 Specificazione delle regioni di rifiuto\nL’ipotesi alternativa \\(H_1\\) può assumere forme diverse e ciò conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell’ipotesi alternativa \\(H_1\\).\n\nSe l’ipotesi alternativa è \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) è un generico parametro e \\(\\theta_0\\) è uno specifico valore del parametro), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l’ipotesi alternativa è \\(H_1: \\theta < \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([-\\infty, \\theta_0]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di sinistra della distribuzione.\nSe l’ipotesi alternativa è \\(H_1: \\theta > \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([\\theta_0, \\infty]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilità pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilità pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\nEsercizio 41.1 Supponiamo che \\(f(\\mathcal{G}_n \\mid H_0) = \\mathcal{N}(100, 15)\\) descriva la distribuzione della statistica test \\(x\\). Supponiamo inoltre che la regione di rifiuto sia posta nella coda di destra e che il livello di significatività sia \\(\\alpha = 0.05\\). Si trovi il valore critico che delimita la regione di rifiuto di \\(H_0\\).\n\n\nSoluzione. Usando R la risposta è: qnorm(0.95, 100, 15) = 124.7. La distribuzione \\(\\mathcal{N}(100, 15)\\) è mostrata nella Figura 41.3. La regione di rifiuto è indicata dall’area ombreggiata.\n\n\nggplot(data.frame(x = c(55, 145)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 100, sd = 15)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 100, sd = 15),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(qnorm(0.95, 100, 15), 200)\n  ) +\n  scale_x_continuous(limits = c(55, 145)) +\n  labs(\n    x = \"QI\",\n    y = \"Densità\"\n  )\n\n\n\nFigura 41.3: Distribuzione campionaria con regione di rifiuto unilaterale destra.\n\n\n\n\n\nEsercizio 41.2 Supponiamo ora che \\(f(\\mathcal{G}_n \\mid H_0) = \\mathcal{N}(100, 15)\\) descriva la distribuzione della statistica test \\(\\mathcal{G}_n\\). Supponiamo inoltre che la regione di rifiuto sia posta nella coda di sinistra e che il livello di significatività sia \\(\\alpha = 0.01\\). Si trovi il valore critico che delimita la regione di rifiuto di \\(H_0\\).\n\n\nSoluzione. Usando R, la risposta è qnorm(0.01, 100, 15) = 65.1 – si veda la Figura 41.4.\n\n\nggplot(data.frame(x = c(55, 145)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 100, sd = 15)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 100, sd = 15),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(0, qnorm(0.01, 100, 15))\n  ) +\n  scale_x_continuous(limits = c(55, 145)) +\n  labs(\n    x = \"QI\",\n    y = \"Densità\"\n  )\n\n\n\nFigura 41.4: Distribuzione campionaria con regione di rifiuto unilaterale sinistra.\n\n\n\n\n\nEsercizio 41.3 In un terzo esempio, supponiamo che \\(f(\\mathcal{G}_n \\mid H_0) = \\mathcal{N}(100, 15)\\) descriva la distribuzione della statistica test \\(\\mathcal{G}_n\\). Supponiamo inoltre che la regione di rifiuto sia bilaterale e che il livello di significatività sia \\(\\alpha = 0.05\\). Si trovino i valori critici che delimitano la regione di rifiuto di \\(H_0\\).\n\n\nSoluzione. Con la seguente istruzione qnorm(c(0.025, 0.975), 100, 15) troviamo i valori \\(70.6\\) e \\(129.4\\) – si veda la Figura 41.5.\n\n\nggplot(data.frame(x = c(55, 145)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 100, sd = 15)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 100, sd = 15),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(0, qnorm(0.025, 100, 15))\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = 100, sd = 15),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(qnorm(0.975, 100, 15), 200)\n  ) +\n  scale_x_continuous(limits = c(55, 145)) +\n  labs(\n    x = \"QI\",\n    y = \"Densità\"\n  )\n\n\n\nFigura 41.5: Distribuzione campionaria con regione di rifiuto bilaterale.\n\n\n\n\n\n41.4.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il “risultato osservato” ha una ‘piccola’ probabilità subordinatamente all’ipotesi assunta, respingiamo l’ipotesi. (p. 441)\n\nOvviamente l’ipotesi a cui von Mises fa riferimento, la cui validità è solo ipotetica, è l’ipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l’ipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) – i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilità di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l’ipotesi nulla è vera. Se il valore-\\(p\\) è minore del livello di significatività \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ciò conduce al rifiuto dell’ipotesi nulla. Tali concetti sono riassunti nella Figura 41.6.\n\n\n\n\nFigura 41.6: Relazione tra il valore-p e il livello di significatività alpha."
  },
  {
    "objectID": "226_test_ipotesi.html#potenza-del-test",
    "href": "226_test_ipotesi.html#potenza-del-test",
    "title": "41  Significatività statistica",
    "section": "\n41.5 Potenza del test",
    "text": "41.5 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significatività e la potenza del test vengono usati per quantificare la qualità dell’inferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa è vera e dovrebbe respingere \\(H_0\\) in favore dell’alternativa quando \\(H_1\\) è vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, come indicato nella Figura 41.6 e corrispondono alle probabilità indicate nella Figura 41.7.\n\n\n\n\nFigura 41.7: Probabilità dei due tipi di errori nel test di ipotesi statistiche.\n\n\n\n\nPossiamo pensare a \\(H_0\\) come all’ipotesi che descrive l’evento “nulla di interessante sta succedendo” – ad esempio, “la moneta è bilanciata”, “il trattamento non è migliore del placebo”, ecc. – e pensare ad \\(H_1\\) come al caso contrario, ovvero: “sta accadendo qualcosa di interessante”. Quindi la potenza del test, ovvero la probabilità \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa è falsa, corrisponde alla probabilità di rilevare qualcosa di interessante, quando qualcosa di interessante è effettivamente successo, mentre il livello di significatività corrisponde alla probabilità di affermare che qualcosa di interessante si è verificato, quando in realtà non è successo nulla di interessante.\nIl calcolo della potenza di un test è spesso difficile, perché richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando è vera l’ipotesi alternativa \\(H_1\\). Nella Figura 41.8, l’area ombreggiata sotto \\(f(\\mathcal{G}_n \\mid H_0)\\) rappresenta il livello di significatività in un test unilaterale. Ricordiamo che il livello di significatività è la probabilità di rifiutare falsamente l’ipotesi nulla quando essa è vera. Invece, l’area sotto \\(f(\\mathcal{G}_n \\mid H_1)\\) a sinistra della linea verticale che delimita la regione ombreggiata rappresenta la potenza del test, ovvero la probabilità che la statistica del test si trovi nella regione di rifiuto di \\(H_0\\) quando è vera \\(H_1\\). Nella Figura 41.8 la potenza del test è alta.\n\n\n\n\nFigura 41.8: Probabilità dei due tipi di errori nel test di ipotesi statistiche.\n\n\n\n\nNella Figura 41.9, invece, la potenza del test è bassa. Entrambi i test hanno lo stesso livello di significatività, ma se \\(f(\\mathcal{G}_n \\mid H_1)\\) si sovrappone di molto con \\(f (\\mathcal{G}_n \\mid H_0)\\), allora la potenza del test è bassa.\n\n\n\n\nFigura 41.9: Probabilità dei due tipi di errori nel test di ipotesi statistiche.\n\n\n\n\nTipicamente possiamo aumentare la potenza di un test aumentando la numerosità del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale è importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n\n\n\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27(4), 486–501."
  },
  {
    "objectID": "227_ttest.html#modello-normale-varianza-nota",
    "href": "227_ttest.html#modello-normale-varianza-nota",
    "title": "42  Inferenza sulle medie",
    "section": "\n42.1 Modello Normale: varianza nota",
    "text": "42.1 Modello Normale: varianza nota\nIn questa sezione inizieremo ad esaminare il test \\(z\\), il quale ci fornisce una versione semplificata del test \\(t\\) di Student, che probabilmente è in assoluto il test statistico più usato (più di una volta a sproposito) dall’approccio frequentista. Lo scopo di questa discussione è quello di presentare la logica che sta alla base della procedura di test di ipotesi frequentista. Il test \\(z\\) chiarisce questa logica esaminando il caso più semplice – un caso che, per motivi che saranno chiariti in seguito, non trova molte applicazioni pratiche. Lo presentiamo qui perché rende trasparente la motivazione frequentista della procedura di test di ipotesi. Gli altri test frequentisti, quelli che si usano nelle applicazioni concrete, sono semplicemente degli sviluppi dell’idea sulla quale si basa il test \\(z\\). Per cui, se si capisce il test \\(z\\), si capiscono tutti i test frequentisti.\nIl test \\(z\\) applica la procedura di test di ipotesi statistiche che è stata presentata nel capitolo precedente e si pone il problema di verificare un’ipotesi a proposito della media della popolazione utilizzando la media campionaria quale statistica test. In precedenza abbiamo discusso un teorema della teoria della probabilità il quale afferma che la media \\(\\bar{X}_n\\) di \\(n\\) variabili aleatorie i.i.d., ciascuna distribuita come \\(\\mathcal{N}(\\mu, \\sigma^2)\\), segue una distribuzione normale con parametri \\(\\mu_{\\bar{X}_n} = \\mu\\) e \\(\\sigma^2_{\\,\\bar{X}_n} = \\sigma^2 / n\\). Questo significa che, conoscendo i parametri (media e deviazione standard) della popolazione di origine, è possibile specificare completamente la distribuzione campionaria di \\(\\bar{X}_n\\).\nOvviamente il valore dei parametri è ignoto, ma è qui che interviene la procedura di test di ipotesi. In base all’approccio NHST, la distribuzione campionaria della statistica test viene costruita assumendo come vera l’ipotesi nulla. Il test \\(z\\) – e lo stesso approccio viene seguito per tutti gli altri test di stampo frequentista – determina la distribuzione campionaria della statistica test (per esempio, la media del campione quale stimatore della media della popolazione) ipotizzando che il campione osservato provenga da una popolazione in cui l’ipotesi nulla è vera. La domanda di come determinare i valori dei parametri incogniti della popolazione trova quindi una facile risposta: il valore di tali parametri è fornito da \\(H_0\\)!\n\n42.1.1 Un test bilaterale\nPer vedere come come si esegue il test \\(z\\), consideriamo il seguente esempio. I valori antropometrici medi della popolazione italiana adulta sono stati descritti, per esempio, da un’indagine nazionale condotta da Briziarelli et al. (1994). Ci concentriamo qui sull’altezza media delle donne adulte, la quale risulta essere pari a 162.5 cm tra 18 e 24 anni, con una deviazione standard di 12 cm. Sappiamo anche che la variabile “altezza” segue la distribuzione normale. Per qualche ragione, sospettiamo che, a Firenze, l’altezza media sia diversa da quella a livello nazionale e, per gli scopi di questo esempio, crediamo che possa essere o maggiore o minore di quella italiana.\n\n42.1.2 La statistica test\nPer sottoporre a verifica la nostra ipotesi della ricerca, misuriamo l’altezza di 20 donne fiorentine scelte a caso. Supponiamo di avere ottenuto i seguenti risultati:\n\nx <- c(173.53, 175.01, 165.19, 161.06, 173.77, 144.68, 174.06, 163.19, 163.09, 155.47, 165.11, 188.31, 170.95, 172.74, 157.49, 176.30, 155.86, 162.52, 179.95, 170.08)\n\nCalcoliamo la media del campione:\n\nmean(x)\n#> [1] 167.418\n\nLa media campionaria è un po’ più grande della media della popolazione \\(\\mu = 162.5\\) e questo suggerisce che, in effetti, le donne fiorentine potrebbero avere un altezza superiore alla media nazionale. Tuttavia, un campione di ampiezza \\(n = 20\\) è molto piccolo, per cui la diffrenza tra il risultato osservato e il valore atteso (\\(\\mu = 162.5\\)) potrebbe essere soltano il prodotto del caso. Per verificare l’ipotesi, che l’altezza delle donne fiorentine sia diversa da quella delle altre donne italiane decidiamo di usare \\(\\bar{X}_{n}\\) quale statistica test, ovvero quale stima di \\(\\mu\\).\nPer valutare la nostra ipotesi iniziamo ad elencare ciò che sappiamo. Chiamiamo \\(X\\) l’altezza delle donne fiorentine. In primo luogo, sappiamo che la media campionaria è \\(\\bar{X}_{n} = 167.418\\). Se siamo disposti ad assumere che la distribuzione dell’altezza delle donne fiorentine ha la stessa deviazione standard dell’altezza delle altre donne della popolazione italiana, allora possiamo dire che la deviazione standard dell’altezza delle donne fiorentine è \\(\\sigma = 12\\). Inoltre, sappiamo che i valori dell’altezza delle donne fiorentine sono distribuiti in maniera normale dato che, in generale, i valori dell’altezza seguono la legge della distribuzione normale.\nOra elenchiamo ciò che non sappiamo, ma che vorremmo sapere. La nostra ipotesi riguarda il valore incognito \\(\\mu\\), ovvero la media dell’altezza della popolazione delle donne fiorentine – infatti, abbiamo misurato l’altezza di 20 donne fiorentine, non di tutte le donne fiorentine! La nostra ipotesi è \\(X \\sim \\mathcal{N}(\\mu \\neq 162.5, \\sigma = 12)\\), con \\(\\mu\\) sconosciuto. Dato che, nella procedura NHST, l’ipotesi del ricercatore definisce “l’ipotesi alternativa” \\(H_1\\), possiamo scrivere:\n\\[\nH_1: X \\sim \\mathcal{N}(\\mu \\neq 162.5, \\sigma = 12).\n\\]\nUna volta definita l’ipotesi alternativa risulta specificata anche l’ipotesi nulla, in quanto essa è l’ipotesi opposta e complementare a \\(H_1\\). Dunque possiamo scrivere:\n\\[\nH_0: X \\sim \\mathcal{N}(\\mu = 162.5, \\sigma = 12).\n\\]\nLe ipotesi nulla e alternativa riguardano i parametri della popolazione. In questo particolare esempio, il paraemtro \\(\\mu\\) (la media dell’altezza delle donne fiorentine) è incognito ma \\(\\sigma\\) è noto (in quanto abbiamo assunto che l’altezza delle donne fiorentine e l’altezza delle donne italiane sono due Normali con la stessa deviazione standard ma con medie diverse). Per stimare \\(\\mu\\) dobbiamo usare una qualche statistica test, e la statistica ovvia a questo riguardo è semplicemente la media del campione \\(\\bar{X}\\). Decidiamo dunque di usare \\(\\bar{X}\\) quale statistica test. Quello che dobbiamo ancora stabilire sono le caratteristiche della distribuzione campionaria di \\(\\bar{X}\\) nel caso di campioni di ampiezza \\(n=20\\).\n\n42.1.3 La distribuzione campionaria della statistica test\nIn base all’approccio NHST, la distribuzione campionaria della statistica test viene determinata assumendo come vera l’ipotesi nulla. Nel caso del nostro esempio, l’ipotesi nulla afferma che \\(X \\sim \\mathcal{N}(\\mu = 162.5, \\sigma = 12)\\). Sotto \\(H_0\\), dunque, la distribuzione campionaria della media di campioni di ampiezza \\(n=20\\) è:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu_{\\bar{X}} = \\mu = 162.5, \\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{12}{\\sqrt{20}}\\right).\n\\]\nSi noti che è l’ipotesi nulla a specificare la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\) della popolazione da cui vengono estatti i campioni che formano la distribuzione campionaria di \\(\\bar{X}\\). Per questa ragione diciamo che la distribuzione campionaria della statistica test, \\(f(\\bar{X} \\mid H_0)\\), è stata generata assumendo vera l’ipotesi nulla.\n\n42.1.4 La decisione\nNel problema che stiamo discutendo l’ipotesi alternativa \\(H_1\\) è bilaterale. Ovvero, possiamo rigettare \\(H_0\\) se troviamo che l’altezza media delle donne fiorentine è molto diverso dal valore postulato da \\(H_0\\), ovvero \\(\\mu_{\\bar{X}} = \\mu = 162.5\\). Rifiuteremo \\(H_0\\) se la statistica test \\(\\bar{X}\\) si dimostra essere di molto maggiore dell’altezza ipotizzata da \\(H_0\\), oppure di molto minore dell’altezza ipotizzata da \\(H_0\\).\nIn altre parole, per valutare \\(H_0\\) dobbiamo determinare se la statistica test cade o meno nella regione di rifiuto. È necessario dunque identificare la regione di rifiuto di \\(H_0\\). Per fare questo dobbiamo prima scegliere \\(\\alpha\\). Seguendo la consuetudine usata in psicologia, poniamo \\(\\alpha = 0.05\\). Dato che il test è bidirezinale, rigettiamo \\(H_0\\) se la statistica test corrisponde ad un valore estremo che cade o nella coda di destra di \\(f(\\bar{X} \\mid H_0)\\) oppure nella coda di sinistra di \\(f(\\bar{X} \\mid H_0)\\). La regione di rifiuto di \\(H_0\\) sarà dunque divisa in due parti: metà sarà collocata nella coda di sinistra di \\(f(\\bar{X} \\mid H_0)\\) e metà nella coda di destra di \\(f(\\bar{X} \\mid H_0)\\). Quali sono i valori critici che delimitano le due regioni di rifiuto di \\(H_0\\)? Per trovarli, dobbiamo calcolare i quantili di ordine 0.025 e 0.975 della distribuzione normale di media 162.5 e deviazione standard \\(\\frac{12}{\\sqrt{20}}\\):\n\nqnorm(0.025, 162.5, 12/sqrt(20))\n#> [1] 157.2409\nqnorm(0.975, 162.5, 12/sqrt(20))\n#> [1] 167.7591\n\nLe due regioni di rifiuto di \\(H_0\\) sono dunque \\([-\\infty, 157.24]\\) e \\([167.76, +\\infty]\\), come indicato nella Figura 42.1.\n\nggplot(data.frame(x = c(55, 145)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 162.5, sd = 12)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 162.5, sd = 12),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(0, qnorm(0.025, 162.5, 12))\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = 162.5, sd = 12),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(qnorm(0.975, 162.5, 12), 200)\n  ) +\n  scale_x_continuous(limits = c(162.5-3*12, 162.5+3*12)) +\n  labs(\n    x = \"Altezza (cm)\",\n    y = \"Densità\"\n  )\n\n\n\nFigura 42.1: Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l’ipotesi nulla \\(X \\sim \\mathcal{N}(\\mu = 162.5, \\sigma = 12)\\). Le aree ombreggiate indicano le regioni di rifiuto di \\(H_0\\) per un test bilaterale posto \\(\\alpha\\) = 0.05.\n\n\n\n\nIl valore osservato della statistica test, ovvero \\(\\bar{X} = 167.418\\), non cade nella regione di rifiuto di \\(H_0\\). Pertanto, sulla base delle informazioni disponibili, non possiamo rigettare \\(H_0\\). E questo conclude la descrizione della logica del test \\(z\\).\n\n42.1.5 La statistica test Z\nSolitamente, per giungere alla conclusione descritta sopra si procede in modo diverso, ovvero applicando una semplice formula. In tale formula non facciamo altro che standardizzare la media campionaria all’interno della distribuzione campionaria costruita assumendo come vera \\(H_0\\). In pratica, per eseguire tale standardizzazione sottraiamo dalla media campionaria la media della distribuzione ipotizzata da \\(H_0\\) e dividiamo per la deviazione standard ipotizzata da \\(H_0\\):\n\\[\\begin{equation}\nZ = \\frac{\\bar{X}_n - \\mu_{\\bar{X}}}{\\sigma_{\\bar{X}}} = \\frac{\\bar{X}_n - \\mu_{\\bar{X}}}{\\frac{\\sigma}{\\sqrt{n}}},\n(\\#eq:testz)\n\\end{equation}\\]\novvero\n\\[\nZ = \\frac{167.418 - 162.5}{\\frac{12}{\\sqrt{20}}} = 1.8328.\n\\] Il valore che abbiamo ottenuto corrisponde alla cosiddetta statistica test \\(Z\\). Il test \\(z\\) si chiama così proprio perché è basato sulla statistica test \\(Z\\), e ovviamente \\(Z\\) ha questo nome perché è una variabile aleatoria normale standard di media 0 e varianza 1.\n\n42.1.6 I valori critici\nQuali sono i valori di una normale standard che lasciano in ciascuna delle due code il 2.5% dell’area sottesa alla funzione di densità \\(f(\\bar{X}_{20} \\mid H_0)\\)? Usando R troviamo\n\nqnorm(0.025, 0, 1)\n#> [1] -1.959964\nqnorm(0.975, 0, 1)\n#> [1] 1.959964\n\nRisultano così specificate le due regioni di rifiuto \\([-\\infty, -1.96]\\) e \\([1.96, +\\infty]\\) illustrate nella Figura 42.2.\n\nggplot(data.frame(x = c(-3, 3)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 0, sd = 1),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(-10, qnorm(0.025, 0, 1))\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = 0, sd = 1),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(qnorm(0.975, 0, 1), 10)\n  ) +\n  scale_x_continuous(limits = c(-3, 3)) +\n  labs(\n    x = \"Altezza (in unità di deviazione standard)\",\n    y = \"Densità\"\n  )\n\n\n\nFigura 42.2: Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l’ipotesi nulla \\(X \\sim \\mathcal{N}(\\mu = 0, \\sigma = 1)\\). Le aree ombreggiate indicano le regioni di rifiuto di \\(H_0\\) per un test bilaterale posto \\(\\alpha\\) = 0.05.\n\n\n\n\nNon è una sorpresa che, facendo i calcoli in questo secondo modo, giungiamo alla stessa conclusione che avevamo trovato in precedenza: la statistica test non cade nella regione di rifiuto di \\(H_0\\) e dunque non possiamo rifiutare l’ipotesi che i dati campionari provengano dalla popolazione specificata da \\(H_0\\), ovvero \\(\\mathcal{N}(\\mu = 162.5, \\sigma = 12)\\).\n\n42.1.7 Il valore-p\nIntroduciamo ora un altro concetto centrale dell’inferenza frequentista: quello del valore-\\(p\\). Il valore-\\(p\\) viene usato per il test dell’ipotesi nulla in base alla regola seguente: se il valore-\\(p\\) è minore di \\(\\alpha\\), allora rigettiamo \\(H_0\\). Ottenere un valore-\\(p\\) minore di \\(\\alpha\\), infatti, significa osservare una media campionaria molto distante dal valore ipotizzato dall’ipotesi nulla.\nNelle parole di Neyman,\n\nil valore-\\(p\\) è la probabilità di osservare un valore della statistica test uguale o più estremo di quello osservato qualora sia vera \\(H_0\\).\n\nDetto in un altro modo: se il mondo avesse le caratteristiche specificate da \\(H_0\\), il valore-\\(p\\) descriverebbe la probabilità di osservare un campione che una media uguale a quella del campione osservato, o una media ancora più lontana da quella specificata da \\(H_0\\). Si noti il carattere ipotetico di questa affermazione: “se il mondo avesse le caratteristiche specificate da \\(H_0\\)”.\nPer trovare il valore-\\(p\\), iniziamo a calcolare l’area sottesa alla funzione di densità \\(f(\\bar{X}_{20} \\mid H_0)\\) nell’intervallo \\([162.5, \\infty]\\):\n\n1 - pnorm(1.8328, 0, 1)\n#> [1] 0.03341616\n\nQuesto però non è il valore-\\(p\\) per un test bidirezionale. Infatti, in un test bidirezionale noi rigettiamo \\(H_0\\) sia quando troviamo valori estremi nella coda di destra di \\(f(\\bar{X} \\mid H_0)\\) sia quando troviamo valori estremi nella coda di sinistra di \\(f(\\bar{X}_{20} \\mid H_0)\\). Dunque, dobbiamo calcolare il valore-\\(p\\) utilizzando il valore assoluto della statistica test, ovvero sommando le aree sottese a \\(f(\\bar{X}_{20} \\mid H_0)\\) negli intervalli \\([-\\infty, \\mathcal{G}_n]\\) e \\([\\mathcal{G}_n, +\\infty]\\):\n\n(1 - pnorm(1.8328, 0, 1)) + pnorm(-1.8328, 0, 1)\n#> [1] 0.06683232\n\nDato che il valore-\\(p\\) trovato nel test è maggiore di \\(\\alpha = 0.05\\), non rigettiamo l’ipotesi nulla. Ovviamente, giungiamo alla stessa conclusione sia confrontando la statistica test \\(\\mathcal{G}_n\\) con il valore critico, sia confrontando il valore-\\(p\\) con \\(\\alpha\\).\n\n42.1.8 Il test unilaterale\nProseguiamo la discussione considerando ora il caso di un test monodirezionale. Un tale test risulta appropriato quando l’ipotesi alternativa ha la forma\n\\[\nH_1: X \\sim \\mathcal{N}(\\mu > 162.5, \\sigma = 12),\n\\]\nper cui, di conseguenza, \\(H_0\\) è:\n\\[\nH_0: X \\sim \\mathcal{N}(\\mu \\leq 162.5, \\sigma = 12).\n\\]\nCome specificata sopra, l’ipotesi alternativa corrisponde all’ipotesi della ricerca secondo la quale le donne fiorentine, in media, sono più alte delle donne italiane.\nAnche nel caso di un test unilaterale, è necessario usare la statistica test \\(Z\\) = 162.5. Ciò che è diverso rispetto al caso di un test bilaterale è dove viene collocata la regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). Se l’ipotesi della ricerca è che le donne fiorentine, in media, sono più alte delle donne italiane, è chiaro che evidenze contrarie all’ipotesi nulla vengono fornite quando la media campionaria assume valori molto superiori al valore del parametro specificato da \\(H_0\\), la quale afferma che l’altezza media delle donne fiorentine è uguale a quella delle donne italiane, o addirittura inferiore. Nel caso del test unidirezionale specificato sopra, quindi, la regione di rifiuto \\(\\mathcal{R}\\) sarà collocata sulla sola coda destra della densità \\(f(\\bar{X}_{n} \\mid H_0)\\) – si veda la Figura 42.3.\n\nggplot(data.frame(x = c(-3, 3)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 0, sd = 1),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(qnorm(0.95, 0, 1), 10)\n  ) +\n  scale_x_continuous(limits = c(-3, 3)) +\n  labs(\n    x = \"Altezza (in unità di deviazione standard)\",\n    y = \"Densità\"\n  )\n\n\n\nFigura 42.3: Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l’ipotesi nulla \\(X \\sim \\mathcal{N}(\\mu = 0, \\sigma = 1)\\). L’area ombreggiata indica la regione di rifiuto di \\(H_0\\) per un test unilaterale destro posto \\(\\alpha\\) = 0.05.\n\n\n\n\nIn generale, in un test unidirezionale il valore-\\(p\\) corrisponde all’area sottesa alla funzione di densità \\(f(\\mathcal{G}_{n} \\mid H_0)\\) nell’intervallo \\([\\mathcal{G}_n, +\\infty]\\), se l’ipotesi nulla ha la forma \\(H_0: \\mu \\leq \\mu_0\\), oppure nell’intervallo \\([-\\infty, \\mathcal{G}_n]\\), se l’ipotesi nulla ha la forma \\(H_0: \\mu \\geq \\mu_0\\). A differenza del caso bidirezionale, dunque, tutta la regione di rifiuto \\(\\mathcal{R}\\) è collocata su una sola coda della distribuzione campionaria della statistica test \\(f(\\bar{X}_{n} \\mid H_0)\\).\nNel caso dell’esempio che stiamo discutendo, \\(Z = 1.8328\\) e, dunque, cade nella regione di rifiuto di \\(H_0\\) per un test unilaterale superiore. Possiamo dunque rigettare \\(H_0\\) e concludere che il campione esaminato fornisce evidenza che le donne fiorentine tendono ad essere più alte della media nazionale.\nMa perché possiamo rifiutare \\(H_0\\) nel caso di un test unidirezionale ma non possiamo farlo quando usiamo un test bidirezionale? Perché il test di ipotesi risulta più conservativo quando il test è bidirezionale. Questo ha senso. L’ipotesi della ricerca è molto vaga: dice semplicemente che succederà qualcosa di diverso dal caso di non interesse, ma non sa dire cosa. Di conseguenza, l’ipotesi nulla può essere rigettata solo quando osserviamo un risultato campionario veramente estremo. D’altra parte, invece, bastano evidenze “più deboli” per rigettare \\(H_0\\) quando sappiamo dove guardare, quando possiamo fare delle predizioni su quello che succederà. La procedura di test di ipotesi, quindi, ci incoraggia ad essere precisi, ad avere la capacità di fare delle predizioni direzionali, piuttosto di chiederci semplicemente se è possibile osservare qualcosa, qualunque cosa, di diverso dall’evento di non interesse specificato da \\(H_0\\)."
  },
  {
    "objectID": "227_ttest.html#test-direzionali-e-non-direzionali",
    "href": "227_ttest.html#test-direzionali-e-non-direzionali",
    "title": "42  Inferenza sulle medie",
    "section": "\n42.2 Test direzionali e non direzionali",
    "text": "42.2 Test direzionali e non direzionali\nRiassumendo, un test d’ipotesi può essere bidirezionale, unidirezionale superiore e unidirezionale inferiore.\n\n42.2.1 Test bidirezionale\nPer un’ipotesi nulla \\[H_0: \\mu = \\mu_0\\] nel caso di un test bidirezionale la regione di non rifiuto \\(\\mathcal{A}\\) di \\(H_0\\) è\n\\[\n\\mathcal{A}: \\quad \\mu_0 - \\frac{\\sigma}{\\sqrt{n}}z_{1-\\alpha/2} \\leq \\mu_n \\leq \\mu_0 + \\frac{\\sigma}{\\sqrt{n}}z_{1-\\alpha/2},\n\\]\ndove \\(\\mu_n\\) è la realizzazione della statistica test, ovvero la media campionaria, \\(n\\) è l’ampiezza del campione e \\(z_{1-\\alpha/2}\\) è il quantile di ordine \\(1-\\alpha/2\\) per la variabile standardizzata\n\\[\nZ_n = \\frac{\\mu_n - \\mu_0}{\\sigma/\\sqrt{n}}.\\notag\n\\]\n\n42.2.2 Test unidirezionale superiore\nLa regione di non rifiuto di \\(H_0: \\mu \\leq \\mu_0\\), con \\(H_1: \\mu > \\mu_0\\), è l’intervallo aperto a sinistra:\n\\[\n\\mathcal{A}: \\quad -\\infty < \\mu_n \\leq \\mu_0 + \\frac{\\sigma}{\\sqrt{n}}z_{1-\\alpha},\n\\]\ndove \\(z_{1-\\alpha}\\) è il quantile di ordine \\(1-\\alpha\\) della normale standard.\n\n42.2.3 Test unidirezionale inferiore\nLa regione di non rifiuto di \\(H_0: \\mu \\geq \\mu_0\\), con \\(H_1: \\mu < \\mu_0\\), è l’intervallo aperto a destra:\n\\[\n\\mathcal{A}: \\quad \\mu_0 - \\frac{\\sigma}{\\sqrt{n}}z_{1-\\alpha} \\leq \\mu_n < +\\infty,\n\\] dove \\(z_{1-\\alpha}\\) è il quantile di ordine \\(1-\\alpha\\) della normale standard.\n\n42.2.4 Eseguire il test Z con R\nCome abbiamo detto in precedenza, nella pratica concreta dell’analisi dei dati il test \\(Z\\) non viene quasi mai usato. Il suo uso è talmente raro che in R non c’è neppure una funzione che lo implementa. Vediamo comunque come svolgere i calcoli con R. Se i dati siano contenuti nel vettore x, non dobbiamo fare altro che calcolare il valore standardizzato della media campionaria assumendo come vera l’ipotesi nulla:\n\nmu_0 <- 162.5\nsigma <- 12\nn <- 20\nz <- (mean(x) - mu_0) / (sigma / sqrt(n))\nz\n#> [1] 1.83283\n\nDato che il valore-\\(p\\)\n\n1 - pnorm(z, 0, 1)\n#> [1] 0.0334139\n\nè minore di \\(\\alpha = 0.05\\), rifiutiamo \\(H_0\\). Riportiamo il risultato nel modo seguente.\n\nAvendo osservato una media campionaria pari a 167.418 cm in un campione casuale di ampiezza \\(n=20\\), assumendo che la deviazione standard della popolazione sia uguale a 12 cm, possiamo concludere che le donne fiorentine tendono ad avere un’altezza maggiore della media nazionale (\\(z = 1.8328\\), \\(n = 20\\), \\(p = 0.0334\\), test unidirezionale).\n\n\n42.2.5 Assunzioni del test Z\nTutti i test statistici fanno delle assunzioni a proposito delle caratteristiche della popolazione da cui sono stati tratti i dati. Alcuni test fanno delle assunzioni ragionevoli, mentre altri test no. Il test \\(z\\) che abbiamo appena descritto è basato sulle seguenti ipotesi:\n\nNormalità. Il test \\(z\\) presuppone che la vera distribuzione della popolazione sia normale. Tale ipotesi è spesso soddisfatta e può essere verificata.\nIndipendenza. La seconda ipotesi del test è che le osservazioni campionarie non sono correlate tra loro, né associate tra loro in qualunque modo. Tale assunzione è difficile da valutare con metodi statistici: deve invece essere garantita dal disegno sperimentale che viene utilizzato per raccogliere i dati. Un caso ovvio nel quale tale assunzione viene falsificata è quando i dati riguardano osservazioni compiute sugli stessi soggetti in condizioni diverse o in tempi diversi. È chiaro in questo caso che ci sarà una correlazione tra le osservazioni. Per esempio, se misuriamo i tempi di reazione, è ovvio che, se un soggetto tende ad essere più veloce della media nella condizione \\(A\\), tenderà anche ad essere più veloce della media nella condizione \\(B\\). Lo stesso si può dire per un soggetto che tende ad essere più lento della media. Pertanto, sapere se un soggetto è più veloce della media nella condizione \\(A\\) ci consente di fare delle predizioni sul suo comportamento nella condizione \\(B\\) – ovvero, i dati sono correlati e l’assunzione di indipendenza viene violata. L’assunzione di indipendenza, invece, non viene violata quando nelle condizioni \\(A\\) e \\(B\\) dell’esempio abbiamo i dati di soggetti diversi. Conoscendo come si sono comportanti i soggetti nella condizione \\(A\\) non ci consente di fare alcuna predizione su come si comporteranno altri soggetti nella condizione \\(B\\) – ovvero, i dati sono indipendenti.\nDeviazione standard nota. La terza ipotesi del test \\(z\\) è che la deviazione standard della popolazione sia nota al ricercatore. Questa assunzione è irragionevole: ciò non si verifica in nessuna applicazione concreta dell’analisi dei dati. In altre parole, questa ipotesi è sempre falsa.\n\nDato che è sempre del tutto fuori luogo assumere che \\(\\sigma\\) sia nota, poniamoci il problema di cosa fare quando non vogliamo assumere qualcosa che è certamente falso. Questo ci conduce al cosiddetto test \\(t\\) di Student."
  },
  {
    "objectID": "227_ttest.html#modello-normale-varianza-sconosciuta",
    "href": "227_ttest.html#modello-normale-varianza-sconosciuta",
    "title": "42  Inferenza sulle medie",
    "section": "\n42.3 Modello Normale: varianza sconosciuta",
    "text": "42.3 Modello Normale: varianza sconosciuta\nSe la varianza \\(\\sigma^2\\) della popolazione normale non è nota essa deve essere stimata con la statistica campionaria corretta \\(s_n^2\\). Il test di ipotesi si esegue valutando se il valore empirico della statistica \\[T_n = \\frac{(\\bar{X}_n -\\mu_0)\\sqrt{n}}{\\hat{s}_n}\\] appartiene alla regione di accettazione di \\(H_0\\) oppure alla regione di rifiuto dell’ipotesi nulla.\nSe il test è bidirezionale, la regione di non rifiuto di \\(H_0\\) è fornita dal seguente intervallo:\n\\[\n\\mathcal{A}: \\quad \\mu_0 - \\frac{s_n}{\\sqrt{n}}t_{1-\\alpha/2} \\leq \\mu_n \\leq \\mu_0 + \\frac{s_n}{\\sqrt{n}}t_{1-\\alpha/2},\n\\]\ndove \\(s_n\\) è il valore empirico della stima di \\(\\sigma\\) e \\(t_{1-\\alpha/2}\\) è il quantile di ordine \\(1-\\alpha/2\\) della distribuzione \\(t\\)-Student con \\(n-1\\) gradi di libertà. In modo analogo, si ricavano le regioni di non rifiuto per un test unidirezionale superiore:\n\\[\n\\mathcal{A}: \\quad -\\infty < \\mu_n \\leq \\mu_0 + \\frac{s_n}{\\sqrt{n}}t_{1-\\alpha},\n\\] oppure unidirezionale inferiore:\n\\[\n\\mathcal{A}: \\quad \\mu_0 - \\frac{s_n}{\\sqrt{n}}t_{1-\\alpha} \\leq \\mu_n < +\\infty.\n\\]\nSe il valore empirico della statistica \\(T_n\\) ricavato dal campione ricade in una delle regioni sopra definite l’ipotesi nulla non può essere rifiutata.\nQuanto descritto sopra mostra che, quando ci basiamo su una stima della deviazione standard della popolazione, dobbiamo fare degli aggiustamenti alla procedura che abbiamo adottato in precedenza. Questi aggiustamenti furono introdotti nel 1908 da William Sealy Gosset, che all’epoca lavorava come chimico per il birrificio della Guinness. Dal momento che Guinness non vedeva di buon occhio il fatto che suoi dipendenti pubblicassero delle analisi statistiche di ciò che ritenevano essere un segreto commerciale, Gosset pubblicò il lavoro sotto lo pseudonimo “A Student”, da cui il nome “test t di Student”. Gosset capì che la stima di \\(\\sigma\\) introduce un ulteriore elemento di incertezza nella procedura di test di ipotesi. Di conseguenza, si rese conto che non è più possibile usare \\(\\mathcal{N}(0, 1)\\) quale funzione di densità che descrive \\(f(\\bar{X}_n \\mid H_0)\\), ma è invece necessario utilizzare una diversa funzione di densità che è, appunto, la \\(t\\) di Student.\nIn precedenza abbiamo visto che ci sono infinite distribuzioni \\(t\\) di Student, ciascuna definita da un diverso numero di gradi di libertà. Abbiamo anche visto che la distribuzione \\(t\\)-Student tende alla normale standard per \\(n \\rightarrow \\infty\\), per cui quando \\(n\\) è sufficientemente grande (\\(n > 30\\)), facendo un’approssimazione, i quantili \\(t_{1-\\alpha/2}\\) e \\(t_{1-\\alpha}\\) possono essere sostituiti dai corrispondenti quantili \\(z_{1-\\alpha/2}\\) e \\(z_{1-\\alpha}\\) della normale standard.\n\n42.3.1 Effetto Stroop\nPer fare un esempio concreto, supponiamo che ad un campione di 59 studenti di psicologia sia stato chiesto di completare una variante del compito Stroop che utilizza come stimoli facce espressive e le parole “felice” o “triste” (Caudek, 2014). In ogni prova dell’esperimento, i soggetti devono classificare l’immagine di un volto (sorridente o triste) nelle due categorie “volto felice” o “volto triste”, ignorando la parola sovrapposta all’immagine. La parola irrilevante per il compito poteva essere compatibile con l’espressione del volto (es., volto felice e parola “felice”: condizione congruente) o incompatibile con essa (es., volto felice e parola “triste”: condizione incongruente). L’effetto Stroop consiste nel ritardo di elaborazione dell’espressione del volto che si riflette in un rallentamento dei tempi di reazione e nell’aumento degli errori nella condizione incongruente rispetto a quella congruente.\nPer ciascun partecipante, su un totale di 180 prove, è stato calcolato l’effetto Stroop, ovvero la differenza tra la media dei tempi di reazione nella condizione incongruente e nella condizione congruente. Valori positivi significano che i tempi di reazione medi nella condizione incongruente sono maggiori di quelli nella condizione congruente.\nPer i \\(59\\) soggetti dell’esperimento eseguito da Caudek (2014), l’effetto Stroop è riportato qui sotto\n\nx <- c(-110, 196, -58, -54, -162, 11, 6, -25, 27, 81, -40, -91, -40, 39, 23, -32, 157,  72, 89, 9, 60, 239, 139, 8, -65, 11, 18, 51, 53, 74, 105, 245, -16, -69, 1, -11, 65, -10, 118, -62, 48, -78, 96, -122, 7, 83, -60, 57, 111, -11, 34, 27, 84, 240, -67, 111, 92, -93, 13)\n\ne vale, in media\n\nmean(x)\n#> [1] 27.52542\n\ncon una deviazione standard pari a\n\nsd(x)\n#> [1] 88.2878\n\nL’ipotesi nulla è che la prestazione non subisca un effetto di interferenza da parte della parola irrilevante, ovvero che la media dell’effetto Stroop sia 0, \\(H_0: \\mu = 0\\). In base all’ipotesi alternativa, invece, la media dell’effetto Stroop è diversa da 0, \\(H_1: \\mu \\neq 0\\).\nPoniamoci il problema di svolgere il test \\(t\\) di Student per questi dati.\nPer calcolare il valore \\(T\\) del test \\(t\\) di Student dobbiamo standardizzare la media campionaria, ovvero dobbiamo specificare la posizione della statistica test all’interno della sua distribuzione avendo assunto come vera l’ipotesi nulla, ovvero avendo assunto che la media della popolazione sia \\(0\\). La statistica test dunque si ottiene dividendo la media campionaria per una stima dell’errore standard della media:\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}} = \\frac{27.52542 - 0}{\\frac{88.2878}{\\sqrt{59}}} = 2.394745.\n\\]\nIn R il calcolo si svolge nel modo seguente:\n\nT <- (mean(x)) / (sd(x) / sqrt(length(x)))\nT\n#> [1] 2.394745\n\nSi noti che, nel test \\(z\\) l’errore standard era dato da \\(\\sigma/\\sqrt{n}\\); nel test \\(t\\) di Student, invece, non conoscendo \\(\\sigma\\), otteniamo una stima dell’errore standard mediante il rapporto \\(\\hat{\\sigma}/\\sqrt{n} = s_n/\\sqrt{n}\\), dove \\(s_n\\) è la stima corretta della deviazione standard della popolazione.\nNel caso presente, per trovare il valore-\\(p\\) è necessario calcolare l’area sottesa alla densità \\(t_{59-1}\\) negli intervalli \\([-\\infty, -T]\\) e \\([T, \\infty]\\), ovvero nel caso di valori della statistica \\(T\\) maggiori in valore assoluto al valore osservato. Usando R otteniamo\n\n2 * (1 - pt(T, 59 - 1)) \n#> [1] 0.01988317\n\nPosto \\(\\alpha = 0.05\\), i limiti della regione di rifiuto nel caso di un test bidirezionale sono dati dai quantili della distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà a cui è associata una probabilità pari a 0.025 in ciascuna coda. Mediante\n\nqt(c(0.025, 0.975), 59 - 1)\n#> [1] -2.001717  2.001717\n\nsi trovano i valori critici di \\(-2.00\\) e \\(2.00\\). Tutti i valori della statistica \\(T\\) minori di \\(-2.00\\) o maggiori di \\(2.00\\) portano dunque al rifiuto di \\(H_0\\).\nCome abbiamo visto in precedenza, ci sono due modi equivalenti per svolgere il test dell’ipotesi: confrontare il valore-\\(p\\) con \\(\\alpha\\) o stabilire se il valore osservato della statistica \\(T\\) cade nella regione di rifiuto di \\(H_0\\). Nel caso presente, il valore-\\(p\\) è minore di \\(\\alpha\\) (\\(0.0199 < 0.05\\)) e dunque rifiutiamo \\(H_0\\). Oppure possiamo confrontare il valore della statistica test con i limiti della regione di rifiuto dell’ipotesi nulla. La statistica \\(T = 2.39\\) ha un valore superiore del valore critico che delimita la regione di rifiuto nella coda di destra della distribuzione di \\(T\\): 2.39 > 2.00. Dato che il valore \\(T\\) osservato cade nella regione di rifiuto concludiamo rifiutando \\(H_0\\).\nCalcoliamo anche l’intervallo di confidenza al 95%:\n\\[\n\\bar{X}_n \\pm t^*\\frac{s_n}{\\sqrt{n}} = 27.52542 \\pm \\frac{88.2878}{\\sqrt{59}} = [4.52, 50.53],\n\\]\nladdove \\(t^*\\) è il quantile della \\(t\\) di Student con \\(n-1 = 59-1\\) gradi di libertà di ordine \\(1 - \\alpha/2\\), ovvero\n\nqt(0.975, 58)\n#> [1] 2.001717\n\nPossiamo riportare i risultati nel modo seguente.\n\nL’esperimento ci fornisce evidenze di un effetto di interferenza pari a 27.5 ms, \\(t_{59} = 2.39\\), \\(p = 0.0199\\), CI\\(_{95}\\) = [4.52, 50.53].\n\nladdove la notazione \\(t_{59}\\) indica il fatto che abbiamo eseguito un test \\(t\\) di Student con 59 gradi di libertà.\n\n42.3.2 Test T di Student con R\nLa procedura del test \\(t\\) di Student è quasi identica a quella del test \\(z\\), a parte il fatto che abbiamo usato la stima della deviazione standard della popolazione al posto di \\(\\sigma\\) e poi abbiamo valutato la nostra ipotesi usando la distribuzione \\(t\\) con \\(n-1\\) gradi di libertà al posto di \\(\\mathcal{N}(0, 1)\\). Dato che è sempre possibile fare degli errori quando svolgiamo dei calcoli tediosi, controlliamo se i risultati ottenuti sono corretti. Dopo avere inserito i dati nel vettore x, confrontiamo i risultati che abbiamo svolto a mano nell’esercizio sull’effetto Stroop con quelli forniti dalla funzione t.test() di :\n\nt.test(x)\n#> \n#>  One Sample t-test\n#> \n#> data:  x\n#> t = 2.3947, df = 58, p-value = 0.01988\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>   4.517497 50.533351\n#> sample estimates:\n#> mean of x \n#>  27.52542\n\nI risultati sono identici a quelli che abbiamo trovato svolgendo i calcoli “a mano”."
  },
  {
    "objectID": "227_ttest.html#test-unidirezionale",
    "href": "227_ttest.html#test-unidirezionale",
    "title": "42  Inferenza sulle medie",
    "section": "\n42.4 Test unidirezionale",
    "text": "42.4 Test unidirezionale\nIn realtà, si parla di effetto Stroop solo quando i tempi di reazione sono maggiori, in media, nella condizione incongruente rispetto a quella congruente. Nel caso presente, dunque, è sensato porre tutta la regione di rifiuto nella coda di destra della distribuzione della statistica \\(T\\). Per calcolare il valore-\\(p\\) di un test unidirezionale superiore è sufficiente calcolare l’area sottesa alla funzione di densità nell’intervallo \\([T, +\\infty]\\). Posto \\(\\alpha = 0.05\\), il valore critico della regione di rifiuto, nel caso di un test unidirezionale superiore, è dato dal quantile della distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà a cui è associata una probabilità pari a 0.05 nella coda di destra. Utilizzando qt(0.95, 59 - 1) tale valore risulta essere pari a \\(1.67\\). Tutti i valori della statistica \\(T\\) maggiori di 1.67 portano al rifiuto di \\(H_0\\). È ovvio che, se abbiamo trovato un risultato statisticamente significativo con un test bilaterale la stessa conclusione sarà ottenuta, a maggior ragione, con un test unilaterale se la statistica test cade nella coda appropriata della distribuzione campionaria (ovvero, nel caso presente, nella coda di destra). In conclusione, il test dell’ipotesi nulla fornisce evidenze coerenti con l’idea che i tempi di reazione dei soggetti di questo esperimento tendano ad essere più lenti, in media, nella nella condizione incongruente rispetto a quella congruente.\n\n42.4.1 Assunzioni\nDato che il test \\(t\\) di Student per un campione non è altro che il test \\(z\\) nel caso in cui \\(\\sigma\\) non viene considerata come nota, non dovrebbe sorprenderci che le assunzioni del test \\(t\\) di Student siano molto simili a quelle del test \\(z\\).\n\nNormalità. Assumiamo che la distribuzione della popolazione sia normale.\nIndipendenza. Dobbiamo assumere che le osservazioni nel nostro campione siano generate indipendentemente le une dalle altre.\n\nQueste due assunzioni sembrano sensate. Di conseguenza, il test \\(t\\) di Student per un campione viene ampiamente usato nella pratica corrente per svolgere il confronto tra una media campionaria e la media ipotizzata di una popolazione.\n\n42.4.2 Popolazione non Normale\nAbbiamo visto in precedenza che la distribuzione campionaria della media, al crescere di \\(n\\), è ben approssimata dalla legge normale \\(\\mathcal{N}(\\mu, \\sigma^2/n)\\), indipendentemente dalla forma della distribuzione della popolazione. Di conseguenza, se \\(n\\) è sufficientemente grande (\\(n > 30\\)) e se \\(H_0\\) è vera, la distribuzione delle medie campionarie si può approssimare con una legge normale avente media \\(\\mu_0\\) e varianza \\(\\sigma^2/n\\), se \\(\\sigma^2\\) è nota, oppure \\(\\hat{s}_n^2/n\\), se \\(\\sigma^2\\) sconosciuta. Pertanto, nel caso di grandi campioni, le regioni di accettazione dell’ipotesi nulla sono ancora quelle descritte nel presente capitolo, indipendentemente dalla forma della distribuzione della popolazione di origine. Nel caso di piccoli campioni tratti da una popolazione non normale, invece, non è possibile, in generale, procedere al test sul valore medio mediante la procedura qui descritta."
  },
  {
    "objectID": "227_ttest.html#due-gruppi-indipendenti",
    "href": "227_ttest.html#due-gruppi-indipendenti",
    "title": "42  Inferenza sulle medie",
    "section": "\n42.5 Due gruppi indipendenti",
    "text": "42.5 Due gruppi indipendenti\nAnche se il \\(t\\) di Student per un singolo campione viene spesso usato, non corrisponde al caso più comune di uso del test \\(t\\) di Student. Una situazione molto più comune è quella nella quale vengono confrontati due gruppi di osservazioni indipendenti. In psicologia, questo corrisponde al caso di due gruppi diversi di partecipanti, un gruppo per ciascuna condizione sperimentale. Per ogni partecipante allo studio viene misurata una variabile di interesse e la domanda della ricerca è se i due gruppi provengano o meno da due popolazioni aventi la stessa media. In tale situazione viene applicato il test \\(t\\) per campioni indipendenti.\n\n42.5.1 Test bidirezionale\nSupponiamo che due popolazioni abbiano distribuzioni normali, con la stessa varianza e con medie incognite. Le due popolazioni sono dunque distribuite come due variabili aleatorie indipendenti\n\\[\nX \\sim \\mathcal{N}(\\mu_1, \\sigma^2), \\quad Y \\sim \\mathcal{N}(\\mu_2, \\sigma^2).\n\\]\nCi chiediamo se ci sono differenze fra le medie di queste due popolazioni e procediamo con il test della seguente ipotesi nulla:\n\\[\nH_0: \\mu_1 - \\mu_2 = 0\\quad \\text{(non ci sono differenze fra le medie)}.\n\\]\nL’ipotesi alternativa bidirezionale è\n\\[\nH_1: \\mu_1  - \\mu_2 \\neq 0.\n\\]\nAvendo osservato i dati di due campioni indipendenti estratti dalle due popolazioni, possiamo calcolare la statistica\n\\[\nT_n = \\frac{(\\bar{X} - \\bar{Y}) - (\\mu_1-\\mu_2)}{\\sqrt{s_p^2 \\big(\\frac{1}{n_1} + \\frac{1}{n_2}\\big) }} \\notag\n\\]\nche si distribuisce come una variabile aleatoria \\(t\\)-Student con \\(\\nu = n_1 + n_2 - 2\\) gradi di libertà, dove una stima combinata della varianza, \\(s^2_p\\), si trova come indicato all’interno della radice quadrata al denominatore della formula precedente. Se l’ipotesi nulla è vera, dunque, la statistica\n\\[\nT_n = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{s_p^2 \\big(\\frac{1}{n_1} + \\frac{1}{n_2}\\big) }} \\notag\n\\]\nsi distribuirà come una variabile aleatoria \\(t\\)-Student con \\(\\nu = n_1 + n_2 - 2\\) gradi di libertà.\nFissato il livello \\(\\alpha\\), la regione di non rifiuto dell’ipotesi nulla è data da:\n\\[\n\\mathcal{A}: \\quad -t^{\\ast} \\cdot s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}} < (\\bar{X} - \\bar{Y}) < +t^{\\ast} \\cdot s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}},\\notag\n\\]\ndove \\(t^{\\ast} = t_{\\nu, 1-\\alpha/2}\\) è il quantile di ordine \\((1-\\alpha/2)\\) della distribuzione \\(t\\)-Student con \\(\\nu = n_1 + n_2 - 2\\) gradi di libertà.\n\n42.5.2 La durata della gravidanza\nPer fare un esempio, consideriamo uno studio svolto su 1408 donne ospedalizzate (1) per un ricovero ordinario o (2) per un ricovero d’urgenza relativo al parto. La durata della gravidanza (chiamiamola \\(x\\)) è misurata in settimane complete dall’inizio dell’ultimo periodo mestruale. I dati sono riassunti nel modo seguente.\n\nRicovero ordinario: 775 osservazioni con \\(\\bar{x}_o = 39.08\\) e \\(\\sigma^2 = 7.77\\).\nRicovero d’urgenza: 633 osservazioni con \\(\\bar{x}_u = 39.60\\) e \\(\\sigma^2 = 4.95\\).\n\nCi chiediamo se ci sono evidenze sufficienti per concludere che la durata della gravidanza sia diversa nel caso di un ricovero ordinario o nel caso di un ricovero d’urgenza.\nSe possiamo assumere che i dati provengano da due distribuzioni normali aventi uguale varianza, il test \\(t\\) di Student si svolge nel modo seguente. Una stima combinata della varianza è data da\n\\[\ns^2_p = \\frac{774 \\cdot 7.77 + 632 \\cdot 4.95}{1406} \\Big(\\frac{1}{775} \\frac{1}{633}\\Big) = 0.0187.\n\\]\nLa statistica test è\n\\[\nT = \\frac{\\bar{x}_o - \\bar{x}_u}{s_p} = -3.8064.\n\\]\nAbbiamo \\(1,406\\) gradi di libertà. Usando R per calcolare il valore-\\(p\\) di un test bilaterale otteniamo\n\\[\np = P(|T| > |t|) = \\texttt{2 * pt(-3.8064, 1406) = 0.00015}.\n\\]\nCon \\(\\alpha = 0.05\\) possiamo dunque rigettare l’ipotesi nulla di eguaglianza della durata delle gravidanze per i due gruppi di donne.\n\n42.5.3 Test unidirezionale\nSe invece siamo interessati a sapere se la media della prima popolazione è maggiore di quella della seconda popolazione, per esempio, le ipotesi statistiche diventano: \\[\\begin{aligned}\nH_0: \\mu_1 \\leq \\mu_2, \\quad H_1: \\mu_1 > \\mu_2. \\notag\\end{aligned}\\]\nCome in precedenza, la statistica test\n\\[T_n = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{s_p^2 \\big(\\frac{1}{n_1} + \\frac{1}{n_2}\\big) }} \\notag\\]\nsi distribuisce come una variabile aleatorie \\(t\\)-Student con \\(\\nu = n_1 + n_2 - 2\\) gradi di libertà. In questo caso, però, fissato il livello \\(\\alpha\\), la regione di accettazione del test è data da:\n\\[\\mathcal{A}: \\quad -\\infty < (\\bar{X} - \\bar{Y}) < +t^{\\ast} \\cdot s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}},\\notag\\]\ndove \\(t^{\\ast} = t_{\\nu, 1 - \\alpha}\\) è il quantile di ordine \\((1 - \\alpha)\\) della distribuzione \\(t\\)-Student con \\(\\nu = n_1 + n_2 - 2\\) gradi di libertà.\n\n42.5.4 Assunzioni\nIl test \\(t\\) per campioni indipendenti si basa sulle seguenti ipotesi.\n\nNormalità. Come nel caso del test \\(t\\) per un singolo campione, anche il test \\(t\\) per campioni indipendenti presume che i dati siano normalmente distribuiti. Specificamente, assumiamo che entrambe le popolazioni da cui sono tratti i due gruppi siano normalmente distribuite. Vedremo in seguito come sia possibile verificare tale assunzione.\nIndipendenza. Ancora una volta, si presume che le osservazioni siano campionate indipendentemente. Nel contesto del test \\(t\\) per campioni indipendenti questa assunzione significa due cose diverse. In primo luogo, assumiamo che le osservazioni all’interno di ciascun campione siano indipendenti l’una dall’altra (esattamente come ne caso di un test \\(t\\) per un singolo campione). In secondo luogo, assumiamo anche che non ci siano dipendenze tra i due campioni. Se, ad esempio, scopriamo di avere accidentalmente incluso alcuni partecipanti in entrambe le condizioni sperimentali dello studio (ad esempio, permettendo alla stessa persona di iscriversi a due condizioni diverse), allora questo introduce delle dipendenze le osservazioni dei due campioni e l’ipotesi di indipendenza viene violata.\nOmogeneità della varianza (detta anche “omoscedasticità”). La terza ipotesi è che le due popolazioni abbiano la stessa la deviazione standard. È possibile verificare questa ipotesi usando il test di Levene. Tuttavia, c’è un rimedio più semplice per la violazione di questa assunzione, di cui parleremo nella prossima sezione.\n\n42.5.5 Test di Welch\nIl problema più grande relativo all’uso del test \\(t\\) di Student per campioni indipendenti ha a che fare con la terza ipotesi elencata nella sezione precedente: l’ipotesi che entrambe le popolazioni abbiano la stessa deviazione standard. Questo accade raramente nella vita reale: se due popolazioni non hanno la stessa media, perché dovrebbero avere la stessa deviazione standard? Non c’è davvero alcuna ragione per aspettarsi che questa ipotesi sia vera. Per superare tale difficoltà, Welch (1947) sviluppò una seconda forma del test \\(t\\) di Student per campioni indipendenti la quale non richiede l’omogeneità della varianza.\nIl test di Welch è molto simile al test \\(t\\) di Student per campioni indipendenti. La statistica test è identica a quella calcolata in precedenza\n\\[\nT_n = \\frac{\\bar{X} - \\bar{Y}}{\\hat{\\sigma}_{\\bar{X} - \\bar{Y}}}\n\\tag{42.1}\\]\novvero, è data dal rapporto tra la differenza tra le medie campionarie e l’errore standard di tale differenza. Ciò che distingue il test di Welch dalla procedura descritta in precedenza è il modo di calcolare l’errore standard della differenza tra due medie. Nel test di Welch, l’errore standard viene stimato nel modo seguente:\n\\[\n\\hat{\\sigma}_{\\bar{X} - \\bar{Y}} = \\sqrt{\\frac{\\hat{\\sigma}_1^2}{n_1} + \\frac{\\hat{\\sigma}_2^2}{n_2}}.\n\\]\nLa statistica test viene poi valutata utilizzando una correzione dei gradi di liberà fornita dall’equazione di Welch–Satterthwaite:\n\\[\ngdl = \\frac{\n(\\hat{\\sigma}_1^2/n_1 + \\hat{\\sigma}_2^2/n_2)^2\n}{\n(\\hat{\\sigma}_1^2/n_1)^2/(n_1-1) + (\\hat{\\sigma}_2^2/n_2)^2/(n_2-1)\n}.\n\\]\nVediamo ora in un caso concreto come applicare il test di Welch.\nConsideriamo il seguente estratto dell’articolo di Mehr et al. (2014):\n\nThe infants’ degree of song exposure was comparable across the two experiments: The estimated total number of song performances was similar in Experiment 1 (\\(M\\) = 76.3, \\(SD\\) = 56.2) and Experiment 2 (\\(M\\) = 81.8, \\(SD\\) = 50.5), \\(t_{61.3}\\) = 0.41, \\(p\\) = .68 (Satterthwaite’s \\(t\\) test) …\n\nSenza entrare nei dettegli dello studio, poniamoci l’obiettivo di replicare l’analisi statistica descritta dagli autori. I dati del primo esperimento sono:\n\nx1 <- c(35.0, 239.0, 102.0, 27.0, 60.0, 126.0, 134.6667, 63.77777, 44.0, 55.0, 88.0, 53.66666, 59.5, 94.0, 54.0, 26.0, 44.0, 23.0, 38.0, 31.0, 78.4, 135.0, 26.0, 120.9091, 13.0, 245.0, 66.5, 63.0, 57.16667, 29.71428, 70.0, 140.0)\n\ne i dati del secondo experimento sono:\n\nx2 <- c(43.16666, 63.0, 35.0, 100.8, 69.0, 66.0, 105.0, 270.6667, 62.0, 80.0, 128.0, 104.0, 49.0, 80.0, 51.0, 114.3333, 168.0, 105.0, 37.0, 38.0,  45.0, 48.0,  84.0, 99.0,  38.5, 74.57143, 49.0, 28.0, 64.0, 86.8, 49.0, 182.0)\n\nDobbiamo eseguire un test \\(t\\) di Student per campioni indipendenti con il metodo di Welch.\nIn questo caso, \\(n_1=n_2 = 32\\). Abbiamo inoltre che \\(\\bar{X} = 76.32191\\) e \\(\\bar{Y} = 81.77619\\), con \\(s_1^2 = 3163.961\\) e \\(s_2^2 = 2554.029\\). L’errore standard stimato mediante la procedura di Welch è pari a 13.36739 per cui, utilizzando l’equazione del test di Welch otteniamo la statistica \\(T = -0.4080286\\). I gradi di libertà per il test di Welch sono pari a 61.30249 il che ci conduce ad un valore-\\(p\\) pari a\n\n2 * pt(-0.4080286, 61.30249)\n#> [1] 0.6846743\n\nQuesti risultati riproducono perfettamente ciò che è stato riportato da Mehr et al. (2014). I calcoli si possono svolgere utilizzando la funzione t.test() di R:\n\nt.test(x1, x2)\n#> \n#>  Welch Two Sample t-test\n#> \n#> data:  x1 and x2\n#> t = -0.40803, df = 61.302, p-value = 0.6847\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -32.18136  21.27281\n#> sample estimates:\n#> mean of x mean of y \n#>  76.32191  81.77619\n\nSi noti che R utilizza di default il test di Welch quando sottopone a verifica l’ipotesi nulla dell’eguaglianza di due medie.\nL’intervallo di confidenza al 95% è dato da\n\nse <- sqrt(var(x1) / length(x1) + var(x2) / length(x2))\ndf <- 61.302\nci <- (mean(x1) - mean(x2)) + c(-1, 1) * qt(0.975, df) * se \nci\n#> [1] -32.18137  21.27281\n\nil che riproduce il risultato trovato dalla funzione t.test().\nIl messaggio che si può ricavare dalla discussione sul test di Welch è che esso dovrebbe sempre essere eseguito al posto del “tradizionale” test \\(t\\) di Student (infatti, questa è l’impostazione di default in ). Questo perché il test di Welch si comporta meglio del test \\(t\\) di Student se le dimensioni e le varianze dei campioni non sono uguali tra i gruppi e dà lo stesso risultato del test \\(t\\) di Student quando le dimensioni e le varianze del campione sono uguali. Un approccio che viene raccomandato nei testi di statistica è di verificare con il test di Levene l’ipotesi che le varianze siano uguali tra i gruppi, ma molti ricercatori ritengono che sia preferibile utilizzare sempre il test di Welch, indipendentemente dai risultati del test di Levene. Infatti, il test di Levene ha spesso una bassa potenza – ovvero non è in grado di respingere l’ipotesi nulla che le varianze siano uguali anche quando esse sono effettivamente diverse – il che rende problematico assumere che le varianze siano uguali anche se il risultato del test di Levene è nullo.\n\n42.5.6 Assunzioni del test di Welch\nLe assunzioni alla base del test di Welch sono simili a quelle del test \\(t\\) di Student per campioni indipendenti, ad eccezione del fatto che il test di Welch non presuppone l’omogeneità della varianza. Rimangono dunque solo l’assunzione di normalità e l’assunzione di indipendenza."
  },
  {
    "objectID": "227_ttest.html#test-t-per-dati-appaiati",
    "href": "227_ttest.html#test-t-per-dati-appaiati",
    "title": "42  Inferenza sulle medie",
    "section": "\n42.6 Test T per dati appaiati",
    "text": "42.6 Test T per dati appaiati\nSe consideriamo il test \\(t\\) di Student per campioni indipendenti o il test di Welch è evidente che tali test possono essere usati in situazioni in cui i due campioni sono, appunto, indipendenti l’uno dall’altro. Una tale situazione si presenta, ad esempio, quando i partecipanti ad un esperimento vengono assegnati casualmente a una di due condizioni sperimentali. Ma ci possono anche essere disegni sperimentali con caratteristiche diverse. In particolare, in un disegno a misure ripetute ciascun partecipante viene valutato (rispetto alla stessa variabile dipendente) in tutte le condizioni sperimentali e, in tali circostanze, i due campioni non sono indipendenti. Ad esempio, potremmo essere interessati a sapere se ascoltare musica riduce la capacità della memoria di lavoro delle persone. A tal fine, potremmo misurare la capacità della memoria di lavoro di ciascun soggetto in due condizioni: con la musica e senza musica. In un disegno sperimentale di questo tipo ciascun partecipante fa parte di ciascuno dei due gruppi che vengono esaminati. Non possiamo dunque usare l’approccio descritto in precedenza e dobbiamo procedere in un modo diverso, ovvero mediante l’uso del test \\(t\\) per dati appaiati\nNel test \\(t\\) per dati appaiati disponiamo di una coppia ordinata di osservazioni per ciascuna u.s. (per esempio, l’osservazione effettuata ad un pre-test e ad un post-test, oppure nelle condizioni con la musica e senza musica dell’esempio precedente) e diventa così possibile calcolare una misura della variazione \\(D\\) della variabile di interesse rispetto alle due osservazioni. Avendo un insieme \\(D_1, \\dots, D_n\\) di variazioni, possiamo calcolarne la media \\(\\bar{D}\\) e la deviazione standard \\(s_D\\):\n\\[\n\\bar{D} = \\frac{1}{n} \\sum_{i = 1}^n D_i, \\quad s_D = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (D_i - \\bar{D})^2}.\n\\]\nL’errore standard per la media delle differenze è dato da\n\\[\ns_{\\bar{D}} = \\frac{s_D}{\\sqrt{n}}.\n\\]\nSe \\(\\delta\\) è la variazione media della popolazione, allora la statistica\n\\[\nT_n = \\frac{\\bar{D} - \\delta}{s_{\\bar{D}}}\n\\]\nsi distribuisce come una v.a. \\(t\\)-Student con \\(\\nu = n - 1\\) gradi di libertà, sotto l’ipotesi che il campione (di variazioni) provenga da una popolazione distribuita in maniera normale. Per il test dell’ipotesi nulla \\(H_0: \\delta = 0\\), si calcola il valore \\(T_n = \\bar{D}/s_{\\bar{D}}\\) e si procede con il confronto con il valore critico per \\(\\nu = n - 1\\) gradi di libertà, dove \\(n\\) è il numero di coppie di osservazioni. Come per tutti i test \\(t\\), la statistica \\(T_n\\) tende a distribuirsi come una \\(t\\)-Student, indipendentemente dalla forma della distribuzione della popolazione di origine, se \\(n\\) è sufficientemente grande.\n\n42.6.1 Proporzione di maschi e femmine\nPer fare un esempio, consideriamo i dati forniti dal censimento indiano relativi rapporto numerico tra i due sessi nel 2001 e nel 2011 in 35 stati dell’India (i dati grezzi sono forniti sulla pagina Moodle di Psicometria).\nAl momento della nascita, la percentuale di bambini di sesso maschile varia nelle diverse zone del mondo, ma in media nascono 101 maschi ogni 100 femmine (Orzack et al., 2015). Nonostante il fatto che le donne, in generale, vivano più a lungo degli uomini, ci sono due paesi nel mondo che hanno al loro interno un grande squilibrio nel rapporto tra i sessi: la Cina ha quasi 50 milioni di uomini in più rispetto alle donne e l’India 43 milioni. Lo squilibrio di Cina e India è dovuto alle pratiche ampiamente documentate degli aborti selettivi sulla base del genere (a causa anche della disponibilità di tecniche di diagnosi prenatale a prezzi accessibili) e all’infanticidio delle neonate (Miller, 2001).\nNell’insieme di dati considerato, ogni osservazione corrisponde ad uno stato dell’India. La variabile considerata (child_sex_ratio) è il numero medio di bambine femmine per ogni 1000 bambini maschi – ciò consente di escludere la maggiore longevità delle donne (l’età dei bambini non è specificata). Nel 2001, risultano esserci in media \\(934\\) bambine rispetto a 1000 bambini maschi e nel 2011 risultano \\(926\\) bambine, in media, per ogni 1000 bambini maschi. Per ciascuno stato, sottraiamo il numero medio di bambine calcolate rispetto a 1000 bambini nel 2011 da quello del 2001. Le \\(35\\) differenze così trovate hanno una media pari a \\(-7.66\\) con una deviazione standard di \\(22.92\\). La statistica test diventa\n\\[\nT = \\frac{-7.66 - 0}{22.92/\\sqrt{35}} = -1.976.\n\\]\nPer un test bilaterale, il valore-\\(p\\) è l’area sottesa alla funzione di densità \\(t\\) con 34 gradi di libertà negli intervalli \\([-\\infty, T]\\) e \\([T, +\\infty]\\) e risulta essere uguale a \\(0.056\\). Essendo il valore-\\(p\\) maggiore di \\(\\alpha = 0.05\\), non possiamo rigettare l’ipotesi nulla \\(H_0: \\delta = 0\\) che la media della popolazione di differenze sia zero (ovvero che nell’arco temporale considerato non vi siano differenze nel rapporto numerico tra i sessi). In conclusione, non ci sono evidenze che nel decennio 2001-2011 la situazione sia migliorata. Addirittura, la differenza media è negativa, il che suggerisce il contrario."
  },
  {
    "objectID": "227_ttest.html#commenti-e-considerazioni-finali",
    "href": "227_ttest.html#commenti-e-considerazioni-finali",
    "title": "42  Inferenza sulle medie",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIl test \\(t\\) di Student nelle sue varianti rappresenta senza dubbio lo strumento statistico di stampo frequentista più ampiamente usato nel mondo della ricerca. Abbiamo visto che è basato su assunzioni ragionevoli, in molte applicazioni pratiche, e quindi potremmo concludere che sia uno strumento utile. Tuttavia, le cose non sono così semplici – non lo sono mai. In questo capitolo abbiamo visto come il test \\(t\\) di Student viene calcolato, come si giunge ad una decisione sulla base della statistica test e del livello di significatività, eccetera. Tali considerazioni, però, sono considerazioni di tipo statistico, ovvero non riguardano le pratiche del mondo reale, ma descrivono solo le proprietà di alcuni teoremi che fanno parte della teoria della probabilità. Il test \\(t\\) di Student, però, non è solo una procedura astratta, che va valutata per la sua eleganza concettuale, ma è invece una procedura che viene usata nella pratica concreta dell’attività di ricerca per rispondere a domande che hanno una grande rilevanza pratica. Per esempio: la psicoterapia è in grado di ridurre lo stato di ansia e depressione? Oppure: l’idrossiclorochina contrasta in maniera efficace il Covid-19?\nQualcuno, ingenuamente, potrebbe pensare che il mondo della ricerca sia una torre d’avorio all’interno della quale l’attività dei ricercatori è motivata, in primo luogo, e quasi soltanto, dal desiderio di fare avanzare le nostre conoscenze. Non è così. La sociologia della scienza ci fornisce un’immagina ben diversa di come stanno le cose. Le motivazioni dei ricercatori sono ben più prosaiche: l’avanzamento in carriera, il potere, il prestigio, il denaro; tutto ciò descrive molto meglio le motivazioni dei ricercatori del “desiderio di fare avanzare le nostre conoscenze”. Ma cosa c’entra il test \\(t\\) di Student in tutto questo? È facile capire che, se lo stipendio dei ricercatori dipende dalle loro pubblicazioni, e se si possono pubblicare solo i risultati statisticamente significativi, allora i ricercatori faranno tutto quello che è in loro potere per ottenere risultati statisticamente significativi. Qui non faccio riferimento al problema della frode nel mondo scientifico, ma al fatto che è inevitabile che, dopo una lunga e onerosa fase di progettazione dello studio e di raccolta dati, i ricercatori eseguano il test \\(t\\) di Student più di una volta, per confrontare tra loro più di due condizioni e per valutare se da qualche parte nei loro dati emerge un risultato statisticamente significativo. Nella pratica corrente, però, la consuetudine è quella di non riportare il fatto che il test sia stato eseguito più volte, quando esso non produce un risultato statisticamente significativo dove avrebbe dovuto, in base alle ipotesi iniziali dei ricercatori. Ma, se questo è quello che fanno i ricercatori nel mondo reale, dobbiamo chiederci: cosa succede in tali circostanze alla probabilità di errore di I tipo? Non occorre essere degli statistici per renderci conto che, così facendo, la probabilità di errore di I tipo non può rimanere al livello nominale \\(\\alpha\\): nella pratica concreta, dunque, la probabilità di falsi positivi è ben più alta della famosa soglia del 5%.\nPer concludere, ricordiamoci che la giustificazione ultima dell’approccio NHST (di cui il test \\(t\\) di Student è la procedura più nota) è proprio quella di mantenere sotto controllo la probabilità di errore di I tipo. Ma, alla luce di quanto abbiamo detto sopra, e considerando soprattutto le le considerazioni svolte da Gelman & Carlin (2014) che esamineremo nel prossimo capitolo, la domanda (retorica) che dovrebbe venirci in mente è: l’approccio frequentista riesce a mantenere la sua promessa?\n\n\n\n\n\n\nCaudek, C. (2014). Individual differences in cognitive control on self-referenced and other-referenced memory. Consciousness and Cognition, 30, 169–183.\n\n\nGelman, A., & Carlin, J. (2014). Beyond power calculations: Assessing type S (sign) and type M (magnitude) errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nMiller, B. D. (2001). Female-selective abortion in Asia: Patterns, policies, and debates. American Anthropologist, 103(4), 1083–1095.\n\n\nOrzack, S. H., Stubblefield, J. W., Akmaev, V. R., Colls, P., Munné, S., Scholl, T., Steinsaltz, D., & Zuckerman, J. E. (2015). The human sex ratio from conception to birth. Proceedings of the National Academy of Sciences, 112(16), E2102–E2111."
  },
  {
    "objectID": "228_limiti_stat_frequentista.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "228_limiti_stat_frequentista.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "43  Limiti dell’inferenza frequentista",
    "section": "43.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "43.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNuzzo (2014) descrive i limiti dell’approccio NHST nella pratica scientifica. Nuzzo (2014) ci ricorda che Ronald Fisher ha introdotto il valore-\\(p\\) negli anni ’20, ma non ha mai pensato ad esso come ad un test formale. Per Fisher, il valore-\\(p\\) era uno strumento per giudicare informalmente se l’evidenza empirica fosse significativa, laddove il termine significativo veniva inteso in un senso colloquiale, ovvero come qualcosa che meritava di essere considerata con attenzione. Secondo Fisher, lo sperimentatore propone un’ipotesi nulla che spera di dimostrare falsa (per esempio, l’assenza di differenza tra due gruppi). Poi gioca a fare l’avvocato del diavolo e assume che l’ipotesi nulla sia vera. Questo gli consente di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello trovato, se il risultato trovato è interamente dovuto alla sola variabilità campionaria. Anche se il metodo frequentista dell’apagogia che abbiamo presentato in precedenza consente di calcolare il valore-\\(p\\) mediante una procedura matematica, per Fisher tale valore è solo uno strumento da usare all’interno di un processo non numerico capace di combinare le evidenze empiriche correnti con le conoscenze precedenti del ricercatore: è uno strumento da usare all’interno del processo decisionale, non la conclusione del processo decisionale stesso.\nLe procedure di decisione statistica vennero formalizzate alla fine degli anni ’20 da due rivali di Fisher, il matematico Jerzy Neyman e lo statistico Egon Pearson, i quali si posero lo scopo di rendere il processo di decisione “rigoroso e obiettivo”. A tal fine, Neyman e Pearson introdussero, tra l’altro, i concetti di potere statistico e di falso positivo (concetti che abbiamo descritto nei paragrafi precedenti). Non usarono invece la nozione di valore-\\(p\\).\nQuesti due approcci contrapposti portarono ad un dibattito molto acceso tra di due gruppi. Neyman descrisse il lavoro di Fisher come matematicamente “worse than useless”. Fisher chiamò l’approccio di Neyman “childish” e “horrifying [for] intellectual freedom in the west”.\nMentre questo dibattito si sviluppava, altri autori iniziarono a scrivere dei manuali di statistica allo scopo di fornire uno strumento di lavoro ai ricercatori. Dato che molti di questi autori non erano statistici, ma avevano solo una comprensione superficiale della distinzione tra l’approccio di Fisher, da una parte, e l’approccio di Neyman e Pearson, dall’altra, finirono per creare un sistema ibrido che utilizzava il valore-\\(p\\) proposto da Fisher (che era un numero facile da calcolare) all’interno del “sistema rigoroso” proposto da Neyman e Pearson. È in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne definita “statisticamente significativa”. Dal punto di vista storico si può dunque dire che il valore-\\(p\\) proposto da Fisher ha un significato ben diverso dal significato che viene attribuito al valore-\\(p\\) al giorno d’oggi nel mondo della ricerca. Come abbiamo visto sopra, il valore-\\(p\\), con il significato che gli attribuiamo oggi, è frutto di un “incidente storico” privo di qualunque giustificazione e fondamento.\nNel 2016 l’American Statistical Association ha pubblicato un articolo di Wasserstein & Lazar (2016) nel quale si esprime una grande preoccupazione per l’uso inappropriato che viene fatto del valore-\\(p\\) nella pratica scientifica odierna:\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue affermando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p < 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as ) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process."
  },
  {
    "objectID": "228_limiti_stat_frequentista.html#p-hacking",
    "href": "228_limiti_stat_frequentista.html#p-hacking",
    "title": "43  Limiti dell’inferenza frequentista",
    "section": "43.2 \\(P\\)-hacking",
    "text": "43.2 \\(P\\)-hacking\nLa fallacia maggiore associata all’uso del valore-\\(p\\) è chiamata “\\(P\\)-hacking” (o anche data-dredging, snooping, fishing, significance-chasing, double-dipping). Secondo Uri Simonsohn della Università della Pennsylvania, \\(P\\)-hacking is trying multiple things until you get the desired result. Esempi di \\(P\\)-hacking sono: That finding seems to have been obtained through \\(p\\)-hacking, the authors dropped one of the conditions so that the overall \\(p\\)-value would be less than .05, oppure She is a \\(p\\)-hacker, she always monitors data while it is being collected.\nLa pratica del \\(P\\)-hacking ha l’effetto di trasformare uno studio esplorativo (che dovrebbe essere sempre considerato con cautela) in uno studio (apparentemente) confermativo, con la conseguenza di proporre al lettore risultati solo in apparenza “robusti” ma che, in realtà, hanno una probabilità pressoché nulla di essere replicati in studi successivi. Le simulazioni di Simonsohn hanno mostrato come il cambiamento di poche decisioni all’interno del processo di analisi dei dati possa aumentare fino al 60% il tasso di falsi positivi in un singolo studio.\nLa pratica del \\(P\\)-hacking emerge soprattutto negli studi che si pongono il problema di dimostrare piccoli effetti usando dati molto rumorosi. In un’analisi della letteratura psicologica, Simonsohn ha trovato che i valori-\\(p\\) riportati dagli psicologi tendono a concentrarsi su valori appena superiori alla soglia “minima” dello 0.05 (Figura 43.1). Questo risultato può essere interpretato come conseguenza della pratica del \\(P\\)-hacking: infatti, i ricercatori possono eseguire molteplici test statistici fino a trovarne uno che risulta “statisticamente significativo” e poi riportano solo quello. Come mostra la Figura 43.1, questa pratica non riguarda solo la psicologia ma è diffusa in tutti i campi della ricerca scientifica.\n\n\n\nFigura 43.1: Distribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia."
  },
  {
    "objectID": "228_limiti_stat_frequentista.html#critiche-al-valore-p",
    "href": "228_limiti_stat_frequentista.html#critiche-al-valore-p",
    "title": "43  Limiti dell’inferenza frequentista",
    "section": "43.3 Critiche al valore-\\(p\\)",
    "text": "43.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato paragonato alle zanzare (creature noiose e impossibili da mandare via), ai vestiti nuovi dell’imperatore (ovvero, il fatto per cui la maggioranza delle persone sceglie di non riconoscere i problemi che sono ovvi a tutti, ma preferisce fingere di non vederli), o ad un sterile intellectual rake che non produce nulla. È stato ironizzato che l’unica ragione di chiamare questa procedura statistical hypothesis inference testing è per l’acronimo che tale espressione produce.\nIl fatto che valore-\\(p\\) incoraggia un modo di pensare sbagliato, in quanto sposta l’attenzione dal problema centrale della ricerca, ovvero il problema di stabilire qual è la forza della manipolazione sperimentale (ovvero, la dimensione dell’effetto), ad un problema irrilevante, ovvero quello di dimostrare falsa un’ipotesi fantoccio che sappiamo essere falsa a priori (l’ipotesi nulla). L’esempio che Nuzzo (2014) propone è quello di uno studio su più di 19,000 individui che ha mostrato come coloro che incontrano il loro partner online hanno una probabilità minore di divorziare (\\(p <\\) 0.002) e mostrano livelli maggiori di soddisfazione maritale (\\(p <\\) 0.001) rispetto alle coppie che non si sono conosciute online (si veda Nature ; 2013). Questo può sembrare un risultato interessante fino a quando non consideriamo la dimensione dell’effetto: per coloro che si sono conosciuti online il tasso di divorzi diminuisce dal 7.67% al 5.96%, mentre l’indice di soddisfazione maritale aumenta solo da 5.48 a 5.64 su una scala a sette passi. In generale, la domanda giusta da porsi non è “c’è un effetto oppure no?” ma bensì “quanto è grande l’effetto?”."
  },
  {
    "objectID": "228_limiti_stat_frequentista.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "228_limiti_stat_frequentista.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "43  Limiti dell’inferenza frequentista",
    "section": "43.4 L’effetto sperimentale è esattamente nullo?",
    "text": "43.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più ovvie che sono state rivolte alla logica della verifica delle ipotesi statistiche riguarda il fatto che non è ragionevole supporre che l’effetto della manipolazione sperimentale sia “esattamente” nullo. Un esempio preso dalla fisica illustra questo punto. Borel (1914) ha dimostrato che lo spostamento di un centimetro di un grammo di massa in una stella a qualche anno luce da noi modifica il movimento delle molecole di un gas sulla terra. Se, come sembra, tutto è collegato con tutto, allora è ragionevole supporre che la manipolazione sperimentale, quale essa sia, un qualche effetto lo produca sempre. Come Andrew Gelman ha ripetuto molte volte, il punto non è dimostrare falsa l’affermazione secondo cui la manipolazione sperimentale produce un effetto esattamente nullo. Importante invece è stabilire se la dimensione dell’effetto sia sufficientemente grande da avere una qualche importanza dal punto di vista pratico, e stabilire se l’effetto sia riproducibile. Se questi sono gli obiettivi, allora la logica della verifica dell’ipotesi nulla si dimostra problematica. Infatti, come abbiamo visto sopra, nel caso di piccoli campioni e di piccoli effetti (caso, questo, che descrive la quasi la totalità delle ricerche in psicologia), essa conduce ad una notevole sovrastima della dimensione dell’effetto. Inoltre, tende a favorire un pensiero binario basato sulla dicotomia vero/falso, mentre quello che è importante non è rifiutare un’ipotesi (nulla) che sicuramente è falsa, ma piuttosto riuscire ad ottenere una stima non distorta della vera dimensione dell’effetto."
  },
  {
    "objectID": "228_limiti_stat_frequentista.html#attenti-al-valore-p",
    "href": "228_limiti_stat_frequentista.html#attenti-al-valore-p",
    "title": "43  Limiti dell’inferenza frequentista",
    "section": "43.5 Attenti al valore-\\(p\\)!",
    "text": "43.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema.\nEseguiamo un \\(t\\)-test per due campioni indipendenti e sottoponiamo a verifica l’ipotesi nulla dell’eguaglianza delle due medie. Sia \\(\\alpha = 0.05\\). Otteniamo un valore-\\(p\\) di \\(0.04\\). Qual è la probabilità che i due campioni siano tratti da distribuzioni con la stessa media?\n(a) \\(19/20; \\quad\\) (b) \\(1/19; \\quad\\) (c) \\(1/20; \\quad\\) (d) \\(95/100; \\quad\\) (e) sconosciuta.\nLa risposta corretta è: (e) sconosciuta. La statistica frequentista definisce le probabilità dei dati condizionatamente alle ipotesi (assunte come vere). Non consente di stabilire la probabilità di un’ipotesi."
  },
  {
    "objectID": "228_limiti_stat_frequentista.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "228_limiti_stat_frequentista.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "43  Limiti dell’inferenza frequentista",
    "section": "43.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "43.6 La crisi della riprodicibilità dei risultati della ricerca\nIn anni recenti è stato sollevato il problema della non replicabilità dei risultati della ricerca, inclusa la ricerca psicologica. Questo tema è rilevante in questo contesto considerato che, tra gli aspetti del metodo scientifico che sono stati evidenziati quali potenziali responsabili di questa “crisi della ricerca scientifica,” il concetto di valore-p e la pratica della verifica della significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing) figurano in modo prominente. Una breve introduzione a questo problema è fornita da Gelman (2016), il quale ritiene che la pratica NHST sia intrinsecamente problematica, ovvero sia problematico il tentativo del ricercatore di cercare di rigettare un’ipotesi “fantoccio” (straw-man) che è certamente falsa a priori o, almeno, poco interessante dal punto di vista scientifico, a favore di un’ipotesi alternativa favorita dal ricercatore. In generale, sembra più sensato dire che la differenza tra due condizioni sia molto piccola, piuttosto di dire che sia esattamente uguale a zero.\nIl messaggio che viene solitamente trasmesso dai libri di testo di statistica è che la NHST sia una forma di “alchimia”, “to convert randomness into a sort of certainty, as associated with words such as ‘confidence’ and ‘significance’” (Gelman, 2016, p. 12). Viene raccolto un campione di dati, viene eseguita l’analisi statistica e l’inferenza statistica che ne risulta viene riassunta in una conclusione formulata nei termini di un valore-p e di un intervallo di confidenza che esclude lo zero, i quali trasmettono la falsa certezza che il ricercatore abbia compreso le proprietà del fenomeno esaminato. In realtà, il problema della NHST è che essa produce risultati “statisticamente significativi” in un grande numero di casi nei quali le caratteristiche del fenomeno in esame non giustificano la conclusione a cui giunge il ricercatore; ciò conduce, come ovvia conseguenza, alla non replicabilità dei risultati delle ricerche.\nLa comunità degli statistici ha messo in evidenza come i problemi della non replicabilità dei risultati delle ricerche sono soprattutto evidenti quando le conclusioni (erronee) a cui giunge il ricercatore derivano, tramite l’uso della metodologia NHST, dall’osservazione di (1) piccoli campioni nei quali (2) la dimensione dell’effetto è piccola. Questo tipo di situazioni rendono estremamente problematica l’applicazione della NHST (anche se non sono le uniche). E, sfortunatamente, tali due condizioni descrivono le caratteristiche di molte (gran parte) delle recenti ricerche in psicologia.\nUna famosa definizione della statistica è che essa sia un metodo che ci consente di prendere delle decisioni razionali in una situazione di incertezza. Gli statistici suggeriscono ai ricercatori non soltanto di diventare buoni conoscitori delle tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la sofisticazione sempre crescente delle tecniche statistiche disponibili. Convivere con l’incertezza significa evitare di pensare che l’avere ottenuto un valore-\\(p\\) “statisticamente significativo” significhi avere risolto un problema scientifico. Alla luce di quanto abbiamo detto sopra, dovrebbe risultare evidente che le cose non stanno così.\nCome possiamo dunque avere alcuna fiducia in ciò che pensiamo di avere imparato dai dati? Una strategia possibile è la replicazione e la convalida esterna, ma questa strategia è spesso difficilmente perseguibile nel mondo reale della ricerca in psicologia e nelle scienze sociali per i grandi oneri che comporta. Il problema di quali siano gli strumenti metodologici e i metodi statistici più appropriati per indagare i fenomeni psicologici, senza essere ingannati, resta dunque un problema aperto."
  },
  {
    "objectID": "228_limiti_stat_frequentista.html#commenti-e-considerazioni-finali",
    "href": "228_limiti_stat_frequentista.html#commenti-e-considerazioni-finali",
    "title": "43  Limiti dell’inferenza frequentista",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nNon possiamo concludere senza ribadire sia quanto controversa la nozione di valore-\\(p\\). Il valore-\\(p\\), che continua ad essere ampiamente utilizzato e interpretato in maniera erronea, fornisce una patina di legittimità a risultati di studi dubbiosi, incoraggia cattive pratiche di ricerca e promuove la produzione di falsi positivi. Un aspetto sul quale tutti i ricercatori sono d’accordo è che è difficile capire esattamente quale sia il significato di tale nozione. Anche ricercatori esperti, quando devono fornire una definizione del valore-\\(p\\), molto spesso “e con grande confidenza” forniscono la risposta sbagliata. Ciò che veramente interessa ai ricercatori è di sapere se i risultati della ricerca “sono giusti oppure no”, ma il valore-\\(p\\) non ci dice questo. Nè ci dice nulla sulla dimensione dell’effetto, né sulla forza dell’evidenza, né sulla probabilità che il risultato sia stato ottenuto in base al caso soltanto. Ma allora che cosa ci dice? A tale domanda, Stuart Buck ha risposto nel modo seguente:\n\nImagine that you have a coin that you suspect is weighted toward heads. (Your null hypothesis is then that the coin is fair.) You flip it 100 times and get more heads than tails. The \\(p\\)-value won’t tell you whether the coin is fair, but it will tell you the probability that you’d get at least as many heads as you did if the coin was fair. That’s it – nothing more.\n\nIn altre parole, una conclusione sintetica a questa discussione potrebbe essere formulata dicendo che il valore-\\(p\\) fornisce una risposta molto precisa ad una domanda che nessuno ha mai voluto chiedere. Nell’epoca della crisi della riproducibilità dei risultati della ricerca (Baker, 2016) la pratica del test dell’ipotesi nulla e degli intervalli di confidenza frequentisti sono stati individuati come una delle cause della crisi, spingendo molti ricercatori a cercare un’alternativa altrove.\n\n\n\n\n\n\nBaker, M. (2016). Reproducibility crisis? Nature, 533(26), 353–366.\n\n\nBorel, E. (1914). Introduction géométrique. G. Villars, New York.\n\n\nNuzzo, R. (2014). Statistical errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: Context, process, and purpose. The American Statistician, 70(2), 129–133."
  },
  {
    "objectID": "999_refs.html",
    "href": "999_refs.html",
    "title": "Riferimenti bibliografici",
    "section": "",
    "text": "Albert, J., & Hu, J. (2019). Probability and bayesian\nmodeling. Chapman; Hall/CRC.\n\n\nBaker, M. (2016). Reproducibility crisis? Nature,\n533(26), 353–366.\n\n\nBechdel, A. (1986). Dykes to watch out for. Firebrand Books.\n\n\nBergh, D. van den, Van Doorn, J., Marsman, M., Draws, T., Van Kesteren,\nE.-J., Derks, K., Dablander, F., Gronau, Q. F., Kucharskỳ, Š., Gupta, A.\nR. K. N., et al. (2020). A tutorial on conducting and interpreting a\nbayesian ANOVA in JASP. L’Année Psychologique,\n120(1), 73–96.\n\n\nBorel, E. (1914). Introduction\ngéométrique. G. Villars, New York.\n\n\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B.,\nBetancourt, M., Brubaker, M., Guo, J., Li, P., & Riddell, A. (2017).\nStan: A probabilistic programming language. Journal of Statistical\nSoftware, 76(1), 1–32.\n\n\nCaudek, C. (2014). Individual differences in cognitive control on\nself-referenced and other-referenced memory. Consciousness and\nCognition, 30, 169–183.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi.\n\n\nClayton, A. (2021). Bernoulli’s fallacy: Statistical illogic and the\ncrisis of modern science. Columbia University Press.\n\n\nEckhardt, R. (1987). Stan Ulam, John Von Neumann\nand the Monte Carlo Method. Los Alamos Science Special\nIssue.\n\n\nFinetti, B. de. (1931). Probabilismo. Logos, 163–219.\n\n\nGautret, P., Lagier, J. C., Parola, P., Meddeb, L., Mailhe, M., Doudier,\nB., & Honoré, S. (2020). Hydroxychloroquine and azithromycin as a\ntreatment of COVID-19: Results of an open-label non-randomized clinical\ntrial. International Journal of Antimicrobial Agents.\n\n\nGelman, A., & Carlin, J. (2014). Beyond power calculations:\nAssessing type S (sign) and type M (magnitude)\nerrors. Perspectives on Psychological Science, 9(6),\n641–651.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995).\nBayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other\nstories. Cambridge University Press.\n\n\nGelman, A., Hwang, J., & Vehtari, A. (2014). Understanding\npredictive information criteria for bayesian models. Statistics and\nComputing, 24(6), 997–1016.\n\n\nGibson, E., & Wu, H.-H. I. (2013). Processing chinese relative\nclauses in context. Language and Cognitive Processes,\n28(1-2), 125–155.\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J.\n(2014). Robust misinterpretation of confidence intervals.\nPsychonomic Bulletin & Review, 21(5), 1157–1164.\n\n\nHoeting, J. A., Madigan, D., Raftery, A. E., & Volinsky, C. T.\n(1999). Bayesian model averaging: A tutorial (with comments by m. Clyde,\ndavid draper and EI george, and a rejoinder by the authors.\nStatistical Science, 14(4), 382–417.\n\n\nHorstmann, A. C., Bock, N., Linhuber, E., Szczuka, J. M., Straßmann, C.,\n& Krämer, N. C. (2018). Do a robot’s social skills and its objection\ndiscourage interactants from switching the robot off? PloS One,\n13(7), e0201581.\n\n\nHulme, O. J., Wagenmakers, E. J., Damkier, P., Madelung, C. F., Siebner,\nH. R., Helweg-Larsen, J., & Madsen, K. H. (2020). Reply to gautret\net al. 2020: A bayesian reanalysis of the effects of hydroxychloroquine\nand azithromycin on viral carriage in patients with COVID-19.\nmedRxiv.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false.\nPLoS Medicine, 2(8), e124.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with\nR. CRC Press.\n\n\nKennedy-Shaffer, L. (2019). Before p< 0.05 to beyond p< 0.05:\nUsing history to contextualize p-values and significance testing.\nThe American Statistician, 73(sup1), 82–90.\n\n\nKruschke, J. (2014). Doing bayesian data analysis: A\ntutorial with R, JAGS, and Stan. Academic\nPress.\n\n\nLee, M. D., & Wagenmakers, E.-J. (2014). Bayesian cognitive\nmodeling: A practical course. Cambridge university press.\n\n\nLord, F. M. (1950). Efficiency of prediction when a regression equation\nfrom one sample is used in a new sample. ETS Research Bulletin\nSeries, 1950(2), 1–6.\n\n\nMartin, O. A., Kumar, R., & Lao, J. (2022). Bayesian modeling\nand computation in python. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A\nBayesian course with examples in R and\nStan (2nd Edition). CRC Press.\n\n\nMcNamara, A., & Horton, N. J. (2018). Wrangling categorical data in\nr. The American Statistician, 72(1), 97–104.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old\ninfants, melodies are social. Psychological Science,\n27(4), 486–501.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H.,\n& Teller, E. (1953). Equation of state calculations by fast\ncomputing machines. The Journal of Chemical Physics,\n21(6), 1087–1092.\n\n\nMilgram, S. (1963). Behavioral study of obedience. The Journal of\nAbnormal and Social Psychology, 67(4), 371–378.\n\n\nMiller, B. D. (2001). Female-selective abortion in Asia:\nPatterns, policies, and debates. American Anthropologist,\n103(4), 1083–1095.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions\nbetween scientific judgement and statistical model selection.\nComputational Brain & Behavior, 2(1), 28–34.\n\n\nNuggerud-Galeas, S., Sáez-Benito Suescun, L., Berenguer Torrijo, N.,\nSáez-Benito Suescun, A., Aguilar-Latorre, A., Magallón Botaya, R., &\nOliván Blázquez, B. (2020). Analysis of depressive episodes, their\nrecurrence and pharmacologic treatment in primary care patients: A\nretrospective descriptive study. Plos One, 15(5),\ne0233454.\n\n\nNuzzo, R. (2014). Statistical errors. Nature,\n506(7487), 150–152.\n\n\nOrzack, S. H., Stubblefield, J. W., Akmaev, V. R., Colls, P., Munné, S.,\nScholl, T., Steinsaltz, D., & Zuckerman, J. E. (2015). The human sex\nratio from conception to birth. Proceedings of the National Academy\nof Sciences, 112(16), E2102–E2111.\n\n\nRubin, D. B. (1981). Estimation in parallel randomized experiments.\nJournal of Educational Statistics, 6(4), 377–401.\n\n\nSavage, V. M., Allen, A. P., Brown, J. H., Gillooly, J. F., Herman, A.\nB., Woodruff, W. H., & West, G. B. (2007). Scaling of number, size,\nand metabolic rate of cells with body size in mammals. Proceedings\nof the National Academy of Sciences, 104(11), 4718–4723.\n\n\nSavage, V. M., & West, G. B. (2007). A quantitative, theoretical\nframework for understanding mammalian sleep. Proceedings of the\nNational Academy of Sciences, 104(3), 1051–1056.\n\n\nSawilowsky, S. S. (2009). New effect size rules of thumb. Journal of\nModern Applied Statistical Methods, 8(2), 26.\n\n\nSchmettow, M. (2021). New statistics for design researchers.\nSpringer.\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., Märtens, K.,\nTadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., &\nYau, C. (2021). Bayesian statistics and modelling. Nature Reviews\nMethods Primer, 1(1), 1–26.\n\n\nSong, Q. C., Tang, C., & Wee, S. (2021). Making sense of model\ngeneralizability: A tutorial on cross-validation in r and shiny.\nAdvances in Methods and Practices in Psychological Science,\n4(1), 2515245920947067.\n\n\nSorensen, T., & Vasishth, S. (2015). Bayesian linear mixed models\nusing stan: A tutorial for psychologists, linguists, and cognitive\nscientists. arXiv Preprint arXiv:1506.06201.\n\n\nStevens, S. S. (1946). On the theory of scales of measurement.\nScience, 103(2684), 677–680.\n\n\nTufte, E. R. (2001). The visual display of quantitative\ninformation. Graphics press Cheshire, CT.\n\n\nVehtari, A., Gelman, A., & Gabry, J. (2017). Practical bayesian\nmodel evaluation using leave-one-out cross-validation and WAIC.\nStatistics and Computing, 27(5), 1413–1432.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s\nstatement on p-values: Context, process, and purpose. The American\nStatistician, 70(2), 129–133.\n\n\nWilkinson, L. (2012). The grammar of graphics. In Handbook of\ncomputational statistics (pp. 375–414). Springer.\n\n\nZetsche, U., Bürkner, P.-C., & Renneberg, B. (2019). Future\nexpectations in clinical depression: Biased or realistic?\nJournal of Abnormal Psychology, 128(7), 678–688.\n\n\nZylberberg, A., Roelfsema, P. R., & Sigman, M. (2014). Variance\nmisperception explains illusions of confidence in simple perceptual\ndecisions. Consciousness and Cognition, 27, 246–253."
  },
  {
    "objectID": "a01_math_symbols.html",
    "href": "a01_math_symbols.html",
    "title": "Appendix A — Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\)."
  },
  {
    "objectID": "a02_number_sets.html#numeri-binari",
    "href": "a02_number_sets.html#numeri-binari",
    "title": "Appendix B — Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.1 Numeri binari",
    "text": "B.1 Numeri binari\nI numeri più semplici sono quelli binari, cioè zero o uno. Useremo spesso numeri binari per indicare se qualcosa è vero o falso, presente o assente. I numeri binari sono molto utili per ottenere facilmente delle statistiche riassuntive in \\(\\mathsf{R}\\).Supponiamo di chiedere a 10 studenti “Ti piacciono i mirtilli?” Poniamo che le risposte siano le seguenti:\n\nopinion <- c(\n  \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\",\n  \"Yes\", \"Yes\", \"Yes\"\n)\nopinion\n\n [1] \"Yes\" \"No\"  \"Yes\" \"No\"  \"Yes\" \"No\"  \"Yes\" \"Yes\" \"Yes\" \"Yes\"\n\n\nTali risposte possono essere ricodificate nei termini di valori di verità, ovvero, vero e falso, generalmente denotati rispettivamente come 1 e 0. In \\(\\R\\) tale ricodifica può essere effettuata mediante l’operatore == che è un test per l’uguaglianza e restituisce il valore logico VERO se i due oggetti valutati sono uguali e FALSO se non lo sono:\n\nopinion <- opinion == \"Yes\"\nopinion\n\n [1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nR considera i valori di verità e i numeri binari in modo equivalente, con TRUE uguale a 1 e FALSE uguale a zero. Di conseguenza, possiamo effettuare operazioni algebriche sui valori logici VERO e FALSO. Nell’esempio, possiamo sommare i valori di verità e dividere per 10\n\nsum(opinion) / length(opinion)\n\n[1] 0.7\n\n\nin modo tale da calcolare una propozione, il che ci consente di concludere che 7 risposte su 10 sono positive."
  },
  {
    "objectID": "a02_number_sets.html#numeri-interi",
    "href": "a02_number_sets.html#numeri-interi",
    "title": "Appendix B — Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.2 Numeri interi",
    "text": "B.2 Numeri interi\nUn numero intero è un numero senza decimali. Si dicono naturali i numeri che servono a contare, come 1, 2, … L’insieme dei numeri naturali si indica con il simbolo \\(\\mathbb{N}\\). È anche necessario introdurre i numeri con il segno per poter trattare grandezze negative. Si ottengono così l’insieme numerico dei numeri interi relativi: \\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\)"
  },
  {
    "objectID": "a02_number_sets.html#numeri-razionali",
    "href": "a02_number_sets.html#numeri-razionali",
    "title": "Appendix B — Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.3 Numeri razionali",
    "text": "B.3 Numeri razionali\nI numeri razionali sono i numeri frazionari \\(m/n\\), dove \\(m, n \\in N\\), con \\(n \\neq 0\\). Si ottengono così i numeri razionali: \\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\in \\mathbb{Z}, n \\neq 0\\}\\). È evidente che \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\). Anche in questo caso è necessario poter trattare grandezze negative. I numeri razionali non negativi sono indicati con \\(\\mathbb{Q^+} = \\{q \\in \\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\)."
  },
  {
    "objectID": "a02_number_sets.html#numeri-irrazionali",
    "href": "a02_number_sets.html#numeri-irrazionali",
    "title": "Appendix B — Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.4 Numeri irrazionali",
    "text": "B.4 Numeri irrazionali\nTuttavia, non tutti i punti di una retta \\(r\\) possono essere rappresentati mediante i numeri interi e razionali. È dunque necessario introdurre un’altra classe di numeri. Si dicono irrazionali, e sono denotati con \\(\\mathbb{R}\\), i numeri che possono essere scritti come una frazione \\(a / b\\), con \\(a\\) e \\(b\\) interi e \\(b\\) diverso da 0. I numeri irrazionali sono i numeri illimitati e non periodici che quindi non possono essere espressi sotto forma di frazione. Per esempio, \\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\({\\displaystyle \\pi =3,141592\\ldots}\\) sono numeri irrazionali."
  },
  {
    "objectID": "a02_number_sets.html#numeri-reali",
    "href": "a02_number_sets.html#numeri-reali",
    "title": "Appendix B — Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.5 Numeri reali",
    "text": "B.5 Numeri reali\nI punti della retta \\(r\\) sono quindi “di più” dei numeri razionali. Per poter rappresentare tutti i punti della retta abbiamo dunque bisogno dei numeri reali. I numeri reali possono essere positivi, negativi o nulli e comprendono, come casi particolari, i numeri interi, i numeri razionali e i numeri irrazionali. Spesso in statisticac il numero dei decimali indica il grado di precisione della misurazione."
  },
  {
    "objectID": "a02_number_sets.html#intervalli",
    "href": "a02_number_sets.html#intervalli",
    "title": "Appendix B — Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.6 Intervalli",
    "text": "B.6 Intervalli\nUn intervallo si dice chiuso se gli estremi sono compresi nell’intervallo, aperto se gli estremi non sono compresi. Le caratteristiche degli intervalli sono riportate nella tabella seguente.\n\n\nIntervallo\n\n\n\n\n\nchiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\naperto\n\\((a, b)\\)\n\\(a < x < b\\)\n\n\nchiuso a sinistra e aperto a destra\n\\([a, b)\\)\n\\(a \\leq x < b\\)\n\n\naperto a sinistra e chiuso a destra\n\\((a, b]\\)\n\\(a < x \\leq b\\)"
  },
  {
    "objectID": "a03_set_theory.html#operazioni-tra-insiemi",
    "href": "a03_set_theory.html#operazioni-tra-insiemi",
    "title": "Appendix C — Insiemi",
    "section": "\nC.1 Operazioni tra insiemi",
    "text": "C.1 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con~} i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\] \\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]"
  },
  {
    "objectID": "a03_set_theory.html#diagrammi-di-eulero-venn",
    "href": "a03_set_theory.html#diagrammi-di-eulero-venn",
    "title": "Appendix C — Insiemi",
    "section": "\nC.2 Diagrammi di Eulero-Venn",
    "text": "C.2 Diagrammi di Eulero-Venn\nIn molte situazioni è utile servirsi dei cosiddetti diagrammi di Eulero-Venn per rappresentare gli insiemi e verificare le proprietà delle operazioni tra insiemi (si veda la figura @ref(fig:sets-venn-diagrams). I diagrammi di Venn sono così nominati in onore del matematico inglese del diciannovesimo secolo John Venn anche se Leibnitz e Eulero avevano già in precedenza utilizzato rappresentazioni simili. In tale rappresentazione, gli insiemi sono individuati da regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare esplicitamente alcuni elementi di un insieme mediante punti, quando si possono anche evidenziare tutti gli elementi degli insiemi considerati.\n\n\n\n\nIn tutte le figure \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\n\n\nI diagrammi di Eulero-Venn che forniscono una dimostrazione delle leggi di DeMorgan sono forniti nella figura @ref(fig:demorgan).\n\n\n\n\nDimostrazione delle leggi di DeMorgan."
  },
  {
    "objectID": "a03_set_theory.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "a03_set_theory.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendix C — Insiemi",
    "section": "\nC.3 Coppie ordinate e prodotto cartesiano",
    "text": "C.3 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata), \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]"
  },
  {
    "objectID": "a03_set_theory.html#cardinalità",
    "href": "a03_set_theory.html#cardinalità",
    "title": "Appendix C — Insiemi",
    "section": "\nC.4 Cardinalità",
    "text": "C.4 Cardinalità\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\)."
  },
  {
    "objectID": "a04_summation_notation.html#manipolazione-di-somme",
    "href": "a04_summation_notation.html#manipolazione-di-somme",
    "title": "Appendix D — Simbolo di somma (sommatorie)",
    "section": "\nD.1 Manipolazione di somme",
    "text": "D.1 Manipolazione di somme\nÈ conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l’operatore della sommatoria.\n\nD.1.1 Proprietà 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a} = {n\\text{ volte } a} = n a.\n\\]\n\nD.1.2 Proprietà 2 (proprietà distributiva)\nNel caso in cui l’argomento contenga una costante, è possibile riscrivere la sommatoria. Ad esempio con\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n\n\\]\nè possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\n\\[\n\\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i.\n\\]\n\nD.1.3 Proprietà 3 (proprietà associativa)\nNel caso in cui\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots  (a + x_n)\n\\]\nsi ha che\n\\[\n\\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nÈ dunque chiaro che in generale possiamo scrivere\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\nD.1.4 Proprietà 4\nSe deve essere eseguita un’operazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull’argomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\nD.1.5 Proprietà 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]\ninfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\)."
  },
  {
    "objectID": "a04_summation_notation.html#doppia-sommatoria",
    "href": "a04_summation_notation.html#doppia-sommatoria",
    "title": "Appendix D — Simbolo di somma (sommatorie)",
    "section": "\nD.2 Doppia sommatoria",
    "text": "D.2 Doppia sommatoria\nÈ possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]\nLa doppia sommatoria comporta che per ogni valore dell’indice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\n\\[\n\\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]\nUn caso particolare interessante di doppia sommatoria è il seguente:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]\nSi può osservare che nella sommatoria interna (quella che dipende dall’indice \\(j\\)), la quantità \\(x_i\\) è costante, ovvero non dipende dall’indice (che è \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall’operatore di sommatoria interna e scrivere\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo si può osservare che nell’argomento della sommatoria esterna la quantità costituita dalla sommatoria in \\(j\\) non dipende dall’indice \\(i\\) e quindi questa quantità può essere estratta dalla sommatoria esterna. Si ottiene quindi\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n} x_i \\sum_{j=1}^{n} y_j.\n\\]\n\nSi verifichi quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto così ottenuto sia uguale al prodotto delle due sommatorie.\n\\[\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\\]\novvero\n[ (2 + 3 + 1) (1+4+9) = 84. ]"
  },
  {
    "objectID": "a04_summation_notation.html#sommatorie-e-produttorie-e-operazioni-vettoriali-in-r",
    "href": "a04_summation_notation.html#sommatorie-e-produttorie-e-operazioni-vettoriali-in-r",
    "title": "Appendix D — Simbolo di somma (sommatorie)",
    "section": "\nD.3 Sommatorie (e produttorie) e operazioni vettoriali in R\n",
    "text": "D.3 Sommatorie (e produttorie) e operazioni vettoriali in R\n\nSi noti che la notazione\n\\[\n\\sum_{n=0}^4 3n\n\\]\nnon è altro che un ciclo for:\n\nsum <- 0\nfor (n in 0:4) {\n  sum = sum + 3 * n\n}\nsum\n\n[1] 30\n\n\nIn maniera equivalente, e più semplice, possiamo scrivere\n\nsum(3 * (0:4))\n\n[1] 30\n\n\nAllo stesso modo, la notazione\n\\[\n\\prod_{n=1}^{4} 2n\n\\] è anch’essa equivalente al ciclo for\n\nprod <- 1\nfor (n in 1:4) {\n  prod <- prod * 2 * n\n}\nprod\n\n[1] 384\n\n\nche si può scrivere, più semplicemente, come\n\nprod(2 * (1:4))\n\n[1] 384\n\n\nIn entrambi i casi precedenti, abbiamo sostituito le operazioni aritmetiche eseguite all’interno di un ciclo for con le stesse operazioni aritmetiche eseguite sui vettori elemento per elemento."
  },
  {
    "objectID": "a05_calculus_notation.html",
    "href": "a05_calculus_notation.html",
    "title": "Appendix E — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Fornisco qui la traduzione (ottenuta con Google Translate, con piccole modifiche) del primo capitolo di Calculus made easy.\nIl terrore preliminare, che impedisce alla maggior parte dei ragazzi di quinta anche solo di tentare di imparare l’analisi, può essere abolito una volta per tutte semplicemente affermando qual è il significato – in termini di buon senso – dei due simboli principali che sono usati nell’analisi matematica.\nQuesti terribili simboli sono:\n\n\\(d\\) che significa semplicemente “un po’ di”.\n\nQuindi \\(\\operatorname{d}\\!x\\) significa un po’ di \\(x\\); o \\(\\operatorname{d}\\!u\\) significa un po’ di \\(u\\). I matematici pensano che sia più educato dire “un elemento di” invece di “un po’ di”. Fai come ti pare. Ma scoprirai che questi piccoli pezzi (o elementi) possono essere considerati indefinitamente piccoli.\n\n\\(\\int\\) che è semplicemente una S allungata, e può essere chiamata (se volete) “la somma di”.\n\nQuindi \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i pezzettini di \\(x\\); oppure \\(\\int \\operatorname{d}\\!t\\) significa la somma di tutti i pezzettini di \\(t\\). I matematici chiamano questo simbolo “l’integrale di”. Ora qualsiasi sciocco può vedere che se \\(x\\) è considerato come composto da tanti piccoli pezzetti, ognuno dei quali è chiamato \\(\\operatorname{d}\\!x\\), se li sommi tutti insieme ottieni la somma di tutti i \\(\\operatorname{d}\\!x\\), (che è la stessa cosa dell’insieme di \\(x\\)). La parola “integrale” significa semplicemente “il tutto”. Se pensi alla durata di un’ora, puoi (se vuoi) pensarla come suddivisa in 3600 piccoli pezzetti chiamati secondi. L’insieme dei 3600 pezzetti sommati fa un’ora.\nQuando vedrete un’espressione che inizia con questo simbolo terrificante, d’ora in poi saprete che è stato messo lì semplicemente per darvi l’istruzione che ora dovete eseguire (se potete) l’operazione di sommare tutti i piccoli pezzetti che sono indicati dai simboli che seguono.\nÈ tutto."
  },
  {
    "objectID": "a10_markov_chains.html#simulare-una-catena-di-markov",
    "href": "a10_markov_chains.html#simulare-una-catena-di-markov",
    "title": "Appendix F — Le catene di Markov",
    "section": "\nF.1 Simulare una catena di Markov",
    "text": "F.1 Simulare una catena di Markov\nUn metodo per dimostrare l’esistenza della distribuzione stazionaria di una catena di Markov è quello di eseguire un esperimento di simulazione. Iniziamo una passeggiata casuale partendo da un particolare stato, diciamo la posizione 3, e quindi simuliamo molti passaggi della catena di Markov usando la matrice di transizione \\(P\\). Al crescere del numero di passi della catena, le frequenze relative che descrivono il passaggio a ciascuno dei sei possibili nodi della catena approssimano sempre meglio la distribuzione stazionaria \\(w\\).\nSenza entrare nei dettagli della simulazione, la Figura F.1 mostra i risultati ottenuti in 10,000 passi di una passeggiata casuale markoviana. Si noti che, all’aumentare del numero di iterazioni, le frequenze relative approssimano sempre meglio le probabilità nella distribuzione stazionaria \\(w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1)\\).\n\nset.seed(123)\ns <- vector(\"numeric\", 10000)\ns[1] <- 3\nfor (j in 2:10000) {\n  s[j] <- sample(1:6, size = 1, prob = P[s[j - 1], ])\n}\nS <- data.frame(\n  Iterazione = 1:10000,\n  Location = s\n)\n\nS %>%\n  mutate(\n    L1 = (Location == 1),\n    L2 = (Location == 2),\n    L3 = (Location == 3),\n    L4 = (Location == 4),\n    L5 = (Location == 5),\n    L6 = (Location == 6)\n  ) %>%\n  mutate(\n    Proporzione_1 = cumsum(L1) / Iterazione,\n    Proporzione_2 = cumsum(L2) / Iterazione,\n    Proporzione_3 = cumsum(L3) / Iterazione,\n    Proporzione_4 = cumsum(L4) / Iterazione,\n    Proporzione_5 = cumsum(L5) / Iterazione,\n    Proporzione_6 = cumsum(L6) / Iterazione\n  ) %>%\n  dplyr::select(\n    Iterazione, Proporzione_1, Proporzione_2, Proporzione_3,\n    Proporzione_4, Proporzione_5, Proporzione_6\n  ) -> S1\n\ngather(S1, Outcome, Probability, -Iterazione) -> S2\n\nggplot(S2, aes(Iterazione, Probability)) +\n  geom_line() +\n  facet_wrap(~Outcome, ncol = 3) +\n  ylim(0, .4) +\n  ylab(\"Frequenza relativa\") +\n  # theme(text=element_text(size=14))  +\n  scale_x_continuous(breaks = c(0, 3000, 6000, 9000))\n\n\n\nFigura F.1: Frequenze relative degli stati da 1 a 6 in funzione del numero di iterazioni per la simulazione di una catena di Markov.\n\n\n\n\nIl metodo di campionamento utilizzato dagli algoritmi MCMC consente di creare una catena di Markov irriducibile e aperiodica, la cui distribuzione stazionaria equivale alla distribuzione a posteriori \\(p(\\theta \\mid y)\\)."
  },
  {
    "objectID": "a15_stan_lang.html#interfacce-e-pacchetti",
    "href": "a15_stan_lang.html#interfacce-e-pacchetti",
    "title": "Appendix G — Programmare in Stan",
    "section": "\nG.1 Interfacce e pacchetti",
    "text": "G.1 Interfacce e pacchetti\nÈ possibile accedere al linguaggio Stan tramite diverse interfacce:\n\n\nCmdStan - eseguibile da riga di comando,\n\nRStan - integrazione con il linguaggio \\(\\mathsf{R}\\);\n\nPyStan - integrazione con il linguaggio di programmazione Python;\n\nMatlabStan - integrazione con MATLAB;\n\nStan.jl - integrazione con il linguaggio di programmazione Julia;\n\nStataStan - integrazione con Stata.\n\nInoltre, vengono fornite interfacce di livello superiore con i pacchetti che utilizzano Stan come backend, principalmente in Linguaggio \\(\\mathsf{R}\\):\n\n\nshinystan - interfaccia grafica interattiva per l’analisi della distribuzione a posteriori e le diagnostiche MCMC;\n\nbayesplot - insieme di funzioni utilizzabili per creare grafici relativi all’analisi della distribuzione a posteriori, ai test del modello e alle diagnostiche MCMC;\n\nbrms - fornisce un’ampia gamma di modelli lineari e non lineari specificando i modelli statistici mediante la sintassi usata in \\(\\mathsf{R}\\);\n\nrstanarm - fornisce un sostituto per i modelli frequentisti forniti da base \\(\\mathsf{R}\\) e lme4 utilizzando la sintassi usata in \\(\\mathsf{R}\\) per la specificazione dei modelli statistici;\n\nedstan - modelli Stan per la Item Response Theory;\n\ncmdstanr - un’interfaccia \\(\\mathsf{R}\\) per CmdStan."
  },
  {
    "objectID": "a15_stan_lang.html#interfaccia-cmdstanr",
    "href": "a15_stan_lang.html#interfaccia-cmdstanr",
    "title": "Appendix G — Programmare in Stan",
    "section": "\nG.2 Interfaccia cmdstanr\n",
    "text": "G.2 Interfaccia cmdstanr\n\nNegli esempi di questa dispensa verrà usata l’interfaccia cmdstanr. Il pacchetto cmdstanr non è ancora disponibile su CRAN, ma può essere installato come indicato su questo link. Una volta che è stato installato, il pacchetto cmdstanr può essere caricato come un qualsiasi altro pacchetto \\(\\mathsf{R}\\).\nSi noti che cmdstanr richiede un’installazione funzionante di CmdStan, l’interfaccia shell per Stan. Se CmdStan non è installato, cmdstanr lo installerà automaticamente se il computer dispone di una Toolchain adatta. Stan richiede infatti che sul computer su cui viene installato siano presenti alcuni strumenti necessari per gestire i file C++. Tra le altre ragioni, questo è dovuto al fatto che il codice Stan viene tradotto in codice C++ e compilato. Il modo migliore per ottenere il software necessario per un computer Windows è quello di installare RTools. Per un computer Linux, è necessario installare build-essential e una versione recente dei compilatori g++ o clang++. Per un Mac è necessario disporre di Xcode Command Line Tools. Se non sono già installati, per installarli, digitare nel Terminal (NON nella console di RStudio):\n\nxcode-select --install\n\nI requisiti sono descritti nella Guida di CmdStan.\nPer verificare che la Toolchain sia configurata correttamente è possibile utilizzare la funzione check_cmdstan_toolchain().\n\ncheck_cmdstan_toolchain()\n\nSe la toolchain è configurata correttamente, CmdStan può essere installato mediante la funzione install_cmdstan().\n\ninstall_cmdstan(cores = 2)\n\nLa versione installata di CmdStan si ottiene con cmdstan_version().\n\ncmdstan_version()\n#> [1] \"2.31.0\""
  },
  {
    "objectID": "a15_stan_lang.html#codice-stan",
    "href": "a15_stan_lang.html#codice-stan",
    "title": "Appendix G — Programmare in Stan",
    "section": "\nG.3 Codice Stan",
    "text": "G.3 Codice Stan\nQualunque sia l’interfaccia che viene usata, i modelli sottostanti sono sempre scritti nel linguaggio Stan, il che significa che lo stesso codice Stan è valido per tutte le interfacce possibili. Il codice Stan è costituito da una serie di blocchi che vengono usati per specificare un modello statistico. In ordine, questi blocchi sono: data, transformed data, parameters, transformed parameters, model, e generated quantities.\n\nG.3.1 “Hello, world” – Stan\nQuando si studia un nuovo linguaggio di programmazione si utilizza spesso un programma “Hello, world”. Questo è un modo semplice, spesso minimo, per dimostrare alcune delle sintassi di base del linguaggio. Qui presentiamo Stan e scriviamo un programma “Hello, world” per Stan.\nPrima di scrivere il nostro primo programma “Hello, world” per Stan (che estrarrà campioni dalla distribuzione a posteriori di un modello gaussiano) spendiamo due parole per spiegare cosa fa Stan. Un utente scrive un modello usando il linguaggio Stan. Questo è solitamente memorizzato in un file di testo .stan. Il modello viene compilato in due passaggi. Innanzitutto, Stan traduce il modello nel file .stan in codice C++. Quindi, quel codice C++ viene compilato in codice macchina. Una volta creato il codice macchina, l’utente può, tramite l’interfaccia CmdStan, campionare la distribuzione definita dal modello ed eseguire altri calcoli con il modello. I risultati del campionamento vengono scritti su disco come file CSV e txt. Come mostrato di seguito, l’utente accede a questi file utilizzando varie funzioni \\(\\mathsf{R}\\), senza interagire direttamente con loro.\nPer iniziare, possiamo dire che un programma Stan contiene tre “blocchi” obbligatori: blocco data, blocco parameters, blocco model.\n\nG.3.2 Blocco data\n\nQui vengono dichiarate le variabili che saranno passate a Stan. Devono essere elencati i nomi delle variabili che saranno utilizzate nel programma, il tipo di dati da registrare per ciascuna variabile, per esempio:\n\n\nint = intero,\n\nreal = numeri reali (ovvero, numeri con cifre decimali),\n\nvector = sequenze ordinate di numeri reali unidimensionali,\n\nmatrix = matrici bidimensionali di numeri reali,\n\narray = sequenze ordinate di dati multidimensionali.\n\nDevono anche essere dichiarate le dimensioni delle variabili e le eventuali restrizioni sulle variabili (es. upper = 1 lower = 0, che fungono da controlli per Stan). Tutti i nomi delle variabili assegnate qui saranno anche usati negli altri blocchi del programma. Per esempio, l’istruzione seguente dichiaria la variabile Y – la quale rappresenta, ad esempio, l’altezza di 10 persone – come una variabile di tipo real. Ciò significa che specifichiamo un array di lunghezza 10, i cui elementi sono variabili continue definite sull’intervallo dei numeri reali \\([-\\infty, +\\infty]\\).\n\ndata {\n  array[10] real Y; // heights for 10 people\n}\n\nInvece, con l’istruzione seguente dichiariamo la variabile Y – la quale rappresenta, ad esempio, il QI di 10 persone – come una variabile di tipo int, ovvero un array di lunghezza 10, i cui elementi sono numeri naturali, cioè numeri interi non negativi \\(\\{0, +1, +2, +3, +4, \\dots\\}\\).\n\ndata {\n  array[10] int Y; // qi for 10 people\n}\n\nUn altro esempio è il seguente, dove viene specificato un array di lunghezza 10, i cui elementi sono delle variabili continue definite sull’intervallo dei numeri reali \\([0, 1]\\) — per esempio, delle proporzioni.\n\ndata {\n  array[10] real<lower=0, upper=1> Y; // 10 proportions\n}\n\nSi noti che i tipi vector e matrix contengono solo elementi di tipo real, ovvero variabili continue, mentre gli array possono contenere dati di qualsiasi tipo. I dati passati a Stan devono essere contenuti in un oggetto del tipo list.\n\nG.3.3 Blocco parameters\n\nI parametri che vengono stimati sono dichiarati nel blocco parameters. Per esempio, l’istruzione seguente dichiara la variabile mu che codifica l’altezza media nella popolazione, che è una variabile continua in un intervallo illimitato di valori, e la deviazione standard sigma, che è una variabile continua non negativa. Avremmo anche potuto specificare un limite inferiore di zero su mu perché deve essere non negativo.\n\nparameters {\n  real mu; // mean height in population\n  real<lower=0> sigma; // sd of height distribution\n}\n\nPer una regressione lineare semplice, ad esempio, devono essere dichiarate le variabili corrispondenti all’intercetta (alpha), alla pendenza (beta) e alla deviazione standard degli errori attorno alla linea di regressione (sigma). In altri termini, nel blocco parameters devono essere elencati tutti i parametri che dovranno essere stimati dal modello. Si noti che parametri discreti non sono possibili. Infatti, Stan attualmente non supporta i parametri con valori interi, almeno non direttamente.\n\nG.3.4 Blocco model\n\nNel blocco model vengono elencate le dichiarazioni relative alla verosimiglianza dei dati e alle distribuzioni a priori dei parametri, come ad esempio, nelle istruzioni seguenti.\n\nmodel {\n  for(i in 1:10) {\n    Y[i] ~ normal(mu, sigma);\n  }\n  mu ~ normal(170, 15); // prior for mu\n  sigma ~ cauchy(0, 20); // prior for sigma\n}\n\nMediante l’istruzione all’interno del ciclo for, ciascun valore dell’altezza viene concepito come una variable casuale proveniente da una distribuzione Normale di parametri \\(\\mu\\) e \\(\\sigma\\) (i parametri di interesse nell’inferenza). Il ciclo for viene ripetuto 10 volte perché i dati sono costituiti da un array di 10 elementi (ovvero, il campione è costituito da 10 osservazioni).\nLe due righe che seguno il ciclo for specificano le distribuzioni a priori dei parametri su cui vogliamo effettuare l’inferenza. Per \\(\\mu\\) assumiamo una distribuzione a priori Normale di parametri \\(\\mu = 170\\) e \\(\\sigma = 15\\); per \\(\\sigma\\) assumiamo una distribuzione a priori Cauchy(0, 20).\nSe non viene definita alcuna distribuzione a priori, Stan utilizzerà la distribuzione a priori predefinita \\(Unif(-\\infty, +\\infty)\\). Raccomandazioni sulle distribuzioni a priori sono fornite in questo link.\nLa precedente notazione di campionamento può anche essere espressa usando la seguente notazione alternativa.\n\n  for(i in 1:10) {\n    target += normal_lpdf(Y[i] | mu, sigma);\n  }\n\nQuesta notazione rende trasparente il fatto che, in pratica, Stan esegue un campionamento nello spazio della log-verosimiglianza.\n\\[\n\\log p(\\theta \\mid y) \\propto \\log p(y \\mid \\theta) + \\log p(\\theta) = \\sum_{i=1}^n \\log p(y_i \\mid \\theta) + \\log p(\\theta).\n\\]\nPer ogni passo MCMC, viene ottenuto un nuovo valore di \\(\\mu\\) e \\(\\sigma\\) eviene valutata la log densità a posteriori non normalizzata. Ad ogni passo MCMC, Stan calcola un nuovo valore della densità a posteriori su scala logaritmica partendo da un valore di 0 e incrementandola ogni volta che incontra un’istruzione ~. Quindi, le istruzioni precedenti aumentano la log-densità di una quantità pari a \\(\\log (p(Y[i])) \\propto -\\frac{1}{2} \\log(\\sigma^2) - (Y[i]-\\mu)^2 / 2\\sigma^2\\) per le altezze si ciascuno degli \\(i=1 \\dots, 10\\) individui – laddove la formula esprime, in termini logaritmici, la densità Normale da cui sono stati esclusi i termini costanti.\nOppure, in termini vettorializzati, il modello descritto sopra può essere espresso come segue.\n\nmodel {\n  Y ~ normal(mu, sigma);\n}\n\ndove il termine a sinistra di \\(\\sim\\) è un array. Questa notazione più compatta è anche la più efficiente.\n\nG.3.5 Blocchi opzionali\nCi sono inoltre tre blocchi opzionali:\n\nIl blocco transformed data consente il pre-processing dei dati. È possibile trasformare i parametri del modello; solitamente ciò viene fatto nel caso dei modelli più avanzati per consentire un campionamento MCMC più efficiente.\nIl blocco transformed parameters consente la manipolazione dei parametri prima del calcolo della distribuzione a posteriori.\nIl blocco generated quantities consente il post-processing riguardante qualsiasi quantità che non fa parte del modello ma può essere calcolata a partire dai parametri del modello, per ogni iterazione dell’algoritmo. Esempi includono la generazione dei campioni a posteriori e le dimensioni degli effetti.\n\nG.3.6 Sintassi\nSi noti che il codice Stan richiede i punti e virgola (;) alla fine di ogni istruzione di assegnazione. Questo accade per le dichiarazioni dei dati, per le dichiarazioni dei parametri e ovunque si acceda ad un elemento di un tipo data e lo si assegni a qualcos’altro. I punti e virgola non sono invece richiesti all’inizio di un ciclo o di un’istruzione condizionale, dove non viene assegnato nulla.\nIn STAN, qualsiasi stringa che segue // denota un commento e viene ignorata dal programma.\nStan è un linguaggio estremamente potente e consente di implementare quasi tutti i modelli statistici, ma al prezzo di un certo sforzo di programmazione. Anche l’adattamento di semplici modelli statistici mediante il linguaggio STAN a volte può essere laborioso. Per molti modelli comunemente usati, come i modelli di regressione e multilivello, tale processo può essere semplificato usando le funzioni del pacchetto brms. D’altra parte, per modelli veramente complessi, non ci sono molte alternative all’uso di STAN. Per chi è curioso, il manuale del linguaggio Stan è accessibile al seguente link."
  },
  {
    "objectID": "a15_stan_lang.html#workflow",
    "href": "a15_stan_lang.html#workflow",
    "title": "Appendix G — Programmare in Stan",
    "section": "\nG.4 Workflow",
    "text": "G.4 Workflow\nSe usiamo cmdstanr, dobbiamo prima scrivere il codice con il modello statistico in un file in formato Stan. È necessario poi “transpile” quel file, ovvero tradurre il file in C++ e compilarlo. Ciò viene fatto mediante la funzione cmdstan_model(). Possiamo poi eseguire il campionamento MCMC con il metodo $sample(). Infine è possibile creare un sommario dei risultati usando, per esempio, usando il metodo $summary()."
  },
  {
    "objectID": "a15_stan_lang.html#ciao-stan",
    "href": "a15_stan_lang.html#ciao-stan",
    "title": "Appendix G — Programmare in Stan",
    "section": "\nG.5 Ciao, Stan",
    "text": "G.5 Ciao, Stan\nScriviamo ora il nostro programma Stan “Hello, world” per generare campioni da una distribuzione Normale standard (con media zero e varianza unitaria).\n\nmodelString = \"\nparameters {\n  real x;\n}\nmodel {\n  x ~ normal(0, 1);\n}\n\"\nwriteLines(modelString, con = \"code/hello_world.stan\")\n\nSi noti che ci sono solo due blocchi in questo particolare codice Stan, il blocco parametri e il blocco modello. Questi sono due dei sette blocchi possibili in un codice Stan. Nel blocco parametri, abbiamo i nomi e i tipi di parametri per i quali vogliamo ottenere i campioni. In questo caso, vogliamo ottenere campioni di numeri reale che chiamiamo x. Nel blocco modello, abbiamo il nostro modello statistico. Specifichiamo che x, il parametro di cui vogliamo ottenere i campioni, è normalmente distribuito con media zero e deviazione standard unitaria. Ora che abbiamo il nostro codice (che è stato memorizzato in un file chiamato hello_world.stan), possiamo usare CmdStan per compilarlo e ottenere mod, che è un oggetto \\(\\mathsf{R}\\) che fornisce l’accesso all’eseguibile Stan compilato.\nLeggiamo il file in cui abbiamo salvato il codice Stan.\n\nfile <- file.path(\"code\", \"hello_world.stan\")\n\nCompiliamo il modello.\n\nmod <- cmdstan_model(file)\n\nEseguiamo il campionamento MCMC.\n\nfit <- mod$sample(\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0,\n  thin = 1\n)\n\nTasformiamo l’oggetto fit nel formato stanfit per manipolarlo più facilmente.\n\nstanfit <- rstan::read_stan_csv(fit$output_files())\n\nEsaminiamo l’oggetto stanfit.\n\nlength(stanfit@sim$samples)\n#> [1] 4\n\nQuello che abbiamo ottenuto sono 4 catene di 4000 osservazioni ciascuna, le quali contengono valori casuali estratti dalla gaussiana standardizzata.\n\nhead(stanfit@sim$samples[[1]])\n\nVerifichiamo.\n\nhist(stanfit@sim$samples[[1]][, 1])"
  },
  {
    "objectID": "023_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "023_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "14  Distribuzioni di v.c. continue",
    "section": "\n14.6 Funzione beta di Eulero",
    "text": "14.6 Funzione beta di Eulero\nLa funzione beta di Eulero è una funzione matematica, non una densità di probabilità. La menzioniamo qui perché viene utilizzata nella distribuzione Beta. La funzione beta di Eulero si può scrivere in molti modi diversi; per i nostri scopi la presentiamo così:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{14.4}\\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, ovvero il fattoriale discendente, cioè\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\n\nEsercizio 14.3 Per esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione beta assume il valore\n\nimport scipy.special as sc\n\nalpha = 3\nbeta = 9\nsc.beta(alpha, beta)\n#> 0.00202020202020202\n\nLo stesso risultato si ottiene con\n\n((2) * (8 * 7 * 6 * 5 * 4 * 3 * 2)) / (11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2)\n#> 0.00202020202020202\n\novvero\n\nalpha = 3\nbeta = 9\nsc.gamma(alpha) * sc.gamma(beta) / sc.gamma(alpha + beta)\n#> 0.00202020202020202"
  },
  {
    "objectID": "036_posterior_sim.html#lalgoritmo-di-metropolis",
    "href": "036_posterior_sim.html#lalgoritmo-di-metropolis",
    "title": "20  Approssimazione della distribuzione a posteriori",
    "section": "\n20.3 L’algoritmo di Metropolis",
    "text": "20.3 L’algoritmo di Metropolis\nL’algoritmo di Metropolis et al. (1953)4 produce una sequenza di valori (chiamata “catena di Markov”) nella quale ciascun valore successivo della catena viene trovato utilizzando solamente le informazioni fornite dal valore precedente della catena. Ad ogni passo della catena, sulla base delle informazioni fornite dal valore corrente, selezioniamo un valore “candidato”. In base ad una certa regola, decidiamo poi se accettare il valore candidato, e muovere la catena al nuovo valore, oppure se rifiutarlo, ripetendo, nel passo successivo della catena, il valore corrente. Ci fermiamo dopo una serie predefinita di passi.\nNell’algoritmo di Metropolis possiamo distinguere le seguenti fasi.\n\nSi inizia con un punto arbitrario \\(\\theta^{(1)}\\); quindi il primo valore \\(\\theta^{(1)}\\) della catena di Markov può corrispondere semplicemente ad un valore a caso tra i valori possibili del parametro.\n\n\nPer ogni passo successivo della catena, \\(m + 1\\), si estrae un valore candidato \\(\\theta'\\) da una distribuzione proposta: \\(\\theta' \\sim \\Pi(\\theta)\\). La distribuzione proposta può essere qualunque distribuzione, anche se, idealmente, è meglio che sia simile alla distribuzione a posteriori. In pratica, però, la distribuzione a posteriori è sconosciuta e quindi il valore \\(\\theta'\\) viene estratto a caso da una qualche distribuzione simmetrica centrata sul valore corrente \\(\\theta^{(m)}\\) del parametro. Nell’esempio presente useremo la gaussiana quale distribuzione proposta. La distribuzione proposta gaussiana sarà centrata sul valore corrente della catena e avrà una deviazione standard appropriata: \\(\\theta' \\sim \\mathcal{N}(\\theta^{(m)}, \\sigma)\\). In pratica, questo significa che, se \\(\\sigma\\) è piccola, il valore candidato \\(\\theta'\\) sarà simile al valore corrente \\(\\theta^{(m)}\\).\nSi calcola il rapporto \\(r\\) tra la densità della distribuzione a posteriori non normalizzata calcolata nel punto \\(\\theta'\\) e nel punto \\(\\theta^{(m)}\\). Si noti che, essendo un rapporto, l’Equazione 20.1 cancella la costante di normalizzazione. Al numeratore dell’Equazione 20.1 abbiamo solo il prodotto tra la verosimiglianza \\(p(y \\mid \\theta')\\) e la densità a priori di \\(\\theta\\), entrambe calcolate nel punto \\(\\theta'\\); il denominatore contiene invece il prodotto tra la verosimiglianza \\(p(y \\mid \\theta^{(m)})\\) e la densità a priori di \\(\\theta\\), entrambe calcolate nel punto \\(\\theta^{(m)}\\).\n\n\\[\nr = \\frac{p(y \\mid \\theta') p(\\theta')}{p(y \\mid \\theta^{(m)}) p(\\theta^{(m)})}.\n\\tag{20.1}\\]\n\nSi decide se accettare il candidato \\(\\theta'\\) oppure se rigettarlo e estrarre un nuovo valore dalla distribuzione proposta. Possiamo pensare al rapporto \\(r\\) come alla risposta alla seguente domanda: alla luce dei dati, quale stima di \\(\\theta\\) è più credibile, il valore candidato o il valore corrente? Se \\(r\\) è maggiore di 1, ciò significa che il candidato è più credibile del valore corrente; dunque se \\(r\\) è maggiore di 1 il candidato viene sempre accettato. Altrimenti, si decide di accettare il candidato con una probabilità minore di 1, ovvero non sempre, ma soltanto con una probabilità uguale ad \\(r\\). Se \\(r\\) è uguale a 0.10, ad esempio, questo significa che la credibilità a posteriori del valore candidato è 10 volte più piccola della credibilità a posteriori del valore corrente. Dunque, il valore candidato verrà accettato solo nel 10% dei casi. Come conseguenza di questa strategia di scelta, l’algoritmo di Metropolis ottiene un campione casuale dalla distribuzione a posteriori, dato che la probabilità di accettare il valore candidato sarà proporzionale alla densità del candidato nella distribuzione a posteriori. Dal punto di vista algoritmico, la procedura descritta sopra viene implementata confrontando il rapporto \\(r\\) con un valore estratto a caso da una distribuzione uniforme \\(\\mbox{Unif}(0, 1)\\). Se \\(r > u \\sim \\mbox{Unif}(0, 1)\\), allora il candidato \\(\\theta'\\) viene accettato e la catena si muove in quella nuova posizione, ovvero \\(\\theta^{(m+1)} = \\theta'\\). Altrimenti \\(\\theta^{(m+1)} = \\theta^{(m)}\\) e si estrae un nuovo candidato dalla distribuzione proposta.\nIl passaggio finale dell’algoritmo calcola l’accettanza in una specifica esecuzione dell’algoritmo, ovvero la proporzione di candidati \\(\\theta'\\) che sono stati accettati quali valori successivi della catena.\n\nL’algoritmo di Metropolis prende come input il numero \\(T\\) di passi da simulare, la deviazione standard \\(\\sigma\\) della distribuzione proposta e la densità a priori, e ritorna come output la sequenza \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\). La chiave del successo dell’algoritmo di Metropolis è il numero di passi fino a che la catena approssima la stazionarietà. Tipicamente i primi da 1000 a 5000 elementi sono scartati. Dopo un certo periodo \\(k\\) (detto di burn-in), la catena di Markov converge ad una variabile casuale che è distribuita secondo la distribuzione a posteriori (stazionarietà). In altre parole, i campioni del vettore \\(\\left(\\theta^{(k+1)}, \\theta^{(k+2)}, \\dots, \\theta^{(T)}\\right)\\) diventano campioni di \\(p(\\theta \\mid y)\\).\n\n20.3.1 Un’applicazione empirica\nUsiamo ora l’algoritmo di Metropolis per trovare la distribuzione a posteriori di \\(\\theta\\) per i dati di Zetsche et al. (2019) (23 successi in 30 prove Bernoulliane), imponendo su \\(\\theta\\) una \\(\\mbox{Beta}(2, 10)\\).\nL’algoritmo di Metropolis richiede l’uso delle seguenti funzioni.\nVerosimiglianza. Usiamo una funzione di verosimiglianza binomiale.\n\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom scipy.stats import binom\nfrom scipy.stats import beta\n\nnp.random.seed(2023)\n\ndef get_likelihood(p):\n    k = 23\n    n = 30\n    return binom.pmf(k, n, p)\n\nDistribuzione a priori. La distribuzione a priori è una \\(\\mbox{Beta}(2, 10)\\).\n\ndef get_prior(p):\n    a = 2\n    b = 10\n    return beta.pdf(p, a, b)\n\nDistribuzione a posteriori. La distribuzione a posteriori è data dal prodotto della distribuzione a priori e della verosimiglianza.\n\ndef get_posterior(p):\n    return get_likelihood(p) * get_prior(p)\n\nDistribuzione proposta. Per implementare l’algoritmo di Metropolis utilizzeremo una distribuzione proposta gaussiana. Il valore candidato sarà dunque un valore selezionato a caso da una gaussiana di parametri \\(\\mu\\) uguale al valore corrente nella catena e \\(\\sigma = 0.9\\). In questo esempio, la deviazione standard \\(\\sigma\\) è stata scelta empiricamente in modo tale da ottenere una accettanza adeguata. L’accettanza ottimale è pari a circa 0.20/0.30 — se l’accettanza è troppo grande, l’algoritmo esplora uno spazio troppo ristretto della distribuzione a posteriori.5 Ho anche inserito un controllo che impone al valore candidato di essere incluso nell’intervallo [0, 1], com’è necessario per il valore di una proporzione.6\n\ndef get_proposal(p_current, proposal_width):\n    while 1:\n        proposal = norm(p_current, proposal_width).rvs()\n        if (proposal > 0 and proposal < 1):\n            break\n    return proposal\n\nL’algoritmo di Metropolis viene implementato nella funzione seguente.\n\ndef sampler(samples=100, p_init=.5, proposal_width=.1):\n    p_current = p_init\n    posterior = [p_current]\n    acceptance = 0\n    for i in range(samples):\n        # Suggest new position\n        proposal = get_proposal(p_current, proposal_width)\n        # Accept proposal?\n        p_accept = get_posterior(proposal) / get_posterior(p_current)\n        accept = np.random.rand() < p_accept\n        if accept:\n            # Update position\n            p_current = proposal\n            acceptance = acceptance +1\n        posterior.append(p_current)\n    return acceptance/samples, np.array(posterior)\n\nMediante la funzione sampler(), genero una sequenza (catena) di valori \\(\\theta\\).\n\nacceptance, posterior = sampler(samples=5000, p_init=.5, proposal_width=.9)\n\nIn questo modo, ottengo una catena di Markov costituita da 5,000 valori.\nEsamino l’accettanza.\n\nacceptance\n#> 0.262\n\nIl valore trovato conferma la bontà della deviazione standard (\\(\\sigma\\) = 0.9) scelta per la distribuzione proposta.\nEscludo i primi 1000 valori considerati come burn-in. Considero i restanti 4,000 valori come un campione casuale estratto dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\nMediante i valori della catena così ottenuta è facile trovare una stima a posteriori del parametro \\(\\theta\\). Per esempio, posso trovare la stima della media a posteriori.\n\nnp.mean(posterior[1001:5000])\n#> 0.5988609691101876\n\nOppure posso calcolare la deviazione standard dell’approssimazione numerica della distribuzione a posteriori.\n\nnp.std(posterior[1001:5000])\n#> 0.07349823170010146\n\nLa Figura 20.1 mostra un trace plot dei valori della catena di Markov.\n\nfig, ax = plt.subplots()\nax.plot(posterior)\n_ = ax.set(xlabel='sample', ylabel='theta');\n\n\n\nFigura 20.1: Trace plot dei valori della catena di Markov escludendo il periodo di burn-in.\n\n\n\n\nNella Figura 20.2, l’istogramma descrive i valori \\(\\theta\\) prodotti dall’algoritmo di Metropolis mentre la linea continua descrive la distribuzione a posteriori ottenuta per via analitica, ovvero una \\(\\mbox{Beta}(25, 17)\\). La figura indica che la catena converge alla corretta distribuzione a posteriori.\n\nplt.hist(posterior, label='estimated posterior', density= True)\n\na = 25\nb = 17\nx = np.linspace(stats.beta.ppf(0.01, a, b),\n                stats.beta.ppf(0.99, a, b), 1000)\nplt.plot(x, stats.beta.pdf(x, a, b),\n       'r--', lw=3, alpha=0.75, label='Beta(25, 17)')\n\n\n\nFigura 20.2: Stima della distribuzione a posteriori della probabilità di una aspettativa futura distorta negativamente per i dati di Zetsche et al. (2019)."
  }
]