<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Data Science per psicologi - 4&nbsp; Indici di posizione e di scala</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./012_correlation.html" rel="next">
<link href="./007_freq_distr.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/data_science/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Benvenuti</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">Prefazione</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./basics.html" class="sidebar-item-text sidebar-link">Parte 1: Nozioni di base</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_key_notions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Concetti chiave</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_measurement.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_freq_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_loc_scale.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_penguins.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Manipolazione e visualizzazione dei dati in <span class="math inline">\(\mathsf{R}\)</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./prob.html" class="sidebar-item-text sidebar-link">Parte 2: Il calcolo delle probabilità</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_prob_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">La logica dell’incerto</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_conditional_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Probabilità condizionata: significato, teoremi, eventi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_bayes_theorem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Il teorema di Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./018_expval_var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Indici di posizione, di varianza e di associazione di variabili casuali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./019_joint_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probabilità congiunta</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./020_density_func.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">La densità di probabilità</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./distr.html" class="sidebar-item-text sidebar-link">Parte 3: Distribuzioni di v.c. discrete e continue</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./022_discr_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./023_cont_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./024_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">La funzione di verosimiglianza</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./bayes_inference.html" class="sidebar-item-text sidebar-link">Parte 4: Inferenza bayesiana</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./025_intro_bayes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Credibilità, modelli e parametri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./026_subj_prop.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./029_conjugate_families.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./030_balance_prior_post.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./036_posterior_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Approssimazione della distribuzione a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./040_beta_binomial_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Il modello beta-binomiale in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./041_mcmc_diagnostics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./045_summarize_posterior.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./046_bayesian_prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./050_normal_normal_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./regression.html" class="sidebar-item-text sidebar-link">Parte 5: Regressione lineare</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./051_reglin1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./052_reglin2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Regressione lineare bivariata</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./053_reglin3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Modello di regressione in linguaggio Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./054_reglin4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Inferenza sul modello lineare</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./055_reglin5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi indipendenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./056_pred_check.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Predictive checks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./060_anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Confronto tra le medie di tre o più gruppi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./070_mod_hier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modello gerarchico</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./071_mod_hier_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Modello gerarchico: simulazioni</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./entropy.html" class="sidebar-item-text sidebar-link">Parte 6: Entropia</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./090_entropy.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Entropia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./091_kl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./092_info_criterion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Criterio di informazione e convalida incrociata</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./frequentist_inference.html" class="sidebar-item-text sidebar-link">Parte 7: Inferenza frequentista</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./220_intro_frequentist.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Legge dei grandi numeri</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./221_conf_interv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Intervallo fiduciale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./225_distr_camp_mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Distribuzione campionaria</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./226_test_ipotesi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Significatività statistica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./227_ttest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Inferenza sulle medie</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./228_limiti_stat_frequentista.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./999_refs.html" class="sidebar-item-text sidebar-link">Riferimenti bibliografici</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">Appendici</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a01_math_symbols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a02_number_sets.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a03_set_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Insiemi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a04_summation_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Simbolo di somma (sommatorie)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a05_calculus_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a10_markov_chains.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Le catene di Markov</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a15_stan_lang.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Programmare in Stan</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul>
<li>
<a href="#indici-di-tendenza-centrale" id="toc-indici-di-tendenza-centrale" class="nav-link active" data-scroll-target="#indici-di-tendenza-centrale"><span class="toc-section-number">4.1</span>  Indici di tendenza centrale</a>
  <ul class="collapse">
<li><a href="#media" id="toc-media" class="nav-link" data-scroll-target="#media"><span class="toc-section-number">4.1.1</span>  Media</a></li>
  <li><a href="#media-spuntata" id="toc-media-spuntata" class="nav-link" data-scroll-target="#media-spuntata"><span class="toc-section-number">4.1.2</span>  Media spuntata</a></li>
  <li><a href="#moda-e-mediana" id="toc-moda-e-mediana" class="nav-link" data-scroll-target="#moda-e-mediana"><span class="toc-section-number">4.1.3</span>  Moda e mediana</a></li>
  </ul>
</li>
  <li>
<a href="#indici-di-dispersione" id="toc-indici-di-dispersione" class="nav-link" data-scroll-target="#indici-di-dispersione"><span class="toc-section-number">4.2</span>  Indici di dispersione</a>
  <ul class="collapse">
<li><a href="#indici-basati-sullordinamento-dei-dati" id="toc-indici-basati-sullordinamento-dei-dati" class="nav-link" data-scroll-target="#indici-basati-sullordinamento-dei-dati"><span class="toc-section-number">4.2.1</span>  Indici basati sull’ordinamento dei dati</a></li>
  <li><a href="#varianza" id="toc-varianza" class="nav-link" data-scroll-target="#varianza"><span class="toc-section-number">4.2.2</span>  Varianza</a></li>
  <li><a href="#precisione" id="toc-precisione" class="nav-link" data-scroll-target="#precisione"><span class="toc-section-number">4.2.3</span>  Precisione</a></li>
  <li><a href="#deviazione-standard" id="toc-deviazione-standard" class="nav-link" data-scroll-target="#deviazione-standard"><span class="toc-section-number">4.2.4</span>  Deviazione standard</a></li>
  <li><a href="#deviazione-mediana-assoluta" id="toc-deviazione-mediana-assoluta" class="nav-link" data-scroll-target="#deviazione-mediana-assoluta"><span class="toc-section-number">4.2.5</span>  Deviazione mediana assoluta</a></li>
  <li><a href="#indici-di-variabilit%C3%A0-relativi" id="toc-indici-di-variabilità-relativi" class="nav-link" data-scroll-target="#indici-di-variabilit%C3%A0-relativi"><span class="toc-section-number">4.2.6</span>  Indici di variabilità relativi</a></li>
  </ul>
</li>
  <li><a href="#commenti-e-considerazioni-finali" id="toc-commenti-e-considerazioni-finali" class="nav-link" data-scroll-target="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-loc-scale" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Codice</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><p>L’analisi grafica esaminata in precedenza costituisce la base di partenza di qualsivoglia analisi quantitativa dei dati. Tramite opportune rappresentazioni grafiche possiamo individuare alcune caratteristiche importanti di una distribuzione: per esempio, è possibile capire se la distribuzione è simmetrica o asimmetrica; oppure se è unimodale o multimodale. Successivamente, è necessario calcolare degli indici numerici che descrivano in modo sintetico le caratteristiche di base dei dati. In questo capitolo verranno introdotti i principali indicatori della statistica descrittiva.</p>
<section id="indici-di-tendenza-centrale" class="level2" data-number="4.1"><h2 data-number="4.1" class="anchored" data-anchor-id="indici-di-tendenza-centrale">
<span class="header-section-number">4.1</span> Indici di tendenza centrale</h2>
<p>Tra le misure di tendenza centrale, ovvero tra gli indici che ci informano sui valori attorno ai quali sono prevalentemente concentrati i dati di un campione, quella più comunemente usata è la media.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pandas for managing datasets</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Matplotlib for additional customization</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Seaborn for plotting and styling</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Set theme</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>sns.set_palette(<span class="st">"colorblind"</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># cwd = os.getcwd()</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># print(cwd)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout-tip callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Per un’introduzione “soft” alla nozione di tendenza centrale di una distribuzione statistica si segua il <a href="https://tinystats.github.io/teacups-giraffes-and-statistics/03_mean.html">link</a>.</p>
</div>
</div>
</div>
<section id="media" class="level3" data-number="4.1.1"><h3 data-number="4.1.1" class="anchored" data-anchor-id="media">
<span class="header-section-number">4.1.1</span> Media</h3>
<p>Tutti conosciamo la media aritmetica di <span class="math inline">\(\{x_1, x_2, \dots, x_n\}\)</span>, ovvero il numero reale <span class="math inline">\(\bar{x}\)</span> definito da</p>
<p><span id="eq-mean"><span class="math display">\[
\begin{equation}
\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i.
\end{equation}
\tag{4.1}\]</span></span></p>
<div class="callout-tip callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Nella <a href="#eq-mean">Equazione&nbsp;<span>4.1</span></a> ho usato la notazione delle sommatorie per descrivere una somma di valori. Questa notazione è molto usata in statistica e viene descritta in Appendice.</p>
</div>
</div>
</div>
<p>La media gode della seguente importante proprietà: la somma degli scarti tra ciascuna modalità <span class="math inline">\(x_i\)</span> e la media aritmetica <span class="math inline">\(\bar{x}\)</span> è nulla, cioè</p>
<p><span id="eq-diffmeansumzero"><span class="math display">\[
\begin{equation}
\sum_{i=1}^n (x_i - \bar{x}) = 0.\notag
\end{equation}
\tag{4.2}\]</span></span></p>
<p>Infatti,</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^n (x_i - \bar{x}) &amp;= \sum_i x_i - \sum_i \bar{x}\notag\\
&amp;= \sum_i x_i - n \bar{x}\notag\\
&amp;= \sum_i x_i - \sum_i x_i = 0.\notag
\end{aligned}
\]</span></p>
<p>Ciò ci consente di pensare alla media come al baricentro della distribuzione.</p>
<p>Un’altra proprietà della media è la seguente. La somma dei quadrati degli scarti tra ciascuna modalità <span class="math inline">\(x_i\)</span> e una costante arbitraria <span class="math inline">\(a\)</span>, cioè</p>
<p><span id="eq-minsq"><span class="math display">\[
\begin{equation}
\varphi(a) = \sum_{i=1}^n (x_i - a)^2,\notag
\end{equation}
\tag{4.3}\]</span></span></p>
<p>è minima per <span class="math inline">\(a = \bar{x}\)</span>.</p>
<div class="callout-note callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Il concetto statistico di media ha suscitato molte battute. Per esempio, il fatto che, in media, ciascuno di noi ha un numero di gambe circa pari a 1.9999999. Oppure, il fatto che, in media, ciascuno di noi ha un testicolo. Ma la media ha altri problemi, oltre al fatto di ispirare battute simili alle precedenti. In particolare, dobbiamo notare che la media non è sempre l’indice che meglio rappresenta la tendenza centrale di una distribuzione. In particolare, ciò non accade quando la distribuzione è asimmetrica, o in presenza di valori anomali (<em>outlier</em>) – si veda il pannello di sinistra della <span class="quarto-unresolved-ref">?fig-raincloud</span>. In tali circostanze, la tendenza centrale della distribuzione è meglio rappresentata dalla mediana o dalla media spuntata (si veda più sotto).</p>
</div>
</div>
</div>
<div id="exr-mean" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 4.1 </strong></span>Si calcoli la media dei valori BDI-II separatamente per ciascuno dei due gruppi di soggetti esaminati da <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Leggo i dati, seleziono le colonne appropriate, elimino i duplicati, rimuovo </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># il dato mancante.</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/data.mood.csv'</span>,index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[[<span class="st">'esm_id'</span>,<span class="st">'group'</span>,<span class="st">'bdi'</span>]]</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop_duplicates(keep<span class="op">=</span><span class="st">'first'</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[pd.notnull(df[<span class="st">'bdi'</span>])]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Trovo le medie dei valori BDI-II dei due gruppi.</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">'group'</span>)[<span class="st">'bdi'</span>].describe().<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        count  mean  std   min   25%   50%   75%   max</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; group                                                </span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ctl     36.0   1.6  2.7   0.0   0.0   1.0   2.0  12.0</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; mdd     30.0  30.9  6.6  19.0  26.0  30.0  35.0  44.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section><section id="media-spuntata" class="level3" data-number="4.1.2"><h3 data-number="4.1.2" class="anchored" data-anchor-id="media-spuntata">
<span class="header-section-number">4.1.2</span> Media spuntata</h3>
<p>La <em>media spuntata</em> <span class="math inline">\(\bar{x}_t\)</span> (<em>trimmed mean</em>) non è altro che la media dei dati calcolata considerando solo il 90% (o altra percentuale) dei dati centrali. Per calcolare <span class="math inline">\(\bar{x}_t\)</span> si ordinando i dati secondo una sequenza crescente, <span class="math inline">\(x_1 \leq x_2 \leq x_3 \leq \dots \leq x_n\)</span>, per poi eliminare il primo 5% e l’ultimo 5% dei dati della serie così ordinata. La media spuntata è data dalla media aritmetica dei dati rimanenti.</p>
<div id="exr-trimmed-mean" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 4.2 </strong></span>Si calcoli la media spuntata dei valori BDI-II per i due gruppi di soggetti esaminati da <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span> escludendo il 10% dei valori più estremi.</p>
<p>Iniziamo ad esaminare la numerosità di ciascun gruppo.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">"group"</span>).size()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; group</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ctl    36</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; mdd    30</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; dtype: int64</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Possiamo selezionare i dati del gruppo <code>mdd</code> nel modo seguente.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df[df[<span class="st">"group"</span>]<span class="op">==</span><span class="st">'mdd'</span>]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      esm_id group   bdi</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1        10   mdd  25.0</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 15        9   mdd  30.0</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 30        6   mdd  26.0</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 46        7   mdd  35.0</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 65       12   mdd  44.0</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 83       16   mdd  30.0</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 100      21   mdd  22.0</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 119      18   mdd  33.0</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 136      20   mdd  43.0</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 151      22   mdd  43.0</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 171      23   mdd  24.0</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 191      25   mdd  39.0</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 211      24   mdd  19.0</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 283      31   mdd  25.0</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 338      30   mdd  31.0</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 358      37   mdd  28.0</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 525      48   mdd  30.0</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 561      45   mdd  35.0</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 646      55   mdd  31.0</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 666      50   mdd  26.0</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 795      63   mdd  36.0</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 811      62   mdd  41.0</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 827      65   mdd  26.0</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 846      66   mdd  35.0</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 864      68   mdd  33.0</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 903      78   mdd  28.0</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 933      80   mdd  27.0</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 953      81   mdd  34.0</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 964      85   mdd  22.0</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 981      84   mdd  27.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcoliamo ora la media spuntata dei due gruppi.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>bdi_mdd <span class="op">=</span> df[df[<span class="st">"group"</span>]<span class="op">==</span><span class="st">'mdd'</span>].bdi</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>stats.trim_mean(bdi_mdd, <span class="fl">0.10</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 30.625</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>bdi_ctl <span class="op">=</span> df[df[<span class="st">"group"</span>]<span class="op">==</span><span class="st">'ctl'</span>].bdi</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>stats.trim_mean(bdi_ctl, <span class="fl">0.10</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section><section id="moda-e-mediana" class="level3" data-number="4.1.3"><h3 data-number="4.1.3" class="anchored" data-anchor-id="moda-e-mediana">
<span class="header-section-number">4.1.3</span> Moda e mediana</h3>
<p>In precedenza abbiamo già incontrato altri due popolari indici di tendenza centrale: la <em>moda</em> (<em>Mo</em>), ovvero il valore centrale della classe con la frequenza massima (può succedere che una distribuzione abbia più mode; in tal caso si dice <em>multimodale</em> e questo operatore perde il suo significato di indice di tendenza centrale) e la <em>mediana</em> <span class="math inline">\(\tilde{x}\)</span>.</p>
<div id="exr-quantile-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 4.3 </strong></span>Si calcolino i quantili di ordine 0.25, 0.5 e 0.75 dei valori BDI-II per i due gruppi di soggetti di <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#create functions to calculate 0.10 and 0.90 quantiles</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> q1(x):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x.quantile(<span class="fl">0.10</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> q3(x):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x.quantile(<span class="fl">0.90</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate quantiles by group</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>vals <span class="op">=</span> {<span class="st">'bdi'</span>: [q1, q3]}</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">'group'</span>).agg(vals)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         bdi      </span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          q1    q3</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; group            </span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ctl     0.0   4.0</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; mdd    23.8  41.2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="callout-note callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Si noti che solitamente i software restituiscono un valore <em>interpolato</em> del <span class="math inline">\(p\)</span>-esimo quantile <span class="math inline">\(q_p\)</span> <span class="math inline">\((0 &lt; p &lt; 1)\)</span>, il quale viene calcolato mediante specifiche procedure. Il risultato fornito dai software, dunque, non sarà identico a quello trovato utilizzando la definizione non interpolata di quantile che abbiamo presentato in precedenza. Se, per qualche ragione, vogliamo conoscere l’algoritmo usato per la determinazione dei quantili interpolati, dobbiamo leggere la documentazione del software.</p>
</div>
</div>
</div>
</section></section><section id="indici-di-dispersione" class="level2" data-number="4.2"><h2 data-number="4.2" class="anchored" data-anchor-id="indici-di-dispersione">
<span class="header-section-number">4.2</span> Indici di dispersione</h2>
<p>Le medie e gli indici di posizione descritti in precedenza forniscono delle sintesi dei dati che mettono in evidenza la tendenza centrale delle osservazioni. Tali indici, tuttavia, non considerano un aspetto importante della distribuzione dei dati, ovvero la variabilità dei valori numerici della variabile statistica. È dunque necessario sintetizzare la distribuzione di una variabile statistica oltre che con le misure di posizione anche tramite l’utilizzo di indicatori che valutino la dispersione delle unità statistice.</p>
<div class="callout-tip callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Per un’introduzione “soft” al tema degli indici di dispersione si segua il <a href="https://tinystats.github.io/teacups-giraffes-and-statistics/04_variance.html">link</a>.</p>
</div>
</div>
</div>
<section id="indici-basati-sullordinamento-dei-dati" class="level3" data-number="4.2.1"><h3 data-number="4.2.1" class="anchored" data-anchor-id="indici-basati-sullordinamento-dei-dati">
<span class="header-section-number">4.2.1</span> Indici basati sull’ordinamento dei dati</h3>
<p>È possibile calcolare degli indici di variabilità basati sull’ordinamento dei dati. L’indice più ovvio è l’<em>intervallo di variazione</em>, ovvero la distanza tra il valore massimo e il valore minimo di una distribuzione di modalità, mentre in precedenza abbiamo già incontrato la <em>differenza interquartile</em>. Questi due indici, però, hanno il limite di essere calcolati sulla base di due soli valori della distribuzione (<span class="math inline">\(x_{\text{max}}\)</span> e <span class="math inline">\(x_{\text{min}}\)</span>, oppure <span class="math inline">\(x_{0.25}\)</span> e <span class="math inline">\(x_{0.75}\)</span>). Pertanto non utilizzano tutte le informazioni che sono disponibili. Inoltre, l’intervallo di variazione ha il limite di essere pesantemente influenzato dalla presenza di valori anomali.</p>
</section><section id="varianza" class="level3" data-number="4.2.2"><h3 data-number="4.2.2" class="anchored" data-anchor-id="varianza">
<span class="header-section-number">4.2.2</span> Varianza</h3>
<p>Dati i limiti delle statistiche precedenti è più comune misurare la variabilità di una variabile statistica come la dispersione dei dati attorno ad un indice di tendenza centrale. Infatti, la misura di variabilità di gran lunga più usata per valutare la variabilità di una variabile statistica è senza dubbio la varianza. La varianza</p>
<p><span id="eq-var-descr"><span class="math display">\[
\begin{equation}
S^2 = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2
\end{equation}
\tag{4.4}\]</span></span></p>
<p>è la media dei quadrati degli scarti <span class="math inline">\(x_i - \bar{x}\)</span> tra ogni valore e la media della distribuzione.</p>
<p>La varianza è una misura di dispersione più complessa di quelle esaminate in precedenza. È appropriata solo nel caso di distribuzioni simmetriche e, anch’essa, è fortemente influenzata dai valori anomali. Inoltre, è espressa in un’unità di misura che è il quadrato dell’unità di misura dei dati originari e quindi ad essa non può essere assegnata un’interpretazione intuitiva.</p>
<div id="exr-var-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 4.4 </strong></span>Si calcoli la varianza dei valori BDI-II per i dati di <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span>.</p>
<p>Applicando la formula precedente, per tutto il campione abbiamo</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>var_bdi <span class="op">=</span> <span class="bu">sum</span>((df.bdi <span class="op">-</span> np.mean(df.bdi))<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> <span class="bu">len</span>(df.bdi)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(var_bdi, <span class="dv">4</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 236.2388</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Possiamo anche usare le funzioni di <code>numpy</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>var_bdi <span class="op">=</span> np.var(df.bdi)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(var_bdi, <span class="dv">4</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 236.2388</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<section id="stima-della-varianza-della-popolazione" class="level4" data-number="4.2.2.1"><h4 data-number="4.2.2.1" class="anchored" data-anchor-id="stima-della-varianza-della-popolazione">
<span class="header-section-number">4.2.2.1</span> Stima della varianza della popolazione</h4>
<p>Si noti il denominatore della formula della varianza. Nell’<a href="#eq-var-descr">Equazione&nbsp;<span>4.4</span></a> ho usato <span class="math inline">\(n\)</span> (l’ampiezza campionaria, ovvero il numero di osservazioni del campione). In questo modo ottengo la varianza quale <em>statistica descrittiva</em> del campione. In alternativa, è possibile usare <span class="math inline">\(n-1\)</span> al denominatore:</p>
<p><span id="eq-var-stimatore"><span class="math display">\[
\begin{equation}
s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2
\end{equation}
\tag{4.5}\]</span></span></p>
<p>In questo secondo modo si trova la varianza quale <em>stimatore</em> della varianza della popolazione. Si può dimostrare che l’<a href="#eq-var-stimatore">Equazione&nbsp;<span>4.5</span></a> fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre invece la <a href="#eq-var-descr">Equazione&nbsp;<span>4.4</span></a> fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: <span class="math inline">\(S^2\)</span> per la varianza quale statistica descrittiva, <span class="math inline">\(s^2\)</span> per la varianza quale stimatore.</p>
<div id="exr-sim-var-stim" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 4.5 </strong></span>Per illustrare il punto precedente svolgiamo una simulazione.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Estraggo un campione casuale di 10 osservazioni dalla popolazione del quoziente di intelligenza.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.normal(loc <span class="op">=</span> <span class="dv">100</span>, scale <span class="op">=</span> <span class="dv">15</span>, size <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [ 81.17070624 100.35069264  68.1950899   57.96551529  90.15808424</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  125.61104223 110.79690116 113.22592754  92.61442233  96.89704775]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Calcolo la varianza con <span class="math inline">\(n\)</span> al denominatore. Si noti che la “vera” varianza del quoziente di intelligenza è <span class="math inline">\(15^2\)</span> = 225.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>np.var(x)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 384.4493983096239</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Consideriamo ora 10 campioni casuali del QI.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>loc <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>scale <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>niter <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>random_samples <span class="op">=</span> []</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(niter):</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    one_sample <span class="op">=</span> np.random.normal(loc, scale, size)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    random_samples.append(one_sample)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Il primo campione è</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>random_samples[<span class="dv">0</span>]</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; array([85.53870397, 91.09826595, 79.48383929, 98.6820146 ])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Il decimo campione è</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>random_samples[<span class="dv">9</span>]</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; array([ 96.9281537 , 101.48833754,  97.02814599,  99.87664806])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Stampiamo tutti e 10 i campioni.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>rs <span class="op">=</span> np.array(random_samples)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>rs</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; array([[ 85.53870397,  91.09826595,  79.48383929,  98.6820146 ],</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [119.09265717,  86.67387284,  95.02799371,  56.46242066],</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [103.12802245, 103.13909694, 112.15934503,  95.8227122 ],</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [ 97.59083982,  67.1746377 , 105.20100163, 108.06586713],</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [111.90171046, 102.71742144,  96.36614998, 104.02118416],</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [ 94.93411727, 108.00656212, 111.37636944,  97.44631896],</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [107.73941918, 123.04392679, 111.77922494, 115.09265642],</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [ 95.87590295,  86.82367216,  90.00344021,  97.0524578 ],</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [103.70110958,  82.89416431,  83.35520427,  77.78202689],</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [ 96.9281537 , 101.48833754,  97.02814599,  99.87664806]])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando <span class="math inline">\(n\)</span> al denominatore. Otteniamo così 10 stime della varianza della popolazione del QI.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>x_var <span class="op">=</span> np.var(rs, axis<span class="op">=</span><span class="dv">1</span>) <span class="co"># applichiamo la funzione su ciascuna riga</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_var)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [ 50.080926   501.4036708   33.5445251  263.69316018  30.52784334</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   47.77926698  31.60706991  17.64003824  98.50565593   3.75648187]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Ripetiamo ora la simulazione usando un numero di iterazioni maggiore.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>loc <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>scale <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>niter <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>random_samples <span class="op">=</span> []</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(niter):</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    one_sample <span class="op">=</span> np.random.normal(loc, scale, size)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    random_samples.append(one_sample)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>rs <span class="op">=</span> np.array(random_samples)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>x_var <span class="op">=</span> np.var(rs, axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Esaminiamo la distribuzione dei valori ottenuti.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>sns.histplot(x_var)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="011_loc_scale_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>La stima più verosimile della varianza del QI è dato dalla media di questa distribuzione.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>np.mean(x_var)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 170.9802825174357</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si noti che il valore medio della stima della varianza ottenuta con l’<a href="#eq-var-descr">Equazione&nbsp;<span>4.4</span></a> è troppo piccolo rispetto al valore corretto di <span class="math inline">\(15^2 = 225\)</span>.</p>
<p>Ripeto ora la simulazione usando la formula della varianza con <span class="math inline">\(n-1\)</span> al denominatore.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">2023</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>loc <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>scale <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>niter <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>random_samples <span class="op">=</span> []</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(niter):</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    one_sample <span class="op">=</span> np.random.normal(loc, scale, size)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    random_samples.append(one_sample)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>rs <span class="op">=</span> np.array(random_samples)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>x_var <span class="op">=</span> np.var(rs, ddof<span class="op">=</span><span class="dv">1</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>np.mean(x_var)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 223.3573010872812</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In questo secondo caso, il <em>valore atteso</em> della stima della varianza trovata con <span class="math inline">\(n-1\)</span> al denominatore è molto simile al valore corretto di 225.</p>
</div>
</section></section><section id="precisione" class="level3" data-number="4.2.3"><h3 data-number="4.2.3" class="anchored" data-anchor-id="precisione">
<span class="header-section-number">4.2.3</span> Precisione</h3>
<p>Si definisce <em>precisione</em> l’inverso della varianza:</p>
<p><span id="eq-precision"><span class="math display">\[
\begin{equation}
\tau = \frac{1}{\sigma^2}.
\end{equation}
\tag{4.6}\]</span></span></p>
<p>Alcuni ritengono che la precisione sia più “intuitiva” della varianza perché dice quanto sono concentrati i valori attorno alla media piuttosto che quanto sono dispersi. In altri termini, si potrebbe argomentare che siamo più interessati a quanto sia precisa una misurazione piuttosto che a quanto sia imprecisa. Più sono dispersi i valori attorno alla media (alta varianza), meno sono precisi (poca precisione); minore è la varianza, maggiore è la precisione.</p>
<div class="callout-note callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>La precisione è uno dei due parametri naturali della distribuzione gaussiana. Nei termini della <a href="#eq-precision">Equazione&nbsp;<span>4.6</span></a>, la distribuzione gaussiana (si veda il Capitolo <span class="citation" data-cites="distr-rv-cont">(<a href="999_refs.html#ref-distr-rv-cont" role="doc-biblioref"><strong>distr-rv-cont?</strong></a>)</span>) può essere espressa nel modo seguente</p>
<p><span class="math display">\[
{\displaystyle f(y)=\sqrt{\frac{\tau}{2\pi}} e^{-{\frac {1}{2}}\tau\left({y-\mu }\right)^{2}}},
\]</span></p>
<p>anziché come</p>
<p><span class="math display">\[
{\displaystyle f(y)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {y-\mu }{\sigma }}\right)^{2}}}.
\]</span></p>
</div>
</div>
</div>
</section><section id="deviazione-standard" class="level3" data-number="4.2.4"><h3 data-number="4.2.4" class="anchored" data-anchor-id="deviazione-standard">
<span class="header-section-number">4.2.4</span> Deviazione standard</h3>
<p>Dato che l’unità di misura della varianza coincide con il quadrato dell’unità di misura dei dati, la varianza è difficile da interpretare. Questo problema si può risolvere prendendo la radice quadrata della varianza, ottenendo così una misura espressa nell’unità di misura originaria dei dati. Una tale misura si chiama <em>deviazione standard</em> (o <em>scarto quadratico medio</em>, o <em>scarto tipo</em>)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<p><span id="eq-sd-stimatore"><span class="math display">\[
s^2 = \sqrt{(n-1)^{-1} \sum_{i=1}^n (x_i - \bar{x})^2}
\tag{4.7}\]</span></span></p>
<p>Quando tutte le osservazioni sono uguali, <span class="math inline">\(s = 0\)</span>, altrimenti <span class="math inline">\(s &gt; 0\)</span>.</p>
<p>Come nel caso della varianza, anche la deviazione standard <span class="math inline">\(s\)</span> dovrebbe essere usata soltanto quando la media è adeguata per descrivere il centro della distribuzione, ovvero, nel caso di distribuzioni simmetriche. Come nel caso della media <span class="math inline">\(\bar{x}\)</span>, anche la deviazione standard è fortemente influenzata dai dati anomali, ovvero dalla presenza di uno o di pochi dati che sono molto più distanti dalla media rispetto agli altri valori della distribuzione.</p>
<div id="exr-sd-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 4.6 </strong></span>Si calcoli la deviazione standard per i valori BDI-II del campione di <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span>.</p>
<p>Applicando l’<a href="#eq-sd-stimatore">Equazione&nbsp;<span>4.7</span></a>, per tutto il campione abbiamo</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>np.std(df.bdi)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 15.370060219395436</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Per ciascun gruppo, abbiamo:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">'group'</span>)[<span class="st">'bdi'</span>].std()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; group</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ctl    2.707427</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; mdd    6.606858</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Name: bdi, dtype: float64</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<section id="interpretazione" class="level4" data-number="4.2.4.1"><h4 data-number="4.2.4.1" class="anchored" data-anchor-id="interpretazione">
<span class="header-section-number">4.2.4.1</span> Interpretazione</h4>
<p>Alla deviazione standard può essere assegnata una semplice interpretazione: la deviazione standard è <em>simile</em> (ma non identica) allo scarto semplice medio campionario, ovvero alla media aritmetica dei valori assoluti degli scarti dalla media. La deviazione standard ci dice, dunque, quanto sono distanti, in media, le singole osservazioni dal centro della distribuzione. Un’interpretazione più precisa del significato dello scarto tipo è fornita nel paragrafo successivo.</p>
<div id="exr-sd-2" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 4.7 </strong></span>Si verifichi l’interpretazione della deviazione standard fornita sopra usando i valori BDI-II del campione di <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span>.</p>
<p>Per questi dati la deviazione standard è</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>np.std(df.bdi)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 15.370060219395436</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Lo scarto semplice medio campionario è</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>np.mean(np.<span class="bu">abs</span>(df.bdi <span class="op">-</span> np.mean(df.bdi)))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 14.539944903581269</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section></section><section id="deviazione-mediana-assoluta" class="level3" data-number="4.2.5"><h3 data-number="4.2.5" class="anchored" data-anchor-id="deviazione-mediana-assoluta">
<span class="header-section-number">4.2.5</span> Deviazione mediana assoluta</h3>
<p>Una misura robusta della dispersione statistica di un campione è la <em>deviazione mediana assoluta</em> (<em>Median Absolute Deviation</em>, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana, ovvero:</p>
<p><span id="eq-mad-def"><span class="math display">\[
{\displaystyle \operatorname {MAD} =\operatorname {median} \left(\ \left|X_{i}-\operatorname {median} (X)\right|\ \right)}
\tag{4.8}\]</span></span></p>
<p>Nel caso di una distribuzione dei dati unimodale simmetrica di forma campanulare (ovvero, normale) si ha che</p>
<p><span class="math display">\[
{\displaystyle \text{deviazione standard} \approx 1.4826\ \operatorname {MAD} .\,}
\]</span></p>
<p>Pertanto, solitamente i software restituiscono il valore MAD moltiplicato per una tale costante.</p>
<div id="exr-mad-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 4.8 </strong></span>I dati di <span class="citation" data-cites="zetschefuture2019">Zetsche et al. (<a href="999_refs.html#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span> seguono una distribuzione bimodale, per cui il vincolo precedente non si applica. Verifichiamo dunque il principio precedente usando un campione di dati estratto da una popolazione normale.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">100</span>, scale<span class="op">=</span><span class="dv">15</span>, size<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fl">1.4826</span> <span class="op">*</span> np.median(np.<span class="bu">abs</span>(x <span class="op">-</span> np.median(x)))</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 14.912293804211595</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section><section id="indici-di-variabilità-relativi" class="level3" data-number="4.2.6"><h3 data-number="4.2.6" class="anchored" data-anchor-id="indici-di-variabilità-relativi">
<span class="header-section-number">4.2.6</span> Indici di variabilità relativi</h3>
<p>A volte può essere interessante effettuare un confronto fra due misure di variabilità di grandezze incommensurabili, ovvero di caratteri rilevati mediante differenti unità di misura. In questi casi, le misure di variabilità precedentemente descritte si rivelano inadeguate in quanto dipendono dall’unità di misura adottata. Diventa dunque necessario ricorrere a particolari numeri adimensionali detti <em>indici relativi di variabilità</em>. Il più importante di tali indici è il <em>coefficiente di variazione</em>, ovvero il numero puro</p>
<p><span id="eq-cv-def"><span class="math display">\[
C_v = \frac{\sigma}{\bar{x}}
\tag{4.9}\]</span></span></p>
<p>ottenuto dal rapporto tra la deviazione standard e la media dei dati.</p>
<p>Un altro indice relativo di variabilità è la differenza interquartile rapportata al primo quartile, oppure al terzo quartile, oppure alla mediana, cioè:</p>
<p><span class="math display">\[
\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \qquad \frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \qquad \frac{x_{0.75} - x_{0.25}}{x_{0.50}}.
\]</span></p>
</section></section><section id="commenti-e-considerazioni-finali" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="commenti-e-considerazioni-finali">Commenti e considerazioni finali</h2>
<p>Le statistiche descrittive ci forniscono degli indici sintetici che riassumono i dati, ovvero le nostre misurazioni dell’intera popolazione o di un campione estratto da una popolazione. Le statistiche descrittive comprendono gli indici di tendenza centrale e gli indici di dispersione. Gli indici di tendenza centrale includono la media, la mediana e la moda, mentre gli indici di dispersione includono la deviazione standard, la varianza, la curtosi e l’asimmetria (questi ultimi due indici sono definiti in relazione alla distribuzione Normale e verranno dunque discussi in quel contesto).</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography" style="display: none">
<div id="ref-zetschefuture2019" class="csl-entry" role="doc-biblioentry">
Zetsche, U., Bürkner, P.-C., &amp; Renneberg, B. (2019). Future expectations in clinical depression: <span>Biased</span> or realistic? <em>Journal of Abnormal Psychology</em>, <em>128</em>(7), 678–688.
</div>
</div>
</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>Il termine <em>standard deviation</em> è stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca <span class="math inline">\(\sigma\)</span> che lo rappresenta. Il termine italiano “deviazione standard” ne è la traduzione più utilizzata nel linguaggio comune; il termine dell’<a href="https://it.wikipedia.org/wiki/Ente_nazionale_italiano_di_unificazione">Ente Nazionale Italiano di Unificazione</a> è tuttavia “scarto tipo”, definito come la radice quadrata positiva della varianza.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./007_freq_distr.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Analisi esplorativa dei dati</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./012_correlation.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb26" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Indici di posizione e di scala {#sec-loc-scale}</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include = FALSE}</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>L'analisi grafica esaminata in precedenza costituisce la base di partenza di qualsivoglia analisi quantitativa dei dati. Tramite opportune rappresentazioni grafiche possiamo individuare alcune caratteristiche importanti di una distribuzione: per esempio, è possibile capire se la distribuzione è simmetrica o asimmetrica; oppure se è unimodale o multimodale. Successivamente, è necessario calcolare degli indici numerici che descrivano in modo sintetico le caratteristiche di base dei dati. In questo capitolo verranno introdotti i principali indicatori della statistica descrittiva.</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="fu">## Indici di tendenza centrale</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>Tra le misure di tendenza centrale, ovvero tra gli indici che ci informano sui valori attorno ai quali sono prevalentemente concentrati i dati di un campione, quella più comunemente usata è la media.</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Pandas for managing datasets</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Matplotlib for additional customization</span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Seaborn for plotting and styling</span></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Set theme</span></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>sns.set_palette(<span class="st">"colorblind"</span>)</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a><span class="co"># cwd = os.getcwd()</span></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a><span class="co"># print(cwd)</span></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>Per un'introduzione "soft" alla nozione di tendenza centrale di una distribuzione statistica si segua il <span class="co">[</span><span class="ot">link</span><span class="co">](https://tinystats.github.io/teacups-giraffes-and-statistics/03_mean.html)</span>.</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a><span class="fu">### Media</span></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>Tutti conosciamo la media aritmetica di $<span class="sc">\{</span>x_1, x_2, \dots, x_n<span class="sc">\}</span>$, ovvero il numero reale $\bar{x}$ definito da</span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>\begin{equation}</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a>\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i.</span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a>$$ {#eq-mean}</span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a>Nella @eq-mean ho usato la notazione delle sommatorie per descrivere una somma di valori. Questa notazione è molto usata in statistica e viene descritta in Appendice.</span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a>La media gode della seguente importante proprietà: la somma degli scarti tra ciascuna modalità $x_i$ e la media aritmetica $\bar{x}$ è nulla, cioè</span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a>\begin{equation}</span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a>\sum_{i=1}^n (x_i - \bar{x}) = 0.\notag</span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>$$ {#eq-diffmeansumzero}</span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a>Infatti,</span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a>\sum_{i=1}^n (x_i - \bar{x}) &amp;= \sum_i x_i - \sum_i \bar{x}\notag<span class="sc">\\</span></span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a>&amp;= \sum_i x_i - n \bar{x}\notag<span class="sc">\\</span></span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a>&amp;= \sum_i x_i - \sum_i x_i = 0.\notag</span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a>Ciò ci consente di pensare alla media come al baricentro della distribuzione.</span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a>Un'altra proprietà della media è la seguente. La somma dei quadrati degli scarti tra ciascuna modalità $x_i$ e una costante arbitraria $a$, cioè</span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a>\begin{equation}</span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a>\varphi(a) = \sum_{i=1}^n (x_i - a)^2,\notag</span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a>$$ {#eq-minsq}</span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a>è minima per $a = \bar{x}$.</span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a>Il concetto statistico di media ha suscitato molte battute. Per esempio, il fatto che, in media, ciascuno di noi ha un numero di gambe circa pari a 1.9999999. Oppure, il fatto che, in media, ciascuno di noi ha un testicolo. Ma la media ha altri problemi, oltre al fatto di ispirare battute simili alle precedenti. In particolare, dobbiamo notare che la media non è sempre l'indice che meglio rappresenta la tendenza centrale di una distribuzione. In particolare, ciò non accade quando la distribuzione è asimmetrica, o in presenza di valori anomali (*outlier*) -- si veda il pannello di sinistra della @fig-raincloud. In tali circostanze, la tendenza centrale della distribuzione è meglio rappresentata dalla mediana o dalla media spuntata (si veda più sotto).</span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a>::: {#exr-mean}</span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a>Si calcoli la media dei valori BDI-II separatamente per ciascuno dei due gruppi di soggetti esaminati da @zetschefuture2019.</span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Leggo i dati, seleziono le colonne appropriate, elimino i duplicati, rimuovo </span></span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a><span class="co"># il dato mancante.</span></span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/data.mood.csv'</span>,index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[[<span class="st">'esm_id'</span>,<span class="st">'group'</span>,<span class="st">'bdi'</span>]]</span>
<span id="cb26-95"><a href="#cb26-95" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop_duplicates(keep<span class="op">=</span><span class="st">'first'</span>)</span>
<span id="cb26-96"><a href="#cb26-96" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[pd.notnull(df[<span class="st">'bdi'</span>])]</span>
<span id="cb26-97"><a href="#cb26-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-98"><a href="#cb26-98" aria-hidden="true" tabindex="-1"></a><span class="co"># Trovo le medie dei valori BDI-II dei due gruppi.</span></span>
<span id="cb26-99"><a href="#cb26-99" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">'group'</span>)[<span class="st">'bdi'</span>].describe().<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb26-100"><a href="#cb26-100" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-101"><a href="#cb26-101" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-102"><a href="#cb26-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-103"><a href="#cb26-103" aria-hidden="true" tabindex="-1"></a><span class="fu">### Media spuntata</span></span>
<span id="cb26-104"><a href="#cb26-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-105"><a href="#cb26-105" aria-hidden="true" tabindex="-1"></a>La *media spuntata* $\bar{x}_t$ (*trimmed mean*) non è altro che la media dei dati calcolata considerando solo il 90% (o altra percentuale) dei dati centrali. Per calcolare $\bar{x}_t$ si ordinando i dati secondo una sequenza crescente, $x_1 \leq x_2 \leq x_3 \leq \dots \leq x_n$, per poi eliminare il primo 5% e l'ultimo 5% dei dati della serie così ordinata. La media spuntata è data dalla media aritmetica dei dati rimanenti.</span>
<span id="cb26-106"><a href="#cb26-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-107"><a href="#cb26-107" aria-hidden="true" tabindex="-1"></a>::: {#exr-trimmed-mean}</span>
<span id="cb26-108"><a href="#cb26-108" aria-hidden="true" tabindex="-1"></a>Si calcoli la media spuntata dei valori BDI-II per i due gruppi di soggetti esaminati da @zetschefuture2019 escludendo il 10% dei valori più estremi.</span>
<span id="cb26-109"><a href="#cb26-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-110"><a href="#cb26-110" aria-hidden="true" tabindex="-1"></a>Iniziamo ad esaminare la numerosità di ciascun gruppo.</span>
<span id="cb26-111"><a href="#cb26-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-114"><a href="#cb26-114" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-115"><a href="#cb26-115" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">"group"</span>).size()</span>
<span id="cb26-116"><a href="#cb26-116" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-117"><a href="#cb26-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-118"><a href="#cb26-118" aria-hidden="true" tabindex="-1"></a>Possiamo selezionare i dati del gruppo <span class="in">`mdd`</span> nel modo seguente.</span>
<span id="cb26-119"><a href="#cb26-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-122"><a href="#cb26-122" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-123"><a href="#cb26-123" aria-hidden="true" tabindex="-1"></a>df[df[<span class="st">"group"</span>]<span class="op">==</span><span class="st">'mdd'</span>]</span>
<span id="cb26-124"><a href="#cb26-124" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-125"><a href="#cb26-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-126"><a href="#cb26-126" aria-hidden="true" tabindex="-1"></a>Calcoliamo ora la media spuntata dei due gruppi.</span>
<span id="cb26-127"><a href="#cb26-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-130"><a href="#cb26-130" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-131"><a href="#cb26-131" aria-hidden="true" tabindex="-1"></a>bdi_mdd <span class="op">=</span> df[df[<span class="st">"group"</span>]<span class="op">==</span><span class="st">'mdd'</span>].bdi</span>
<span id="cb26-132"><a href="#cb26-132" aria-hidden="true" tabindex="-1"></a>stats.trim_mean(bdi_mdd, <span class="fl">0.10</span>)</span>
<span id="cb26-133"><a href="#cb26-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-134"><a href="#cb26-134" aria-hidden="true" tabindex="-1"></a>bdi_ctl <span class="op">=</span> df[df[<span class="st">"group"</span>]<span class="op">==</span><span class="st">'ctl'</span>].bdi</span>
<span id="cb26-135"><a href="#cb26-135" aria-hidden="true" tabindex="-1"></a>stats.trim_mean(bdi_ctl, <span class="fl">0.10</span>)</span>
<span id="cb26-136"><a href="#cb26-136" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-137"><a href="#cb26-137" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-138"><a href="#cb26-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-139"><a href="#cb26-139" aria-hidden="true" tabindex="-1"></a><span class="fu">### Moda e mediana</span></span>
<span id="cb26-140"><a href="#cb26-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-141"><a href="#cb26-141" aria-hidden="true" tabindex="-1"></a>In precedenza abbiamo già incontrato altri due popolari indici di tendenza centrale: la *moda* (*Mo*), ovvero il valore centrale della classe con la frequenza massima (può succedere che una distribuzione abbia più mode; in tal caso si dice *multimodale* e questo operatore perde il suo significato di indice di tendenza centrale) e la *mediana* $\tilde{x}$.</span>
<span id="cb26-142"><a href="#cb26-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-143"><a href="#cb26-143" aria-hidden="true" tabindex="-1"></a>::: {#exr-quantile-1}</span>
<span id="cb26-144"><a href="#cb26-144" aria-hidden="true" tabindex="-1"></a>Si calcolino i quantili di ordine 0.25, 0.5 e 0.75 dei valori BDI-II per i due gruppi di soggetti di @zetschefuture2019.</span>
<span id="cb26-145"><a href="#cb26-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-148"><a href="#cb26-148" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-149"><a href="#cb26-149" aria-hidden="true" tabindex="-1"></a><span class="co">#create functions to calculate 0.10 and 0.90 quantiles</span></span>
<span id="cb26-150"><a href="#cb26-150" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> q1(x):</span>
<span id="cb26-151"><a href="#cb26-151" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x.quantile(<span class="fl">0.10</span>)</span>
<span id="cb26-152"><a href="#cb26-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-153"><a href="#cb26-153" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> q3(x):</span>
<span id="cb26-154"><a href="#cb26-154" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x.quantile(<span class="fl">0.90</span>)</span>
<span id="cb26-155"><a href="#cb26-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-156"><a href="#cb26-156" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate quantiles by group</span></span>
<span id="cb26-157"><a href="#cb26-157" aria-hidden="true" tabindex="-1"></a>vals <span class="op">=</span> {<span class="st">'bdi'</span>: [q1, q3]}</span>
<span id="cb26-158"><a href="#cb26-158" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">'group'</span>).agg(vals)</span>
<span id="cb26-159"><a href="#cb26-159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-160"><a href="#cb26-160" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-161"><a href="#cb26-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-162"><a href="#cb26-162" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb26-163"><a href="#cb26-163" aria-hidden="true" tabindex="-1"></a>Si noti che solitamente i software restituiscono un valore *interpolato* del $p$-esimo quantile $q_p$ $(0 &lt; p &lt; 1)$, il quale viene calcolato mediante specifiche procedure. Il risultato fornito dai software, dunque, non sarà identico a quello trovato utilizzando la definizione non interpolata di quantile che abbiamo presentato in precedenza. Se, per qualche ragione, vogliamo conoscere l'algoritmo usato per la determinazione dei quantili interpolati, dobbiamo leggere la documentazione del software.</span>
<span id="cb26-164"><a href="#cb26-164" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-165"><a href="#cb26-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-166"><a href="#cb26-166" aria-hidden="true" tabindex="-1"></a><span class="fu">## Indici di dispersione</span></span>
<span id="cb26-167"><a href="#cb26-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-168"><a href="#cb26-168" aria-hidden="true" tabindex="-1"></a>Le medie e gli indici di posizione descritti in precedenza forniscono delle sintesi dei dati che mettono in evidenza la tendenza centrale delle osservazioni. Tali indici, tuttavia, non considerano un aspetto importante della distribuzione dei dati, ovvero la variabilità dei valori numerici della variabile statistica. È dunque necessario sintetizzare la distribuzione di una variabile statistica oltre che con le misure di posizione anche tramite l'utilizzo di indicatori che valutino la dispersione delle unità statistice.</span>
<span id="cb26-169"><a href="#cb26-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-170"><a href="#cb26-170" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb26-171"><a href="#cb26-171" aria-hidden="true" tabindex="-1"></a>Per un'introduzione "soft" al tema degli indici di dispersione si segua il <span class="co">[</span><span class="ot">link</span><span class="co">](https://tinystats.github.io/teacups-giraffes-and-statistics/04_variance.html)</span>.</span>
<span id="cb26-172"><a href="#cb26-172" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-173"><a href="#cb26-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-174"><a href="#cb26-174" aria-hidden="true" tabindex="-1"></a><span class="fu">### Indici basati sull'ordinamento dei dati</span></span>
<span id="cb26-175"><a href="#cb26-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-176"><a href="#cb26-176" aria-hidden="true" tabindex="-1"></a>È possibile calcolare degli indici di variabilità basati sull'ordinamento dei dati. L'indice più ovvio è l'*intervallo di variazione*, ovvero la distanza tra il valore massimo e il valore minimo di una distribuzione di modalità, mentre in precedenza abbiamo già incontrato la *differenza interquartile*. Questi due indici, però, hanno il limite di essere calcolati sulla base di due soli valori della distribuzione ($x_{\text{max}}$ e $x_{\text{min}}$, oppure $x_{0.25}$ e $x_{0.75}$). Pertanto non utilizzano tutte le informazioni che sono disponibili. Inoltre, l'intervallo di variazione ha il limite di essere pesantemente influenzato dalla presenza di valori anomali.</span>
<span id="cb26-177"><a href="#cb26-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-178"><a href="#cb26-178" aria-hidden="true" tabindex="-1"></a><span class="fu">### Varianza</span></span>
<span id="cb26-179"><a href="#cb26-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-180"><a href="#cb26-180" aria-hidden="true" tabindex="-1"></a>Dati i limiti delle statistiche precedenti è più comune misurare la variabilità di una variabile statistica come la dispersione dei dati attorno ad un indice di tendenza centrale. Infatti, la misura di variabilità di gran lunga più usata per valutare la variabilità di una variabile statistica è senza dubbio la varianza. La varianza</span>
<span id="cb26-181"><a href="#cb26-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-182"><a href="#cb26-182" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-183"><a href="#cb26-183" aria-hidden="true" tabindex="-1"></a>\begin{equation}</span>
<span id="cb26-184"><a href="#cb26-184" aria-hidden="true" tabindex="-1"></a>S^2 = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2</span>
<span id="cb26-185"><a href="#cb26-185" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb26-186"><a href="#cb26-186" aria-hidden="true" tabindex="-1"></a>$$ {#eq-var-descr}</span>
<span id="cb26-187"><a href="#cb26-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-188"><a href="#cb26-188" aria-hidden="true" tabindex="-1"></a>è la media dei quadrati degli scarti $x_i - \bar{x}$ tra ogni valore e la media della distribuzione.</span>
<span id="cb26-189"><a href="#cb26-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-190"><a href="#cb26-190" aria-hidden="true" tabindex="-1"></a>La varianza è una misura di dispersione più complessa di quelle esaminate in precedenza. È appropriata solo nel caso di distribuzioni simmetriche e, anch'essa, è fortemente influenzata dai valori anomali. Inoltre, è espressa in un'unità di misura che è il quadrato dell'unità di misura dei dati originari e quindi ad essa non può essere assegnata un'interpretazione intuitiva.</span>
<span id="cb26-191"><a href="#cb26-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-192"><a href="#cb26-192" aria-hidden="true" tabindex="-1"></a>::: {#exr-var-1}</span>
<span id="cb26-193"><a href="#cb26-193" aria-hidden="true" tabindex="-1"></a>Si calcoli la varianza dei valori BDI-II per i dati di @zetschefuture2019.</span>
<span id="cb26-194"><a href="#cb26-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-195"><a href="#cb26-195" aria-hidden="true" tabindex="-1"></a>Applicando la formula precedente, per tutto il campione abbiamo</span>
<span id="cb26-196"><a href="#cb26-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-199"><a href="#cb26-199" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-200"><a href="#cb26-200" aria-hidden="true" tabindex="-1"></a>var_bdi <span class="op">=</span> <span class="bu">sum</span>((df.bdi <span class="op">-</span> np.mean(df.bdi))<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> <span class="bu">len</span>(df.bdi)</span>
<span id="cb26-201"><a href="#cb26-201" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(var_bdi, <span class="dv">4</span>)</span>
<span id="cb26-202"><a href="#cb26-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-203"><a href="#cb26-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-204"><a href="#cb26-204" aria-hidden="true" tabindex="-1"></a>Possiamo anche usare le funzioni di <span class="in">`numpy`</span>.</span>
<span id="cb26-205"><a href="#cb26-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-208"><a href="#cb26-208" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-209"><a href="#cb26-209" aria-hidden="true" tabindex="-1"></a>var_bdi <span class="op">=</span> np.var(df.bdi)</span>
<span id="cb26-210"><a href="#cb26-210" aria-hidden="true" tabindex="-1"></a><span class="bu">round</span>(var_bdi, <span class="dv">4</span>)</span>
<span id="cb26-211"><a href="#cb26-211" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-212"><a href="#cb26-212" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-213"><a href="#cb26-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-214"><a href="#cb26-214" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Stima della varianza della popolazione</span></span>
<span id="cb26-215"><a href="#cb26-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-216"><a href="#cb26-216" aria-hidden="true" tabindex="-1"></a>Si noti il denominatore della formula della varianza. Nell'@eq-var-descr ho usato $n$ (l'ampiezza campionaria, ovvero il numero di osservazioni del campione). In questo modo ottengo la varianza quale *statistica descrittiva* del campione. In alternativa, è possibile usare $n-1$ al denominatore:</span>
<span id="cb26-217"><a href="#cb26-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-218"><a href="#cb26-218" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-219"><a href="#cb26-219" aria-hidden="true" tabindex="-1"></a>\begin{equation}</span>
<span id="cb26-220"><a href="#cb26-220" aria-hidden="true" tabindex="-1"></a>s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2</span>
<span id="cb26-221"><a href="#cb26-221" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb26-222"><a href="#cb26-222" aria-hidden="true" tabindex="-1"></a>$$ {#eq-var-stimatore}</span>
<span id="cb26-223"><a href="#cb26-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-224"><a href="#cb26-224" aria-hidden="true" tabindex="-1"></a>In questo secondo modo si trova la varianza quale *stimatore* della varianza della popolazione. Si può dimostrare che l'@eq-var-stimatore fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre invece la @eq-var-descr fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: $S^2$ per la varianza quale statistica descrittiva, $s^2$ per la varianza quale stimatore.</span>
<span id="cb26-225"><a href="#cb26-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-226"><a href="#cb26-226" aria-hidden="true" tabindex="-1"></a>::: {#exr-sim-var-stim}</span>
<span id="cb26-227"><a href="#cb26-227" aria-hidden="true" tabindex="-1"></a>Per illustrare il punto precedente svolgiamo una simulazione.</span>
<span id="cb26-228"><a href="#cb26-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-231"><a href="#cb26-231" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-232"><a href="#cb26-232" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb26-233"><a href="#cb26-233" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-234"><a href="#cb26-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-235"><a href="#cb26-235" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-236"><a href="#cb26-236" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb26-237"><a href="#cb26-237" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-238"><a href="#cb26-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-239"><a href="#cb26-239" aria-hidden="true" tabindex="-1"></a>Estraggo un campione casuale di 10 osservazioni dalla popolazione del quoziente di intelligenza.</span>
<span id="cb26-240"><a href="#cb26-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-243"><a href="#cb26-243" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-244"><a href="#cb26-244" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.normal(loc <span class="op">=</span> <span class="dv">100</span>, scale <span class="op">=</span> <span class="dv">15</span>, size <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb26-245"><a href="#cb26-245" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb26-246"><a href="#cb26-246" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-247"><a href="#cb26-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-248"><a href="#cb26-248" aria-hidden="true" tabindex="-1"></a>Calcolo la varianza con $n$ al denominatore. Si noti che la "vera" varianza del quoziente di intelligenza è $15^2$ = 225.</span>
<span id="cb26-249"><a href="#cb26-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-252"><a href="#cb26-252" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-253"><a href="#cb26-253" aria-hidden="true" tabindex="-1"></a>np.var(x)</span>
<span id="cb26-254"><a href="#cb26-254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-255"><a href="#cb26-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-256"><a href="#cb26-256" aria-hidden="true" tabindex="-1"></a>Consideriamo ora 10 campioni casuali del QI.</span>
<span id="cb26-257"><a href="#cb26-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-260"><a href="#cb26-260" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-261"><a href="#cb26-261" aria-hidden="true" tabindex="-1"></a>loc <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb26-262"><a href="#cb26-262" aria-hidden="true" tabindex="-1"></a>scale <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb26-263"><a href="#cb26-263" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb26-264"><a href="#cb26-264" aria-hidden="true" tabindex="-1"></a>niter <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb26-265"><a href="#cb26-265" aria-hidden="true" tabindex="-1"></a>random_samples <span class="op">=</span> []</span>
<span id="cb26-266"><a href="#cb26-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-267"><a href="#cb26-267" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(niter):</span>
<span id="cb26-268"><a href="#cb26-268" aria-hidden="true" tabindex="-1"></a>    one_sample <span class="op">=</span> np.random.normal(loc, scale, size)</span>
<span id="cb26-269"><a href="#cb26-269" aria-hidden="true" tabindex="-1"></a>    random_samples.append(one_sample)</span>
<span id="cb26-270"><a href="#cb26-270" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-271"><a href="#cb26-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-272"><a href="#cb26-272" aria-hidden="true" tabindex="-1"></a>Il primo campione è</span>
<span id="cb26-273"><a href="#cb26-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-276"><a href="#cb26-276" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-277"><a href="#cb26-277" aria-hidden="true" tabindex="-1"></a>random_samples[<span class="dv">0</span>]</span>
<span id="cb26-278"><a href="#cb26-278" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-279"><a href="#cb26-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-280"><a href="#cb26-280" aria-hidden="true" tabindex="-1"></a>Il decimo campione è</span>
<span id="cb26-281"><a href="#cb26-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-284"><a href="#cb26-284" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-285"><a href="#cb26-285" aria-hidden="true" tabindex="-1"></a>random_samples[<span class="dv">9</span>]</span>
<span id="cb26-286"><a href="#cb26-286" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-287"><a href="#cb26-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-288"><a href="#cb26-288" aria-hidden="true" tabindex="-1"></a>Stampiamo tutti e 10 i campioni.</span>
<span id="cb26-289"><a href="#cb26-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-292"><a href="#cb26-292" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-293"><a href="#cb26-293" aria-hidden="true" tabindex="-1"></a>rs <span class="op">=</span> np.array(random_samples)</span>
<span id="cb26-294"><a href="#cb26-294" aria-hidden="true" tabindex="-1"></a>rs</span>
<span id="cb26-295"><a href="#cb26-295" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-296"><a href="#cb26-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-297"><a href="#cb26-297" aria-hidden="true" tabindex="-1"></a>Per ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando $n$ al denominatore. Otteniamo così 10 stime della varianza della popolazione del QI.</span>
<span id="cb26-298"><a href="#cb26-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-301"><a href="#cb26-301" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-302"><a href="#cb26-302" aria-hidden="true" tabindex="-1"></a>x_var <span class="op">=</span> np.var(rs, axis<span class="op">=</span><span class="dv">1</span>) <span class="co"># applichiamo la funzione su ciascuna riga</span></span>
<span id="cb26-303"><a href="#cb26-303" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_var)</span>
<span id="cb26-304"><a href="#cb26-304" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-305"><a href="#cb26-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-306"><a href="#cb26-306" aria-hidden="true" tabindex="-1"></a>Ripetiamo ora la simulazione usando un numero di iterazioni maggiore.</span>
<span id="cb26-307"><a href="#cb26-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-310"><a href="#cb26-310" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-311"><a href="#cb26-311" aria-hidden="true" tabindex="-1"></a>loc <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb26-312"><a href="#cb26-312" aria-hidden="true" tabindex="-1"></a>scale <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb26-313"><a href="#cb26-313" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb26-314"><a href="#cb26-314" aria-hidden="true" tabindex="-1"></a>niter <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb26-315"><a href="#cb26-315" aria-hidden="true" tabindex="-1"></a>random_samples <span class="op">=</span> []</span>
<span id="cb26-316"><a href="#cb26-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-317"><a href="#cb26-317" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(niter):</span>
<span id="cb26-318"><a href="#cb26-318" aria-hidden="true" tabindex="-1"></a>    one_sample <span class="op">=</span> np.random.normal(loc, scale, size)</span>
<span id="cb26-319"><a href="#cb26-319" aria-hidden="true" tabindex="-1"></a>    random_samples.append(one_sample)</span>
<span id="cb26-320"><a href="#cb26-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-321"><a href="#cb26-321" aria-hidden="true" tabindex="-1"></a>rs <span class="op">=</span> np.array(random_samples)</span>
<span id="cb26-322"><a href="#cb26-322" aria-hidden="true" tabindex="-1"></a>x_var <span class="op">=</span> np.var(rs, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-323"><a href="#cb26-323" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-324"><a href="#cb26-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-325"><a href="#cb26-325" aria-hidden="true" tabindex="-1"></a>Esaminiamo la distribuzione dei valori ottenuti.</span>
<span id="cb26-326"><a href="#cb26-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-329"><a href="#cb26-329" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-330"><a href="#cb26-330" aria-hidden="true" tabindex="-1"></a>sns.histplot(x_var)</span>
<span id="cb26-331"><a href="#cb26-331" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-332"><a href="#cb26-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-333"><a href="#cb26-333" aria-hidden="true" tabindex="-1"></a>La stima più verosimile della varianza del QI è dato dalla media di questa distribuzione.</span>
<span id="cb26-334"><a href="#cb26-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-337"><a href="#cb26-337" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-338"><a href="#cb26-338" aria-hidden="true" tabindex="-1"></a>np.mean(x_var)</span>
<span id="cb26-339"><a href="#cb26-339" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-340"><a href="#cb26-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-341"><a href="#cb26-341" aria-hidden="true" tabindex="-1"></a>Si noti che il valore medio della stima della varianza ottenuta con l'@eq-var-descr è troppo piccolo rispetto al valore corretto di $15^2 = 225$.</span>
<span id="cb26-342"><a href="#cb26-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-343"><a href="#cb26-343" aria-hidden="true" tabindex="-1"></a>Ripeto ora la simulazione usando la formula della varianza con $n-1$ al denominatore.</span>
<span id="cb26-344"><a href="#cb26-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-347"><a href="#cb26-347" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-348"><a href="#cb26-348" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">2023</span>)</span>
<span id="cb26-349"><a href="#cb26-349" aria-hidden="true" tabindex="-1"></a>loc <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb26-350"><a href="#cb26-350" aria-hidden="true" tabindex="-1"></a>scale <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb26-351"><a href="#cb26-351" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb26-352"><a href="#cb26-352" aria-hidden="true" tabindex="-1"></a>niter <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb26-353"><a href="#cb26-353" aria-hidden="true" tabindex="-1"></a>random_samples <span class="op">=</span> []</span>
<span id="cb26-354"><a href="#cb26-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-355"><a href="#cb26-355" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(niter):</span>
<span id="cb26-356"><a href="#cb26-356" aria-hidden="true" tabindex="-1"></a>    one_sample <span class="op">=</span> np.random.normal(loc, scale, size)</span>
<span id="cb26-357"><a href="#cb26-357" aria-hidden="true" tabindex="-1"></a>    random_samples.append(one_sample)</span>
<span id="cb26-358"><a href="#cb26-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-359"><a href="#cb26-359" aria-hidden="true" tabindex="-1"></a>rs <span class="op">=</span> np.array(random_samples)</span>
<span id="cb26-360"><a href="#cb26-360" aria-hidden="true" tabindex="-1"></a>x_var <span class="op">=</span> np.var(rs, ddof<span class="op">=</span><span class="dv">1</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-361"><a href="#cb26-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-362"><a href="#cb26-362" aria-hidden="true" tabindex="-1"></a>np.mean(x_var)</span>
<span id="cb26-363"><a href="#cb26-363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-364"><a href="#cb26-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-365"><a href="#cb26-365" aria-hidden="true" tabindex="-1"></a>In questo secondo caso, il *valore atteso* della stima della varianza trovata con $n-1$ al denominatore è molto simile al valore corretto di 225.</span>
<span id="cb26-366"><a href="#cb26-366" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-367"><a href="#cb26-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-368"><a href="#cb26-368" aria-hidden="true" tabindex="-1"></a><span class="fu">### Precisione</span></span>
<span id="cb26-369"><a href="#cb26-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-370"><a href="#cb26-370" aria-hidden="true" tabindex="-1"></a>Si definisce *precisione* l'inverso della varianza:</span>
<span id="cb26-371"><a href="#cb26-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-372"><a href="#cb26-372" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-373"><a href="#cb26-373" aria-hidden="true" tabindex="-1"></a>\begin{equation}</span>
<span id="cb26-374"><a href="#cb26-374" aria-hidden="true" tabindex="-1"></a>\tau = \frac{1}{\sigma^2}.</span>
<span id="cb26-375"><a href="#cb26-375" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb26-376"><a href="#cb26-376" aria-hidden="true" tabindex="-1"></a>$$ {#eq-precision}</span>
<span id="cb26-377"><a href="#cb26-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-378"><a href="#cb26-378" aria-hidden="true" tabindex="-1"></a>Alcuni ritengono che la precisione sia più "intuitiva" della varianza perché dice quanto sono concentrati i valori attorno alla media piuttosto che quanto sono dispersi. In altri termini, si potrebbe argomentare che siamo più interessati a quanto sia precisa una misurazione piuttosto che a quanto sia imprecisa. Più sono dispersi i valori attorno alla media (alta varianza), meno sono precisi (poca precisione); minore è la varianza, maggiore è la precisione.</span>
<span id="cb26-379"><a href="#cb26-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-380"><a href="#cb26-380" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb26-381"><a href="#cb26-381" aria-hidden="true" tabindex="-1"></a>La precisione è uno dei due parametri naturali della distribuzione gaussiana. Nei termini della @eq-precision, la distribuzione gaussiana (si veda il Capitolo @distr-rv-cont) può essere espressa nel modo seguente</span>
<span id="cb26-382"><a href="#cb26-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-383"><a href="#cb26-383" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-384"><a href="#cb26-384" aria-hidden="true" tabindex="-1"></a>{\displaystyle f(y)=\sqrt{\frac{\tau}{2\pi}} e^{-{\frac {1}{2}}\tau\left({y-\mu }\right)^{2}}},</span>
<span id="cb26-385"><a href="#cb26-385" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-386"><a href="#cb26-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-387"><a href="#cb26-387" aria-hidden="true" tabindex="-1"></a>anziché come</span>
<span id="cb26-388"><a href="#cb26-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-389"><a href="#cb26-389" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-390"><a href="#cb26-390" aria-hidden="true" tabindex="-1"></a>{\displaystyle f(y)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {y-\mu }{\sigma }}\right)^{2}}}.</span>
<span id="cb26-391"><a href="#cb26-391" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-392"><a href="#cb26-392" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-393"><a href="#cb26-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-394"><a href="#cb26-394" aria-hidden="true" tabindex="-1"></a><span class="fu">### Deviazione standard</span></span>
<span id="cb26-395"><a href="#cb26-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-396"><a href="#cb26-396" aria-hidden="true" tabindex="-1"></a>Dato che l'unità di misura della varianza coincide con il quadrato dell'unità di misura dei dati, la varianza è difficile da interpretare. Questo problema si può risolvere prendendo la radice quadrata della varianza, ottenendo così una misura espressa nell'unità di misura originaria dei dati. Una tale misura si chiama *deviazione standard* (o *scarto quadratico medio*, o *scarto tipo*)<span class="ot">[^011_loc_scale-1]</span>:</span>
<span id="cb26-397"><a href="#cb26-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-398"><a href="#cb26-398" aria-hidden="true" tabindex="-1"></a><span class="ot">[^011_loc_scale-1]: </span>Il termine *standard deviation* è stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca $\sigma$ che lo rappresenta. Il termine italiano "deviazione standard" ne è la traduzione più utilizzata nel linguaggio comune; il termine dell'<span class="co">[</span><span class="ot">Ente Nazionale Italiano di Unificazione</span><span class="co">](https://it.wikipedia.org/wiki/Ente_nazionale_italiano_di_unificazione)</span> è tuttavia "scarto tipo", definito come la radice quadrata positiva della varianza.</span>
<span id="cb26-399"><a href="#cb26-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-400"><a href="#cb26-400" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-401"><a href="#cb26-401" aria-hidden="true" tabindex="-1"></a>s^2 = \sqrt{(n-1)^{-1} \sum_{i=1}^n (x_i - \bar{x})^2}</span>
<span id="cb26-402"><a href="#cb26-402" aria-hidden="true" tabindex="-1"></a>$$ {#eq-sd-stimatore}</span>
<span id="cb26-403"><a href="#cb26-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-404"><a href="#cb26-404" aria-hidden="true" tabindex="-1"></a>Quando tutte le osservazioni sono uguali, $s = 0$, altrimenti $s &gt; 0$.</span>
<span id="cb26-405"><a href="#cb26-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-406"><a href="#cb26-406" aria-hidden="true" tabindex="-1"></a>Come nel caso della varianza, anche la deviazione standard $s$ dovrebbe essere usata soltanto quando la media è adeguata per descrivere il centro della distribuzione, ovvero, nel caso di distribuzioni simmetriche. Come nel caso della media $\bar{x}$, anche la deviazione standard è fortemente influenzata dai dati anomali, ovvero dalla presenza di uno o di pochi dati che sono molto più distanti dalla media rispetto agli altri valori della distribuzione.</span>
<span id="cb26-407"><a href="#cb26-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-408"><a href="#cb26-408" aria-hidden="true" tabindex="-1"></a>::: {#exr-sd-1}</span>
<span id="cb26-409"><a href="#cb26-409" aria-hidden="true" tabindex="-1"></a>Si calcoli la deviazione standard per i valori BDI-II del campione di @zetschefuture2019.</span>
<span id="cb26-410"><a href="#cb26-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-411"><a href="#cb26-411" aria-hidden="true" tabindex="-1"></a>Applicando l'@eq-sd-stimatore, per tutto il campione abbiamo</span>
<span id="cb26-412"><a href="#cb26-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-415"><a href="#cb26-415" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-416"><a href="#cb26-416" aria-hidden="true" tabindex="-1"></a>np.std(df.bdi)</span>
<span id="cb26-417"><a href="#cb26-417" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-418"><a href="#cb26-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-419"><a href="#cb26-419" aria-hidden="true" tabindex="-1"></a>Per ciascun gruppo, abbiamo:</span>
<span id="cb26-420"><a href="#cb26-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-423"><a href="#cb26-423" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-424"><a href="#cb26-424" aria-hidden="true" tabindex="-1"></a>df.groupby(<span class="st">'group'</span>)[<span class="st">'bdi'</span>].std()</span>
<span id="cb26-425"><a href="#cb26-425" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-426"><a href="#cb26-426" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-427"><a href="#cb26-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-428"><a href="#cb26-428" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Interpretazione</span></span>
<span id="cb26-429"><a href="#cb26-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-430"><a href="#cb26-430" aria-hidden="true" tabindex="-1"></a>Alla deviazione standard può essere assegnata una semplice interpretazione: la deviazione standard è *simile* (ma non identica) allo scarto semplice medio campionario, ovvero alla media aritmetica dei valori assoluti degli scarti dalla media. La deviazione standard ci dice, dunque, quanto sono distanti, in media, le singole osservazioni dal centro della distribuzione. Un'interpretazione più precisa del significato dello scarto tipo è fornita nel paragrafo successivo.</span>
<span id="cb26-431"><a href="#cb26-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-432"><a href="#cb26-432" aria-hidden="true" tabindex="-1"></a>::: {#exr-sd-2}</span>
<span id="cb26-433"><a href="#cb26-433" aria-hidden="true" tabindex="-1"></a>Si verifichi l'interpretazione della deviazione standard fornita sopra usando i valori BDI-II del campione di @zetschefuture2019.</span>
<span id="cb26-434"><a href="#cb26-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-435"><a href="#cb26-435" aria-hidden="true" tabindex="-1"></a>Per questi dati la deviazione standard è</span>
<span id="cb26-436"><a href="#cb26-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-439"><a href="#cb26-439" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-440"><a href="#cb26-440" aria-hidden="true" tabindex="-1"></a>np.std(df.bdi)</span>
<span id="cb26-441"><a href="#cb26-441" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-442"><a href="#cb26-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-443"><a href="#cb26-443" aria-hidden="true" tabindex="-1"></a>Lo scarto semplice medio campionario è</span>
<span id="cb26-444"><a href="#cb26-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-447"><a href="#cb26-447" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-448"><a href="#cb26-448" aria-hidden="true" tabindex="-1"></a>np.mean(np.<span class="bu">abs</span>(df.bdi <span class="op">-</span> np.mean(df.bdi)))</span>
<span id="cb26-449"><a href="#cb26-449" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-450"><a href="#cb26-450" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-451"><a href="#cb26-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-452"><a href="#cb26-452" aria-hidden="true" tabindex="-1"></a><span class="fu">### Deviazione mediana assoluta</span></span>
<span id="cb26-453"><a href="#cb26-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-454"><a href="#cb26-454" aria-hidden="true" tabindex="-1"></a>Una misura robusta della dispersione statistica di un campione è la *deviazione mediana assoluta* (*Median Absolute Deviation*, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana, ovvero:</span>
<span id="cb26-455"><a href="#cb26-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-456"><a href="#cb26-456" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-457"><a href="#cb26-457" aria-hidden="true" tabindex="-1"></a>{\displaystyle \operatorname {MAD} =\operatorname {median} \left(\ \left|X_{i}-\operatorname {median} (X)\right|\ \right)}</span>
<span id="cb26-458"><a href="#cb26-458" aria-hidden="true" tabindex="-1"></a>$$ {#eq-mad-def}</span>
<span id="cb26-459"><a href="#cb26-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-460"><a href="#cb26-460" aria-hidden="true" tabindex="-1"></a>Nel caso di una distribuzione dei dati unimodale simmetrica di forma campanulare (ovvero, normale) si ha che</span>
<span id="cb26-461"><a href="#cb26-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-462"><a href="#cb26-462" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-463"><a href="#cb26-463" aria-hidden="true" tabindex="-1"></a>{\displaystyle \text{deviazione standard} \approx 1.4826\ \operatorname {MAD} .\,}</span>
<span id="cb26-464"><a href="#cb26-464" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-465"><a href="#cb26-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-466"><a href="#cb26-466" aria-hidden="true" tabindex="-1"></a>Pertanto, solitamente i software restituiscono il valore MAD moltiplicato per una tale costante.</span>
<span id="cb26-467"><a href="#cb26-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-468"><a href="#cb26-468" aria-hidden="true" tabindex="-1"></a>::: {#exr-mad-1}</span>
<span id="cb26-469"><a href="#cb26-469" aria-hidden="true" tabindex="-1"></a>I dati di @zetschefuture2019 seguono una distribuzione bimodale, per cui il vincolo precedente non si applica. Verifichiamo dunque il principio precedente usando un campione di dati estratto da una popolazione normale.</span>
<span id="cb26-470"><a href="#cb26-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-473"><a href="#cb26-473" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-474"><a href="#cb26-474" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">100</span>, scale<span class="op">=</span><span class="dv">15</span>, size<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb26-475"><a href="#cb26-475" aria-hidden="true" tabindex="-1"></a><span class="fl">1.4826</span> <span class="op">*</span> np.median(np.<span class="bu">abs</span>(x <span class="op">-</span> np.median(x)))</span>
<span id="cb26-476"><a href="#cb26-476" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-477"><a href="#cb26-477" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-478"><a href="#cb26-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-479"><a href="#cb26-479" aria-hidden="true" tabindex="-1"></a><span class="fu">### Indici di variabilità relativi</span></span>
<span id="cb26-480"><a href="#cb26-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-481"><a href="#cb26-481" aria-hidden="true" tabindex="-1"></a>A volte può essere interessante effettuare un confronto fra due misure di variabilità di grandezze incommensurabili, ovvero di caratteri rilevati mediante differenti unità di misura. In questi casi, le misure di variabilità precedentemente descritte si rivelano inadeguate in quanto dipendono dall'unità di misura adottata. Diventa dunque necessario ricorrere a particolari numeri adimensionali detti *indici relativi di variabilità*. Il più importante di tali indici è il *coefficiente di variazione*, ovvero il numero puro</span>
<span id="cb26-482"><a href="#cb26-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-483"><a href="#cb26-483" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-484"><a href="#cb26-484" aria-hidden="true" tabindex="-1"></a>C_v = \frac{\sigma}{\bar{x}}</span>
<span id="cb26-485"><a href="#cb26-485" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cv-def}</span>
<span id="cb26-486"><a href="#cb26-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-487"><a href="#cb26-487" aria-hidden="true" tabindex="-1"></a>ottenuto dal rapporto tra la deviazione standard e la media dei dati.</span>
<span id="cb26-488"><a href="#cb26-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-489"><a href="#cb26-489" aria-hidden="true" tabindex="-1"></a>Un altro indice relativo di variabilità è la differenza interquartile rapportata al primo quartile, oppure al terzo quartile, oppure alla mediana, cioè:</span>
<span id="cb26-490"><a href="#cb26-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-491"><a href="#cb26-491" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-492"><a href="#cb26-492" aria-hidden="true" tabindex="-1"></a>\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \qquad \frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \qquad \frac{x_{0.75} - x_{0.25}}{x_{0.50}}.</span>
<span id="cb26-493"><a href="#cb26-493" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-494"><a href="#cb26-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-495"><a href="#cb26-495" aria-hidden="true" tabindex="-1"></a><span class="fu">## Commenti e considerazioni finali {.unnumbered}</span></span>
<span id="cb26-496"><a href="#cb26-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-497"><a href="#cb26-497" aria-hidden="true" tabindex="-1"></a>Le statistiche descrittive ci forniscono degli indici sintetici che riassumono i dati, ovvero le nostre misurazioni dell'intera popolazione o di un campione estratto da una popolazione. Le statistiche descrittive comprendono gli indici di tendenza centrale e gli indici di dispersione. Gli indici di tendenza centrale includono la media, la mediana e la moda, mentre gli indici di dispersione includono la deviazione standard, la varianza, la curtosi e l'asimmetria (questi ultimi due indici sono definiti in relazione alla distribuzione Normale e verranno dunque discussi in quel contesto).</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>